import re
import os
import json
from functools import lru_cache
from datetime import datetime

# --- é…ç½® ---

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
# åœ¨è¿™é‡Œæ’é™¤ä¸éœ€è¦ç»Ÿè®¡å’Œæ˜¾ç¤ºå¼•ç”¨ä¿¡æ¯çš„æ–‡ä»¶ï¼š
EXCLUDE_PATTERNS = [
    re.compile(r'^index\.md$'),
    re.compile(r'^about/'),
    re.compile(r'^trip/index\.md$'),
    re.compile(r'^relax/index\.md$'),
    re.compile(r'^blog/indexblog\.md$'),
    re.compile(r'^blog/posts\.md$'),
    re.compile(r'^develop/index\.md$'),
    re.compile(r'waline\.md$'),
    re.compile(r'link\.md$'),
    re.compile(r'404\.md$'),
]

# ä¼˜åŒ–çš„å­—ç¬¦ç»Ÿè®¡æ­£åˆ™è¡¨è¾¾å¼
CHINESE_CHARS_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
CODE_BLOCK_PATTERN = re.compile(r'```.*?```', re.DOTALL)

# é¢„å®šä¹‰æ’é™¤ç±»å‹
EXCLUDE_TYPES = frozenset({'landing', 'special', 'widget'})

# --- æ ¸å¿ƒå‡½æ•° ---

@lru_cache(maxsize=256)
def extract_non_code_content(content_hash, markdown):
    """æå–ä¸åœ¨ä»£ç å—ä¸­çš„å†…å®¹"""
    content = CODE_BLOCK_PATTERN.sub('', markdown)
    return content

def count_code_lines(markdown):
    """ç»Ÿè®¡ä»£ç è¡Œæ•° - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªè®¡ç®—ä»£ç å—ä¸­çš„è¡Œæ•°"""
    code_blocks = CODE_BLOCK_PATTERN.findall(markdown)
    total_code_lines = 0
    for block in code_blocks:
        lines = block.split('\n')
        code_lines = [
            line for line in lines 
            if not line.strip().startswith('```') and line.strip()
        ]
        total_code_lines += len(code_lines)
    return total_code_lines

def calculate_reading_stats(markdown):
    """è®¡ç®—ä¸­æ–‡å­—ç¬¦æ•°å’Œä»£ç è¡Œæ•°"""
    content_hash = hash(markdown)
    non_code_content = extract_non_code_content(content_hash, markdown)
    chinese_chars = len(CHINESE_CHARS_PATTERN.findall(non_code_content))
    code_lines = count_code_lines(markdown)
    reading_time = max(1, round(chinese_chars / 200))
    return reading_time, chinese_chars, code_lines

@lru_cache(maxsize=1)
def load_timestamps(docs_dir):
    """åŠ è½½å¹¶ç¼“å­˜ timestamps.json æ–‡ä»¶ï¼Œé¿å…é‡å¤è¯»å–"""
    timestamps_path = os.path.join(docs_dir, 'timestamps.json')
    if not os.path.exists(timestamps_path):
        print(f"Warning: timestamps.json not found at {timestamps_path}")
        return None
    try:
        with open(timestamps_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading or parsing timestamps.json: {e}")
        return None

def get_git_revision_date(page, config):
    """ä» timestamps.json è·å–æ–‡ä»¶çš„æœ€å Git æäº¤æ—¶é—´"""
    docs_dir = config['docs_dir']
    relative_path_key = page.file.src_path.replace(os.path.sep, '/')
    
    timestamps = load_timestamps(docs_dir)
    if timestamps and relative_path_key in timestamps:
        timestamp_value = timestamps[relative_path_key]
        return datetime.fromtimestamp(timestamp_value)
        
    return None

def get_file_modification_time(page, config):
    """è·å–æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´ï¼Œä¼˜å…ˆä½¿ç”¨ Git æ—¶é—´"""
    last_modified = get_git_revision_date(page, config)
    
    if not last_modified:
        # å¦‚æœ Git æ—¶é—´æˆ³æ‰¾ä¸åˆ°ï¼Œæ‰å›é€€åˆ°æ–‡ä»¶ç³»ç»Ÿæ—¶é—´
        file_path = page.file.abs_src_path
        if os.path.exists(file_path):
            mtime = os.path.getmtime(file_path)
            last_modified = datetime.fromtimestamp(mtime)

    # å¦‚æœä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œæä¾›ä¸€ä¸ªé»˜è®¤å€¼ï¼ˆå½“å‰æ—¶é—´ï¼‰
    if not last_modified:
        last_modified = datetime.now()
        
    return last_modified, bool(last_modified)

def generate_citation(page, config):
    """ç”Ÿæˆå¼•ç”¨æŒ‡å¼•"""
    title = page.meta.get('title', page.title)
    author = 'Yan Li'
    
    mod_time, _ = get_file_modification_time(page, config)
    
    year = mod_time.year
    month_en = mod_time.strftime('%b')
    day = mod_time.day
    date_display = f"{month_en}. {day}, {year}"
    
    site_url = config.get('site_url', 'https://example.com').rstrip('/')
    page_url = page.url.rstrip('/')
    full_url = f"{site_url}/{page_url}"
    
    page_id = page_url.split('/')[-1] or 'index'
    
    citation = f"""
!!! info "ğŸ“ å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡"
    {author}. ({date_display}). {title} [Blog post]. Retrieved from {full_url}

    åœ¨ BibTeX æ ¼å¼ä¸­ï¼š
    ```text
    @online{{{page_id},
        title={{{title}}},
        author={{{author}}},
        year={{{year}}},
        month={{{month_en}}},
        url={{\\url{{{full_url}}}}},
    }}
    ```
"""
    return citation

# --- MkDocs Hook å‡½æ•° ---

def on_page_markdown(markdown, *, page, config, **kwargs):
    """
    åœ¨æ¯ä¸ª Markdown é¡µé¢æ¸²æŸ“å‰æ‰§è¡Œæ­¤å‡½æ•°ã€‚
    """
    # å¿«é€Ÿæ’é™¤æ£€æŸ¥
    if page.meta.get('hide_reading_time', False):
        return markdown
    
    src_path = page.file.src_path
    if any(pattern.match(src_path) for pattern in EXCLUDE_PATTERNS):
        return markdown
    
    page_type = page.meta.get('type', '')
    if page_type in EXCLUDE_TYPES:
        return markdown
    
    # å¿«é€Ÿé¢„æ£€æŸ¥ï¼Œé¿å…å¯¹éå¸¸çŸ­çš„æ–‡ä»¶è¿›è¡Œå¤æ‚è®¡ç®—
    if len(markdown) < 300:
        # å³ä½¿å†…å®¹çŸ­ï¼Œä¹Ÿå¯èƒ½éœ€è¦æ·»åŠ å¼•ç”¨
        if not page.meta.get('hide_citation', False):
            citation = generate_citation(page, config)
            return markdown + citation
        return markdown

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    reading_time, chinese_chars, code_lines = calculate_reading_stats(markdown)
    
    # å¦‚æœä¸­æ–‡å­—ç¬¦è¿‡å°‘ï¼Œåˆ™ä¸æ˜¾ç¤ºé˜…è¯»ä¿¡æ¯ï¼Œä½†å¯èƒ½ä»æ˜¾ç¤ºå¼•ç”¨
    if chinese_chars < 50:
        if not page.meta.get('hide_citation', False):
            citation = generate_citation(page, config)
            return markdown + citation
        return markdown
        
    # --- æ„å»ºä¿¡æ¯å— ---
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ›ä½œå£°æ˜å’Œæ˜¯å¦éšè—ä¿¡æ¯
    creation_statement = page.meta.get('statement', '')
    no_info = page.meta.get('noinfo', False)

    reading_info_parts = [
        f"é˜…è¯»æ—¶é—´çº¦ **{reading_time}** åˆ†é’Ÿ",
        f"çº¦ **{chinese_chars}** å­—"
    ]
    if chinese_chars > 10000:
        reading_info_parts.append("âš ï¸ ä¸‡å­—é•¿æ–‡ï¼Œè¯·æ…¢æ…¢é˜…è¯»")
    if code_lines > 0:
        reading_info_parts.append(f"çº¦ **{code_lines}** è¡Œä»£ç ")
    else:
        reading_info_parts.append("æ²¡æœ‰ä»£ç ï¼Œè¯·æ”¾å¿ƒé£Ÿç”¨")

    reading_info_content = "ã€€|ã€€".join(reading_info_parts)
    reading_info = f'!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯"\n    {reading_info_content}\n\n'

    if creation_statement:
        reading_info += f"    åˆ›ä½œå£°æ˜ï¼š{creation_statement}\n\n"

    if no_info:
        reading_info = ""

    # --- æ’å…¥ä¿¡æ¯å—åˆ° Markdown ---
    
    # ç”¨æ­£åˆ™æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼Œå¹¶åœ¨å…¶åæ’å…¥é˜…è¯»ä¿¡æ¯
    h1_pattern = re.compile(r'(^# .*\n)', re.MULTILINE)
    if h1_pattern.search(markdown):
        markdown = h1_pattern.sub(r'\1' + reading_info, markdown, count=1)
    else:
        # æ²¡æœ‰ä¸€çº§æ ‡é¢˜å°±æ’åœ¨æœ€å‰é¢
        markdown = reading_info + markdown
    
    # --- æ·»åŠ å¼•ç”¨æŒ‡å¼• ---
    
    if not page.meta.get('hide_citation', False):
        citation = generate_citation(page, config)
        markdown += citation
    
    return markdown