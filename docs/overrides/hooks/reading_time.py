import re
import os
from functools import lru_cache
from datetime import datetime

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
# åœ¨è¿™é‡Œæ’é™¤ä¸éœ€è¦ç»Ÿè®¡çš„æ–‡ä»¶ï¼š
EXCLUDE_PATTERNS = [
    re.compile(r'^index\.md$'),
    re.compile(r'^about/'),
    re.compile(r'^trip/index\.md$'),
    re.compile(r'^relax/index\.md$'),
    re.compile(r'^blog/indexblog\.md$'),
    re.compile(r'^blog/posts\.md$'),
    re.compile(r'^develop/index\.md$'),
    re.compile(r'waline\.md$'),
    re.compile(r'link\.md$'),
    re.compile(r'404\.md$'),
]

# ä¼˜åŒ–çš„å­—ç¬¦ç»Ÿè®¡æ­£åˆ™è¡¨è¾¾å¼
CHINESE_CHARS_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
CODE_BLOCK_PATTERN = re.compile(r'```.*?```', re.DOTALL)

# é¢„å®šä¹‰æ’é™¤ç±»å‹
EXCLUDE_TYPES = frozenset({'landing', 'special', 'widget'})

@lru_cache(maxsize=256)
def extract_non_code_content(content_hash, markdown):
    """æå–ä¸åœ¨ä»£ç å—ä¸­çš„å†…å®¹"""
    # ç§»é™¤æ‰€æœ‰ä»£ç å—
    content = CODE_BLOCK_PATTERN.sub('', markdown)
    return content

def count_code_lines(markdown):
    """ç»Ÿè®¡ä»£ç è¡Œæ•° - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªè®¡ç®—ä»£ç å—ä¸­çš„è¡Œæ•°"""
    code_blocks = CODE_BLOCK_PATTERN.findall(markdown)
    total_code_lines = 0
    
    for block in code_blocks:
        # ç§»é™¤ä»£ç å—çš„æ ‡è®°è¡Œï¼ˆå¼€å¤´å’Œç»“å°¾çš„```ï¼‰
        lines = block.split('\n')
        
        # è¿‡æ»¤æ‰ä»£ç å—æ ‡è®°è¡Œå’Œç©ºè¡Œ
        code_lines = [
            line for line in lines 
            if not line.strip().startswith('```') and line.strip()
        ]
        
        total_code_lines += len(code_lines)
    
    return total_code_lines

def calculate_reading_stats(markdown):
    """è®¡ç®—ä¸­æ–‡å­—ç¬¦æ•°å’Œä»£ç è¡Œæ•°"""
    # ç”Ÿæˆå†…å®¹å“ˆå¸Œç”¨äºç¼“å­˜
    content_hash = hash(markdown)
    
    # æå–ä¸åœ¨ä»£ç å—ä¸­çš„å†…å®¹
    non_code_content = extract_non_code_content(content_hash, markdown)
    
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆä¸åœ¨ä»£ç å—ä¸­çš„ï¼‰
    chinese_chars = len(CHINESE_CHARS_PATTERN.findall(non_code_content))
    
    # ç»Ÿè®¡ä»£ç è¡Œæ•°
    code_lines = count_code_lines(markdown)
    
    # è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆä¸­æ–‡ï¼š200å­—/åˆ†é’Ÿï¼‰
    reading_time = max(1, round(chinese_chars / 200))
    
    return reading_time, chinese_chars, code_lines

def get_file_modification_time(file_path):
    """è·å–æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´"""
    try:
        # è·å–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
        mod_time = os.path.getmtime(file_path)
        # è½¬æ¢ä¸ºdatetimeå¯¹è±¡
        return datetime.fromtimestamp(mod_time)
    except (OSError, FileNotFoundError):
        # å¦‚æœæ— æ³•è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼Œè¿”å›å½“å‰æ—¶é—´
        return datetime.now()

def generate_citation(page, config):
    """ç”Ÿæˆå¼•ç”¨æŒ‡å¼•"""
    # è·å–é¡µé¢å…ƒæ•°æ®
    title = page.meta.get('title', page.title)
    author = 'Dicaeopolis'
    
    # è·å–æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    file_path = page.file.abs_src_path
    
    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
    mod_time = get_file_modification_time(file_path)
    
    # å¤„ç†æ—¥æœŸ
    year = mod_time.year
    month_en = mod_time.strftime('%b')
    month_cn = mod_time.strftime('%-m')  # ä¸­æ–‡æ ¼å¼çš„æœˆä»½ï¼ˆä¸å¸¦å‰å¯¼é›¶ï¼‰
    day = mod_time.day
    date_display = f"{year}å¹´{month_cn}æœˆ{day}æ—¥"
    
    # è·å–é¡µé¢URL
    site_url = 'https://dicaeopolis.github.io'.rstrip('/')
    page_url = page.url.rstrip('/')
    full_url = f"{site_url}{page_url}"
    
    # ç”Ÿæˆé¡µé¢æ ‡è¯†ç¬¦ï¼ˆä½¿ç”¨URLçš„æœ€åä¸€éƒ¨åˆ†ï¼‰
    page_id = page_url.split('/')[-1] or 'index'
    
    # ç”Ÿæˆå¼•ç”¨æ–‡æœ¬
    citation = f"""
!!! info "ğŸ“ å¼•ç”¨"
    å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡ï¼Œè¯·å‚è€ƒï¼š

    {author}. ({date_display}). ã€Š{title}ã€‹[Blog post]. Retrieved from {full_url}

    @online{{{page_id},
        title={{{title}}},
        author={{{author}}},
        year={{{year}}},
        month={{{month_en}}},
        url={{\\url{{{full_url}}}}},
    }}
"""
    return citation

def on_page_markdown(markdown, **kwargs):
    page = kwargs['page']
    config = kwargs['config']
    
    # å¿«é€Ÿæ’é™¤æ£€æŸ¥
    if page.meta.get('hide_reading_time', False):
        return markdown
    
    # ä¿æŒåŸæœ‰çš„EXCLUDE_PATTERNSå¾ªç¯æ£€æŸ¥æ–¹å¼
    src_path = page.file.src_path
    for pattern in EXCLUDE_PATTERNS:
        if pattern.match(src_path):
            return markdown
    
    # ä¼˜åŒ–ç±»å‹æ£€æŸ¥
    page_type = page.meta.get('type', '')
    if page_type in EXCLUDE_TYPES:
        return markdown
    
    # å¿«é€Ÿé¢„æ£€æŸ¥
    if len(markdown) < 300:
        return markdown
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    reading_time, chinese_chars, code_lines = calculate_reading_stats(markdown)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ›ä½œå£°æ˜
    creation_statement = page.meta.get('my_creation_statement', '')
    
    # ç”Ÿæˆé˜…è¯»ä¿¡æ¯
    reading_info = f"""!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯"
    é˜…è¯»æ—¶é—´çº¦ **{reading_time}** åˆ†é’Ÿã€€|ã€€çº¦ **{chinese_chars}** å­—"""
    
    if chinese_chars > 10000:
        reading_info += f"""ã€€âš ï¸ ä¸‡å­—é•¿æ–‡ï¼Œè¯·æ…¢æ…¢é˜…è¯»"""

    if code_lines > 0:
        reading_info += f"""ã€€|ã€€çº¦ **{code_lines}** è¡Œä»£ç 

"""
    else:
        reading_info += f"""ã€€|ã€€æ²¡æœ‰ä»£ç ï¼Œè¯·æ”¾å¿ƒé£Ÿç”¨

"""
    
    # å¦‚æœæœ‰åˆ›ä½œå£°æ˜ï¼Œæ·»åŠ åˆ°é˜…è¯»ä¿¡æ¯ä¸‹æ–¹
    if creation_statement:
        reading_info += f"    åˆ›ä½œå£°æ˜ï¼š{creation_statement}\n\n"

    # ç”¨æ­£åˆ™æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼Œå¹¶åœ¨å…¶åæ’å…¥é˜…è¯»ä¿¡æ¯
    pattern = r'(^# .*\n)'
    if re.search(pattern, markdown, flags=re.MULTILINE):
        markdown = re.sub(pattern, r'\1' + reading_info, markdown, count=1, flags=re.MULTILINE)
    else:
        # æ²¡æœ‰ä¸€çº§æ ‡é¢˜å°±æ’åœ¨æœ€å‰é¢
        markdown = reading_info + markdown
    
    # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹ - ç°åœ¨æ”¾åœ¨åé¢ï¼Œå› ä¸ºå³ä½¿å†…å®¹çŸ­ä¹Ÿè¦æ·»åŠ å¼•ç”¨
    if chinese_chars < 50:
        return markdown
    
    # ç”Ÿæˆå¹¶æ·»åŠ å¼•ç”¨æŒ‡å¼•ï¼ˆé™¤éæ˜ç¡®éšè—ï¼‰
    if not page.meta.get('hide_citation', False):
        citation = generate_citation(page, config)
        markdown += citation
    
    return markdown