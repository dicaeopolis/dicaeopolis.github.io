import re
import os
import json
from functools import lru_cache
from datetime import datetime

# --- è°ƒè¯•å¼€å…³ ---
# è¿™ä¸ªå…¨å±€å˜é‡ç¡®ä¿æˆ‘ä»¬åªæ‰“å°ä¸€æ¬¡æ‰€æœ‰å¯ç”¨çš„é”®ï¼Œé¿å…åˆ·å±
_TIMESTAMP_KEYS_PRINTED = False

# --- é…ç½® ---

# ... (æ‚¨çš„ EXCLUDE_PATTERNS, CHINESE_CHARS_PATTERN ç­‰é…ç½®ä¿æŒä¸å˜)
EXCLUDE_PATTERNS = [re.compile(r'^index\.md$'), re.compile(r'^about/'), re.compile(r'^trip/index\.md$'), re.compile(r'^relax/index\.md$'), re.compile(r'^blog/indexblog\.md$'), re.compile(r'^blog/posts\.md$'), re.compile(r'^develop/index\.md$'), re.compile(r'waline\.md$'), re.compile(r'link\.md$'), re.compile(r'404\.md$')]
CHINESE_CHARS_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
CODE_BLOCK_PATTERN = re.compile(r'```.*?```', re.DOTALL)
EXCLUDE_TYPES = frozenset({'landing', 'special', 'widget'})


# --- æ ¸å¿ƒå‡½æ•° (å…¶ä»–å‡½æ•°ä¿æŒä¸å˜) ---
@lru_cache(maxsize=256)
def extract_non_code_content(content_hash, markdown):
    return CODE_BLOCK_PATTERN.sub('', markdown)

def count_code_lines(markdown):
    code_blocks = CODE_BLOCK_PATTERN.findall(markdown)
    total_code_lines = 0
    for block in code_blocks:
        lines = block.split('\n')
        code_lines = [line for line in lines if not line.strip().startswith('```') and line.strip()]
        total_code_lines += len(code_lines)
    return total_code_lines

def calculate_reading_stats(markdown):
    content_hash = hash(markdown)
    non_code_content = extract_non_code_content(content_hash, markdown)
    chinese_chars = len(CHINESE_CHARS_PATTERN.findall(non_code_content))
    code_lines = count_code_lines(markdown)
    reading_time = max(1, round(chinese_chars / 200))
    return reading_time, chinese_chars, code_lines

@lru_cache(maxsize=1)
def load_timestamps(docs_dir):
    timestamps_path = os.path.join(docs_dir, 'timestamps.json')
    if not os.path.exists(timestamps_path):
        print(f"DEBUG: timestamps.json not found at {timestamps_path}")
        return None
    try:
        with open(timestamps_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"DEBUG: Error loading or parsing timestamps.json: {e}")
        return None

# ###############################################################
# #                  â†“ â†“ â†“ è¿™æ˜¯è¦æ›¿æ¢çš„å…³é”®å‡½æ•° â†“ â†“ â†“                #
# ###############################################################

def get_git_revision_date(page, config):
    """
    ã€è°ƒè¯•ç‰ˆæœ¬ã€‘è·å–æ–‡ä»¶çš„æœ€å Git æäº¤æ—¶é—´
    """
    global _TIMESTAMP_KEYS_PRINTED
    from datetime import datetime

    print("\n--- [DEBUG] Entering get_git_revision_date ---")

    # 1. æ‰“å°æˆ‘ä»¬ç”¨æ¥æŸ¥æ‰¾çš„ KEY æ˜¯ä»€ä¹ˆ
    relative_path_key = page.file.src_path.replace(os.path.sep, '/')
    print(f"[*] Page being processed: '{page.title}' (from file: {page.file.src_path})")
    print(f"[*] Generated lookup KEY: '{relative_path_key}'")

    # 2. æ‰“å°æˆ‘ä»¬æŸ¥æ‰¾çš„ JSON æ–‡ä»¶åœ¨å“ªé‡Œ
    docs_dir = config['docs_dir']
    timestamps_path = os.path.join(docs_dir, 'timestamps.json')
    print(f"[*] Path to timestamps.json: '{timestamps_path}'")

    # 3. åŠ è½½æ•°æ®
    timestamps = load_timestamps(docs_dir)
    if timestamps is None:
        print("[!] FAILURE: timestamps.json could not be loaded. Aborting lookup.")
        print("--- [DEBUG] Exiting ---\n")
        return None

    # 4. æ‰“å° JSON æ–‡ä»¶ä¸­æ‰€æœ‰å¯ç”¨çš„ KEY (åªæ‰“å°ä¸€æ¬¡)
    if not _TIMESTAMP_KEYS_PRINTED:
        print("[*] All available KEYS in timestamps.json (first 20 shown):")
        import pprint
        # åªæ˜¾ç¤ºå‰20ä¸ªï¼Œé¿å…åˆ·å±
        pprint.pprint(sorted(list(timestamps.keys()))[:20])
        print(f"    ... (total {len(timestamps.keys())} keys)")
        _TIMESTAMP_KEYS_PRINTED = True

    # 5. è¿›è¡ŒæŸ¥æ‰¾å¹¶æŠ¥å‘Šç»“æœ
    if relative_path_key in timestamps:
        timestamp_value = timestamps[relative_path_key]
        print(f"[+] SUCCESS: Key '{relative_path_key}' found!")
        print("--- [DEBUG] Exiting ---\n")
        return datetime.fromtimestamp(timestamp_value)
    else:
        print(f"[!] FAILURE: Key '{relative_path_key}' was NOT FOUND in the available keys.")
        print("--- [DEBUG] Exiting ---\n")
        return None

# ###############################################################
# #                  â†‘ â†‘ â†‘ å…³é”®å‡½æ•°ç»“æŸ â†‘ â†‘ â†‘                     #
# ###############################################################

def get_file_modification_time(page, config):
    last_modified = get_git_revision_date(page, config)
    if not last_modified:
        file_path = page.file.abs_src_path
        if os.path.exists(file_path):
            mtime = os.path.getmtime(file_path)
            last_modified = datetime.fromtimestamp(mtime)
    if not last_modified:
        last_modified = datetime.now()
    return last_modified, bool(last_modified)

def generate_citation(page, config):
    title = page.meta.get('title', page.title)
    author = 'Yan Li'
    mod_time, _ = get_file_modification_time(page, config)
    year = mod_time.year
    month_en = mod_time.strftime('%b')
    day = mod_time.day
    date_display = f"{month_en}. {day}, {year}"
    site_url = config.get('site_url', 'https://example.com').rstrip('/')
    page_url = page.url.rstrip('/')
    full_url = f"{site_url}/{page_url}"
    page_id = page_url.split('/')[-1] or 'index'
    citation = f"""
!!! info "ğŸ“ å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡"
    {author}. ({date_display}). {title} [Blog post]. Retrieved from {full_url}

    åœ¨ BibTeX æ ¼å¼ä¸­ï¼š
    ```text
    @online{{{page_id},
        title={{{title}}},
        author={{{author}}},
        year={{{year}}},
        month={{{month_en}}},
        url={{\\url{{{full_url}}}}},
    }}
    ```
"""
    return citation

def on_page_markdown(markdown, *, page, config, **kwargs):
    # ... è¿™ä¸ªå‡½æ•°ä¿æŒä¸å˜ ...
    if page.meta.get('hide_reading_time', False): return markdown
    src_path = page.file.src_path
    if any(pattern.match(src_path) for pattern in EXCLUDE_PATTERNS): return markdown
    page_type = page.meta.get('type', '')
    if page_type in EXCLUDE_TYPES: return markdown
    if len(markdown) < 300:
        if not page.meta.get('hide_citation', False):
            return markdown + generate_citation(page, config)
        return markdown
    reading_time, chinese_chars, code_lines = calculate_reading_stats(markdown)
    if chinese_chars < 50:
        if not page.meta.get('hide_citation', False):
            return markdown + generate_citation(page, config)
        return markdown
    creation_statement = page.meta.get('statement', '')
    no_info = page.meta.get('noinfo', False)
    reading_info_parts = [f"é˜…è¯»æ—¶é—´çº¦ **{reading_time}** åˆ†é’Ÿ", f"çº¦ **{chinese_chars}** å­—"]
    if chinese_chars > 10000: reading_info_parts.append("âš ï¸ ä¸‡å­—é•¿æ–‡ï¼Œè¯·æ…¢æ…¢é˜…è¯»")
    if code_lines > 0: reading_info_parts.append(f"çº¦ **{code_lines}** è¡Œä»£ç ")
    else: reading_info_parts.append("æ²¡æœ‰ä»£ç ï¼Œè¯·æ”¾å¿ƒé£Ÿç”¨")
    reading_info_content = "ã€€|ã€€".join(reading_info_parts)
    reading_info = f'!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯"\n    {reading_info_content}\n\n'
    if creation_statement: reading_info += f"    åˆ›ä½œå£°æ˜ï¼š{creation_statement}\n\n"
    if no_info: reading_info = ""
    h1_pattern = re.compile(r'(^# .*\n)', re.MULTILINE)
    if h1_pattern.search(markdown): markdown = h1_pattern.sub(r'\1' + reading_info, markdown, count=1)
    else: markdown = reading_info + markdown
    if not page.meta.get('hide_citation', False): markdown += generate_citation(page, config)
    return markdown