import re
from functools import lru_cache

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
# åœ¨è¿™é‡Œæ’é™¤ä¸éœ€è¦ç»Ÿè®¡çš„æ–‡ä»¶ï¼š
EXCLUDE_PATTERNS = [
    re.compile(r'^index\.md$'),
    re.compile(r'^about/'),
    re.compile(r'^trip/index\.md$'),
    re.compile(r'^relax/index\.md$'),
    re.compile(r'^blog/indexblog\.md$'),
    re.compile(r'^blog/posts\.md$'),
    re.compile(r'^develop/index\.md$'),
    re.compile(r'waline\.md$'),
    re.compile(r'link\.md$'),
    re.compile(r'404\.md$'),
]

# ä¼˜åŒ–çš„å­—ç¬¦ç»Ÿè®¡æ­£åˆ™è¡¨è¾¾å¼
CHINESE_CHARS_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
CODE_BLOCK_PATTERN = re.compile(r'```.*?```', re.DOTALL)

# é¢„å®šä¹‰æ’é™¤ç±»å‹
EXCLUDE_TYPES = frozenset({'landing', 'special', 'widget'})

@lru_cache(maxsize=256)
def extract_non_code_content(content_hash, markdown):
    """æå–ä¸åœ¨ä»£ç å—ä¸­çš„å†…å®¹"""
    # ç§»é™¤æ‰€æœ‰ä»£ç å—
    content = CODE_BLOCK_PATTERN.sub('', markdown)
    return content

def count_code_lines(markdown):
    """ç»Ÿè®¡ä»£ç è¡Œæ•° - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªè®¡ç®—ä»£ç å—ä¸­çš„è¡Œæ•°"""
    code_blocks = CODE_BLOCK_PATTERN.findall(markdown)
    total_code_lines = 0
    
    for block in code_blocks:
        # ç§»é™¤ä»£ç å—çš„æ ‡è®°è¡Œï¼ˆå¼€å¤´å’Œç»“å°¾çš„```ï¼‰
        lines = block.split('\n')
        
        # è¿‡æ»¤æ‰ä»£ç å—æ ‡è®°è¡Œå’Œç©ºè¡Œ
        code_lines = [
            line for line in lines 
            if not line.strip().startswith('```') and line.strip()
        ]
        
        total_code_lines += len(code_lines)
    
    return total_code_lines

def calculate_reading_stats(markdown):
    """è®¡ç®—ä¸­æ–‡å­—ç¬¦æ•°å’Œä»£ç è¡Œæ•°"""
    # ç”Ÿæˆå†…å®¹å“ˆå¸Œç”¨äºç¼“å­˜
    content_hash = hash(markdown)
    
    # æå–ä¸åœ¨ä»£ç å—ä¸­çš„å†…å®¹
    non_code_content = extract_non_code_content(content_hash, markdown)
    
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆä¸åœ¨ä»£ç å—ä¸­çš„ï¼‰
    chinese_chars = len(CHINESE_CHARS_PATTERN.findall(non_code_content))
    
    # ç»Ÿè®¡ä»£ç è¡Œæ•°
    code_lines = count_code_lines(markdown)
    
    # è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆä¸­æ–‡ï¼š200å­—/åˆ†é’Ÿï¼‰
    reading_time = max(1, round(chinese_chars / 200))
    
    return reading_time, chinese_chars, code_lines

def on_page_markdown(markdown, **kwargs):
    page = kwargs['page']
    
    # å¿«é€Ÿæ’é™¤æ£€æŸ¥
    if page.meta.get('hide_reading_time', False):
        return markdown
    
    # ä¿æŒåŸæœ‰çš„EXCLUDE_PATTERNSå¾ªç¯æ£€æŸ¥æ–¹å¼
    src_path = page.file.src_path
    for pattern in EXCLUDE_PATTERNS:
        if pattern.match(src_path):
            return markdown
    
    # ä¼˜åŒ–ç±»å‹æ£€æŸ¥
    page_type = page.meta.get('type', '')
    if page_type in EXCLUDE_TYPES:
        return markdown
    
    # å¿«é€Ÿé¢„æ£€æŸ¥
    if len(markdown) < 300:
        return markdown
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    reading_time, chinese_chars, code_lines = calculate_reading_stats(markdown)
    
    # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
    if chinese_chars < 50:
        return markdown
    
    # ç”Ÿæˆé˜…è¯»ä¿¡æ¯
    
    reading_info = f"""!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯"
é˜…è¯»æ—¶é—´çº¦ **{reading_time}** åˆ†é’Ÿã€€|ã€€çº¦ **{chinese_chars}** å­—"""
    
    if chinese_chars > 10000:
        reading_info += f"""ã€€âš ï¸âš ï¸âš ï¸ä¸‡å­—é•¿æ–‡ï¼Œè¯·æ…¢æ…¢é˜…è¯»"""

    if code_lines > 0:
        reading_info += f"""ã€€|ã€€çº¦ **{code_lines}** è¡Œä»£ç 

"""
    else:
        reading_info += f"""ã€€|ã€€æ²¡æœ‰ä»£ç ï¼Œè¯·æ”¾å¿ƒé£Ÿç”¨

"""

    # ç”¨æ­£åˆ™æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼Œå¹¶åœ¨å…¶åæ’å…¥é˜…è¯»ä¿¡æ¯
    pattern = r'(^# .*\n)'
    if re.search(pattern, markdown, flags=re.MULTILINE):
        markdown = re.sub(pattern, r'\1' + reading_info, markdown, count=1, flags=re.MULTILINE)
        return markdown
    else:
        # æ²¡æœ‰ä¸€çº§æ ‡é¢˜å°±æ’åœ¨æœ€å‰é¢
        return reading_info + markdown