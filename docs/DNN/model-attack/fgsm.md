# FGSM 攻击

[文章](https://arxiv.org/abs/1412.6572) 发表在 ICLR 2015，作者是 GAN 的提出者 Ian Goodfellow。

本文的行文思路肯定和原论文不一样，要不然白写了……而且我觉得原论文蛮像那种知乎专栏文章，挺好读的，以前的 ICLR 这么好发吗😱😱😱

## 攻击方式

FGSM 攻击是一种**白盒攻击**，必须拿到模型对输入的梯度，也就是

$$
g_x=\nabla_x \mathcal L(\theta;x)
$$

这里很微妙的一点是，在优化器领域，我们是基于计算

$$
g_\theta=\nabla_\theta \mathcal L(\theta;x)
$$

来实现对参数的快速更新的。这里的“快速”意即利用尽可能少的迭代次数得到尽可能小的损失，即让模型参数 $\theta$ 在固定的输入 $x$ 构建的损失地形上实现快速下降。

FGSM 也是类似，不过此时我们面对一个训练好的（固定的）模型 $\theta$，需要构建 $x$ 来更改输出。此时我们的目标是**利用尽可能少的迭代次数得到尽可能大的损失**。当然迭代法会在后面介绍，FGSM 作为一种古老的攻击方法，是**单步**的。

一个相当朴素的思路是，我们在单步内**直接选取梯度变化最大的那个方向进行上升**，也就是：

$$
\tilde x_{L_2}=x+\epsilon g_x
$$

这里的 $\epsilon$ 可以类比于学习率。

如果对现代优化器理论比较熟悉的话，可能会考虑 Adam 优化器对应的 signSGD，或者是 Muon 的 $\mathrm{msign}(M)=UV^\top$，但它们更多依赖于**更广阔的损失地形视野**，或许在单步下没那么有效？换句话说，我们对梯度其实有三种比较经典的约束形式：

$$
\begin{align*}
    \tilde x_{L_2}&=x+\epsilon g_x\\
    \tilde x_{L_\infty}&=x+\epsilon \mathrm{sign}(g_x)\\
    \tilde x_{L_\mathrm{spec}}&=x+\epsilon \mathrm{msign}(g_x)
\end{align*}
$$

这里选择 $L_2$ 范数作为约束只是因为比较“经典”，其实也可以拿着 $L_p$ 范数来说事的。

我个人更倾向于把它们叫做**不同范数约束下的 FGSM 攻击**，尽管 FGSM 全称是 Fast Gradient **Sign** Method……

到底选择哪个范数进行约束，我们放在后面讲。下面一节我们来聊聊这一攻击方式的另外一种看待视角。

## 线性角度

这个视角是原论文的第三节给出来的。由于深层神经网络依赖矩阵乘法，因此考虑矩阵某一列 $w^\top$ 和扰动后的输入 $\tilde x=x+\eta$ 相乘：

$$
w^\top\tilde x=w^\top x+w^\top\eta
$$

那你问我 $\eta$ 取哪个方向可以使得扰动项最大化呢？这不就是高中大家都学过的**柯西不等式**嘛——如果扰动项和 $w$ “平行”的时候能够最大化。

这里的平行要打引号，因为严格意义上说它的意思是要让下面的等号取到：

$$
|\langle u,v\rangle|\le\|u\|\cdot\|v\|
$$

而不同的内积又为空间赋予了不同的范数。

好，我们似乎就可以得到：取矩阵元素乘以 $\epsilon$，然后考虑一下内积约束，就可以了……对吗？

大错特错！谁告诉你，**深度神经网络就是线性的矩阵乘法的**？！

正是引入了非线性，神经网络才具有丰富的拟合能力哦。

事实上，原论文这一段的意思是，**如果神经网络在样本附近近似线性，那么它可以被相当高效地扰动**！

为什么呢？我们来估算一下 $w^\top\eta$。假定 $w\sim\mathcal{N}(0,I_n)$，$\eta=\epsilon w$，那么这个点乘的结果就是 $\epsilon n\mathrm{Var}[w_i]=\epsilon n$，也就是说维度越高，即使保持一个比较小的 $\epsilon$，也可以积累起很大的扰动。

P.S. 这里我要 diss 一下原论文这一节里面这句话：

> If $w$ has $n$ dimensions and the average magnitude of an element of the weight vector is $m$, then the activation will grow by $\epsilon mn$.

这里是拿 $\eta=\mathrm{sign}(w)$ 算的，但是按理说一个降维映射的中间层，其参数大小分布理应近似服从正态分布的，这里取符号函数相当于把大于零的部分挑出来单独求和，不能直接拿均值算的……

这也就导致了基于 ReLU 的浅层神经网络相当容易被攻击，而基于 sigmoid 的神经网络呢？嘿嘿想逃是逃不掉的——为了防止梯度消失，你在训练的时候就要把权重压到 0 附近，这正是 sigmoid 近似线性的地方。

## 范数选择

这一节我们来讨论一下为什么这个方法叫 FGSM 而不是 FGM 或者其他，也就是为什么原作者要选择使用**符号函数**。

这里我在 MNIST 上训练了一个 LeNet 来可视化一下。（原论文还使用了更大规模的数据集如 CIFAR-10 和 ImageNet 等，我这边为了方便就直接在笔记本上面跑咯）

训练的参数是：学习率 5e-4 跑 5 个 epoch，无任何数据增强，训练集准确率 0.9756，测试集准确率 0.9775。

如下，是使用 $L_\infty$ 范数约束的结果：

![alt text](image-3.png)

$L_2$ 范数：

![alt text](image-4.png)

谱范数：

![alt text](image-6.png)

## “对抗样本”和“垃圾样本”
