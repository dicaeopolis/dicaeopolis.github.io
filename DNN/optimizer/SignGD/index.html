
<!DOCTYPE html>

<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../misc/" rel="prev"/>
<link href="../Adaptive/" rel="next"/>
<link href="../../../favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.22" name="generator"/>
<title>符号梯度下降 - Dicaeopolis' Wiki</title>
<link href="../../../assets/stylesheets/main.84d31ad4.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../themes/css/custom.css" rel="stylesheet"/>
<link href="../../../themes/css/simpleLightbox.min.css" rel="stylesheet"/>
<link href="../../../themes/css/pied_piper.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet"/>
<link href="../../../stylesheets/customize.css" rel="stylesheet"/>
<link href="../../../assets/css/custom.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#_1">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="Dicaeopolis' Wiki" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="Dicaeopolis' Wiki">
<img alt="logo" src="../../../favicon.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Dicaeopolis' Wiki
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              符号梯度下降
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../">
          
  
  
    
  
  深度神经网络

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../campus-sources/">
          
  
  
    
  
  校内课程知识

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../misc/">
          
  
  
    
  
  配置和杂谈笔记

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../algorithm/">
          
  
  
    
  
  传统算法与性能

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Dicaeopolis' Wiki" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="Dicaeopolis' Wiki">
<img alt="logo" src="../../../favicon.png"/>
</a>
    Dicaeopolis' Wiki
  </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../">
<span class="md-ellipsis">
    深度神经网络
    
  </span>
</a>
<label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_1_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
            深度神经网络
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../RL/">
<span class="md-ellipsis">
    RL学习笔记 - 上篇
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../SVM_SMO/">
<span class="md-ellipsis">
    SMO 算法的推导
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_4" id="__nav_1_4_label" tabindex="0">
<span class="md-ellipsis">
    Wp
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_1_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_4">
<span class="md-nav__icon md-icon"></span>
            Wp
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../WP/aiwp/">
<span class="md-ellipsis">
    MISC-AI 方向 WriteUp
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1_5" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../model-attack/">
<span class="md-ellipsis">
    深度学习模型攻击理论与复现归档
    
  </span>
</a>
<label class="md-nav__link" for="__nav_1_5" id="__nav_1_5_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_1_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_5">
<span class="md-nav__icon md-icon"></span>
            深度学习模型攻击理论与复现归档
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-attack/hsja/">
<span class="md-ellipsis">
    HSJA 攻击
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-attack/BadNets/">
<span class="md-ellipsis">
    BadNets
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-attack/CandW/">
<span class="md-ellipsis">
    C&amp;W 攻击
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-attack/pgd/">
<span class="md-ellipsis">
    PGD 攻击
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-attack/fgsm/">
<span class="md-ellipsis">
    FGSM 攻击
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1_6" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../model-expr/">
<span class="md-ellipsis">
    深度学习相关模型理论与复现归档
    
  </span>
</a>
<label class="md-nav__link" for="__nav_1_6" id="__nav_1_6_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_1_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_6">
<span class="md-nav__icon md-icon"></span>
            深度学习相关模型理论与复现归档
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-expr/DDPM/">
<span class="md-ellipsis">
    扩散模型理论篇: 从多阶段变分自编码器到概率流常微分方程采样器系列
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-expr/S-and-D-models-replication/">
<span class="md-ellipsis">
    图像语义分割和目标检测相关模型复现手记
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-expr/Image-models-replication/">
<span class="md-ellipsis">
    图像分类相关模型复现手记
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model-expr/DC-GAN-%E8%80%81%E5%A9%86%E7%94%9F%E6%88%90%E5%99%A8/">
<span class="md-ellipsis">
    DC-GAN 老婆生成器
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_1_7" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    优化器
    
  </span>
</a>
<label class="md-nav__link" for="__nav_1_7" id="__nav_1_7_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_1_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_7">
<span class="md-nav__icon md-icon"></span>
            优化器
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../misc/">
<span class="md-ellipsis">
    后续的写作计划
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    符号梯度下降
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    符号梯度下降
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#rprop">
<span class="md-ellipsis">
      Rprop
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lion">
<span class="md-ellipsis">
      Lion
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#muon">
<span class="md-ellipsis">
      Muon
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Adaptive/">
<span class="md-ellipsis">
    自适应学习率改进策略
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SGD/">
<span class="md-ellipsis">
    SGD 系列算法
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../campus-sources/">
<span class="md-ellipsis">
    校内课程知识
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            校内课程知识
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/SDC_assignments/">
<span class="md-ellipsis">
    《计算机组成原理》理论课程作业与笔记归档
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/Descrete_assignments/">
<span class="md-ellipsis">
    《离散数学》课程作业与笔记归档
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/PU_Bii_assignments/">
<span class="md-ellipsis">
    《大学物理B下》课程作业与笔记归档
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/Prob_Stats_assignments/">
<span class="md-ellipsis">
    《概率论与数理统计》课程作业与笔记归档
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/binmul/">
<span class="md-ellipsis">
<i class="fas fa-calculator"></i> 二进制乘法可视化工具
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/textbook/">
<span class="md-ellipsis">
    本科教科书电子资源
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/ds-keynote/">
<span class="md-ellipsis">
    《数据结构》划重点笔记
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/ds-write-up/">
<span class="md-ellipsis">
    《数据结构》期末复习题题解
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../campus-sources/autosignin/">
<span class="md-ellipsis">
    自动签到脚本
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../misc/">
<span class="md-ellipsis">
    配置和杂谈笔记
    
  </span>
</a>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            配置和杂谈笔记
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../misc/test/">
<span class="md-ellipsis">
    功能测试页面
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../algorithm/">
<span class="md-ellipsis">
    传统算法与性能
    
  </span>
</a>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            传统算法与性能
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../algorithm/benchmark-on-stl/">
<span class="md-ellipsis">
    STL的一些性能测试
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../algorithm/stl-wheels/">
<span class="md-ellipsis">
    嗯造轮子
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../algorithm/template-on-numeric-ring/">
<span class="md-ellipsis">
    整数环取模模板
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#rprop">
<span class="md-ellipsis">
      Rprop
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lion">
<span class="md-ellipsis">
      Lion
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#muon">
<span class="md-ellipsis">
      Muon
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="_1">符号梯度下降<a class="headerlink" href="#_1" title="Permanent link">¶</a></h1>
<div class="admonition info">
<p class="admonition-title">📖 阅读信息</p>
<p>阅读时间约 <strong>19</strong> 分钟　|　约 <strong>2029</strong> 字　|　约 <strong>57</strong> 个公式　|　约 <strong>470</strong> 行代码</p>
</div>
<p>如果是近似 Hessian 矩阵是优化器理论发展的一条“明线”，那么对梯度取“符号”来计算，则是对应的一条“暗线”。</p>
<p>在接下来的讨论中，我们将看到刚刚讨论的那些优化器是如何在这条“暗线”下走向统一的。同时，这条“暗线”也渐渐越挑越明，逐渐成为大规模神经网络训练优化的新的理论指导。</p>
<h2 id="rprop">Rprop<a class="headerlink" href="#rprop" title="Permanent link">¶</a></h2>
<p>Rprop 的出现早于 RMSprop，从命名风格就可以看出它们的一脉相承。</p>
<p>回忆一下 RMSprop 的计算，它提供了一个梯度缩放系数 <span class="arithmatex">\(\sqrt{G_n}\)</span>，其中 <span class="arithmatex">\(G\)</span> 是对 <span class="arithmatex">\(g^2\)</span> 的平均。</p>
<p>那么最后的参数更新就变成了 <span class="arithmatex">\(-\eta\dfrac{g}{\sqrt{\bar g^2}}\)</span>，如果我们考虑全量（Full batch）更新，也就是让 <span class="arithmatex">\(\mathcal{|B|}=n\)</span> 即 Batch size 等于样本数量，那么我们甚至可以把这个“平均梯度”的平均去掉。这样实际的更新量就是梯度的<strong>符号函数</strong> <span class="arithmatex">\(\mathrm{sign}(g)\)</span> 了！</p>
<p>这就是 Rprop 的更新原理。也就是所有符号梯度下降优化器的理论核心：梯度的<strong>方向</strong>相比其在不同方向的<strong>大小</strong>更重要！</p>
<p>回到我们之前讨论的那个椭圆抛物面，如果我们过于依赖梯度大小，就会造成“反复横跳”的问题，因为梯度在我们预期的优化方向的<strong>垂直</strong>方向上，有相当大的大小，这就影响了优化器在 Hessian 矩阵条件数相当大的时候，逃离鞍点的能力。</p>
<p>在看公式之前，先看看 Rprop 的效果吧：</p>
<p><img alt="rastrigin_Rprop" src="../optimizer_pics/rastrigin_Rprop.gif"/></p>
<p><img alt="rosenbrock_Rprop" src="../optimizer_pics/rosenbrock_Rprop.gif"/></p>
<p>可以看到，如果忽略全量梯度计算这个（大）问题，Rprop 在这两个地形的收敛能力完全可以媲美 Adam！尤其是在 rosenbrock 地形下 Rprop 沿着谷底移动的速度是相当快的。</p>
<p>下面则展示了如果以 mini-batch 方式运行 Rprop 的惨烈效果：</p>
<p><img alt="Rprop_performance_curves" src="../optimizer_pics/Rprop_performance_curves.png"/></p>
<p><img alt="Rprop_landscape_pca" src="../optimizer_pics/Rprop_landscape_pca.png"/></p>
<p>演都不演了，根本收敛不了。</p>
<p>现在让我们来看看 Rprop 的更新公式：</p>
<div class="arithmatex">\[
\begin{align*}
    g_n&amp;=\nabla\mathcal{L({x_{\mathrm{full}}};\theta_{n-1})}\\
    \hat g_n&amp;=\mathrm{sign}(g_n)\\
    \theta_n&amp;=\theta_{n-1}-\eta\hat g_n
\end{align*}
\]</div>
<p>由此，就能写出代码了：</p>
<details>
<summary> Rprop 的实现</summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">_single_tensor_rprop</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">params</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">grads</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">prevs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">step_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">state_steps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">step_size_min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">step_size_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">etaminus</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">etaplus</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">capturable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="n">differentiable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">has_complex</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="p">):</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="c1"># 循环处理每个参数</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">grad</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">maximize</span> <span class="k">else</span> <span class="o">-</span><span class="n">grad</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="n">prev</span> <span class="o">=</span> <span class="n">prevs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="n">step_size</span> <span class="o">=</span> <span class="n">step_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="n">step</span> <span class="o">=</span> <span class="n">state_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="c1"># --- CUDA Graph 捕获检查 ---</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">is_compiling</span><span class="p">()</span> <span class="ow">and</span> <span class="n">capturable</span><span class="p">:</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>            <span class="n">capturable_supported_devices</span> <span class="o">=</span> <span class="n">_get_capturable_supported_devices</span><span class="p">()</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="k">assert</span> <span class="p">(</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>                <span class="n">param</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">step</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>                <span class="ow">and</span> <span class="n">param</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="n">capturable_supported_devices</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>            <span class="p">),</span> <span class="s2">"如果 capturable=True, params 和 state_steps 必须在支持的设备上。"</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="c1"># --- 处理复数 ---</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_complex</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>            <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>            <span class="n">prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">(</span><span class="n">prev</span><span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>            <span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>            <span class="n">step_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">(</span><span class="n">step_size</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="c1"># --- Rprop 核心逻辑 ---</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="c1"># 1. 计算当前梯度与上一步梯度的乘积的符号</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="c1"># sign &gt; 0: 梯度符号相同</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="c1"># sign &lt; 0: 梯度符号相反</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="c1"># sign = 0: 其中一个梯度为零</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="k">if</span> <span class="n">differentiable</span><span class="p">:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>            <span class="c1"># 在可微分模式下，需要克隆 prev 以防原地操作破坏计算图</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>            <span class="n">sign</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">prev</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>            <span class="n">sign</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">prev</span><span class="p">)</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="c1"># 2. 根据符号 sign 的值，确定步长的更新因子</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="c1"># 这里用 sign 张量来存储更新因子 (etaplus, etaminus, 1)</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="k">if</span> <span class="n">capturable</span><span class="p">:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>            <span class="c1"># Capturable 模式下使用 torch.where</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>            <span class="n">sign</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">sign</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">etaplus</span><span class="p">,</span> <span class="n">sign</span><span class="p">))</span>   <span class="c1"># 符号相同，更新因子为 etaplus</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>            <span class="n">sign</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">sign</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">etaminus</span><span class="p">,</span> <span class="n">sign</span><span class="p">))</span>  <span class="c1"># 符号相反，更新因子为 etaminus</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>            <span class="n">sign</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">sign</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sign</span><span class="p">))</span>         <span class="c1"># 符号为0，更新因子为 1 (步长不变)</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>            <span class="c1"># 常规模式下使用索引赋值，通常更高效</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>            <span class="n">sign</span><span class="p">[</span><span class="n">sign</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">etaplus</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>            <span class="n">sign</span><span class="p">[</span><span class="n">sign</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">etaminus</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>            <span class="n">sign</span><span class="p">[</span><span class="n">sign</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="c1"># 3. 更新步长</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="c1"># 用更新因子乘以当前步长，并将其限制在 [step_size_min, step_size_max] 范围内</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="n">step_size</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">sign</span><span class="p">)</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="n">step_size_min</span><span class="p">,</span> <span class="n">step_size_max</span><span class="p">)</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="c1"># 4. 根据 Rprop 规则修改当前梯度</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="c1"># 这是一个 Rprop 的变体规则：如果梯度符号反转 (sign.eq(etaminus))，</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="c1"># 则本次更新的梯度设为0，意味着参数在这一步不移动。</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="k">if</span> <span class="n">capturable</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>            <span class="n">grad</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">sign</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">etaminus</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">grad</span><span class="p">))</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>            <span class="n">grad</span><span class="p">[</span><span class="n">sign</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">etaminus</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="c1"># 5. 更新参数</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="c1"># 参数的更新量只取决于当前梯度的符号和更新后的步长</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="c1"># 公式: param_t = param_{t-1} - sign(grad_t) * step_size_t</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">param</span><span class="o">.</span><span class="n">addcmul_</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">sign</span><span class="p">(),</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="c1"># 6. 保存当前梯度，作为下一步的 "prev"</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">prev</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<p>代码相对刚刚的讲解多了亿点点细节，因为它实现的是名叫 Rprop with weight-backtracking 的算法。这个改进的作用体现在我们之前提过无数次的椭圆抛物面上面，加入 <code>sign</code> 项之后，就可以检测到梯度在“反复横跳”，这个时候就不应该放任它跳，而是减少步长才更有希望落到下面。</p>
<h2 id="lion">Lion<a class="headerlink" href="#lion" title="Permanent link">¶</a></h2>
<p>Lion 优化器是 Google 团队搜出来的优化器，尽管不是从某个理论推导下来，Lion 优化器仍然在同等参数量下取得了至少和 AdamW 打平的性能。</p>
<p>具体而言，Lion 优化器的参数更新规则是：</p>
<div class="arithmatex">\[
\begin{align*}
    g_n&amp;=\nabla\mathcal{L(x;\theta_{n-1})}\\
    G_n&amp;=\mathrm{sign}(\beta_1 M_{n-1}+(1-\beta_1)g_n)\\
    \theta_n&amp;=\theta_{n-1}+\eta(G_n+\lambda \theta_{n-1})\\
    M_n &amp;= \beta_2 M_{n-1}+(1-\beta_2)g_n
\end{align*}
\]</div>
<p>可以看到，Lion 类似于引入动量的 Rprop，不过只是把动量的更新放到了最后。这里没有使用全量计算，而是使用平均梯度来规避全量计算的复杂度。由于动量的引入，Lion 需要更小的学习率。</p>
<p>让我们看看 Lion 的效果：</p>
<p><img alt="rastrigin_Lion" src="../optimizer_pics/rastrigin_Lion.gif"/></p>
<p><img alt="rastrigin_Lion_2" src="../optimizer_pics/rastrigin_Lion_2.gif"/></p>
<p><img alt="rosenbrock_Lion" src="../optimizer_pics/rosenbrock_Lion.gif"/></p>
<p>可以看见 Lion 也在这两个地形获得了不错的表现。虽然在 rastrigin 地形下面 hyperopt 并没有搜出一个特别好的参数（第一张图太小第二张图太大），但是对于 rosenbrock 地形，Lion 取得了我们目前所见最快的谷底行进速度。</p>
<p><img alt="Lion_performance_curves" src="../optimizer_pics/Lion_performance_curves.png"/></p>
<p><img alt="Lion_landscape_pca" src="../optimizer_pics/Lion_landscape_pca.png"/></p>
<p>Lion 在这个任务下面相当能打啊。仅需要约 3500 个 batch 就可以将 train_loss 降到 0.1 水平，约 700 个 batch 就可以把 acc 刷上 0.9。</p>
<p>让我们看看 <code>torch-optimizer</code> 库的实现：</p>
<details>
<summary> Lion 优化器的实现 </summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1">  1</a></span>
<span class="normal"><a href="#__codelineno-1-2">  2</a></span>
<span class="normal"><a href="#__codelineno-1-3">  3</a></span>
<span class="normal"><a href="#__codelineno-1-4">  4</a></span>
<span class="normal"><a href="#__codelineno-1-5">  5</a></span>
<span class="normal"><a href="#__codelineno-1-6">  6</a></span>
<span class="normal"><a href="#__codelineno-1-7">  7</a></span>
<span class="normal"><a href="#__codelineno-1-8">  8</a></span>
<span class="normal"><a href="#__codelineno-1-9">  9</a></span>
<span class="normal"><a href="#__codelineno-1-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-1-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-1-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-1-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-1-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-1-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-1-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-1-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-1-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-1-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-1-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-1-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-1-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-1-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-1-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-1-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-1-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-1-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-1-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-1-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-1-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-1-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-1-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-1-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-1-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-1-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-1-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-1-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-1-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-1-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-1-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-1-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-1-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-1-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-1-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-1-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-1-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-1-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-1-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-1-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-1-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-1-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-1-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-1-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-1-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-1-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-1-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-1-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-1-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-1-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-1-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-1-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-1-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-1-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-1-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-1-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-1-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-1-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-1-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-1-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-1-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-1-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-1-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-1-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-1-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-1-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-1-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-1-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-1-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-1-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-1-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-1-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-1-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-1-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-1-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-1-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-1-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-1-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-1-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-1-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-1-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-1-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-1-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-1-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-1-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-1-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-1-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-1-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-1-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-1-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-1-100">100</a></span>
<span class="normal"><a href="#__codelineno-1-101">101</a></span>
<span class="normal"><a href="#__codelineno-1-102">102</a></span>
<span class="normal"><a href="#__codelineno-1-103">103</a></span>
<span class="normal"><a href="#__codelineno-1-104">104</a></span>
<span class="normal"><a href="#__codelineno-1-105">105</a></span>
<span class="normal"><a href="#__codelineno-1-106">106</a></span>
<span class="normal"><a href="#__codelineno-1-107">107</a></span>
<span class="normal"><a href="#__codelineno-1-108">108</a></span>
<span class="normal"><a href="#__codelineno-1-109">109</a></span>
<span class="normal"><a href="#__codelineno-1-110">110</a></span>
<span class="normal"><a href="#__codelineno-1-111">111</a></span>
<span class="normal"><a href="#__codelineno-1-112">112</a></span>
<span class="normal"><a href="#__codelineno-1-113">113</a></span>
<span class="normal"><a href="#__codelineno-1-114">114</a></span>
<span class="normal"><a href="#__codelineno-1-115">115</a></span>
<span class="normal"><a href="#__codelineno-1-116">116</a></span>
<span class="normal"><a href="#__codelineno-1-117">117</a></span>
<span class="normal"><a href="#__codelineno-1-118">118</a></span>
<span class="normal"><a href="#__codelineno-1-119">119</a></span>
<span class="normal"><a href="#__codelineno-1-120">120</a></span>
<span class="normal"><a href="#__codelineno-1-121">121</a></span>
<span class="normal"><a href="#__codelineno-1-122">122</a></span>
<span class="normal"><a href="#__codelineno-1-123">123</a></span>
<span class="normal"><a href="#__codelineno-1-124">124</a></span>
<span class="normal"><a href="#__codelineno-1-125">125</a></span>
<span class="normal"><a href="#__codelineno-1-126">126</a></span>
<span class="normal"><a href="#__codelineno-1-127">127</a></span>
<span class="normal"><a href="#__codelineno-1-128">128</a></span>
<span class="normal"><a href="#__codelineno-1-129">129</a></span>
<span class="normal"><a href="#__codelineno-1-130">130</a></span>
<span class="normal"><a href="#__codelineno-1-131">131</a></span>
<span class="normal"><a href="#__codelineno-1-132">132</a></span>
<span class="normal"><a href="#__codelineno-1-133">133</a></span>
<span class="normal"><a href="#__codelineno-1-134">134</a></span>
<span class="normal"><a href="#__codelineno-1-135">135</a></span>
<span class="normal"><a href="#__codelineno-1-136">136</a></span>
<span class="normal"><a href="#__codelineno-1-137">137</a></span>
<span class="normal"><a href="#__codelineno-1-138">138</a></span>
<span class="normal"><a href="#__codelineno-1-139">139</a></span>
<span class="normal"><a href="#__codelineno-1-140">140</a></span>
<span class="normal"><a href="#__codelineno-1-141">141</a></span>
<span class="normal"><a href="#__codelineno-1-142">142</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="c1"># 导入 PyTorch 核心库</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="c1"># 从 PyTorch 优化器基类中导入 Optimizer，所有自定义优化器都应继承它</span>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.optimizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="c1"># 从本地类型定义文件中导入类型提示，增强代码可读性</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a><span class="c1"># Betas2: 一个包含两个浮点数的元组，如 (0.9, 0.99)</span>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a><span class="c1"># OptFloat: 可选的浮点数，即 float 或 None</span>
<a id="__codelineno-1-9" name="__codelineno-1-9"></a><span class="c1"># OptLossClosure: 可选的损失闭包函数</span>
<a id="__codelineno-1-10" name="__codelineno-1-10"></a><span class="c1"># Params: 可迭代的参数或定义了参数组的字典</span>
<a id="__codelineno-1-11" name="__codelineno-1-11"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch_optimizer.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">Betas2</span><span class="p">,</span> <span class="n">OptFloat</span><span class="p">,</span> <span class="n">OptLossClosure</span><span class="p">,</span> <span class="n">Params</span>
<a id="__codelineno-1-12" name="__codelineno-1-12"></a>
<a id="__codelineno-1-13" name="__codelineno-1-13"></a><span class="c1"># 定义当 `from module import *` 时，哪些对象会被导出</span>
<a id="__codelineno-1-14" name="__codelineno-1-14"></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"Lion"</span><span class="p">,)</span>
<a id="__codelineno-1-15" name="__codelineno-1-15"></a>
<a id="__codelineno-1-16" name="__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17"></a><span class="c1"># 定义 Lion 优化器类，它继承自 PyTorch 的 Optimizer 基类</span>
<a id="__codelineno-1-18" name="__codelineno-1-18"></a><span class="k">class</span><span class="w"> </span><span class="nc">Lion</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<a id="__codelineno-1-19" name="__codelineno-1-19"></a><span class="w">    </span><span class="sa">r</span><span class="sd">"""实现了 Lion 算法。</span>
<a id="__codelineno-1-20" name="__codelineno-1-20"></a>
<a id="__codelineno-1-21" name="__codelineno-1-21"></a><span class="sd">    代码改编自 Google 的官方实现: https://github.com/google/automl/tree/master/lion</span>
<a id="__codelineno-1-22" name="__codelineno-1-22"></a>
<a id="__codelineno-1-23" name="__codelineno-1-23"></a><span class="sd">    Lion - EvoLved SIgn MOmeNtum (演进的符号动量) 算法在</span>
<a id="__codelineno-1-24" name="__codelineno-1-24"></a><span class="sd">    论文 https://arxiv.org/pdf/2302.06675.pdf 中被提出。</span>
<a id="__codelineno-1-25" name="__codelineno-1-25"></a><span class="sd">    Lion 的目标是通过只跟踪动量来比 Adam 算法更节省内存。</span>
<a id="__codelineno-1-26" name="__codelineno-1-26"></a>
<a id="__codelineno-1-27" name="__codelineno-1-27"></a><span class="sd">    注意事项:</span>
<a id="__codelineno-1-28" name="__codelineno-1-28"></a><span class="sd">    - 如论文中所述，Lion 需要一个更小的学习率 (lr)。</span>
<a id="__codelineno-1-29" name="__codelineno-1-29"></a><span class="sd">    - 为了维持有效的权重衰减强度，需要一个更大的解耦权重衰减 (decoupled weight decay) 值。</span>
<a id="__codelineno-1-30" name="__codelineno-1-30"></a><span class="sd">    - Lion 的性能增益会随着批处理大小 (batch size) 的增加而变大。</span>
<a id="__codelineno-1-31" name="__codelineno-1-31"></a><span class="sd">    - 此外，在一些大型语言模型和文本/图像数据集上，Lion 并未被发现能超越 AdamW。</span>
<a id="__codelineno-1-32" name="__codelineno-1-32"></a>
<a id="__codelineno-1-33" name="__codelineno-1-33"></a><span class="sd">    参数:</span>
<a id="__codelineno-1-34" name="__codelineno-1-34"></a><span class="sd">        params: 需要优化的、可迭代的参数，或定义了参数组的字典。</span>
<a id="__codelineno-1-35" name="__codelineno-1-35"></a><span class="sd">        lr: 学习率 (learning rate)，默认为 1e-4 (注意，论文建议比 Adam 小 3-10 倍)。</span>
<a id="__codelineno-1-36" name="__codelineno-1-36"></a><span class="sd">        betas: 用于计算梯度及其平方的运行平均值的系数 (默认: (0.9, 0.99))。</span>
<a id="__codelineno-1-37" name="__codelineno-1-37"></a><span class="sd">               在 Lion 中，beta1 用于插值，beta2 用于动量更新。</span>
<a id="__codelineno-1-38" name="__codelineno-1-38"></a><span class="sd">        weight_decay: 权重衰减 (L2 惩罚项) (默认: 0)。</span>
<a id="__codelineno-1-39" name="__codelineno-1-39"></a>
<a id="__codelineno-1-40" name="__codelineno-1-40"></a><span class="sd">    示例:</span>
<a id="__codelineno-1-41" name="__codelineno-1-41"></a><span class="sd">        &gt;&gt;&gt; import torch_optimizer as optim</span>
<a id="__codelineno-1-42" name="__codelineno-1-42"></a><span class="sd">        &gt;&gt;&gt; optimizer = optim.Lion(model.parameters(), lr=0.001)</span>
<a id="__codelineno-1-43" name="__codelineno-1-43"></a><span class="sd">        &gt;&gt;&gt; optimizer.zero_grad()</span>
<a id="__codelineno-1-44" name="__codelineno-1-44"></a><span class="sd">        &gt;&gt;&gt; loss_fn(model(input), target).backward()</span>
<a id="__codelineno-1-45" name="__codelineno-1-45"></a><span class="sd">        &gt;&gt;&gt; optimizer.step()</span>
<a id="__codelineno-1-46" name="__codelineno-1-46"></a><span class="sd">    """</span>
<a id="__codelineno-1-47" name="__codelineno-1-47"></a>
<a id="__codelineno-1-48" name="__codelineno-1-48"></a>    <span class="c1"># 类的构造函数</span>
<a id="__codelineno-1-49" name="__codelineno-1-49"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-1-50" name="__codelineno-1-50"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-1-51" name="__codelineno-1-51"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">Params</span><span class="p">,</span>
<a id="__codelineno-1-52" name="__codelineno-1-52"></a>        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>          <span class="c1"># 学习率</span>
<a id="__codelineno-1-53" name="__codelineno-1-53"></a>        <span class="n">betas</span><span class="p">:</span> <span class="n">Betas2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span> <span class="c1"># beta 参数</span>
<a id="__codelineno-1-54" name="__codelineno-1-54"></a>        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="c1"># 权重衰减系数</span>
<a id="__codelineno-1-55" name="__codelineno-1-55"></a>    <span class="p">):</span>
<a id="__codelineno-1-56" name="__codelineno-1-56"></a>        <span class="c1"># --- 输入参数合法性检查 ---</span>
<a id="__codelineno-1-57" name="__codelineno-1-57"></a>        <span class="k">if</span> <span class="n">lr</span> <span class="o">&lt;=</span> <span class="mf">0.0</span><span class="p">:</span>
<a id="__codelineno-1-58" name="__codelineno-1-58"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"无效的学习率: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>
<a id="__codelineno-1-59" name="__codelineno-1-59"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
<a id="__codelineno-1-60" name="__codelineno-1-60"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-1-61" name="__codelineno-1-61"></a>                <span class="s2">"无效的 beta 参数 (索引 0): </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-1-62" name="__codelineno-1-62"></a>            <span class="p">)</span>
<a id="__codelineno-1-63" name="__codelineno-1-63"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
<a id="__codelineno-1-64" name="__codelineno-1-64"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-1-65" name="__codelineno-1-65"></a>                <span class="s2">"无效的 beta 参数 (索引 1): </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-1-66" name="__codelineno-1-66"></a>            <span class="p">)</span>
<a id="__codelineno-1-67" name="__codelineno-1-67"></a>        <span class="k">if</span> <span class="n">weight_decay</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-1-68" name="__codelineno-1-68"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-1-69" name="__codelineno-1-69"></a>                <span class="s2">"无效的 weight_decay 值: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span>
<a id="__codelineno-1-70" name="__codelineno-1-70"></a>            <span class="p">)</span>
<a id="__codelineno-1-71" name="__codelineno-1-71"></a>
<a id="__codelineno-1-72" name="__codelineno-1-72"></a>        <span class="c1"># 将超参数打包成一个字典，作为默认配置</span>
<a id="__codelineno-1-73" name="__codelineno-1-73"></a>        <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
<a id="__codelineno-1-74" name="__codelineno-1-74"></a>        <span class="c1"># 调用父类 (Optimizer) 的构造函数，完成初始化</span>
<a id="__codelineno-1-75" name="__codelineno-1-75"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>
<a id="__codelineno-1-76" name="__codelineno-1-76"></a>
<a id="__codelineno-1-77" name="__codelineno-1-77"></a>    <span class="c1"># `@torch.no_grad()` 是一个装饰器，它会禁用此函数内的梯度计算。</span>
<a id="__codelineno-1-78" name="__codelineno-1-78"></a>    <span class="c1"># 这对于优化器是至关重要的，因为我们是在修改参数值，而不是在计算关于这些修改的梯度。</span>
<a id="__codelineno-1-79" name="__codelineno-1-79"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-1-80" name="__codelineno-1-80"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="p">:</span> <span class="n">OptLossClosure</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptFloat</span><span class="p">:</span>
<a id="__codelineno-1-81" name="__codelineno-1-81"></a><span class="w">        </span><span class="sa">r</span><span class="sd">"""执行单步优化。</span>
<a id="__codelineno-1-82" name="__codelineno-1-82"></a>
<a id="__codelineno-1-83" name="__codelineno-1-83"></a><span class="sd">        参数:</span>
<a id="__codelineno-1-84" name="__codelineno-1-84"></a><span class="sd">            closure: 一个可以重新评估模型并返回损失的闭包函数 (可选)。</span>
<a id="__codelineno-1-85" name="__codelineno-1-85"></a><span class="sd">        """</span>
<a id="__codelineno-1-86" name="__codelineno-1-86"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-1-87" name="__codelineno-1-87"></a>        <span class="c1"># 如果提供了闭包函数 (closure)，则执行它来计算损失。</span>
<a id="__codelineno-1-88" name="__codelineno-1-88"></a>        <span class="c1"># 这在某些优化算法（如 L-BFGS）中很常见，可以多次评估模型。</span>
<a id="__codelineno-1-89" name="__codelineno-1-89"></a>        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-1-90" name="__codelineno-1-90"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span> <span class="c1"># 在闭包内需要确保梯度是开启的</span>
<a id="__codelineno-1-91" name="__codelineno-1-91"></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>
<a id="__codelineno-1-92" name="__codelineno-1-92"></a>
<a id="__codelineno-1-93" name="__codelineno-1-93"></a>        <span class="c1"># 遍历所有的参数组 (param_groups)，例如可以为模型的不同部分设置不同的学习率</span>
<a id="__codelineno-1-94" name="__codelineno-1-94"></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
<a id="__codelineno-1-95" name="__codelineno-1-95"></a>            <span class="c1"># 遍历当前参数组中的每一个参数 (p)</span>
<a id="__codelineno-1-96" name="__codelineno-1-96"></a>            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">"params"</span><span class="p">]:</span>
<a id="__codelineno-1-97" name="__codelineno-1-97"></a>                <span class="c1"># 如果参数没有梯度 (例如，在冻结层中)，则跳过</span>
<a id="__codelineno-1-98" name="__codelineno-1-98"></a>                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-1-99" name="__codelineno-1-99"></a>                    <span class="k">continue</span>
<a id="__codelineno-1-100" name="__codelineno-1-100"></a>
<a id="__codelineno-1-101" name="__codelineno-1-101"></a>                <span class="c1"># --- 核心算法开始 ---</span>
<a id="__codelineno-1-102" name="__codelineno-1-102"></a>
<a id="__codelineno-1-103" name="__codelineno-1-103"></a>                <span class="c1"># 1. 执行解耦权重衰减 (Decoupled Weight Decay)</span>
<a id="__codelineno-1-104" name="__codelineno-1-104"></a>                <span class="c1"># 这是一种 L2 正则化的形式，它直接从参数中减去一个与其自身大小成正比的值。</span>
<a id="__codelineno-1-105" name="__codelineno-1-105"></a>                <span class="c1"># 注意这里的衰减量是 `lr * weight_decay`，与 AdamW 不同 (AdamW 是 `weight_decay`)。</span>
<a id="__codelineno-1-106" name="__codelineno-1-106"></a>                <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
<a id="__codelineno-1-107" name="__codelineno-1-107"></a>
<a id="__codelineno-1-108" name="__codelineno-1-108"></a>                <span class="n">grad</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span>
<a id="__codelineno-1-109" name="__codelineno-1-109"></a>                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="c1"># 获取该参数的状态字典，用于存储动量等信息</span>
<a id="__codelineno-1-110" name="__codelineno-1-110"></a>
<a id="__codelineno-1-111" name="__codelineno-1-111"></a>                <span class="c1"># 2. 状态初始化 (State Initialization)</span>
<a id="__codelineno-1-112" name="__codelineno-1-112"></a>                <span class="c1"># 如果一个参数第一次被优化，其状态字典 `state` 是空的</span>
<a id="__codelineno-1-113" name="__codelineno-1-113"></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-1-114" name="__codelineno-1-114"></a>                    <span class="c1"># 初始化动量 (momentum)，命名为 `exp_avg` 以与 Adam 保持一致</span>
<a id="__codelineno-1-115" name="__codelineno-1-115"></a>                    <span class="c1"># 创建一个与参数 p 形状相同、值全为 0 的张量</span>
<a id="__codelineno-1-116" name="__codelineno-1-116"></a>                    <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-1-117" name="__codelineno-1-117"></a>
<a id="__codelineno-1-118" name="__codelineno-1-118"></a>                <span class="c1"># 获取动量和 beta 系数</span>
<a id="__codelineno-1-119" name="__codelineno-1-119"></a>                <span class="n">exp_avg</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg"</span><span class="p">]</span>
<a id="__codelineno-1-120" name="__codelineno-1-120"></a>                <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s2">"betas"</span><span class="p">]</span>
<a id="__codelineno-1-121" name="__codelineno-1-121"></a>
<a id="__codelineno-1-122" name="__codelineno-1-122"></a>                <span class="c1"># 3. 计算用于更新的插值 (Interpolation for update)</span>
<a id="__codelineno-1-123" name="__codelineno-1-123"></a>                <span class="c1"># 这一步是 Lion 算法的核心之一。它使用 beta1 来混合（插值）旧的动量和当前的梯度。</span>
<a id="__codelineno-1-124" name="__codelineno-1-124"></a>                <span class="c1"># 公式: c_t = β₁ * m_t + (1 - β₁) * g_t</span>
<a id="__codelineno-1-125" name="__codelineno-1-125"></a>                <span class="n">update</span> <span class="o">=</span> <span class="n">exp_avg</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta1</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
<a id="__codelineno-1-126" name="__codelineno-1-126"></a>
<a id="__codelineno-1-127" name="__codelineno-1-127"></a>                <span class="c1"># 4. 参数更新 (Parameter Update)</span>
<a id="__codelineno-1-128" name="__codelineno-1-128"></a>                <span class="c1"># 使用 `update` 的符号 (sign) 来更新参数。</span>
<a id="__codelineno-1-129" name="__codelineno-1-129"></a>                <span class="c1"># `torch.sign(update)` 会得到一个由 -1, 0, 1 组成的张量。</span>
<a id="__codelineno-1-130" name="__codelineno-1-130"></a>                <span class="c1"># `p.add_(..., alpha=-lr)` 等价于 `p.data = p.data - lr * torch.sign(update)`。</span>
<a id="__codelineno-1-131" name="__codelineno-1-131"></a>                <span class="c1"># 这是 "Sign Momentum" 名称的由来。</span>
<a id="__codelineno-1-132" name="__codelineno-1-132"></a>                <span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">update</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">])</span>
<a id="__codelineno-1-133" name="__codelineno-1-133"></a>
<a id="__codelineno-1-134" name="__codelineno-1-134"></a>                <span class="c1"># 5. 更新动量 (Momentum Update)</span>
<a id="__codelineno-1-135" name="__codelineno-1-135"></a>                <span class="c1"># 这一步使用 beta2 来更新动量，为下一次迭代做准备。</span>
<a id="__codelineno-1-136" name="__codelineno-1-136"></a>                <span class="c1"># 公式: m_{t+1} = β₂ * m_t + (1 - β₂) * g_t</span>
<a id="__codelineno-1-137" name="__codelineno-1-137"></a>                <span class="c1"># `exp_avg.mul_(beta2)`: 先将旧动量乘以 beta2</span>
<a id="__codelineno-1-138" name="__codelineno-1-138"></a>                <span class="c1"># `.add_(grad, alpha=1 - beta2)`: 再加上 `(1 - beta2) * grad`</span>
<a id="__codelineno-1-139" name="__codelineno-1-139"></a>                <span class="n">exp_avg</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>
<a id="__codelineno-1-140" name="__codelineno-1-140"></a>
<a id="__codelineno-1-141" name="__codelineno-1-141"></a>        <span class="c1"># 返回本次 step 计算的损失值（如果提供了闭包）</span>
<a id="__codelineno-1-142" name="__codelineno-1-142"></a>        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
</details>
<h2 id="muon">Muon<a class="headerlink" href="#muon" title="Permanent link">¶</a></h2>
<p>最后让我们祭出 Muon 优化器，也就是 Kimi-K2 模型训练使用的优化器。这一节的撰写，在很大程度上参考了苏剑林的博客。</p>
<p>我们计划从两条路线“包抄”推导 Muon 优化器。</p>
<p>第一条思路是 Lion 优化器的思路，或者说是 Rprop 的思路。最开始对 Rprop 的分析建立在参数更新量是 <span class="arithmatex">\(-\eta\dfrac{g}{\sqrt{\bar g^2}}\)</span> 的基础上，然后非常武断地认为对于<strong>矩阵</strong>而言 <span class="arithmatex">\(\dfrac{g}{\sqrt{\bar g^2}}=\mathrm{sign}(g)\)</span>，但是如果我们<strong>从表达式本身出发</strong>呢？</p>
<p>让我们回到梦开始的地方，AdaGrad 优化器的初衷是计算 <span class="arithmatex">\(\dfrac{g}{\sqrt{gg^\top}}\)</span>。考虑单个 fc layer（正如我们在 Shampoo 优化器中做的那样），则 <span class="arithmatex">\(g\)</span> 是一个 <span class="arithmatex">\(n\times m\)</span> 的矩阵。这启发我们设计这样一个<strong>矩阵符号函数</strong>：<span class="arithmatex">\(\mathrm{msign}(M)=(MM^\top)^{-\frac 12}M\)</span>。</p>
<p>依旧是和 Shampoo 优化器一样，矩阵的逆 <span class="arithmatex">\(p\)</span> 次方根是通过 SVD 计算（得到推广）的。也就是考虑 <span class="arithmatex">\(M=U\Sigma V^\top\)</span> 则 <span class="arithmatex">\(M^{-\frac 1p}=U\Sigma^{-\frac 1p}V^\top\)</span>。</p>
<p>对 <span class="arithmatex">\(M\)</span> 做 SVD 也就是 <span class="arithmatex">\(M=U\Sigma V^\top\)</span>，那么：</p>
<div class="arithmatex">\[
\begin{align*}
    \mathrm{msign}(M)&amp;=(U\Sigma V^\top V\Sigma U^\top)^{-\frac 12}(U\Sigma V^\top)\\
    &amp;=(U\Sigma^2U^\top)^{-\frac 12}(U\Sigma V^\top)\\
    &amp;=U\Sigma^{-1}U^\top U\Sigma V^\top\\
    &amp;=U_{[:r]}V_{[:r]}^\top
\end{align*}
\]</div>
<p>其中 <span class="arithmatex">\(r\)</span> 为 <span class="arithmatex">\(M\)</span> 的奇异值个数。</p>
<p>利用这个<strong>矩阵符号函数</strong>代替 Rprop 的符号函数，并引入动量（但是，不像 Lion 一样把动量的更新放在最后），就得到 Muon 优化器的更新公式了：</p>
<div class="arithmatex">\[
\begin{align*}
    g_n&amp;=\nabla \mathcal{L}(x;\theta_{n-1})\\
    M_n&amp;=\beta M_{n-1}+g_n\\
    \theta_n&amp;=\theta_{n-1}-\eta\mathrm{msign}(M_n+\lambda \theta_{n-1})
\end{align*}
\]</div>
<p>这里和 Lion 不一样的是把正则化解耦到了符号函数里面。</p>
<p>第二条路，如果我们重新审视 Shampoo 优化器在一个 fc layer 的情况：</p>
<div class="arithmatex">\[
\begin{align*}
    L_n &amp;= \beta L_{n-1} + g_n g_n^\top\\
R_n &amp;= \beta R_{n-1} + g_n^\top g_n\\
H^{-\frac 12}g&amp;=L^{- \frac 14}g_nR^{- \frac 14}
\end{align*}
\]</div>
<p>在 <span class="arithmatex">\(\beta=0\)</span> 的时候，我们有：</p>
<div class="arithmatex">\[
\begin{align*}
    L^{- \frac 14}gR^{- \frac 14}=(g_n g_n^\top)^{- \frac 14}g_n(g_n^\top g_n)^{- \frac 14}
\end{align*}
\]</div>
<p>对 <span class="arithmatex">\(g_n\)</span> 做 SVD 即 <span class="arithmatex">\(g_n=U\Sigma V^\top\)</span>，接着推式子：</p>
<div class="arithmatex">\[
\begin{align*}
    L^{- \frac 14}gR^{- \frac 14}&amp;=(g_n g_n^\top)^{- \frac 14}g_n(g_n^\top g_n)^{- \frac 14}\\
    &amp;=(U\Sigma V^\top V\Sigma U^\top)^{- \frac 14}(U\Sigma V^\top)(V\Sigma U^\top U\Sigma V^\top)\\
    &amp;=(U\Sigma^2 U^\top)^{- \frac 14}(U\Sigma V^\top)(V\Sigma^2 V^\top)^{- \frac 14}\\
    &amp;=U\Sigma^{- \frac 12}\Sigma \Sigma^{- \frac 12} V^\top\\
    &amp;=\mathrm{msign}(g_n)
\end{align*}
\]</div>
<p>这意味着 Shampoo 也冥冥中使用了 <span class="arithmatex">\(\mathrm{msign}\)</span> 函数！</p>
<p>反观 Muon 的显存占用和 SGDM 一样，但是理论上打包算出了 <span class="arithmatex">\(gg^\top\)</span>，效果应该会相当赞啊！</p>
<p>我们知道 Shampoo 优化器的目标是使用 Kronecker 积高效优化 Hessian 计算，最终近似 <span class="arithmatex">\(gg^\top\)</span>；而 Muon 一个打包处理，就非常高效地计算出来了……吗？</p>
<p>我们只是得到了参数更新时，如果每一次都要计算 SVD 的话，那代价仍然是不可承担的。这，便是 Muon 最后一个字 N (for Newton-Schulz) 的含义！</p>
<p>我们不使用 SVD，而是采用 <span class="arithmatex">\(\mathrm{msign}(M)=(MM^\top)^{-\frac 12}M\)</span> 来计算。具体而言，我们要计算 <span class="arithmatex">\((MM^\top)^{-\frac 12}\)</span>。</p>
<p>Muon 的作者使用 Newton-Schulz 迭代来计算这个矩阵。Newton-Schulz 迭代是一种迭代法矩阵求逆算法，从 <span class="arithmatex">\(AX=I\)</span> 开始用 Newton 法类似的迭代式子逐步求解 <span class="arithmatex">\(X=A^{-1}\)</span>。</p>
<p>在这里，我们其实是从 <span class="arithmatex">\(MM^\top=I\)</span> 开始进行迭代。也就是将 <span class="arithmatex">\((MM^\top)^{-\frac 12}\)</span> 近似成 <span class="arithmatex">\(MM^\top-I\)</span> 的多项式。嘿，我知道你在想泰勒展开的事情，但是想想我们最小/大化的是什么？（比如，如果我们想最大化正弦和三次函数的相似度，我们应该使用基于勒让德多项式的傅里叶级数来展开而不是使用泰勒展开……）</p>
<p>所以别急。我们考虑展开到三项，也就是</p>
<div class="arithmatex">\[
\mathrm{msign}(M)\approx aM+b(MM^\top)M+c(MM^\top)^2M
\]</div>
<p>我们的优化目标是：尽可能对于所有的 <span class="arithmatex">\(M\)</span> 都具有最快的收敛速度。</p>
<p>我们对 <span class="arithmatex">\(M\)</span> 做一下 SVD，也就是</p>
<div class="arithmatex">\[
\begin{align*}
    \mathrm{msign}(M)&amp;=aU\Sigma V^\top+b(U\Sigma V^\top V\Sigma U^\top)(U\Sigma V^\top)+c(U\Sigma V^\top V\Sigma U^\top)^2(U\Sigma V^\top)\\
    &amp;=aU\Sigma V^\top+bU\Sigma^3V^\top+cU\Sigma^5V^\top\\
    &amp;=U(a\Sigma+b\Sigma^3+c\Sigma^5)V^\top
\end{align*}
\]</div>
<p>对于奇异值的每一项 <span class="arithmatex">\(\sigma\in(0,1]\)</span> 而言，我们其实希望 <span class="arithmatex">\(a\sigma+b\sigma^3+c\sigma^5\)</span> 能够在 <span class="arithmatex">\(k\)</span> 次迭代中尽量逼近 <span class="arithmatex">\(1\)</span>。</p>
<p>现在我们就可以设计问题了：固定迭代次数 <span class="arithmatex">\(k\)</span>，令 <span class="arithmatex">\(f(x)=ax+bx^3+cx^5(x\in(0,1])\)</span>，然后损失函数使用 MSE：<span class="arithmatex">\(\mathcal{L}([1-f^{(k)}(x)]^2;a,b,c)\)</span>，寻找 <span class="arithmatex">\(a,b,c\)</span> 使得 <span class="arithmatex">\(\mathcal{L}\)</span> 最小。我们采用 Adam 来跑一跑。</p>
<details>
<summary> 优化使用的代码</summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1">  1</a></span>
<span class="normal"><a href="#__codelineno-2-2">  2</a></span>
<span class="normal"><a href="#__codelineno-2-3">  3</a></span>
<span class="normal"><a href="#__codelineno-2-4">  4</a></span>
<span class="normal"><a href="#__codelineno-2-5">  5</a></span>
<span class="normal"><a href="#__codelineno-2-6">  6</a></span>
<span class="normal"><a href="#__codelineno-2-7">  7</a></span>
<span class="normal"><a href="#__codelineno-2-8">  8</a></span>
<span class="normal"><a href="#__codelineno-2-9">  9</a></span>
<span class="normal"><a href="#__codelineno-2-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-2-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-2-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-2-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-2-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-2-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-2-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-2-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-2-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-2-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-2-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-2-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-2-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-2-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-2-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-2-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-2-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-2-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-2-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-2-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-2-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-2-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-2-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-2-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-2-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-2-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-2-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-2-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-2-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-2-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-2-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-2-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-2-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-2-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-2-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-2-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-2-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-2-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-2-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-2-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-2-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-2-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-2-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-2-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-2-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-2-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-2-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-2-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-2-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-2-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-2-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-2-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-2-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-2-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-2-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-2-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-2-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-2-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-2-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-2-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-2-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-2-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-2-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-2-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-2-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-2-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-2-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-2-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-2-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-2-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-2-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-2-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-2-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-2-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-2-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-2-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-2-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-2-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-2-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-2-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-2-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-2-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-2-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-2-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-2-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-2-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-2-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-2-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-2-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-2-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-2-100">100</a></span>
<span class="normal"><a href="#__codelineno-2-101">101</a></span>
<span class="normal"><a href="#__codelineno-2-102">102</a></span>
<span class="normal"><a href="#__codelineno-2-103">103</a></span>
<span class="normal"><a href="#__codelineno-2-104">104</a></span>
<span class="normal"><a href="#__codelineno-2-105">105</a></span>
<span class="normal"><a href="#__codelineno-2-106">106</a></span>
<span class="normal"><a href="#__codelineno-2-107">107</a></span>
<span class="normal"><a href="#__codelineno-2-108">108</a></span>
<span class="normal"><a href="#__codelineno-2-109">109</a></span>
<span class="normal"><a href="#__codelineno-2-110">110</a></span>
<span class="normal"><a href="#__codelineno-2-111">111</a></span>
<span class="normal"><a href="#__codelineno-2-112">112</a></span>
<span class="normal"><a href="#__codelineno-2-113">113</a></span>
<span class="normal"><a href="#__codelineno-2-114">114</a></span>
<span class="normal"><a href="#__codelineno-2-115">115</a></span>
<span class="normal"><a href="#__codelineno-2-116">116</a></span>
<span class="normal"><a href="#__codelineno-2-117">117</a></span>
<span class="normal"><a href="#__codelineno-2-118">118</a></span>
<span class="normal"><a href="#__codelineno-2-119">119</a></span>
<span class="normal"><a href="#__codelineno-2-120">120</a></span>
<span class="normal"><a href="#__codelineno-2-121">121</a></span>
<span class="normal"><a href="#__codelineno-2-122">122</a></span>
<span class="normal"><a href="#__codelineno-2-123">123</a></span>
<span class="normal"><a href="#__codelineno-2-124">124</a></span>
<span class="normal"><a href="#__codelineno-2-125">125</a></span>
<span class="normal"><a href="#__codelineno-2-126">126</a></span>
<span class="normal"><a href="#__codelineno-2-127">127</a></span>
<span class="normal"><a href="#__codelineno-2-128">128</a></span>
<span class="normal"><a href="#__codelineno-2-129">129</a></span>
<span class="normal"><a href="#__codelineno-2-130">130</a></span>
<span class="normal"><a href="#__codelineno-2-131">131</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="c1"># --- 1. 设置超参数和固定值 ---</span>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>                <span class="c1"># 固定迭代次数</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-5</span> <span class="c1"># Adam 优化器的学习率</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100000</span>     <span class="c1"># 优化步数</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>    <span class="c1"># 每步优化中采样的 x 的数量</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-14" name="__codelineno-2-14"></a><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-15" name="__codelineno-2-15"></a>
<a id="__codelineno-2-16" name="__codelineno-2-16"></a><span class="c1"># --- 3. 设置优化器 ---</span>
<a id="__codelineno-2-17" name="__codelineno-2-17"></a><span class="c1"># 使用 Adam 优化器来更新 a, b, c</span>
<a id="__codelineno-2-18" name="__codelineno-2-18"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<a id="__codelineno-2-19" name="__codelineno-2-19"></a>
<a id="__codelineno-2-20" name="__codelineno-2-20"></a><span class="c1"># 存储历史记录以供可视化</span>
<a id="__codelineno-2-21" name="__codelineno-2-21"></a><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-2-22" name="__codelineno-2-22"></a><span class="n">a_history</span><span class="p">,</span> <span class="n">b_history</span><span class="p">,</span> <span class="n">c_history</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<a id="__codelineno-2-23" name="__codelineno-2-23"></a>
<a id="__codelineno-2-24" name="__codelineno-2-24"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"开始优化... k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">, 初始值 a=</span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, b=</span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, c=</span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-2-25" name="__codelineno-2-25"></a>
<a id="__codelineno-2-26" name="__codelineno-2-26"></a><span class="c1"># --- 4. 优化循环 ---</span>
<a id="__codelineno-2-27" name="__codelineno-2-27"></a><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
<a id="__codelineno-2-28" name="__codelineno-2-28"></a>    <span class="c1"># 将梯度清零</span>
<a id="__codelineno-2-29" name="__codelineno-2-29"></a>    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-2-30" name="__codelineno-2-30"></a>
<a id="__codelineno-2-31" name="__codelineno-2-31"></a>    <span class="c1"># 定义 f(x)</span>
<a id="__codelineno-2-32" name="__codelineno-2-32"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x_in</span><span class="p">):</span>
<a id="__codelineno-2-33" name="__codelineno-2-33"></a>        <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x_in</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">5</span>
<a id="__codelineno-2-34" name="__codelineno-2-34"></a>
<a id="__codelineno-2-35" name="__codelineno-2-35"></a>    <span class="c1"># 在 (0, 1] 区间随机采样一个 mini-batch 的 x</span>
<a id="__codelineno-2-36" name="__codelineno-2-36"></a>    <span class="c1"># torch.rand 生成 [0, 1) 的值，对于我们的目的来说足够了</span>
<a id="__codelineno-2-37" name="__codelineno-2-37"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-2-38" name="__codelineno-2-38"></a>
<a id="__codelineno-2-39" name="__codelineno-2-39"></a>    <span class="c1"># 计算 f^(k)(x)</span>
<a id="__codelineno-2-40" name="__codelineno-2-40"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-2-41" name="__codelineno-2-41"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
<a id="__codelineno-2-42" name="__codelineno-2-42"></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<a id="__codelineno-2-43" name="__codelineno-2-43"></a>
<a id="__codelineno-2-44" name="__codelineno-2-44"></a>    <span class="c1"># 最终的输出</span>
<a id="__codelineno-2-45" name="__codelineno-2-45"></a>    <span class="n">f_k_x</span> <span class="o">=</span> <span class="n">y</span>
<a id="__codelineno-2-46" name="__codelineno-2-46"></a>
<a id="__codelineno-2-47" name="__codelineno-2-47"></a>    <span class="c1"># 定义目标值 (全为 1 的张量)</span>
<a id="__codelineno-2-48" name="__codelineno-2-48"></a>    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">f_k_x</span><span class="p">)</span>
<a id="__codelineno-2-49" name="__codelineno-2-49"></a>
<a id="__codelineno-2-50" name="__codelineno-2-50"></a>    <span class="c1"># 计算损失函数 (MSE)</span>
<a id="__codelineno-2-51" name="__codelineno-2-51"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">target</span> <span class="o">-</span> <span class="n">f_k_x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-2-52" name="__codelineno-2-52"></a>
<a id="__codelineno-2-53" name="__codelineno-2-53"></a>    <span class="c1"># 反向传播计算梯度</span>
<a id="__codelineno-2-54" name="__codelineno-2-54"></a>    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-2-55" name="__codelineno-2-55"></a>
<a id="__codelineno-2-56" name="__codelineno-2-56"></a>    <span class="c1"># 使用优化器更新参数 a, b, c</span>
<a id="__codelineno-2-57" name="__codelineno-2-57"></a>    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-2-58" name="__codelineno-2-58"></a>
<a id="__codelineno-2-59" name="__codelineno-2-59"></a>    <span class="c1"># 记录历史数据</span>
<a id="__codelineno-2-60" name="__codelineno-2-60"></a>    <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-2-61" name="__codelineno-2-61"></a>    <span class="n">a_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-2-62" name="__codelineno-2-62"></a>    <span class="n">b_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-2-63" name="__codelineno-2-63"></a>    <span class="n">c_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-2-64" name="__codelineno-2-64"></a>
<a id="__codelineno-2-65" name="__codelineno-2-65"></a>    <span class="c1"># 每 1000 步打印一次进度</span>
<a id="__codelineno-2-66" name="__codelineno-2-66"></a>    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">step</span> <span class="o">==</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-2-67" name="__codelineno-2-67"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Step </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="s2">&gt;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_steps</span><span class="p">))</span><span class="si">}}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">, "</span>
<a id="__codelineno-2-68" name="__codelineno-2-68"></a>              <span class="sa">f</span><span class="s2">"a = </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, b = </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, c = </span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-2-69" name="__codelineno-2-69"></a>
<a id="__codelineno-2-70" name="__codelineno-2-70"></a><span class="c1"># --- 5. 结果展示 ---</span>
<a id="__codelineno-2-71" name="__codelineno-2-71"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- 优化完成 ---"</span><span class="p">)</span>
<a id="__codelineno-2-72" name="__codelineno-2-72"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"固定迭代次数 k = </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-2-73" name="__codelineno-2-73"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"最终损失: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-2-74" name="__codelineno-2-74"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"优化后的参数: a = </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, b = </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, c = </span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<a id="__codelineno-2-75" name="__codelineno-2-75"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"参数和 a+b+c = </span><span class="si">{</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="o">+</span><span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (理论上应趋近于 1)"</span><span class="p">)</span>
<a id="__codelineno-2-76" name="__codelineno-2-76"></a>
<a id="__codelineno-2-77" name="__codelineno-2-77"></a>
<a id="__codelineno-2-78" name="__codelineno-2-78"></a><span class="c1"># --- 6. 可视化 ---</span>
<a id="__codelineno-2-79" name="__codelineno-2-79"></a>
<a id="__codelineno-2-80" name="__codelineno-2-80"></a><span class="c1"># 绘制损失和参数值的变化过程</span>
<a id="__codelineno-2-81" name="__codelineno-2-81"></a><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">'seaborn-v0_8-whitegrid'</span><span class="p">)</span>
<a id="__codelineno-2-82" name="__codelineno-2-82"></a><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-83" name="__codelineno-2-83"></a>
<a id="__codelineno-2-84" name="__codelineno-2-84"></a><span class="c1"># 绘制损失函数</span>
<a id="__codelineno-2-85" name="__codelineno-2-85"></a><span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Loss (MSE)'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span>
<a id="__codelineno-2-86" name="__codelineno-2-86"></a><span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<a id="__codelineno-2-87" name="__codelineno-2-87"></a><span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Loss and Parameter Evolution (k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
<a id="__codelineno-2-88" name="__codelineno-2-88"></a><span class="n">ax1</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">'log'</span><span class="p">)</span> <span class="c1"># 使用对数坐标轴以便观察</span>
<a id="__codelineno-2-89" name="__codelineno-2-89"></a><span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<a id="__codelineno-2-90" name="__codelineno-2-90"></a>
<a id="__codelineno-2-91" name="__codelineno-2-91"></a><span class="c1"># 绘制参数 a, b, c</span>
<a id="__codelineno-2-92" name="__codelineno-2-92"></a><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'a'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">)</span>
<a id="__codelineno-2-93" name="__codelineno-2-93"></a><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
<a id="__codelineno-2-94" name="__codelineno-2-94"></a><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'c'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">':'</span><span class="p">)</span>
<a id="__codelineno-2-95" name="__codelineno-2-95"></a><span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Optimization Step'</span><span class="p">)</span>
<a id="__codelineno-2-96" name="__codelineno-2-96"></a><span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Parameter Value'</span><span class="p">)</span>
<a id="__codelineno-2-97" name="__codelineno-2-97"></a><span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<a id="__codelineno-2-98" name="__codelineno-2-98"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<a id="__codelineno-2-99" name="__codelineno-2-99"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<a id="__codelineno-2-100" name="__codelineno-2-100"></a>
<a id="__codelineno-2-101" name="__codelineno-2-101"></a><span class="c1"># 绘制优化前后的函数 f(x) 和 f^(k)(x)</span>
<a id="__codelineno-2-102" name="__codelineno-2-102"></a><span class="n">x_plot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-2-103" name="__codelineno-2-103"></a>
<a id="__codelineno-2-104" name="__codelineno-2-104"></a><span class="c1"># 优化后的函数</span>
<a id="__codelineno-2-105" name="__codelineno-2-105"></a><span class="k">def</span><span class="w"> </span><span class="nf">f_final</span><span class="p">(</span><span class="n">x_in</span><span class="p">):</span>
<a id="__codelineno-2-106" name="__codelineno-2-106"></a>    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_in</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">c</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">5</span>
<a id="__codelineno-2-107" name="__codelineno-2-107"></a>
<a id="__codelineno-2-108" name="__codelineno-2-108"></a><span class="c1"># 初始函数</span>
<a id="__codelineno-2-109" name="__codelineno-2-109"></a><span class="k">def</span><span class="w"> </span><span class="nf">f_initial</span><span class="p">(</span><span class="n">x_in</span><span class="p">):</span>
<a id="__codelineno-2-110" name="__codelineno-2-110"></a>    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">x_in</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">x_in</span><span class="o">**</span><span class="mi">5</span>
<a id="__codelineno-2-111" name="__codelineno-2-111"></a>
<a id="__codelineno-2-112" name="__codelineno-2-112"></a><span class="c1"># 计算 k 次迭代</span>
<a id="__codelineno-2-113" name="__codelineno-2-113"></a><span class="n">y_final_k</span> <span class="o">=</span> <span class="n">x_plot</span>
<a id="__codelineno-2-114" name="__codelineno-2-114"></a><span class="n">y_initial_k</span> <span class="o">=</span> <span class="n">x_plot</span>
<a id="__codelineno-2-115" name="__codelineno-2-115"></a><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
<a id="__codelineno-2-116" name="__codelineno-2-116"></a>    <span class="n">y_final_k</span> <span class="o">=</span> <span class="n">f_final</span><span class="p">(</span><span class="n">y_final_k</span><span class="p">)</span>
<a id="__codelineno-2-117" name="__codelineno-2-117"></a>    <span class="n">y_initial_k</span> <span class="o">=</span> <span class="n">f_initial</span><span class="p">(</span><span class="n">y_initial_k</span><span class="p">)</span>
<a id="__codelineno-2-118" name="__codelineno-2-118"></a>
<a id="__codelineno-2-119" name="__codelineno-2-119"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<a id="__codelineno-2-120" name="__codelineno-2-120"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">f_initial</span><span class="p">(</span><span class="n">x_plot</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s1">'b--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Initial $f(x) = x-x^3+x^5$'</span><span class="p">)</span>
<a id="__codelineno-2-121" name="__codelineno-2-121"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">f_final</span><span class="p">(</span><span class="n">x_plot</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s1">'g-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Optimized $f(x)$ (k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
<a id="__codelineno-2-122" name="__codelineno-2-122"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_final_k</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s1">'r-'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Optimized $f^</span><span class="se">{{</span><span class="s1">(</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)</span><span class="se">}}</span><span class="s1">(x)$'</span><span class="p">)</span>
<a id="__codelineno-2-123" name="__codelineno-2-123"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">x_plot</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s1">'k:'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'$y=x$ (identity)'</span><span class="p">)</span>
<a id="__codelineno-2-124" name="__codelineno-2-124"></a><span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Target y=1'</span><span class="p">)</span>
<a id="__codelineno-2-125" name="__codelineno-2-125"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Comparison of Functions (k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
<a id="__codelineno-2-126" name="__codelineno-2-126"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<a id="__codelineno-2-127" name="__codelineno-2-127"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'f(x) or $f^{(k)}(x)$'</span><span class="p">)</span>
<a id="__codelineno-2-128" name="__codelineno-2-128"></a><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<a id="__codelineno-2-129" name="__codelineno-2-129"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<a id="__codelineno-2-130" name="__codelineno-2-130"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-2-131" name="__codelineno-2-131"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
<p>这里我选择的初始值是任意选取的 <span class="arithmatex">\(a=1,b=-1,c=1\)</span> 满足 <span class="arithmatex">\(a+b+c=1\)</span>，下面是（截断的）日志输出：</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-3-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-3-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-3-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-3-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-3-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-3-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-3-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-3-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-3-10">10</a></span>
<span class="normal"><a href="#__codelineno-3-11">11</a></span>
<span class="normal"><a href="#__codelineno-3-12">12</a></span>
<span class="normal"><a href="#__codelineno-3-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a>开始优化... k=5, 初始值 a=1.00, b=-1.00, c=1.00
<a id="__codelineno-3-2" name="__codelineno-3-2"></a>Step      0: Loss = 0.58154202, a = 1.0000, b = -0.9999, c = 1.0000
<a id="__codelineno-3-3" name="__codelineno-3-3"></a>Step   1000: Loss = 0.52524936, a = 1.0461, b = -1.0118, c = 0.9704
<a id="__codelineno-3-4" name="__codelineno-3-4"></a>Step   2000: Loss = 0.46161765, a = 1.0933, b = -1.0257, c = 0.9381
<a id="__codelineno-3-5" name="__codelineno-3-5"></a>......
<a id="__codelineno-3-6" name="__codelineno-3-6"></a>Step  99000: Loss = 0.00160778, a = 3.1010, b = -3.4233, c = 1.3183
<a id="__codelineno-3-7" name="__codelineno-3-7"></a>Step  99999: Loss = 0.00136968, a = 3.1010, b = -3.4236, c = 1.3181
<a id="__codelineno-3-8" name="__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9"></a>--- 优化完成 ---
<a id="__codelineno-3-10" name="__codelineno-3-10"></a>固定迭代次数 k = 5
<a id="__codelineno-3-11" name="__codelineno-3-11"></a>最终损失: 0.00136968
<a id="__codelineno-3-12" name="__codelineno-3-12"></a>优化后的参数: a = 3.1010, b = -3.4236, c = 1.3181
<a id="__codelineno-3-13" name="__codelineno-3-13"></a>参数和 a+b+c = 0.9954 (理论上应趋近于 1)
</code></pre></div></td></tr></table></div>
<p>MSE 干到了 1e-3 量级。下面是训练过程的损失曲线、参数变化曲线和最终函数的拟合图线：</p>
<p><img alt="loss" src="../optimizer_pics/loss.png"/></p>
<p><img alt="curve" src="../optimizer_pics/curve.png"/></p>
<p>当然也可以拿牛顿法训，毕竟就三个参数，但是我自己实测训练不大稳定，时不时就训炸了。</p>
<p>相比之下，这是 Muon 作者提出的参数配置：<span class="arithmatex">\(a=3.4445,b=−4.7750,c=2.0315\)</span></p>
<p><img alt="curve_2" src="../optimizer_pics/curve_2.png"/></p>
<p>这是 Muon 优化器在这两个损失地形下面的表现：</p>
<p><img alt="rastrigin_Muon" src="../optimizer_pics/rastrigin_SingleDeviceMuon.gif"/></p>
<p><img alt="rosenbrock_Muon" src="../optimizer_pics/rosenbrock_SingleDeviceMuon.gif"/></p>
<p>但是，由于层数和维度比较低，这个地形没有发挥出 Muon 的 Newton-Schulz 迭代真正的潜力！</p>
<p>我们来看看 Muon 在 Fashion-MNIST 上面的性能：</p>
<p>下面是官方参数 <span class="arithmatex">\(a,b,c=(3.4445,−4.7750,2.0315)\)</span> 的损失曲线、准确率和最优附近的损失地形。</p>
<p><img alt="SingleDeviceMuonWithAuxAdam_performance_curves" src="../optimizer_pics/SingleDeviceMuonWithAuxAdam_performance_curves.png"/></p>
<p><img alt="SingleDeviceMuonWithAuxAdam_landscape_pca" src="../optimizer_pics/SingleDeviceMuonWithAuxAdam_landscape_pca.png"/></p>
<p>下面是我自己跑出来的参数 <span class="arithmatex">\(a,b,c=(3.1010, -3.4236, 1.3181)\)</span> 的损失曲线、准确率和最优附近的损失地形。（甚至 Hyperopt 搜出来的学习率都一样）</p>
<p><img alt="SingleDeviceMuonWithAuxAdam_performance_curves" src="../optimizer_pics/SingleDeviceMuonWithAuxAdam_performance_curves_my.png"/></p>
<p><img alt="SingleDeviceMuonWithAuxAdam_landscape_pca" src="../optimizer_pics/SingleDeviceMuonWithAuxAdam_landscape_pca_my.png"/></p>
<p>真的不是同一张图哈，可以自行放大对比一下。</p>
<p>可以看到 Newton-Shculz 迭代需要的这个参数容差还比较大，只要不是特别离谱，有理有据搜索出来的参数基本上效果都差不多。</p>
<p>Muon 在这个任务上面的表现已经到了逆天的水平了。不到 2000 个 batch 就能让 train_loss 降到 0.1 左右，让 acc 上升到 0.9 也只用了大约 500 个 batch。简直干趴下之前一众优化算法。</p>
<p>下面，让我们看看 Muon 的代码（为展示原理这里只给出单设备的）：</p>
<details>
<summary> Muon 优化器的实现 </summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">  1</a></span>
<span class="normal"><a href="#__codelineno-4-2">  2</a></span>
<span class="normal"><a href="#__codelineno-4-3">  3</a></span>
<span class="normal"><a href="#__codelineno-4-4">  4</a></span>
<span class="normal"><a href="#__codelineno-4-5">  5</a></span>
<span class="normal"><a href="#__codelineno-4-6">  6</a></span>
<span class="normal"><a href="#__codelineno-4-7">  7</a></span>
<span class="normal"><a href="#__codelineno-4-8">  8</a></span>
<span class="normal"><a href="#__codelineno-4-9">  9</a></span>
<span class="normal"><a href="#__codelineno-4-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-4-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-4-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-4-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-4-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-4-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-4-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-4-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-4-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-4-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-4-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-4-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-4-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-4-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-4-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-4-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-4-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-4-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-4-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-4-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-4-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-4-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-4-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-4-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-4-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-4-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-4-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-4-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-4-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-4-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-4-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-4-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-4-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-4-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-4-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-4-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-4-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-4-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-4-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-4-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-4-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-4-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-4-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-4-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-4-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-4-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-4-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-4-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-4-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-4-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-4-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-4-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-4-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-4-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-4-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-4-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-4-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-4-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-4-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-4-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-4-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-4-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-4-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-4-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-4-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-4-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-4-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-4-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-4-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-4-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-4-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-4-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-4-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-4-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-4-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-4-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-4-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-4-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-4-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-4-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-4-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-4-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-4-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-4-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-4-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-4-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-4-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-4-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-4-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-4-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-4-100">100</a></span>
<span class="normal"><a href="#__codelineno-4-101">101</a></span>
<span class="normal"><a href="#__codelineno-4-102">102</a></span>
<span class="normal"><a href="#__codelineno-4-103">103</a></span>
<span class="normal"><a href="#__codelineno-4-104">104</a></span>
<span class="normal"><a href="#__codelineno-4-105">105</a></span>
<span class="normal"><a href="#__codelineno-4-106">106</a></span>
<span class="normal"><a href="#__codelineno-4-107">107</a></span>
<span class="normal"><a href="#__codelineno-4-108">108</a></span>
<span class="normal"><a href="#__codelineno-4-109">109</a></span>
<span class="normal"><a href="#__codelineno-4-110">110</a></span>
<span class="normal"><a href="#__codelineno-4-111">111</a></span>
<span class="normal"><a href="#__codelineno-4-112">112</a></span>
<span class="normal"><a href="#__codelineno-4-113">113</a></span>
<span class="normal"><a href="#__codelineno-4-114">114</a></span>
<span class="normal"><a href="#__codelineno-4-115">115</a></span>
<span class="normal"><a href="#__codelineno-4-116">116</a></span>
<span class="normal"><a href="#__codelineno-4-117">117</a></span>
<span class="normal"><a href="#__codelineno-4-118">118</a></span>
<span class="normal"><a href="#__codelineno-4-119">119</a></span>
<span class="normal"><a href="#__codelineno-4-120">120</a></span>
<span class="normal"><a href="#__codelineno-4-121">121</a></span>
<span class="normal"><a href="#__codelineno-4-122">122</a></span>
<span class="normal"><a href="#__codelineno-4-123">123</a></span>
<span class="normal"><a href="#__codelineno-4-124">124</a></span>
<span class="normal"><a href="#__codelineno-4-125">125</a></span>
<span class="normal"><a href="#__codelineno-4-126">126</a></span>
<span class="normal"><a href="#__codelineno-4-127">127</a></span>
<span class="normal"><a href="#__codelineno-4-128">128</a></span>
<span class="normal"><a href="#__codelineno-4-129">129</a></span>
<span class="normal"><a href="#__codelineno-4-130">130</a></span>
<span class="normal"><a href="#__codelineno-4-131">131</a></span>
<span class="normal"><a href="#__codelineno-4-132">132</a></span>
<span class="normal"><a href="#__codelineno-4-133">133</a></span>
<span class="normal"><a href="#__codelineno-4-134">134</a></span>
<span class="normal"><a href="#__codelineno-4-135">135</a></span>
<span class="normal"><a href="#__codelineno-4-136">136</a></span>
<span class="normal"><a href="#__codelineno-4-137">137</a></span>
<span class="normal"><a href="#__codelineno-4-138">138</a></span>
<span class="normal"><a href="#__codelineno-4-139">139</a></span>
<span class="normal"><a href="#__codelineno-4-140">140</a></span>
<span class="normal"><a href="#__codelineno-4-141">141</a></span>
<span class="normal"><a href="#__codelineno-4-142">142</a></span>
<span class="normal"><a href="#__codelineno-4-143">143</a></span>
<span class="normal"><a href="#__codelineno-4-144">144</a></span>
<span class="normal"><a href="#__codelineno-4-145">145</a></span>
<span class="normal"><a href="#__codelineno-4-146">146</a></span>
<span class="normal"><a href="#__codelineno-4-147">147</a></span>
<span class="normal"><a href="#__codelineno-4-148">148</a></span>
<span class="normal"><a href="#__codelineno-4-149">149</a></span>
<span class="normal"><a href="#__codelineno-4-150">150</a></span>
<span class="normal"><a href="#__codelineno-4-151">151</a></span>
<span class="normal"><a href="#__codelineno-4-152">152</a></span>
<span class="normal"><a href="#__codelineno-4-153">153</a></span>
<span class="normal"><a href="#__codelineno-4-154">154</a></span>
<span class="normal"><a href="#__codelineno-4-155">155</a></span>
<span class="normal"><a href="#__codelineno-4-156">156</a></span>
<span class="normal"><a href="#__codelineno-4-157">157</a></span>
<span class="normal"><a href="#__codelineno-4-158">158</a></span>
<span class="normal"><a href="#__codelineno-4-159">159</a></span>
<span class="normal"><a href="#__codelineno-4-160">160</a></span>
<span class="normal"><a href="#__codelineno-4-161">161</a></span>
<span class="normal"><a href="#__codelineno-4-162">162</a></span>
<span class="normal"><a href="#__codelineno-4-163">163</a></span>
<span class="normal"><a href="#__codelineno-4-164">164</a></span>
<span class="normal"><a href="#__codelineno-4-165">165</a></span>
<span class="normal"><a href="#__codelineno-4-166">166</a></span>
<span class="normal"><a href="#__codelineno-4-167">167</a></span>
<span class="normal"><a href="#__codelineno-4-168">168</a></span>
<span class="normal"><a href="#__codelineno-4-169">169</a></span>
<span class="normal"><a href="#__codelineno-4-170">170</a></span>
<span class="normal"><a href="#__codelineno-4-171">171</a></span>
<span class="normal"><a href="#__codelineno-4-172">172</a></span>
<span class="normal"><a href="#__codelineno-4-173">173</a></span>
<span class="normal"><a href="#__codelineno-4-174">174</a></span>
<span class="normal"><a href="#__codelineno-4-175">175</a></span>
<span class="normal"><a href="#__codelineno-4-176">176</a></span>
<span class="normal"><a href="#__codelineno-4-177">177</a></span>
<span class="normal"><a href="#__codelineno-4-178">178</a></span>
<span class="normal"><a href="#__codelineno-4-179">179</a></span>
<span class="normal"><a href="#__codelineno-4-180">180</a></span>
<span class="normal"><a href="#__codelineno-4-181">181</a></span>
<span class="normal"><a href="#__codelineno-4-182">182</a></span>
<span class="normal"><a href="#__codelineno-4-183">183</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a><span class="c1"># 导入 PyTorch 分布式训练库</span>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a>
<a id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="c1"># --- 核心数学函数 ---</span>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="k">def</span><span class="w"> </span><span class="nf">zeropower_via_newtonschulz5</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<a id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-4-8" name="__codelineno-4-8"></a><span class="sd">    使用牛顿-舒尔茨迭代计算矩阵 G 的零次幂，即对 G 进行正交化。</span>
<a id="__codelineno-4-9" name="__codelineno-4-9"></a><span class="sd">    我们选择使用一个五次迭代，其系数经过精心选择，以最大化在零点处的斜率。</span>
<a id="__codelineno-4-10" name="__codelineno-4-10"></a><span class="sd">    为了最小化迭代步数，经验表明，即使迭代在区间上不再完全收敛到1，持续增加零点处的斜率也是有效的。</span>
<a id="__codelineno-4-11" name="__codelineno-4-11"></a><span class="sd">    因此，这个迭代不会精确地产生 UV^T (其中 U 和 V 是正交矩阵)，而是产生类似 US'V^T 的东西，</span>
<a id="__codelineno-4-12" name="__codelineno-4-12"></a><span class="sd">    其中 S' 是对角矩阵，其对角线元素 S'_{ii} 大约在 Uniform(0.5, 1.5) 分布。</span>
<a id="__codelineno-4-13" name="__codelineno-4-13"></a><span class="sd">    事实证明，相对于精确的 UV^T，这种近似完全不会损害模型性能。(其中 USV^T = G 是 G 的奇异值分解)。</span>
<a id="__codelineno-4-14" name="__codelineno-4-14"></a><span class="sd">    """</span>
<a id="__codelineno-4-15" name="__codelineno-4-15"></a>    <span class="c1"># G 的维度必须至少为 2 (即一个矩阵)。支持批处理矩阵。</span>
<a id="__codelineno-4-16" name="__codelineno-4-16"></a>    <span class="k">assert</span> <span class="n">G</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="mi">2</span> 
<a id="__codelineno-4-17" name="__codelineno-4-17"></a>    <span class="c1"># 五次迭代的预计算系数</span>
<a id="__codelineno-4-18" name="__codelineno-4-18"></a>    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="mf">3.4445</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.7750</span><span class="p">,</span>  <span class="mf">2.0315</span><span class="p">)</span>
<a id="__codelineno-4-19" name="__codelineno-4-19"></a>    <span class="c1"># 为了计算效率和稳定性，将输入矩阵转换为 bfloat16 类型</span>
<a id="__codelineno-4-20" name="__codelineno-4-20"></a>    <span class="n">X</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">()</span>
<a id="__codelineno-4-21" name="__codelineno-4-21"></a>
<a id="__codelineno-4-22" name="__codelineno-4-22"></a>    <span class="c1"># 如果矩阵是“高瘦”的 (行数 &gt; 列数)，则进行转置。</span>
<a id="__codelineno-4-23" name="__codelineno-4-23"></a>    <span class="c1"># 矩阵乘法通常在“矮胖”矩阵上更高效。</span>
<a id="__codelineno-4-24" name="__codelineno-4-24"></a>    <span class="k">if</span> <span class="n">G</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">G</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-4-25" name="__codelineno-4-25"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mT</span>
<a id="__codelineno-4-26" name="__codelineno-4-26"></a>
<a id="__codelineno-4-27" name="__codelineno-4-27"></a>    <span class="c1"># 关键步骤：确保谱范数 (spectral norm) 最多为 1。</span>
<a id="__codelineno-4-28" name="__codelineno-4-28"></a>    <span class="c1"># 牛顿-舒尔茨迭代的收敛性要求输入矩阵的谱范数 &lt;= 1。</span>
<a id="__codelineno-4-29" name="__codelineno-4-29"></a>    <span class="c1"># 这里通过除以其谱范数（矩阵的最大奇异值）来进行归一化。</span>
<a id="__codelineno-4-30" name="__codelineno-4-30"></a>    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>
<a id="__codelineno-4-31" name="__codelineno-4-31"></a>
<a id="__codelineno-4-32" name="__codelineno-4-32"></a>    <span class="c1"># 执行指定步数的牛顿-舒尔茨迭代</span>
<a id="__codelineno-4-33" name="__codelineno-4-33"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
<a id="__codelineno-4-34" name="__codelineno-4-34"></a>        <span class="n">A</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">mT</span>  <span class="c1"># 计算 X * X^T</span>
<a id="__codelineno-4-35" name="__codelineno-4-35"></a>        <span class="c1"># 使用优化的策略计算五次多项式，避免高次幂的直接计算</span>
<a id="__codelineno-4-36" name="__codelineno-4-36"></a>        <span class="n">B</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">A</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">A</span> <span class="o">@</span> <span class="n">A</span> 
<a id="__codelineno-4-37" name="__codelineno-4-37"></a>        <span class="c1"># 更新 X，形式为 X_{k+1} = p(X_k @ X_k^T) @ X_k</span>
<a id="__codelineno-4-38" name="__codelineno-4-38"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">B</span> <span class="o">@</span> <span class="n">X</span>
<a id="__codelineno-4-39" name="__codelineno-4-39"></a>
<a id="__codelineno-4-40" name="__codelineno-4-40"></a>    <span class="c1"># 如果之前转置了，现在转置回来</span>
<a id="__codelineno-4-41" name="__codelineno-4-41"></a>    <span class="k">if</span> <span class="n">G</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">G</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-4-42" name="__codelineno-4-42"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mT</span>
<a id="__codelineno-4-43" name="__codelineno-4-43"></a>
<a id="__codelineno-4-44" name="__codelineno-4-44"></a>    <span class="c1"># 返回近似正交化的矩阵</span>
<a id="__codelineno-4-45" name="__codelineno-4-45"></a>    <span class="k">return</span> <span class="n">X</span>
<a id="__codelineno-4-46" name="__codelineno-4-46"></a>
<a id="__codelineno-4-47" name="__codelineno-4-47"></a>
<a id="__codelineno-4-48" name="__codelineno-4-48"></a><span class="c1"># --- Muon 更新规则 ---</span>
<a id="__codelineno-4-49" name="__codelineno-4-49"></a><span class="k">def</span><span class="w"> </span><span class="nf">muon_update</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">ns_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-4-50" name="__codelineno-4-50"></a><span class="w">    </span><span class="sd">"""计算单步的 Muon 更新量"""</span>
<a id="__codelineno-4-51" name="__codelineno-4-51"></a>    <span class="c1"># 1. 标准的动量更新：momentum = beta * momentum + (1 - beta) * grad</span>
<a id="__codelineno-4-52" name="__codelineno-4-52"></a>    <span class="n">momentum</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta</span><span class="p">)</span>
<a id="__codelineno-4-53" name="__codelineno-4-53"></a>
<a id="__codelineno-4-54" name="__codelineno-4-54"></a>    <span class="c1"># 2. 计算更新方向：如果使用 Nesterov 动量，则为 grad + beta * momentum；否则就是更新后的动量。</span>
<a id="__codelineno-4-55" name="__codelineno-4-55"></a>    <span class="n">update</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">momentum</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="k">if</span> <span class="n">nesterov</span> <span class="k">else</span> <span class="n">momentum</span>
<a id="__codelineno-4-56" name="__codelineno-4-56"></a>
<a id="__codelineno-4-57" name="__codelineno-4-57"></a>    <span class="c1"># 3. 处理卷积核：如果更新对象是4D的卷积核 (out, in, h, w)，</span>
<a id="__codelineno-4-58" name="__codelineno-4-58"></a>    <span class="c1">#    则将其展平为2D矩阵 (out, in*h*w)，以便进行正交化。</span>
<a id="__codelineno-4-59" name="__codelineno-4-59"></a>    <span class="k">if</span> <span class="n">update</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span> 
<a id="__codelineno-4-60" name="__codelineno-4-60"></a>        <span class="n">update</span> <span class="o">=</span> <span class="n">update</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">update</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-4-61" name="__codelineno-4-61"></a>
<a id="__codelineno-4-62" name="__codelineno-4-62"></a>    <span class="c1"># 4. 核心步骤：将计算出的更新方向进行正交化。</span>
<a id="__codelineno-4-63" name="__codelineno-4-63"></a>    <span class="n">update</span> <span class="o">=</span> <span class="n">zeropower_via_newtonschulz5</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">ns_steps</span><span class="p">)</span>
<a id="__codelineno-4-64" name="__codelineno-4-64"></a>
<a id="__codelineno-4-65" name="__codelineno-4-65"></a>    <span class="c1"># 5. 尺寸缩放：根据矩阵的形状进行缩放，以保持更新的谱范数单位一致。</span>
<a id="__codelineno-4-66" name="__codelineno-4-66"></a>    <span class="n">update</span> <span class="o">*=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">grad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">grad</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>
<a id="__codelineno-4-67" name="__codelineno-4-67"></a>    <span class="k">return</span> <span class="n">update</span>
<a id="__codelineno-4-68" name="__codelineno-4-68"></a>
<a id="__codelineno-4-69" name="__codelineno-4-69"></a><span class="c1"># --- Muon 优化器 (单设备版本) ---</span>
<a id="__codelineno-4-70" name="__codelineno-4-70"></a><span class="k">class</span><span class="w"> </span><span class="nc">SingleDeviceMuon</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
<a id="__codelineno-4-71" name="__codelineno-4-71"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-4-72" name="__codelineno-4-72"></a><span class="sd">    用于非分布式设置的 Muon 变体。</span>
<a id="__codelineno-4-73" name="__codelineno-4-73"></a><span class="sd">    """</span>
<a id="__codelineno-4-74" name="__codelineno-4-74"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-4-75" name="__codelineno-4-75"></a><span class="sd">    Muon - 通过牛顿-舒尔茨正交化的动量优化器</span>
<a id="__codelineno-4-76" name="__codelineno-4-76"></a>
<a id="__codelineno-4-77" name="__codelineno-4-77"></a><span class="sd">    Muon 内部运行标准的 SGD-momentum, 然后执行一个正交化后处理步骤，</span>
<a id="__codelineno-4-78" name="__codelineno-4-78"></a><span class="sd">    其中每个 2D 参数的更新被替换为最近的正交矩阵。</span>
<a id="__codelineno-4-79" name="__codelineno-4-79"></a><span class="sd">    我们使用牛顿-舒尔茨迭代来高效地进行正交化，其优点是可以在 GPU 上稳定地以 bfloat16 运行。</span>
<a id="__codelineno-4-80" name="__codelineno-4-80"></a>
<a id="__codelineno-4-81" name="__codelineno-4-81"></a><span class="sd">    Muon 只应用于隐藏层的权重。输入嵌入、最终输出层以及任何内部的增益或偏置项</span>
<a id="__codelineno-4-82" name="__codelineno-4-82"></a><span class="sd">    应使用标准方法（如 AdamW）进行优化。</span>
<a id="__codelineno-4-83" name="__codelineno-4-83"></a><span class="sd">    隐藏的卷积权重可以通过将其视为 2D 并折叠其最后3个维度来使用 Muon 进行训练。</span>
<a id="__codelineno-4-84" name="__codelineno-4-84"></a>
<a id="__codelineno-4-85" name="__codelineno-4-85"></a><span class="sd">    参数:</span>
<a id="__codelineno-4-86" name="__codelineno-4-86"></a><span class="sd">        lr: 学习率，单位是每次更新的谱范数。</span>
<a id="__codelineno-4-87" name="__codelineno-4-87"></a><span class="sd">        weight_decay: AdamW 风格的权重衰减。</span>
<a id="__codelineno-4-88" name="__codelineno-4-88"></a><span class="sd">        momentum: 动量系数，通常 0.95 效果不错。</span>
<a id="__codelineno-4-89" name="__codelineno-4-89"></a><span class="sd">    """</span>
<a id="__codelineno-4-90" name="__codelineno-4-90"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
<a id="__codelineno-4-91" name="__codelineno-4-91"></a>        <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
<a id="__codelineno-4-92" name="__codelineno-4-92"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>
<a id="__codelineno-4-93" name="__codelineno-4-93"></a>
<a id="__codelineno-4-94" name="__codelineno-4-94"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-4-95" name="__codelineno-4-95"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-4-96" name="__codelineno-4-96"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-4-97" name="__codelineno-4-97"></a>        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-4-98" name="__codelineno-4-98"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
<a id="__codelineno-4-99" name="__codelineno-4-99"></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>
<a id="__codelineno-4-100" name="__codelineno-4-100"></a>
<a id="__codelineno-4-101" name="__codelineno-4-101"></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
<a id="__codelineno-4-102" name="__codelineno-4-102"></a>            <span class="c1"># 逻辑与分布式版本相同，但没有了复杂的分布式通信代码</span>
<a id="__codelineno-4-103" name="__codelineno-4-103"></a>            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">"params"</span><span class="p">]:</span>
<a id="__codelineno-4-104" name="__codelineno-4-104"></a>                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-4-105" name="__codelineno-4-105"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-106" name="__codelineno-4-106"></a>                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
<a id="__codelineno-4-107" name="__codelineno-4-107"></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-4-108" name="__codelineno-4-108"></a>                    <span class="n">state</span><span class="p">[</span><span class="s2">"momentum_buffer"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-109" name="__codelineno-4-109"></a>                <span class="n">update</span> <span class="o">=</span> <span class="n">muon_update</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="s2">"momentum_buffer"</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s2">"momentum"</span><span class="p">])</span>
<a id="__codelineno-4-110" name="__codelineno-4-110"></a>                <span class="n">p</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
<a id="__codelineno-4-111" name="__codelineno-4-111"></a>                <span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">update</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">])</span>
<a id="__codelineno-4-112" name="__codelineno-4-112"></a>
<a id="__codelineno-4-113" name="__codelineno-4-113"></a>        <span class="k">return</span> <span class="n">loss</span>
<a id="__codelineno-4-114" name="__codelineno-4-114"></a>
<a id="__codelineno-4-115" name="__codelineno-4-115"></a><span class="c1"># --- Adam 更新规则 (辅助函数) ---</span>
<a id="__codelineno-4-116" name="__codelineno-4-116"></a><span class="k">def</span><span class="w"> </span><span class="nf">adam_update</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">buf1</span><span class="p">,</span> <span class="n">buf2</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
<a id="__codelineno-4-117" name="__codelineno-4-117"></a><span class="w">    </span><span class="sd">"""标准的 Adam 更新规则"""</span>
<a id="__codelineno-4-118" name="__codelineno-4-118"></a>    <span class="c1"># 更新一阶矩 (动量)</span>
<a id="__codelineno-4-119" name="__codelineno-4-119"></a>    <span class="n">buf1</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-4-120" name="__codelineno-4-120"></a>    <span class="c1"># 更新二阶矩 (RMSProp 部分)</span>
<a id="__codelineno-4-121" name="__codelineno-4-121"></a>    <span class="n">buf2</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-4-122" name="__codelineno-4-122"></a>    <span class="c1"># 偏差修正</span>
<a id="__codelineno-4-123" name="__codelineno-4-123"></a>    <span class="n">buf1c</span> <span class="o">=</span> <span class="n">buf1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="n">step</span><span class="p">)</span>
<a id="__codelineno-4-124" name="__codelineno-4-124"></a>    <span class="n">buf2c</span> <span class="o">=</span> <span class="n">buf2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="n">step</span><span class="p">)</span>
<a id="__codelineno-4-125" name="__codelineno-4-125"></a>    <span class="c1"># 计算更新量</span>
<a id="__codelineno-4-126" name="__codelineno-4-126"></a>    <span class="k">return</span> <span class="n">buf1c</span> <span class="o">/</span> <span class="p">(</span><span class="n">buf2c</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
<a id="__codelineno-4-127" name="__codelineno-4-127"></a>
<a id="__codelineno-4-128" name="__codelineno-4-128"></a><span class="c1"># --- 混合优化器 (单设备版本) ---</span>
<a id="__codelineno-4-129" name="__codelineno-4-129"></a><span class="k">class</span><span class="w"> </span><span class="nc">SingleDeviceMuonWithAuxAdam</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
<a id="__codelineno-4-130" name="__codelineno-4-130"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-4-131" name="__codelineno-4-131"></a><span class="sd">    MuonWithAuxAdam 的非分布式版本。</span>
<a id="__codelineno-4-132" name="__codelineno-4-132"></a><span class="sd">    """</span>
<a id="__codelineno-4-133" name="__codelineno-4-133"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_groups</span><span class="p">):</span>
<a id="__codelineno-4-134" name="__codelineno-4-134"></a>        <span class="c1"># 初始化逻辑与分布式版本相同</span>
<a id="__codelineno-4-135" name="__codelineno-4-135"></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">param_groups</span><span class="p">:</span>
<a id="__codelineno-4-136" name="__codelineno-4-136"></a>            <span class="k">assert</span> <span class="s2">"use_muon"</span> <span class="ow">in</span> <span class="n">group</span>
<a id="__codelineno-4-137" name="__codelineno-4-137"></a>            <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s2">"use_muon"</span><span class="p">]:</span>
<a id="__codelineno-4-138" name="__codelineno-4-138"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
<a id="__codelineno-4-139" name="__codelineno-4-139"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"momentum"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"momentum"</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
<a id="__codelineno-4-140" name="__codelineno-4-140"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"weight_decay"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-4-141" name="__codelineno-4-141"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-4-142" name="__codelineno-4-142"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">3e-4</span><span class="p">)</span>
<a id="__codelineno-4-143" name="__codelineno-4-143"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"betas"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"betas"</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">))</span>
<a id="__codelineno-4-144" name="__codelineno-4-144"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"eps"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eps"</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
<a id="__codelineno-4-145" name="__codelineno-4-145"></a>                <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"weight_decay"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-4-146" name="__codelineno-4-146"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">param_groups</span><span class="p">,</span> <span class="nb">dict</span><span class="p">())</span>
<a id="__codelineno-4-147" name="__codelineno-4-147"></a>
<a id="__codelineno-4-148" name="__codelineno-4-148"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-4-149" name="__codelineno-4-149"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-4-150" name="__codelineno-4-150"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-4-151" name="__codelineno-4-151"></a>        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-4-152" name="__codelineno-4-152"></a>            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
<a id="__codelineno-4-153" name="__codelineno-4-153"></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>
<a id="__codelineno-4-154" name="__codelineno-4-154"></a>
<a id="__codelineno-4-155" name="__codelineno-4-155"></a>        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
<a id="__codelineno-4-156" name="__codelineno-4-156"></a>            <span class="k">if</span> <span class="n">group</span><span class="p">[</span><span class="s2">"use_muon"</span><span class="p">]:</span>
<a id="__codelineno-4-157" name="__codelineno-4-157"></a>                <span class="c1"># 单设备 Muon 更新逻辑</span>
<a id="__codelineno-4-158" name="__codelineno-4-158"></a>                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">"params"</span><span class="p">]:</span>
<a id="__codelineno-4-159" name="__codelineno-4-159"></a>                    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-4-160" name="__codelineno-4-160"></a>                        <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-161" name="__codelineno-4-161"></a>                    <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
<a id="__codelineno-4-162" name="__codelineno-4-162"></a>                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-4-163" name="__codelineno-4-163"></a>                        <span class="n">state</span><span class="p">[</span><span class="s2">"momentum_buffer"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-164" name="__codelineno-4-164"></a>                    <span class="n">update</span> <span class="o">=</span> <span class="n">muon_update</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="s2">"momentum_buffer"</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s2">"momentum"</span><span class="p">])</span>
<a id="__codelineno-4-165" name="__codelineno-4-165"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
<a id="__codelineno-4-166" name="__codelineno-4-166"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">update</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">])</span>
<a id="__codelineno-4-167" name="__codelineno-4-167"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-4-168" name="__codelineno-4-168"></a>                <span class="c1"># 单设备 AdamW 更新逻辑</span>
<a id="__codelineno-4-169" name="__codelineno-4-169"></a>                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">"params"</span><span class="p">]:</span>
<a id="__codelineno-4-170" name="__codelineno-4-170"></a>                    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-4-171" name="__codelineno-4-171"></a>                        <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-172" name="__codelineno-4-172"></a>                    <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
<a id="__codelineno-4-173" name="__codelineno-4-173"></a>                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-4-174" name="__codelineno-4-174"></a>                        <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-175" name="__codelineno-4-175"></a>                        <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg_sq"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<a id="__codelineno-4-176" name="__codelineno-4-176"></a>                        <span class="n">state</span><span class="p">[</span><span class="s2">"step"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-4-177" name="__codelineno-4-177"></a>                    <span class="n">state</span><span class="p">[</span><span class="s2">"step"</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-4-178" name="__codelineno-4-178"></a>                    <span class="n">update</span> <span class="o">=</span> <span class="n">adam_update</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg"</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="s2">"exp_avg_sq"</span><span class="p">],</span>
<a id="__codelineno-4-179" name="__codelineno-4-179"></a>                                         <span class="n">state</span><span class="p">[</span><span class="s2">"step"</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="s2">"betas"</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="s2">"eps"</span><span class="p">])</span>
<a id="__codelineno-4-180" name="__codelineno-4-180"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">*</span> <span class="n">group</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
<a id="__codelineno-4-181" name="__codelineno-4-181"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">group</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">])</span>
<a id="__codelineno-4-182" name="__codelineno-4-182"></a>
<a id="__codelineno-4-183" name="__codelineno-4-183"></a>        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="admonition info">
<p class="admonition-title">📝 如果您需要引用本文</p>
<p>Yan Li. (Sep. 1, 2025). 符号梯度下降 [Blog post]. Retrieved from <a href="https://dicaeopolis.github.io/DNN/optimizer/SignGD">https://dicaeopolis.github.io/DNN/optimizer/SignGD</a></p>
<p>在 BibTeX 格式中：
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span>
<span class="normal"><a href="#__codelineno-5-3">3</a></span>
<span class="normal"><a href="#__codelineno-5-4">4</a></span>
<span class="normal"><a href="#__codelineno-5-5">5</a></span>
<span class="normal"><a href="#__codelineno-5-6">6</a></span>
<span class="normal"><a href="#__codelineno-5-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a>@online{SignGD,
<a id="__codelineno-5-2" name="__codelineno-5-2"></a>    title={符号梯度下降},
<a id="__codelineno-5-3" name="__codelineno-5-3"></a>    author={Yan Li},
<a id="__codelineno-5-4" name="__codelineno-5-4"></a>    year={2025},
<a id="__codelineno-5-5" name="__codelineno-5-5"></a>    month={Sep},
<a id="__codelineno-5-6" name="__codelineno-5-6"></a>    url={\url{https://dicaeopolis.github.io/DNN/optimizer/SignGD}},
<a id="__codelineno-5-7" name="__codelineno-5-7"></a>}
</code></pre></div></td></tr></table></div></p>
</div>
<form class="md-feedback" hidden="" name="feedback">
<fieldset>
<legend class="md-feedback__title">
        Was this page helpful?
      </legend>
<div class="md-feedback__inner">
<div class="md-feedback__list">
<button class="md-feedback__icon md-icon" data-md-value="1" title="This page was helpful" type="submit">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"></path></svg>
</button>
<button class="md-feedback__icon md-icon" data-md-value="0" title="This page could be improved" type="submit">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"></path></svg>
</button>
</div>
<div class="md-feedback__note">
<div data-md-value="1" hidden="">
              
              
                
              
              
              
                
                
              
              Thanks for your feedback!
            </div>
<div data-md-value="0" hidden="">
              
              
                
              
              
              
                
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." rel="noopener" target="_blank">feedback form</a>.
            </div>
</div>
</div>
</fieldset>
</form>
<h2 id="__comments">评论</h2>
<!-- Giscus 脚本粘贴在这里 -->
<script async="" crossorigin="anonymous" data-category="Comments" data-category-id="DIC_kwDOOfbpCM4CtuiH" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="dicaeopolis/dicaeopolis.github.io" data-repo-id="R_kgDOOfbpCA" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<!-- 这段脚本用于同步 Giscus 和 mkdocs-material 的主题 -->
<script>
    var giscus = document.querySelector("script[src*=giscus]");
    document.addEventListener("DOMContentLoaded", function () {
      var palette = __md_get("__palette");
      if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "transparent_dark" : "light";
        giscus.setAttribute("data-theme", theme);
      }
      var ref = document.querySelector("[data-md-component=palette]");
      ref.addEventListener("change", function () {
        var palette = __md_get("__palette");
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate" ? "transparent_dark" : "light";
          var message = { setConfig: { theme: theme } };
          var frame = document.querySelector(".giscus-frame");
          frame.contentWindow.postMessage({ giscus: message }, "https://giscus.app");
        }
      });
    });
  </script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "content.code.select", "navigation.titles", "navigation.tabs", "navigation.indexes"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
<script src="../../../assets/js/custom.js"></script>
<script src="../../../themes/js/custom.js"></script>
<script src="../../../themes/js/simpleLightbox.min.js"></script>
<script src="../../../themes/js/optionalConfig.js"></script>
<script src="../../../themes/js/mermaidloader.js"></script>
<script src="../../../themes/js/umlconvert.js"></script>
<script src="../../../themes/js/mathjax.js"></script>
<script src="../../../themes/js/katex.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.17.1/flowchart.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.3.0/raphael.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.13.6/underscore-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mermaid-js/mermaid-mindmap@9.3.0/dist/diagram-definition.0faef4c2.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/markdown-it-plantuml@1.4.1/index.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml-full.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-svg-full.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
</body>
</html>