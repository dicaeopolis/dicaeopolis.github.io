{"config": {"lang": ["en"], "separator": "[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+", "pipeline": ["stemmer"]}, "docs": [{"location": "", "title": "\u6b22\u8fce\u6765\u5230Dicaeopolis' Wiki", "text": ""}, {"location": "#wiki", "title": "\u5173\u4e8e\u672c Wiki", "text": "<p>\u672cWiki\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u4ea4\u6d41\u6280\u672f\u548c\u77e5\u8bc6\u7684\u5e73\u53f0\u3002</p>"}, {"location": "#_1", "title": "\u5173\u4e8e\u4f5c\u8005", "text": "<p>\u4f5c\u8005\u76ee\u524d\u6f5c\u5fc3\u4e8e\u7814\u7a76\u6df1\u5ea6\u5b66\u4e60\uff0c\u540c\u65f6\u4e5f\u4e0d\u5f97\u4e0d\u5e94\u4ed8\u6765\u81ea\u5b66\u4e1a GPA \u7b49\u7684\u538b\u529b\u3002\u56e0\u6b64\u4f5c\u8005\u9009\u62e9\u5728\u6b64\u5f00\u6e90\u4f5c\u8005\u7684\u5b66\u4e60\u5fc3\u5f97\u3001\u7075\u611f\u95ea\u70c1\u548c\u751f\u5b58\u6307\u5357\uff0c\u4ee5\u98e8\u8bfb\u8005\u3002</p>"}, {"location": "#_2", "title": "\u8d21\u732e\u4e0e\u4ea4\u6d41", "text": "<p>\u5982\u679c\u60a8\u5e0c\u671b\u4ea4\u6d41\uff0c\u8bf7\u5728\u8bc4\u8bba\u533a\u5584\u610f\u8ba8\u8bba\u3002</p> <p>\u5982\u679c\u60a8\u5e0c\u671b\u5bf9\u5185\u5bb9\u6709\u6240\u8d21\u732e\uff08\u5c24\u5176\u662f\u6559\u6750\u7535\u5b50\u4e66\u7b49\u8d44\u6e90\uff09\u53ef\u4ee5\u9009\u62e9\u4e3a\u672c\u4ed3\u5e93\u63d0 PR\uff0c\u6216\u8005\u53d1\u90ae\u4ef6\u81f3\u7248\u4e3b\u90ae\u7bb1\u3002</p> <p>\u611f\u8c22\u60a8\u7684\u5149\u4e34\u3002</p>"}, {"location": "DNN/", "title": "\u5173\u4e8e\u672c\u7c7b\u522b", "text": "<p>\u672c\u7c7b\u522b\u4e3b\u8981\u6536\u5f55\u7b14\u8005\u5728\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u9886\u57df\u7684\u5b66\u4e60\u5fc3\u5f97\u3002</p> <p>\u7b14\u8005\u5b66\u8bc6\u6d45\u964b\uff0c\u8fd8\u8bf7\u591a\u591a\u6279\u8bc4\u6307\u6b63\u3002</p>"}, {"location": "DNN/RL/", "title": "RL\u5b66\u4e60\u7b14\u8bb0 - \u4e0a\u7bc7", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 75 \u5206\u949f\u3000|\u3000\u7ea6 8729 \u5b57\u3000|\u3000\u7ea6 285 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 333 \u884c\u4ee3\u7801</p>"}, {"location": "DNN/RL/#_1", "title": "\u7f18\u8d77", "text": "<p>\u7b14\u8005\u56fd\u5e86\u8282\u8fd4\u6821\u7684\u67d0\u4e2a\u665a\u8bfe\u4e0a\u770b\u52a8\u624b\u5b66\u5f3a\u5316\u5b66\u4e60\u770b\u5f97\u8981\u7761\u7740\u4e86\uff0c\u56e0\u6b64\u51c6\u5907\u5728\u8fd9\u91cc\u6574\u7406\u4e00\u4e0b\u7b14\u8bb0\u8ba9\u81ea\u5df1\u6253\u8d77\u7cbe\u795e\u3002</p> <p>\u7b14\u8bb0\u7684\u98ce\u683c\u548c\u6211\u7684\u5176\u4ed6\u535a\u5ba2\u5dee\u4e0d\u591a\uff0c\u4ee5\u6253\u901a\u601d\u8def\u7684\u63a8\u7406\u4e3a\u4e3b\uff0c\u4e0d\u4f1a\u641e\u590d\u5236\u7c98\u8d34\uff0c\u56e0\u4e3a\u6211\u770b\u90a3\u4e2a\u6559\u7a0b\u540e\u9762\u5199\u5f97\u6709\u70b9\u70b9\u7f3a\u4e4f\u7ebf\u7d22\u2026\u2026</p> <p>\u6700\u8fd1\u5929\u5929\u770b\u7f51\u4e0a RL \u6765 RL \u53bb\u7684\uff0c\u4e00\u5f00\u59cb\u4e0d\u77e5\u6240\u4e91\uff0c\u73b0\u5728\u529b\u6c42\u641e\u61c2\uff0c\u56e0\u6b64\u6709\u7a7a\u5c31\u6765\u66f4\u65b0\u4e00\u4e0b~</p> <p>\u7b14\u8bb0\u4e3b\u8981\u662f\u9488\u5bf9\u4e0a\u9762\u90a3\u4e2a\u6559\u7a0b\u7684\uff0c\u5927\u4f53\u4e0a\u4e5f\u7167\u7740\u5176\u601d\u8def\u5199\uff0c\u4f46\u662f\u8c03\u6574\u4e86\u90e8\u5206\u987a\u5e8f\u548c\u8be6\u7565\u4ee5\u7b26\u5408\u6211\u4e2a\u4eba\u7684\u601d\u8def\u7ebf\u7d22\uff0c\u4e5f\u53c2\u8003\u4e86\u897f\u6e56\u5927\u5b66\u8d75\u4e16\u94b0\u7684\u300a\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u539f\u7406\u300b\u4f5c\u4e3a\u4e00\u90e8\u5206\u7684\u77e5\u8bc6\u4e0e\u7406\u8bba\u8865\u5145\u3002\u5728\u6b64\u5411\u8bf8\u4f4d\u524d\u8f88\u4ee5\u53ca Anna's Archive \u81f4\u656c\u3002</p> <p>\u5982\u679c\u672c\u5b66\u671f\u6216\u4ee5\u540e\u6709\u65f6\u95f4\uff0c\u53ef\u4ee5\u6413\u4e00\u4e2a\u81ea\u52a8\u8eb2\u5f39\u5e55\u7684 THARL (TouHou Agent through Reinforced Learning) \u9879\u76ee\u6765\u73a9\u73a9\u3002</p>"}, {"location": "DNN/RL/#_2", "title": "\u7b2c\u4e00\u7ae0", "text": "<p>\u7b80\u5355\u56de\u987e\u4e00\u4e0b\u4e00\u822c\u7684\u6709\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff0c\u4e5f\u5c31\u662f</p> \\[ \\mathrm{arg}\\min_{\\theta\\quad} \\mathbb{E}_{x,t\\sim p(x,t)}[\\mathcal{L(\\theta;x,t)}] \\] <p>\u8fd9\u91cc\u7684 \\(\\theta\\) \u5c31\u662f\u7f51\u7edc\u53c2\u6570\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u7684\u4f18\u5316\u5bf9\u8c61\uff1b\\(x,t\\sim p(x,t)\\) \u5c31\u662f\u4ece\u6837\u672c\u4e0e\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\u4e2d\u91c7\u6837\u4e00\u4e2a\uff08\u6837\u672c\uff0c\u6807\u7b7e\uff09\u5bf9\uff0c\u4f5c\u4e3a\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e\u3002\u5728\u8fd9\u4e2a\u6570\u636e\u4e0a\u9762\uff0c\u6211\u4eec\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}(\\theta;x,t)\\) \u7528\u6765\u8868\u5f81\u6211\u4eec\u7684\u7f51\u7edc \\(\\theta\\) \u80fd\u4e0d\u80fd\u5c3d\u53ef\u80fd\u5c06 \\(x\\) \u6620\u5c04\u5230 \\(t\\)\u3002\u6700\u540e\u6211\u4eec\u8981\u9488\u5bf9\u5168\u90e8\uff08\u6216\u8005\u5bf9\u4e8e\u57fa\u4e8e\u5c0f\u6279\u91cf\u68af\u5ea6\u7684\u4f18\u5316\u5668\u800c\u8a00\uff0c\u53ea\u9700\u8981\u9488\u5bf9\u4e00\u90e8\u5206\uff09\u7684\u7ecf\u9a8c\u6837\u672c\u8ba1\u7b97\u51fa\u6765\u7684\u635f\u5931\u5bf9\u5176\u8fdb\u884c\u6700\u5c0f\u5316\u3002</p> <p>\u800c\u5f3a\u5316\u5b66\u4e60\u548c\u5b83\u6709\u76f8\u4f3c\u4e5f\u6709\u4e0d\u540c\u3002\u4e00\u4e2a Agent \u5904\u4e8e\u67d0\u4e2a\u72b6\u6001 \\(s_{t-1}\\)\uff0c\u57fa\u4e8e\u81ea\u6211\u7b56\u7565 \\(\\pi\\) \u505a\u51fa\u52a8\u4f5c \\(a_i\\)\uff0c\u4ece\u800c\u8f6c\u79fb\u5230\u65b0\u7684\u72b6\u6001 \\(s_t\\)\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u5f97\u5230\u5bf9\u5e94\u7684\u5956\u52b1\u6216\u8005\u60e9\u7f5a\uff0c\u8fd9\u79cd\u53cd\u9988\u662f\u57fa\u4e8e\u73af\u5883\u56fa\u6709\u7684\u3002\u8b6c\u5982\u4e00\u4e2a\u4e0b\u56fd\u9645\u8c61\u68cb\u7684 Agent\uff0c\u4f1a\u9009\u62e9\u5c06\u67d0\u4e2a\u4f4d\u7f6e\u7684\u56fd\u738b\u79fb\u5230\u53e6\u5916\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u5982\u679c\u5b83\u80fd\u591f\u4ee5\u6b64\u907f\u5f00\u5c06\u519b\uff0c\u5219\u80fd\u83b7\u5f97\u4e00\u70b9\u5956\u52b1\uff1b\u5982\u679c\u4e0d\u80fd\u907f\u5f00\u6216\u8005\u9677\u5165\u4e86\u4e0d\u5408\u6cd5\u7684\u79fb\u52a8\uff0c\u5219\u83b7\u5f97\u8d1f\u5956\u52b1\u4e5f\u5c31\u662f\u60e9\u7f5a\uff08\u8fd9\u91cc\u7684\u5956\u52b1\u662f\u57fa\u4e8e\u51b3\u7b56\u7684\uff09\u3002\u901a\u8fc7\u8c61\u68cb\u89c4\u5219\u5e26\u6765\u7684\u7ea6\u675f\uff0c\u5c31\u53ef\u4ee5\u4f7f\u5f97\u8be5 Agent \u9ad8\u6548\u8fdb\u884c\u5b66\u4e60\u89c4\u5219\u3002\u66f4\u8fdb\u4e00\u6b65\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5b50\u529b\uff0c\u68cb\u5c40\u4ef7\u503c\u7b49\u66f4\u9ad8\u7ea7\u7684\u5956\u52b1\uff08\u8fd9\u91cc\u7684\u5956\u52b1\u662f\u57fa\u4e8e\u72b6\u6001\u7684\uff09\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8ba9\u8fd9\u4e2a Agent \u5b66\u4e60\u5982\u4f55\u8d62\u68cb\uff0c\u6700\u540e\u6253\u8d25\u56fd\u9645\u8c61\u68cb\u5927\u5e08\u5361\u65af\u5e15\u7f57\u592b\u2026\u2026</p> <p>\u521a\u521a\u7684\u8fc7\u7a0b\u5c31\u63cf\u8ff0\u4e86 RL \u7684\u4e00\u6b65\u8fc7\u7a0b\uff0c\u6a21\u578b\u63a2\u7d22\u5e76\u4ece\u9519\u8bef\u4e2d\u5b66\u4e60\u3002\u6211\u4eec\u73b0\u5728\u5c31\u53ef\u4ee5\u660e\u786e RL \u7684\u76ee\u6807\u6240\u5728\u2014\u2014\u901a\u8fc7\u8fd9\u6837\u4e00\u4e2a\u8fc7\u7a0b\uff0c\u4e0d\u65ad\u4f18\u5316\u7b56\u7565\u4f7f\u5f97\u81ea\u5df1\u6bcf\u4e00\u6b21\u884c\u52a8\u90fd\u80fd\u89c4\u907f\u60e9\u7f5a\u5e76\u83b7\u53d6\u6700\u591a\u5956\u52b1\u3002\u5f53\u7136\u6a21\u578b\u7684\u7b56\u7565\u5e76\u4e0d\u4e00\u5b9a\u4f1a\u5747\u7b49\u5730\u8986\u76d6\u6240\u6709\u53ef\u80fd\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u800c\u662f\u5bf9\u4e0d\u540c\u7684\u72b6\u6001\u548c\u884c\u52a8\u6709\u4e0d\u540c\u7684\u6982\u7387\u51fa\u73b0\uff0c\u4e5f\u5c31\u53ef\u4ee5\u5efa\u6a21\u6210\u4e00\u4e2a\u5206\u5e03\uff0c\u88ab\u79f0\u4f5c\u5176\u7b56\u7565\u7684\u5360\u7528\u5ea6\u91cf \\(\\rho_\\pi\\)\u3002\u6211\u4eec\u5e0c\u671b\u5728\u8fd9\u4e2a\u6d3b\u52a8\u8303\u56f4\u5185\uff0c\u80fd\u591f\u4ee5\u4f18\u5316\u7b56\u7565\u7684\u65b9\u5f0f\u6700\u5927\u5316\u5956\u52b1 \\(r\\)\uff0c\u4e5f\u5c31\u662f</p> \\[ \\mathrm{arg}\\max_{\\pi\\quad} \\mathbb{E}_{s,a\\sim \\rho_\\pi(s,a)}[r(s,a)] \\] <p>\u5f88\u50cf\u5427\uff0c\u5176\u5b9e\u5f62\u5f0f\u4e0a\u53ef\u4ee5\u8bf4\u548c\u6709\u76d1\u7763\u5b66\u4e60\u6ca1\u6709\u4ec0\u4e48\u533a\u522b\uff0c\u4f46\u662f\u533a\u522b\u8fd8\u662f\u6bd4\u8f83\u5927\uff0c\u6bd4\u5982\u8bf4\u4e00\u4e2a\u6a21\u578b\u53ef\u4ee5\u63a2\u7d22\u7684\u7b56\u7565\u7684\u5360\u7528\u5ea6\u91cf\u4f1a\u968f\u7740\u7b56\u7565\u6539\u53d8\u800c\u6539\u53d8\uff1b\u800c\u6211\u4eec\u4e5f\u4e0d\u662f\u57fa\u4e8e\u5956\u52b1\u51fd\u6570\u76f4\u63a5\u5c31\u6765\u7b97\u68af\u5ea6\u505a\u68af\u5ea6\u4e0a\u5347\uff08\u6709\u7684\u64cd\u4f5c\u53ef\u80fd\u6ca1\u68af\u5ea6\u5462\uff09\u3002</p> <p>\u4e0d\u8fc7\u5176\u5b9e\u6700\u5927\u7684\u533a\u522b\u662f\u5e8f\u5217\u6027\uff0c\u56e0\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e00\u6b65\u6b65\u7684\u8f6c\u79fb\u662f\u6709\u5e8f\u7684\uff0c\u4e0d\u50cf\u7aef\u5230\u7aef\u5b66\u4e60\u90a3\u6837\u53ef\u4ee5\u968f\u673a\u62bd\u6837\u672c\u7b97\u68af\u5ea6\u3002</p>"}, {"location": "DNN/RL/#_3", "title": "\u7b2c\u4e8c\u7ae0", "text": ""}, {"location": "DNN/RL/#_4", "title": "\u95ee\u9898\u7684\u5f15\u5165", "text": "<p>\u672c\u7ae0\u805a\u7126 RL \u7684\u7b2c\u4e00\u4e2a\u7ecf\u5178\u95ee\u9898\uff1a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u3002\u4f46\u662f\u6211\u89c9\u5f97\u8fd9\u4e2a\u5176\u5b9e\u4e0d\u50cf\u8001\u864e\u673a\uff0c\u56e0\u4e3a\u8981\u8001\u864e\u673a\u4ed8\u8d39\u4f7f\u7528\u4f46\u662f\u8fd9\u4e2a\u95ee\u9898\u8d60\u9001\u4e86\u514d\u8d39\u989d\u5ea6\uff0c\u56e0\u6b64\u4e0d\u5982\u628a\u8fd9\u4e2a\u95ee\u9898\u5efa\u6a21\u5982\u4e0b\uff1a</p> <p>\u4f60\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u4eba\uff0c\u88ab\u821e\u840c\u75f4\u597d\u53cb\u5b89\u5229\u6765\u5230\u4e86\u673a\u5385\u3002\u821e\u840c\u7684\u65b0\u4eba\u53ef\u4ee5\u6709\u514d\u8d39\u6253\u6b4c\u7684\u989d\u5ea6\uff0c\u6211\u4eec\u8003\u8651\u4f60\u6709 \\(T\\) \u6b21\u673a\u4f1a\u514d\u8d39\u6253\u6b4c\u3002\u7531\u4e8e\u4f60\u662f\u65b0\u4eba\u5e76\u4e0d\u7406\u89e3\u821e\u840c\u7684\u8c31\u9762\u96be\u5ea6\u5982\u4f55\uff0c\u4f46\u662f\u90a3\u4e9b\u7b80\u5355\u94fa\u9762\u8ddf\u7740\u6309\u8fd8\u662f\u53ef\u4ee5\u7684\uff0c\u56e0\u6b64\u5bf9\u4e8e \\(K\\) \u4e2a\u8c31\u9762\uff0c\u4f60\u6709 \\(p_i\\) \u7684\u6982\u7387\u901a\u8fc7\uff08\\(i=1\\dots K\\)\uff09\uff0c\u4e5f\u5c31\u662f\u670d\u4ece\u4f2f\u52aa\u5229\u5206\u5e03\uff0c\u4f46\u662f\u4f60\u5e76\u4e0d\u77e5\u9053\u8fd9\u4e2a\u6982\u7387\u5177\u4f53\u7684\u503c\uff0c\u53ea\u6709\u6bcf\u4e00\u6b21\u73a9\u67d0\u4e2a\u8c31\u9762\uff0c\u901a\u8fc7\u548c\u4e0d\u901a\u8fc7\u7684\u533a\u522b\u3002</p> <p>\u4f60\u4ec5\u4ec5\u662f\u4f53\u9a8c\uff0c\u6240\u4ee5\u53ea\u8981\u901a\u8fc7\u8c31\u9762\u5373\u53ef\uff0c\u73b0\u5728\u4f60\u60f3\u8981\u4f7f\u4f60\u5408\u8ba1\u83b7\u5f97\u7684\u7684\u901a\u8fc7\u6b21\u6570\u6700\u5927\u5316\uff0c\u53ef\u4ee5\u9009\u62e9\u4ec0\u4e48\u7b56\u7565\uff1f</p>"}, {"location": "DNN/RL/#_5", "title": "\u6743\u8861", "text": "<p>\u8fd9\u91cc\u7684\u6743\u8861\u5f88\u7b80\u5355\uff0c\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u4f1a\u6d88\u8017\u6709\u9650\u7684\u673a\u4f1a\u53bb\u83b7\u53d6\u5bf9\u8c31\u9762\u901a\u8fc7\u6982\u7387\u7684\u4f30\u8ba1\u503c \\(\\hat p_i\\)\uff0c\u4f46\u662f\u4e00\u65e6\u6211\u4eec\u8db3\u591f\u76f8\u4fe1\u81ea\u5df1\u7684\u4f30\u8ba1\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u902e\u7740\u90a3\u4e2a\u6700\u5927\u6982\u7387\u4f7f\u52b2\u8585~</p> <p>\u6211\u4eec\u53ef\u4ee5\u63a7\u5236\u4e00\u4e2a\u6bd4\u4f8b \\(\\epsilon\\) \u6765\u6743\u8861\u5230\u5e95\u662f\u8d70\u7a33\u5065\u6d41\u53bb\u63a5\u7740\u6253\u81ea\u5df1\u76ee\u524d\u4f30\u8ba1\u51fa\u6982\u7387\u6700\u9ad8\u7684\u8c31\u5b50\uff0c\u6216\u8005\u63a2\u7d22\u4e00\u4e0b\u5176\u4ed6\u8c31\u5b50\u4e07\u4e00\u81ea\u5df1\u53ea\u662f\u4e00\u5f00\u59cb\u624b\u611f\u4e0d\u597d\u5462\u2026\u2026</p> <p>\u6240\u4ee5\u6211\u4eec\u6bcf\u4e00\u6b65\u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570 \\(r\\in U(0,1)\\)\uff0c\u7136\u540e\u6839\u636e \\(\\epsilon\\)\uff0c\u8fdb\u884c\u4e0b\u9762\u7684\u51b3\u7b56\uff1a</p> \\[ \\mathrm{Choice\\ of\\ index}= \\begin{cases}     i\\mathrm{\\ \\ for\\ \\ arg}\\max_{i} \\hat p_i,\\quad &amp;r&gt;\\epsilon\\\\     \\mathrm{Randomly},&amp;r\\le \\epsilon \\end{cases} \\] <p>\u5f53\u7136\u6bcf\u4e00\u6b21\u9009\u62e9\u4e4b\u540e\u8981\u66f4\u65b0\u4f30\u8ba1\u7684\u6982\u7387\u6c60\u5b50\u3002</p> <p>\u6211\u4eec\u600e\u4e48\u770b\u8fd9\u4e2a\u7b56\u7565\u662f\u5426\u8db3\u591f\u597d\u5462\uff0c\u5176\u5b9e\u53ef\u4ee5\u91cf\u5316\u5b83\u4e0e\u6211\u4eec\u5148\u9a8c\u77e5\u9053\u7684\u6700\u4f18\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8fd9\u88ab\u79f0\u4f5c\u61ca\u6094\uff08Regret\uff09\u3002</p> <p>\u8fd9\u4e2a\u7b97\u6cd5\u53ea\u6709\u4e00\u4e2a\u8d85\u53c2\u6570\u53ef\u8c03\uff0c\u4e5f\u5c31\u662f \\(\\epsilon\\)\uff0c\u9996\u5148\u6211\u4eec\u53ef\u80fd\u4f1a\u9009\u62e9\u4e00\u4e2a\u56fa\u5b9a\u7684\u503c\uff1a</p> <p></p> <p>\u4f46\u662f\u53ef\u89c1\uff0c\u968f\u7740\u5c1d\u8bd5\u6b21\u6570\u7684\u589e\u52a0\uff0c\u61ca\u6094\u503c\u4e5f\u5728\u589e\u52a0\uff01\u4e3a\u4ec0\u4e48\uff1f\u5f53\u6211\u4eec\u79ef\u7d2f\u4e86\u8db3\u591f\u591a\u7684\u5c1d\u8bd5\u4e4b\u540e\uff0c\u5176\u5b9e\u5df2\u7ecf\u6709\u8db3\u591f\u7406\u7531\u53bb\u8ba4\u4e3a\u9891\u7387\u662f\u6982\u7387\u7684\u5408\u7406\u4f30\u8ba1\u4e86\uff0c\u8fd9\u4e2a\u65f6\u5019\u8fd8\u4ee5\u4e00\u4e2a\u56fa\u5b9a\u6bd4\u4f8b\u8fdb\u884c\u968f\u673a\u5c1d\u8bd5\uff0c\u5c31\u5f88\u611a\u8822\u4e86\uff0c\u5047\u8bbe\u6211\u4eec\u7684\u4f30\u8ba1\u5df2\u7ecf\u6536\u655b\uff0c\u4f46\u662f\u6bcf\u4e00\u6b65\u589e\u957f\u7684\u61ca\u6094\u503c\u671f\u671b\u4e3a \\(\\epsilon\\times\\dfrac{K-1}{K}\\)\uff0c\u5219\u603b\u7684\u61ca\u6094\u503c\u5c31\u662f \\(\\epsilon T\\) \u7684\u91cf\u7ea7\uff0c\u968f\u7740\u5c1d\u8bd5\u6b21\u6570\u7ebf\u6027\u589e\u957f\u3002</p> <p>\u90a3\u600e\u4e48\u641e\u5462\uff1f\u6211\u4eec\u80af\u5b9a\u662f\u8ba9 \\(\\epsilon\\) \u8870\u51cf\uff0c\u4f46\u662f\u600e\u4e48\u8870\u51cf\u5462\uff1f</p> <p>\u6211\u4eec\u628a\u603b\u61ca\u6094\u5206\u5272\u6210\u4e24\u4e2a\u90e8\u5206\uff0c\u7b2c\u4e00\u4e2a\u662f\u968f\u673a\u62bd\u51fa\u6765\u7684\u61ca\u6094\uff0c\u7b2c\u4e8c\u4e2a\u662f\u56fa\u5b9a\u62bd\u51fa\u6765\u7684\u61ca\u6094\u3002\u5bf9\u4e8e\u80fd\u591f\u6536\u655b\u5230\u6700\u4f18\u6982\u7387\u7684\u60c5\u51b5\uff0c\u603b\u61ca\u6094\u5c31\u53d6\u51b3\u4e8e\u7b2c\u4e00\u90e8\u5206\uff0c\u800c\u7b2c\u4e00\u90e8\u5206\u80fd\u4ea7\u751f\u7684\u61ca\u6094\u671f\u671b\u503c\u662f\u56fa\u5b9a\u53ef\u4ee5\u8ba1\u7b97\u7684\uff0c\u5373\uff1a</p> \\[ \\sum_i^T \\epsilon_i = O(F(T))\\implies \\mathrm{Acc.\\ Reg.}=O(F(T)) \\] <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u9009\u53d6 \\(\\epsilon_i\\) \u4f5c\u4e3a\u6536\u655b\u7684\u7ea7\u6570\uff0c\u5c31\u53ef\u4ee5\u8ba9\u7d2f\u79ef\u61ca\u6094\u4e5f\u6536\u655b\u3002</p> <p>\u4e0a\u9762\u90a3\u4e2a\u5f0f\u5b50\u53ef\u4ee5\u7528\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u521a\u521a\u6211\u4eec\u770b\u5230\u4e86 \\(\\epsilon\\) \u662f\u5e38\u6570\u7684\u60c5\u51b5\uff0c\u5982\u679c\u6362\u6210 \\(\\epsilon_i=1/i\\)\uff0c\u5c31\u53ef\u89c1\u7d2f\u79ef\u61ca\u6094\u662f\u5bf9\u6570\u7ea7\u589e\u957f\uff0c\u800c\u6362\u6210 \\(\\epsilon_i=1/i^2\\) \u6216\u8005 \\(\\epsilon_i=\\exp(-i)\\) \u5c31\u53ef\u4ee5\u89c2\u5bdf\u5230\u7d2f\u79ef\u61ca\u6094\u6536\u655b\u5230\u5e38\u6570\u3002</p> <p>\u4f46\u662f\u524d\u63d0\u662f\u80fd\u591f\u6536\u655b\u5230\u6700\u4f18\u6982\u7387\u4e0a\uff01</p> <p></p> <p>\u6240\u4ee5\u6211\u8ba4\u4e3a\u8bfe\u4ef6\u4e0a\u201c\u5f88\u96be\u627e\u5230\u5408\u9002\u7684\u8870\u51cf\u89c4\u5212\u201d\u8fd9\u53e5\u8bdd\u53ea\u8bf4\u4e86\u4e00\u534a\u3002\u8fd9\u4e2a\u95ee\u9898\u7684\u6982\u7387\u53ef\u80fd\u66f4\u52a0\u4e0d\u786e\u5b9a\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u6253\u6cd5\uff08\u6bd5\u7adf\u521a\u521a\u7684\u5206\u6790\u5efa\u7acb\u5728\u7b2c\u4e8c\u90e8\u5206\u7684\u61ca\u6094\u6536\u655b\u52300\u7684\u60c5\u51b5\uff0c\u5982\u679c\u8870\u51cf\u592a\u5feb\u53ef\u80fd\u6ca1\u6cd5\u6536\u655b\u5230\u6700\u4f18\uff0c\u4e0d\u80fd\u4fdd\u8bc1\u6536\u655b\u6027\uff09\uff0c\u800c\u5728\u5dee\u5f02\u5927\uff0c\u66f4\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u89c9\u5f97\u53d6\u6307\u6570\u8870\u51cf\u57fa\u672c\u4e0a\u53ef\u4ee5\u901a\u6740\u4e86\u3002</p> <p>\u4f46\u95ee\u9898\u6ca1\u6709\u6d88\u5931\uff1a\u5982\u679c\u4e00\u5f00\u59cb\u9677\u5165\u5c40\u90e8\u6700\u4f18\u4e86\uff0c\u90a3\u4f60\u8fd9\u4e0d\u5c31\u70b8\u4e86\u5417\uff0c\u6240\u4ee5\u6709\u6ca1\u6709\u66f4\u7a33\u5065\u7684\u6253\u6cd5\uff0c\u80fd\u591f\u4fdd\u8bc1\u7d2f\u79ef\u61ca\u6094\u80fd\u591f\u6536\u655b\u5230\u4e00\u4e2a\u8d8b\u52bf\u5462\u3002</p>"}, {"location": "DNN/RL/#_6", "title": "\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528", "text": "<p>\u4e0b\u9762\u4ecb\u7ecd UCB \u7b97\u6cd5\uff0c\u4e5f\u5c31\u662f\u7f6e\u4fe1\u4e0a\u754c\u6cd5\uff0c\u5728\u5f15\u5165\u8fd9\u4e2a\u65b9\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u8fd8\u662f\u56de\u5230\u4e4b\u524d\u7684\u90a3\u4e2a\u95ee\u9898\uff0c\u5373\uff1a\u5f53\u6211\u4eec\u6709\u4e00\u7cfb\u5217\u62bd\u6837\u7ed3\u679c\u4e4b\u540e\uff0c\u6211\u4eec\u662f\u5c06\u5176\u89c6\u4f5c\u771f\u5b9e\u5206\u5e03\u8fdb\u884c\u201c\u5229\u7528\u201d\uff0c\u8fd8\u662f\u8ba4\u4e3a\u8bc1\u636e\u4e0d\u8db3\u800c\u53bb\u201c\u63a2\u7d22\u201d\u65b0\u7684\u6570\u636e\u5462\uff1f</p> <p>\u8fd9\u5c31\u5f15\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u600e\u4e48\u6837\u523b\u753b\u8fd9\u4e2a\u201c\u8ba4\u4e3a\u8bc1\u636e\u4e0d\u8db3\u201d\uff1f\u4e5f\u5c31\u662f\u5728\u591a\u5927\u7684\u6982\u7387\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u65ad\u8a00\u8fd9\u4e2a\u5efa\u6a21\u8db3\u591f\u62df\u5408\u539f\u6709\u5206\u5e03\uff1f</p> <p>\u6211\u4eec\u6709 Hoeffding's inequality\uff0c\u5b83\u80fd\u544a\u8bc9\u6211\u4eec\u7b54\u6848\uff1a\u8003\u8651 \\([0,1]\\) \u5185\u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf \\(x_1,\\dots, x_n\\)\uff0c\u4ee5\u6837\u672c\u5747\u503c \\(\\bar x\\) \u4e3a\u539f\u5206\u5e03\u5747\u503c \\(\\mu\\) \u7684\u5efa\u6a21\uff0c\u5e76\u4e14\u5f15\u5165\u5bb9\u5dee\u6216\u8005\u8bf4\u4e0d\u786e\u5b9a\u5ea6 \\(u\\)\uff0c\u5219\u6709\u4ee5\u4e0b\u7684\u6982\u7387\u4e0d\u7b49\u5f0f\uff1a</p> \\[ P(\\mu &gt;\\bar x + u) \\le \\exp(-2nu^2) \\] <p>\u628a\u8fd9\u4e2a\u4e0d\u7b49\u5f0f\u7ffb\u8bd1\u5230\u95ee\u9898\u91cc\u9762\uff0c\u4e5f\u5c31\u662f\u5bf9\u4e8e\u67d0\u8c31\u9762 \\(a\\)\uff0c\u4e3a\u4e86\u63a7\u5236\u4f30\u8ba1\u503c\u548c\u771f\u5b9e\u503c\u4e4b\u5dee\u5927\u4e8e\u4e0d\u786e\u5b9a\u5ea6\u7684\u6982\u7387 \\(P(\\mu_a &gt;\\bar x_a + u_a)\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u63a7\u5236\u5176\u4e0a\u754c \\(\\exp(-2nu_a^2)\\)\uff0c\u628a\u5b83\u9650\u5236\u5728\u5bb9\u5fcd\u7684\u6982\u7387\u503c \\(p\\) \u5185\u3002</p> <p>\u65e2\u7136\u6211\u4eec\u5df2\u7ecf\u80fd\u591f\u63a7\u5236\u903c\u8fd1\u5747\u503c\u7684\u7cbe\u5ea6\uff0c\u90a3\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5229\u7528\u4f30\u8ba1\u503c\u7684\u6700\u5927\u503c \\(\\mathrm{arg}\\max_a\\bar x_a + u_a\\) \u6765\u505a\u9009\u62e9\uff0c\u8fd9\u5c31\u548c\u524d\u9762\u7684\u6982\u7387\u8d2a\u5fc3\u505a\u6cd5\u6709\u672c\u8d28\u4e0d\u540c\uff1a\u5373\u4f7f\u6700\u574f\u60c5\u51b5 \\(\\exp(-2nu_a^2)=p\\)\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u53d6 \\(u_a=\\sqrt{- \\dfrac{\\log p}{2n}}\\)\uff0c\u968f\u7740 \\(n\\) \u7684\u589e\u957f\uff0c\u8ba9 \\(p\\to 0\\) \u5c31\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u5206\u5e03\u7cbe\u786e\u5747\u503c\u7684\u6536\u655b\u3002</p> <p>\u8fd9\u5c31\u662f UCB \u7b97\u6cd5\u7684\u6d41\u7a0b\u4e86\u3002\u5177\u4f53\u800c\u8a00\uff1a</p> <ul> <li>\u4e3a\u4e86\u8ba9 \\(p\\to 0\\)\uff0c\u6211\u4eec\u53d6 \\(p=1/n\\)\uff0c\u7136\u540e\u6839\u636e\u73b0\u6709\u7684\u5747\u503c\u8ba1\u7b97\u8fd9\u4e2a\u671f\u671b\u5956\u52b1\u4e0a\u754c \\(U_a(t)=\\bar x_a(t)+u(t)=\\bar x_a(t)+\\sqrt{\\dfrac{\\log n}{2(n+1)}}\\)\u3002</li> <li>\u6c42\u4f7f\u5176\u6700\u5927\u7684\u90a3\u4e2a \\(i\\) \u4f5c\u4e3a\u9009\u62e9\u3002</li> <li>\u9009\u62e9\u540e\uff0c\u66f4\u65b0\u5747\u503c\u4e3a \\(\\bar x_i(t+1)\\)\u3002</li> </ul> <p>\u81ea\u7136\u6211\u4eec\u4e5f\u53ef\u4ee5\u6539\u53d8\u5747\u503c\u548c\u4e0d\u786e\u5b9a\u5ea6\u4e24\u8005\u7684\u914d\u6bd4\u3002</p> <p></p> <p>\u8bfe\u4ef6\u91cc\u9762\u7ed9\u51fa\u4e86\u5176\u7d2f\u79ef\u61ca\u6094\u662f \\(O(\\log n)\\) \u7ea7\u522b\u7684\u7ed3\u8bba\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u5bf9\u6bd4\u4e00\u4e0b\u5148\u524d\u7684\u8ba8\u8bba\uff0c\u53ef\u4ee5\u770b\u5230\u867d\u7136\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u66f4\u9ad8\uff0c\u4f46\u662f\u53ef\u4ee5\u4fdd\u8bc1\u6e10\u8fdb\u6536\u655b\u4e0d\u4f1a\u70b8\uff0c\u5982\u679c\u628a\u4e00\u5f00\u59cb\u90a3\u4e2a\u968f\u673a \u03b5-\u8d2a\u5fc3\u7b56\u7565\u7684\u4e0d\u6536\u655b\u60c5\u51b5\u8003\u8651\u8fdb\u6765\uff0c\u5176\u5b9e\u7d2f\u79ef\u7684\u671f\u671b\u61ca\u6094\u4e5f\u662f\u7ebf\u6027\u589e\u957f\u7684\u3002\u6709\u6ca1\u6709\u53ef\u80fd\u6709\u66f4\u597d\u7684\u7b97\u6cd5\u5462\uff1f</p> <p>\u6ca1\u53ef\u80fd\u4e86\u3002Lai \u548c Robbins \u5df2\u7ecf\u8bc1\u660e\u4e86\u7d2f\u79ef\u61ca\u6094\u7684\u4e0b\u754c\u662f\u5bf9\u6570\u7ea7\u7684\u3002\u6211\u4e4b\u524d\u4e5f\u8003\u8651\u8fc7\u8ba9 \\(p\\) \u8d8b\u4e8e \\(0\\) \u7684\u901f\u5ea6\u66f4\u5feb\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u90fd\u8868\u660e\u4f46\u4efb\u4f55\u9636\u6570\u66f4\u9ad8\u7684\u5c1d\u8bd5\u90fd\u4e0d\u80fd\u907f\u514d\u63a2\u7d22\u8fc7\u5c11\u7684\u95ee\u9898\u3002\uff08\u5982\u679c\u60f3\u505a\u5b9e\u9a8c\u7684\u8bdd\u53ef\u4ee5\u628a\u51e0\u4e2a\u81c2\u7684\u6982\u7387\u5dee\u8c03\u5c0f\u4e00\u70b9\uff0c\u8fd9\u6837\u5c31\u66f4\u5bb9\u6613\u8ba9\u6a21\u578b\u6536\u655b\u5230\u9519\u8bef\u7684\u81c2\u4e0a\u9762\uff09</p> <p>\u4e5f\u5c31\u662f\u8bf4\u8fd9\u4e2a\u95ee\u9898\u662f\u6709\u89e3\u7684\uff0c\u65e0\u8bba\u662f UCB \u7b97\u6cd5\u8fd8\u662f \u03b5-\u8d2a\u5fc3\u7b56\u7565\uff0c\u63a7\u5236\u5230\u5bf9\u6570\u9636\u5c31\u53ef\u4ee5\u505a\u5230\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861\u3002</p> <p>\u6559\u7a0b\u6700\u540e\u8fd8\u4ecb\u7ecd\u4e86 Thompson \u91c7\u6837\u7b97\u6cd5\uff0c\u5176\u5b9e\u6709\u70b9\u50cf\u8499\u7279\u5361\u7f57\u91c7\u6837\u3002\u521a\u521a\u6211\u4eec\u662f\u7528\u6837\u672c\u5747\u503c\u4f30\u8ba1\u5b9e\u9645\u5206\u5e03\u5747\u503c\uff0c\u800c\u8fd9\u4e2a\u7b97\u6cd5\u662f\u6839\u636e\u6837\u672c\u5206\u5e03\u4f30\u8ba1\u5b9e\u9645\u5206\u5e03\u3002\u6211\u4eec\u7684\u76f4\u89c9\u662f\uff0c\\(\\alpha+\\beta -2\\) \u6b21\u62bd\u6837\u91cc\u9762\uff0c\u51fa\u73b0\u4e86 \\(\\alpha-1\\) \u6b21\u901a\u8fc7\u548c \\(\\beta - 1\\) \u6b21\u4e0d\u901a\u8fc7\uff0c\u6bcf\u4e00\u6b21\u670d\u4ece\u6982\u7387 \\(p\\) \u7684\u4f2f\u52aa\u5229\u5206\u5e03\uff0c\u90a3\u4e48\u603b\u6982\u7387\u548c \\(p^{\\alpha-1}(1-p)^{\\beta-1}\\) \u6210\u6bd4\u4f8b\u3002\u8fd9\u4e2a\u5f62\u5f0f\u548c Beta \u5206\u5e03\u4e5f\u662f\u6210\u6bd4\u4f8b\u7684\uff0c\u4e3a\u6b64\u53ef\u4ee5\u9009\u62e9\u5229\u7528 Beta \u5206\u5e03\u4e3a\u76ee\u6807\u7684\u6982\u7387\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\uff0c\u7136\u540e\u6c42\u5747\u503c\uff0c\u5c31\u53ef\u4ee5\u627e argmax \u505a\u51b3\u7b56\u4e86\u3002</p> <p></p> <p>\u8fd9\u4e2a\u7b97\u6cd5\u7684\u60f3\u6cd5\u5c31\u66f4\u7cbe\u5999\u4e00\u4e9b\uff0c\u4e0d\u662f\u5148\u89e3\u8026\u63a2\u7d22\u548c\u5229\u7528\u4e24\u6b65\u518d\u8fdb\u884c\u5e73\u8861\uff0c\u800c\u662f\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u4f18\u79c0\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u5373 Beta \u5206\u5e03\uff0c\u800c\u4e0d\u540c\u7684\u62bd\u53d6\u6b21\u6570\u548c\u7ed3\u679c\u5bf9\u201c\u63a2\u7d22\u201d\u548c\u201c\u5229\u7528\u201d\u7684\u5171\u540c\u5f71\u54cd\uff0c\u81ea\u7136\u5728\u8fd9\u4e2a\u5206\u5e03\u91cc\u9762\u5f97\u5230\u4e86\u4e00\u4f53\u5316\u7684\u5efa\u6a21\u3002\u8fd9\u4e2a\u601d\u60f3\u5176\u5b9e\u548c\u4ece GAN \u5230 VAE \u7684\u601d\u60f3\u5f88\u50cf\u3002</p> <p>\u8fd9\u7bc7\u6587\u7ae0\u8868\u660e\u4e86 Thompson \u91c7\u6837\u7b97\u6cd5\u5728\u9636\u6570\u4e0a\u4e5f\u662f\u6e10\u8fdb\u6700\u4f18\u7684\uff0c\u5e76\u4e14\u5e38\u6570\u751a\u81f3\u8fd8\u8981\u4f4e\u4e00\u4e9b\u3002</p> <p></p>"}, {"location": "DNN/RL/#_7", "title": "\u603b\u7ed3", "text": "<p>\u8fd9\u4e2a\u540d\u53eb\u591a\u81c2\u8001\u864e\u673a\u7684\u95ee\u9898\u5c55\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u6743\u8861\u7684\u4e00\u4e2a\u95ee\u9898\uff0c\u611f\u6027\u5730\u7406\u89e3\u5c31\u662f\u9009\u62e9\u66f4\u6fc0\u8fdb\u6216\u66f4\u4fdd\u5b88\u7684\u7b56\u7565\uff0c\u7528\u672f\u8bed\u8bb2\u5c31\u53eb\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u3002\u5728\u7aef\u5230\u7aef\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u9047\u5230\u7684\u7c7b\u4f3c\u95ee\u9898\u662f\u6536\u655b\u5230\u978d\u70b9\u6216\u5c40\u90e8\u6700\u5c0f\uff0c\u4e3a\u6b64\u6211\u4eec\u5f15\u5165\u4e86\u968f\u673a\u6027\u6765\u89e3\u51b3\u2014\u2014\u53ef\u4ee5\u770b\u5230\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u6211\u4eec\u4e5f\u53ea\u4e0d\u8fc7\u662f\u6362\u4e86\u79cd\u5229\u7528\u968f\u673a\u6027\u7684\u65b9\u5f0f\u800c\u5df2\u3002</p>"}, {"location": "DNN/RL/#_8", "title": "\u7b2c\u4e09\u7ae0", "text": "<p>\u7b2c\u4e09\u7ae0\u4e3b\u8981\u8bb2\u7684\u662f\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u9996\u5148\u662f\u6bd4\u8f83\u7b80\u5355\u7684 Markov \u5956\u52b1\u8fc7\u7a0b MRP\u3002</p>"}, {"location": "DNN/RL/#mrp", "title": "MRP", "text": "<p>\u6211\u4eec\u8003\u8651\u4e00\u4e2a\u56fe \\(G\\)\uff0c\u4f7f\u7528\u90bb\u63a5\u77e9\u9635\u6765 \\(\\mathcal{P}\\) \u63cf\u8ff0\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u6709\u8282\u70b9\u5217\u8868 \\(s_i\\) \u4ee3\u8868\u5f53\u65f6\u7684\u72b6\u6001\uff0c\u800c \\(\\mathcal{P}_{ij}\\) \u8868\u5f81\u4ece\u72b6\u6001 \\(s_i\\) \u8df3\u5230\u72b6\u6001 \\(s_j\\) \u7684\u6982\u7387\u3002</p> <p>\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u72b6\u6001 \\(s\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u786e\u5b9a\u72b6\u6001\u672c\u8eab\u7684\u5956\u52b1 \\(R=r(s)\\)\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u6709\u4e86\u4e00\u4e2a\u5e26\u70b9\u6743\u548c\u8fb9\u6743\u7684\u6709\u5411\u56fe\u3002</p> <p>\u7531\u4e8e\u8f6c\u79fb\u6982\u7387\u5df2\u7ecf\u7ed9\u5b9a\uff0c\u6211\u4eec\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f\u9009\u62e9\u4e00\u4e2a\u8d77\u59cb\u7684\u72b6\u6001\uff0c\u80fd\u591f\u4f7f\u5f97\u7d2f\u79ef\u7684\u671f\u671b\u5956\u52b1\u6700\u5927\u3002</p> <p>\u4f46\u662f\u8fd9\u4e2a\u8868\u8ff0\u6709\u4e00\u4e2a\u9690\u542b\u7684\u95ee\u9898\uff1a\u5982\u679c\u6240\u6709\u72b6\u6001\u7684\u5956\u52b1\u90fd\u662f\u6b63\u6570\uff0c\u5e76\u4e14\u5927\u5c0f\u4e0d\u4e00\uff0c\u7406\u8bba\u4e0a\u6240\u6709\u72b6\u6001\u7d2f\u79ef\u7684\u5956\u52b1\u90fd\u80fd\u65e0\u4e0a\u9650\u5730\u589e\u957f\uff01</p> <p>\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5f15\u5165\u4e00\u4e2a\u8870\u51cf\u56e0\u5b50 \\(\\gamma\\) \u7528\u6765\u63a7\u5236\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8fd9\u4e2a\u503c\u8d8a\u5927\uff0c\u6a21\u578b\u8d8a\u5173\u6ce8\u957f\u671f\u5956\u52b1\uff0c\u8d8a\u5c0f\u6a21\u578b\u8d8a\u5173\u6ce8\u77ed\u671f\u5956\u52b1\u3002</p> <p>\u8fd9\u6837\uff0c\\(t\\) \u65f6\u523b\u4ece\u67d0\u4e2a\u72b6\u6001 \\(s\\) \u51fa\u53d1\uff0c\u6211\u4eec\u5c31\u80fd\u591f\u4ea7\u751f\u4e00\u6761\u8def\u5f84\u3002\u6bcf\u4e00\u6b21\u8d70\u4e00\u6b65\uff0c\u5c31\u80fd\u591f\u4ea7\u751f\u4e00\u4e2a\u5956\u52b1\u7684\u5e8f\u5217 \\(R_t,R_{t+1},\\dots\\)\u3002\u800c\u8fd9\u6761\u8def\u5f84\u7684\u5956\u52b1\u5c31\u662f \\(G_t=R_t+\\gamma R_{t+1}+\\dots\\)</p> <p>\u7531\u4e8e\u72b6\u6001\u7684\u8f6c\u79fb\u662f\u57fa\u4e8e\u6982\u7387\u7684\uff0c\u56e0\u6b64\u6bcf\u4e00\u6b21\u4ea7\u751f\u7684\u8def\u5f84\u90fd\u4e0d\u4e00\u6837\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u6c42\u671f\u671b\u3002\u6211\u4eec\u628a\u8fd9\u4e2a\u76ee\u6807\u53eb\u505a\u67d0\u4e2a\u72b6\u6001\u7684\u4ef7\u503c \\(V(s)\\)\uff0c\u4e5f\u5c31\u662f</p> \\[ \\begin{align*}     V(s)&amp;=\\mathbb{E}[G_t|S_t=s]\\\\     &amp;=\\mathbb{E}[R_t+\\gamma R_{t+1}+\\dots|S_t=s]\\\\     &amp;=R_t+\\gamma\\mathbb{E}[R_{t+1}+\\gamma R_{t+2}+\\dots|S_t=s]\\\\     &amp;=R_t+\\gamma\\mathbb{E}[G_{t+1}+\\dots|S_t=s]\\\\     &amp;=R_t+\\gamma\\sum_{s_i\\in S} p(s_i|s)V(s_i) \\end{align*} \\] <p>\u4e0d\u597d\u610f\u601d\u54c8\u54c8\uff0c\u4f60\u770b\u8fd9\u4e8b\u641e\u5f97\uff0c\u600e\u4e48\u4e00\u4e0d\u5c0f\u5fc3\u5c31\u628a MRP \u7684\u8d1d\u5c14\u66fc\u65b9\u7a0b\u4e5f\u4e00\u5e76\u63a8\u5bfc\u4e86\u51fa\u6765\u5462\u2026\u2026</p> <p>\u8ba9\u6211\u4eec\u6765\u89e3\u8bfb\u4e00\u4e0b\u5427\u3002\\(R_t\\) \u5c31\u662f\u5f53\u524d\u72b6\u6001 \\(s\\) \u7684\u5956\u52b1 \\(r(s)\\)\uff0c\u800c\u540e\u9762\u90a3\u4e2a\u6c42\u548c\u5c31\u662f\u8ba1\u7b97\u4ece\u5f53\u524d\u72b6\u6001\u8f6c\u79fb\u5230\u4e0b\u4e00\u72b6\u6001\u7684\u6982\u7387\u4e58\u4ee5\u4e0b\u4e00\u72b6\u6001\u7684\u4ef7\u503c\u51fd\u6570\uff0c\u4e5f\u5c31\u662f\u6240\u6709\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u671f\u671b\u4ef7\u503c\uff0c\u6700\u540e\u4e58\u4ee5\u8870\u51cf\u7cfb\u6570 \\(\\gamma\\)\u3002</p> <p>\u5f0f\u5b50\u7684\u610f\u56fe\u8fd8\u662f\u76f8\u5f53\u660e\u6670\u7684\uff0c\u751a\u81f3\u6211\u4eec\u53ef\u4ee5\u57fa\u4e8e\u8f6c\u79fb\u77e9\u9635\u628a\u8fd9\u4e2a\u8d1d\u5c14\u66fc\u65b9\u7a0b\u5199\u6210\u77e9\u9635\u5f62\u5f0f\uff1a</p> \\[ V=R+\\gamma \\mathcal PV\\\\ \\implies V=(I-\\gamma \\mathcal P)^{-1}R \\] <p>\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u4ee5 \\(O(n^3)\\) \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u7cbe\u786e\u6c42\u5f97 \\(V\\) \u800c\u80fd\u591f\u5f97\u5230\u6bcf\u4e2a\u72b6\u6001\u7684\u671f\u671b\u4ef7\u503c\u4e86\u3002</p> <p>\u8ba9\u6211\u4eec\u5047\u8bbe\u4e00\u79cd\u5355\u56de\u5408\u7684\u5854\u9632\u6e38\u620f\uff0c\u4f60\u6709 \\(n\\) \u4e2a\u683c\u5b50\uff0c\u6bcf\u4e2a\u683c\u5b50\u53ef\u4ee5\u9009\u62e9\u653e \\(k\\) \u79cd\u7b49\u7ea7\u7684\u9632\u5fa1\u5854\uff0c\u9632\u5fa1\u5854\u7684\u7b49\u7ea7\u4e4b\u548c\u4e0d\u5927\u4e8e\u4e00\u4e2a\u7ed9\u5b9a\u503c\u3002\u653e\u597d\u4e4b\u540e\uff0c\u654c\u4eba\u6765\u88ad\uff0c\u654c\u4eba\u7684\u653b\u51fb\u6709\u6982\u7387\u4f7f\u5f97\u4f60\u7684\u9632\u5fa1\u5854\u964d\u7ea7\u6216\u8005\u76f4\u63a5\u88ab\u7834\u574f\u3002\u9700\u8981\u6c42\u89e3\u4e00\u4e2a\u6700\u4f18\u7684\u653e\u7f6e\u7b56\u7565\uff0c\u8ba9\u81ea\u5df1\u4fdd\u7559\u7684\u9632\u5fa1\u5854\u7b49\u7ea7\u4e4b\u548c\u6700\u5927\u3002</p> <p>\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u8d34\u5408\u521a\u521a\u63d0\u5230\u7684 MRP \u8fc7\u7a0b\u7684\u573a\u666f\u3002\u4f46\u662f\u5982\u679c\u4f60\u8981\u5bf9\u6b64\u8fdb\u884c\u7cbe\u786e\u6c42\u89e3\uff0c\u8ba1\u7b97\u91cf\u4f1a\u8fbe\u5230 \\(n^3k^3\\)\uff0c\u5373\u4f7f\u6709 50 \u4e2a\u683c\u5b50 8 \u79cd\u7b49\u7ea7\uff0c\u4e5f\u81f3\u5c11\u9700\u8981\u8ba1\u7b97 64M \u6b21\u3002</p> <p>\u5e76\u4e14\u4e00\u5f00\u59cb\u6211\u4eec\u8fd8\u53ef\u80fd\u4e0d\u77e5\u9053\u6bc1\u4f24\u548c\u51fb\u6bc1\u7684\u6982\u7387\uff0c\u8fd9\u5c31\u9700\u8981\u66f4\u5927\u91cf\u7684\u8ba1\u7b97\u8fdb\u884c\u91c7\u6837\u3002</p> <p>\u56e0\u6b64\u6211\u4eec\u9700\u8981\u66f4\u9ad8\u6548\u5374\u4e0d\u90a3\u4e48\u7cbe\u786e\u7684\u7b97\u6cd5\uff01\u5177\u4f53\u600e\u4e48\u641e\uff0c\u4e14\u542c\u4e0b\u56de\u5206\u89e3\u3002</p>"}, {"location": "DNN/RL/#mdp", "title": "MDP", "text": "<p>\u6211\u4eec\u6ce8\u610f\u5230 MRP \u7c7b\u4f3c\u4e8e\u201c\u4e00\u9524\u5b50\u7684\u4e70\u5356\u201d\uff0c\u786e\u5b9a\u4e00\u4e2a\u72b6\u6001\u540e\uff0c\u5c31\u968f\u7740\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u5728\u90a3\u91cc\u968f\u6ce2\u9010\u6d41\u4e86\u3002\u80fd\u4e0d\u80fd\u66f4\u6709\u4e3b\u89c1\u4e00\u70b9\uff0c\u8ba9\u6a21\u578b\u8fdb\u884c\u6bcf\u4e00\u6b65\u7684\u51b3\u7b56\u5462\uff1f\u53ef\u4ee5\u7684\uff0c\u8fd9\u5c31\u662f Markov \u51b3\u7b56\u8fc7\u7a0b MDP\u3002</p> <p>\u4ece\u5b9a\u4e49\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u521a\u521a\u7684 MRP \u8fdb\u884c\u4fee\u6539\u3002\u9996\u5148\u72b6\u6001\u8f6c\u79fb\u77e9\u9635 \\(\\mathcal{P}\\) \u5c31\u53d8\u6210\u4e86\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>[N, N, A]</code> \u7684\u4e09\u7ef4\u5f20\u91cf\uff0c\u7528\u6570\u5b66\u8bed\u8a00\u8bf4\u5c31\u662f \\(P(s_i|s_j,a)\\) \u8868\u793a\u4ece \\(s_j\\) \u51fa\u53d1\u91c7\u53d6\u52a8\u4f5c \\(a\\) \u80fd\u591f\u5230\u8fbe\u7684\u6982\u7387\u3002\u6211\u7b2c\u4e00\u6b21\u770b\u611f\u89c9\u5f88\u79bb\u8c31\uff0c\u6bd4\u5982\u52a8\u4f5c \\(a\\) \u5c31\u662f\u4ece \\(s_j\\) \u5230 \\(s_i\\)\uff0c\u4e00\u4e2a\u786e\u5b9a\u6027\u7684\u4e1c\u897f\u4e3a\u4ec0\u4e48\u8981\u5f15\u5165\u6982\u7387\u5462\uff1f\u5176\u5b9e\u6709\u4e00\u4e2a\u6a21\u578b\u53eb\u505a\u51b0\u6e56\u6a21\u578b\uff0c\u5373\u4f7f\u6211\u4eec\u91c7\u53d6\u4e86\u8fd9\u6837\u76f4\u63a5\u7684\u52a8\u4f5c\uff0c\u4e5f\u6709\u53ef\u80fd\u6ed1\u5230\u5176\u4ed6\u72b6\u6001\u53bb\u3002</p> <p>\u5bf9\u5e94\u7684\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u628a\u5956\u52b1\u6539\u6210\u77e9\u9635 \\(r(s,a)\\)\uff0c\u901a\u8fc7\u589e\u52a0\u5bf9\u52a8\u4f5c\u7684\u5956\u52b1\uff0c\u6211\u4eec\u53ef\u4ee5\u4fee\u6539\u6a21\u578b\u5bf9\u67d0\u4e9b\u7279\u5b9a\u52a8\u4f5c\u7684\u504f\u597d\u3002\u5f53\u7136\u6211\u4eec\u4e5f\u53ef\u4ee5\u4e0d\u52a0\uff0c\u7eaf\u76ee\u6807\u5bfc\u5411\u3002</p> <p>\u63a5\u4e0b\u6765\u5c31\u6d89\u53ca\u5230\u6700\u6838\u5fc3\u7684\u90e8\u5206\uff1a\u7b56\u7565\u3002\u667a\u80fd\u4f53\u7684\u7b56\u7565\u662f\u57fa\u4e8e\u72b6\u6001\u7684\u884c\u52a8\uff0c\u4e5f\u5c31\u662f \\(\\pi(a|s)=P(A_t=a|S_t=s)\\)\u3002\u5982\u679c\u667a\u80fd\u4f53\u91c7\u7528\u968f\u673a\u7684\u7b56\u7565\uff0c\u90a3 \\(\\pi\\) \u5c31\u523b\u753b\u5176\u5206\u5e03\uff1b\u5982\u679c\u667a\u80fd\u4f53\u91c7\u7528\u786e\u5b9a\u7684\u7b56\u7565\uff0c\u90a3\u8fd9\u4e2a\u5206\u5e03\u5c31\u53d8\u6210\u5355\u70b9\u5206\u5e03\u3002\u8fd9\u4e2a\u5206\u5e03\u5c06\u72b6\u6001\u7a7a\u95f4\u6620\u5c04\u5230\u52a8\u4f5c\u7a7a\u95f4\uff0c\u81ea\u7136\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6765\u62df\u5408\u8fd9\u4e2a\u5206\u5e03\u3002\u8fd9\u5c31\u662f\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u3002</p> <p>\u73b0\u5728\uff0c\u6211\u4eec\u53ef\u4ee5\u5199\u51fa\u57fa\u4e8e\u7b56\u7565 \\(\\pi\\) \u7684\u72b6\u6001\u4ef7\u503c\u51fd\u6570\uff1a</p> \\[ V^\\pi(s)=\\mathbb{E}_{a\\sim\\pi(a|s)}[G_t|S_t=s] \\] <p>\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u628a\u8fd9\u4e2a\u5f0f\u5b50\u9488\u5bf9\u6bcf\u4e2a\u52a8\u4f5c\u62c6\u5f00\uff0c\u5b9a\u4e49\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u4e3a\u67d0\u4e2a\u52a8\u4f5c\u7684\u4ef7\u503c\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u52a8\u4f5c\u7684\u56de\u62a5\u52a0\u4e0a\u52a8\u4f5c\u4e4b\u540e\u7684\u671f\u671b\u72b6\u6001\u4ef7\u503c\uff1a</p> \\[ Q^\\pi(s,a)=\\mathbb{E}[G_t|S_t=s,A_t=a]=r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^\\pi(s_i) \\] <p>\u6ce8\u610f\u5230\u8fd9\u4e2a\u65f6\u5019 \\(Q^\\pi\\) \u548c \\(V^\\pi\\) \u76f8\u4e92\u4f9d\u8d56\uff0c\u4e3a\u4e86\u50cf\u4e4b\u524d\u7684 MRP \u4e00\u6837\u80fd\u591f\u5199\u6210\u65b9\u7a0b\u7684\u5f62\u5f0f\u8fdb\u884c\u6c42\u89e3\uff0c\u6211\u4eec\u9700\u8981\u6539\u5199\u6210\u8ba9\u5b83\u4eec\u4f9d\u8d56\u4e8e\u81ea\u8eab\u7684\u81ea\u4e3e\u5f62\u5f0f\uff1a</p> \\[ \\begin{align*}     V^\\pi(s)&amp;=\\sum_{a\\in A}\\pi(a|s)Q^\\pi(s,a)\\\\     &amp;=\\sum_{a\\in A}\\pi(a|s)\\left(r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^\\pi(s_i)\\right)\\\\     Q^\\pi(s,a)&amp;=r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^\\pi(s_i)\\\\     &amp;=r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)\\sum_{a\\in A}\\pi(a|s_i)Q^\\pi(s_i,a) \\end{align*} \\] <p>\u8fd9\u88ab\u53eb\u505a\u8d1d\u5c14\u66fc\u671f\u671b\u65b9\u7a0b\u3002</p> <p>\u5bf9\u4e8e\u4e00\u4e2a\u786e\u5b9a\u7684\u7b56\u7565 \\(\\pi(a|s)\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8fb9\u7f18\u5316\u7684\u65b9\u5f0f\u5c06 MDP \u8f6c\u6362\u6210\u5df2\u77e5\u6c42\u89e3\u65b9\u5f0f\u7684 MRP \u6765\u6c42\u89e3\u3002\u5177\u4f53\u800c\u8a00\uff0c\u67d0\u4e2a\u72b6\u6001\u7684\u671f\u671b\u5956\u52b1\u548c\u671f\u671b\u7684\u8f6c\u79fb\u6982\u7387\u53ef\u4ee5\u901a\u8fc7\u5168\u671f\u671b\uff08\u6982\u7387\uff09\u516c\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff1a</p> \\[ \\begin{align*}     \\hat r(s)&amp;=\\sum_{a\\in A}\\pi(a|s)r(s,a)\\\\     \\hat P(s_i,s)&amp;=\\sum_{a\\in A}\\pi(a|s)P(s_i|s,a) \\end{align*} \\] <p>\u7b80\u5355\u8bf4\uff0c\u5c31\u662f\u5229\u7528\u5206\u5e03 \\(\\pi(a|s)\\) \u4f5c\u4e3a\u6743\u91cd\u8fdb\u884c\u52a0\u6743\uff0c\u5c06\u5956\u52b1\u77e9\u9635\u7684 \\(a\\) \u7ef4\u5ea6\u62cd\u5230 \\(s\\) \u7ef4\u5ea6\u4e0a\u9762\uff0c\u5c06\u8f6c\u79fb\u5f20\u91cf\u7684 \\(a\\) \u7ef4\u5ea6\u62cd\u5230 \\(s\\times s\\) \u77e9\u9635\u4e0a\u9762\u3002\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u8f6c\u5316\u6210 MDP \u6765\u6c42\u89e3\u6bcf\u4e00\u4e2a\u72b6\u6001\u7684\u4ef7\u503c\u4e86\u3002</p> <p>\u81ea\u7136\u8fd9\u6837\u505a\u9700\u8981\u6211\u4eec\u660e\u786e\u9664\u4e86 \\(V^\\pi\\) \u548c \\(Q^\\pi\\) \u5916\u7684\u7b56\u7565\u5206\u5e03\u3001\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u548c\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u4e00\u822c\u800c\u8a00\uff0c\u8fd9\u4e9b\u4e1c\u897f\u57fa\u672c\u4e0a\u90fd\u662f\u9ed1\u76d2\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u8fdb\u884c\u91c7\u6837\u3002\u4e5f\u5c31\u662f\u57fa\u4e8e\u7b56\u7565 \\(\\pi\\) \u91c7\u6837\u72b6\u6001\u8def\u5f84\uff0c\u5e76\u8ba1\u7b97\u4f30\u8ba1\u7684 \\(V^\\pi(s)\\)\u3002</p> <p>\u77e5\u9053\u4e86\u67d0\u4e2a\u7b56\u7565 \\(\\pi\\) \u5bf9\u5e94\u7684\u72b6\u6001\u4ef7\u503c \\(V^\\pi(s)\\) \u4e4b\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8003\u8651\u4f18\u5316\u8fd9\u4e2a\u7b56\u7565\uff0c\u8ba9\u5176\u4ef7\u503c\u5c3d\u53ef\u80fd\u9ad8\uff0c\u4e5f\u5c31\u662f\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\uff1a</p> \\[ \\begin{align*}     V^*(s)&amp;=\\max_{a\\in A}\\left(r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^*(s_i)\\right)\\\\     Q^*(s,a)&amp;=r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)\\max_{a\\in A}Q^*(s_i,a) \\end{align*} \\] <p>\u548c\u4e4b\u524d\u7684\u8d1d\u5c14\u66fc\u671f\u671b\u65b9\u7a0b\u6bd4\u8f83\uff0c\u5176\u5b9e\u5c31\u662f\u628a \\(\\sum_{a\\in A}\\pi(a|s_i)\\) \u6362\u6210\u4e86 \\(\\max_{a\\in A}\\)\uff0c\u4e5f\u5c31\u662f\u4ece\u6c42\u671f\u671b\u53d8\u6210\u4e86\u53d6\u6700\u4f18\u3002</p> <p>\u4e0b\u9762\u7684\u4efb\u52a1\uff0c\u5c31\u662f\u5bf9\u8fd9\u4e2a\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\u8fdb\u884c\u6c42\u89e3\u4e86\u3002</p> <p>\u7cbe\u786e\u89e3\u6cd5\u8bf7\u770b\u7b2c\u56db\u7ae0\uff0c\u57fa\u4e8e\u968f\u673a\u5316\u91c7\u6837\u7684\u5404\u79cd\u7b97\u6cd5\u8bf7\u770b\u7b2c\u4e09\u70b9\u4e94\u7ae0\u548c\u7b2c\u4e94\u7ae0\u3002</p>"}, {"location": "DNN/RL/#_9", "title": "\u7b2c\u4e09\u70b9\u4e94\u7ae0", "text": "<p>\u672c\u7ae0\u662f\u8865\u5145\u5185\u5bb9\uff0c\u65e8\u5728\u8865\u5145\u8bb2\u89e3\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff0c\u5bf9\u5e94\u539f\u6559\u7a0b 3.5 \u8282\u3002\u300a\u52a8\u624b\u5b66\u5f3a\u5316\u5b66\u4e60\u300b\u6ca1\u6709\u8fd9\u4e00\u7ae0\u7279\u522b\u8be6\u7ec6\u7684\u5185\u5bb9\uff0c\u63d0\u4e86\u4e00\u5634\u4e4b\u540e\u5c31\u5728\u90a3\u7ea0\u7ed3\u5360\u7528\u5ea6\u91cf\uff0c\u4f46\u662f\u6211\u89c9\u5f97\u5360\u7528\u5ea6\u91cf\u4e0d\u662f\u4e00\u4e2a\u7279\u522b\u503c\u5f97\u5355\u72ec\u8ba8\u8bba\u7684\u70b9\uff0c\u56e0\u6b64\u6211\u5c31\u8df3\u8fc7\u4e86\uff0c\u672c\u7ae0\u57fa\u4e8e\u300a\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u539f\u7406\u300b\u8865\u5145\u3002</p>"}, {"location": "DNN/RL/#_10", "title": "\u56de\u987e", "text": "<p>\u4ece\u6700\u62bd\u8c61\u7684\u610f\u4e49\u4e0a\u8bf4\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u7b56\u7565\uff0c\u600e\u4e48\u6837\u627e\u5230\u6700\u4f18\u7b56\u7565\u5462\uff1f\u5bf9\u4e8e\u72b6\u6001 \\(s\\)\uff0c\u7b56\u7565\u7ed9\u51fa\u52a8\u4f5c \\(a\\)\uff0c\u6211\u4eec\u80af\u5b9a\u9996\u5148\u8981\u8db3\u591f\u80af\u5b9a\u5f53\u524d\u72b6\u6001\u5bf9\u5e94\u8fd9\u4e2a\u52a8\u4f5c\u7684\u4ef7\u503c\u662f\u591a\u5c11\uff0c\u66f4\u8981\u80af\u5b9a\u8fd9\u4e2a\u52a8\u4f5c\u662f\u4e0d\u662f\u5e26\u6765\u6700\u5927\u4ef7\u503c\u7684\u52a8\u4f5c\u3002</p> <p>\u56de\u5fc6\u4e00\u4e0b\u2014\u2014\u8fd9\u4e0d\u5c31\u662f\u7b2c\u4e8c\u7ae0\u6211\u4eec\u8ba8\u8bba\u8fc7\u7684\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u5417\uff01</p>"}, {"location": "DNN/RL/#_11", "title": "\u8fc1\u79fb", "text": "<p>\u8ba9\u6211\u4eec\u8bd5\u56fe\u628a\u6700\u7b80\u5355\u7684\u03b5-\u8d2a\u5a6a\u7b97\u6cd5\u8fc1\u79fb\u5230\u8fd9\u4e2a\u573a\u666f\u6765\u3002</p> <p>\u4ece\u4e00\u4e2a\u521d\u59cb\u7684\u72b6\u6001-\u52a8\u4f5c\u7ec4 \\((s,a)\\) \u5f00\u59cb\uff0c\u6211\u4eec\u53ef\u4ee5\u4ea7\u751f\u957f\u5ea6 \\(T\\) \u7684\u4e00\u7cfb\u5217\u72b6\u6001-\u52a8\u4f5c\u7ec4\u3002\u5012\u8fc7\u6765\u770b\uff0c\u6211\u4eec\u53ef\u4ee5\u5c42\u5c42\u5411\u5916\u53bb\u7d2f\u8ba1\u4ef7\u503c\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6bd4\u5982\u8bf4\u72b6\u6001-\u52a8\u4f5c\u7ec4 \\((s_{t},a_{t})\\) \u80fd\u4ea7\u751f\u7684\u5956\u52b1 \\(R_{t}\\) \u5c31\u662f \\(r(s_{t},a_{t})\\)\uff0c\u800c\u6b64\u65f6\u7684\u7d2f\u79ef\u5956\u52b1 \\(G_{t}=\\gamma G_{t+1}+R_{t+1}\\)\uff0c\u5c31\u53ef\u4ee5\u5012\u7740\u4e00\u6b65\u6b65\u6c42\u51fa\u6765\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u8d70\u8fd9\u4e00\u8d9f\u6211\u4eec\u53ef\u4ee5\u6c42\u5f97\u8fd9\u4e2a\u8def\u5f84\u4e3a\u72b6\u6001-\u52a8\u4f5c\u7ec4 \\((s_{t},a_{t})\\) \u5e26\u6765\u7684\u603b\u7684\u5956\u52b1 \\(R\\)\u3002</p> <p>\u8fdb\u800c\uff0c\u884c\u52a8\u7684\u4ef7\u503c\u51fd\u6570 \\(Q(s_t,a_t)\\) \u5c31\u662f\u72b6\u6001-\u52a8\u4f5c\u7ec4 \\((s_{t},a_{t})\\) \u5bf9\u5e94\u7684 \\(G\\) \u7684\u671f\u671b\uff0c\u90a3\u4e48\u8ba1\u7b97\u8def\u5f84\u8bbf\u95ee\u7684\u8fd9\u4e2a\u7ec4\u7684\u6b21\u6570 \\(N_{s_t,a_t}\\)\uff0c\u7528 \\(R\\) \u9664\u4ee5\u8fd9\u4e2a\u6b21\u6570\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230 \\(Q\\) \u7684\u671f\u671b\u503c\u4e86\u3002</p> <p>\u6309\u5148\u524d\u7684\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\uff0c\u90a3\u6211\u5c31\u76f4\u63a5\u9009\u80fd\u4f7f\u5f97 \\(Q\\) \u6700\u5927\u7684\u884c\u52a8\u5c31\u884c\u4e86\u554a\u2026\u2026\u5bf9\u5417\uff1f</p> <p>\u73b0\u5728\u7684\u95ee\u9898\u662f\uff0c\u5bf9\u4e8e\u72b6\u6001 \\(s_t\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u5bf9\u5e94\u5404\u4e2a\u52a8\u4f5c\u4f30\u8ba1\u7684\u4ef7\u503c\u51fd\u6570\uff0c\u4f46\u8fd9\u7ec8\u7a76\u662f\u4f30\u8ba1\uff0c\u9700\u8981\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u4e0d\u80fd\u786c\u53d6 \\(\\max\\) \u53d8\u6210\u7eaf\u8d2a\u5fc3\uff0c\u800c\u662f\u9009\u62e9\u91c7\u7528\u03b5-\u8d2a\u5a6a\u7b56\u7565\uff1a\u628a \\(\\max\\) \u7684\u90a3\u4e2a\u52a8\u4f5c\u7684\u6982\u7387\u8bbe\u7f6e\u6210 \\(1-\\dfrac{|A(s_t)|-1}{|A(s_t)|}\\epsilon\\)\uff0c\u5176\u4ed6\u52a8\u4f5c\u7684\u6982\u7387\u8bbe\u7f6e\u6210 \\(\\dfrac{1}{|A(s_t)|}\\epsilon\\)\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u770b\u770b\u5177\u4f53\u7684\u7b97\u6cd5\u6d41\u7a0b\u5427\uff1a</p>"}, {"location": "DNN/RL/#_12", "title": "\u7b97\u6cd5", "text": "<p>\u8fd9\u4e2a\u7b97\u6cd5\u53eb\u505a MC \u03b5-Greedy\u3002\u8ba9\u6211\u4eec\u7406\u4e00\u4e0b\u7b97\u6cd5\u6d41\u7a0b\uff1a</p> <ul> <li>\u9700\u8981\u7b56\u7565 \\(\\pi\\)\uff0c\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570 \\(Q(s,a)\\)\uff0c\u6bcf\u5bf9\u7684\u7d2f\u8ba1\u5956\u52b1 \\(R(s,a)=0\\) \u548c\u8ba1\u6570\u51fd\u6570 \\(N(s,a)=0\\)</li> <li>\u5f00\u59cb\u91c7\u6837\uff1a</li> <li>\u4ece\u67d0\u4e2a\u968f\u673a\u9009\u62e9\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9 \\((s_0,a_0)\\) \u5f00\u59cb\uff0c\u91c7\u6837\u4e00\u4e2a\u957f\u5ea6\u4e3a \\(T\\) \u7684\u5e8f\u5217\u3002</li> <li>\u521d\u59cb\u5316\u7d2f\u8ba1\u5956\u52b1 \\(G=0\\)<ul> <li>\u5bf9\u4e8e \\(t=T-1,T-2,\\dots,0\\)\uff1a</li> <li>\u8ba1\u7b97\u5e8f\u5217\u7d2f\u8ba1\u5956\u52b1 \\(G\\leftarrow \\gamma G+r(s_t,a_t)\\)</li> <li>\u8ba1\u7b97\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u7d2f\u79ef\u5956\u52b1 \\(R(s_t,a_t)\\leftarrow R(s_t,a_t)+G\\)\uff0c\u66f4\u65b0\u8ba1\u6570\u51fd\u6570 \\(N(s_t,a_t)\\leftarrow N(s_t,a_t)+1\\)</li> <li>\u8ba1\u7b97\u671f\u671b\u503c \\(Q(s_t,a_t)=\\dfrac{R(s_t,a_t)}{N(s_t,a_t)}\\)</li> <li>\u6539\u8fdb\u7b56\u7565\uff1a\u5982\u679c\u8fd9\u4e2a \\(a_t\\) \u80fd\u591f\u4f7f \\(Q\\) \u66f4\u5927\uff0c\u5c31\u628a\u8fd9\u4e2a\u52a8\u4f5c\u7684\u6982\u7387 \\(\\pi(a=a_t|s_t)\\) \u8bbe\u7f6e\u6210 \\(1-\\dfrac{|A(s_t)|-1}{|A(s_t)|}\\epsilon\\)\uff0c\u5176\u4ed6\u52a8\u4f5c\u7684\u6982\u7387 \\(\\pi(a\\ne a_t|s_t)\\) \u8bbe\u7f6e\u6210 \\(\\dfrac{1}{|A(s_t)|}\\epsilon\\)\u3002</li> </ul> </li> <li>\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\uff0c\u8fbe\u5230\u8bbe\u5b9a\u7684\u91c7\u6837\u6b21\u6570\u5c31\u505c\u6b62\u3002</li> </ul> <p>\u8fd9\u4e2a\u6a21\u578b\u662f\u65e0\u6a21\u578b\u7684\u7b56\u7565\u6539\u8fdb\u7b97\u6cd5\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u4e0d\u5148\u9a8c\u5730\u9884\u77e5\u73af\u5883\u5e26\u6765\u7684\u72b6\u6001\u8f6c\u79fb\u6982\u7387\uff0c\u800c\u662f\u901a\u8fc7\u91c7\u6837\u7684\u5e8f\u5217\u548c\u5bf9\u5e94\u7684\u5956\u52b1\u6765\u8fdb\u884c\u5b66\u4e60\u3002\u540c\u65f6\uff0c\u6211\u4eec\u4e0d\u77e5\u9053\u6700\u540e\u5f97\u5230\u7684\u7b56\u7565\u662f\u5426\u662f\u6700\u4f18\u7684\u3002</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u8981\u770b\u7684\u7b97\u6cd5\u662f\u6709\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u57fa\u4e8e\u7ed9\u5b9a\u7684\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u3001\u5956\u52b1\u51fd\u6570\u548c\u7b56\u7565\u5206\u5e03\u3002\u6b64\u65f6\u6211\u4eec\u80fd\u591f\u786e\u5b9a\u5730\u5f97\u5230\u6700\u4f18\u7b56\u7565\u3002</p>"}, {"location": "DNN/RL/#_13", "title": "\u7b2c\u56db\u7ae0", "text": "<p>\u672c\u7ae0\u4ecb\u7ecd\u7684\u662f\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff0c\u867d\u7136\u53eb\u8fd9\u4e2a\u540d\u5b57\uff0c\u4f46\u5176\u5b9e\u662f\u8d2a\u5fc3\u7b97\u6cd5\u3002</p>"}, {"location": "DNN/RL/#_14", "title": "\u7b56\u7565\u8fed\u4ee3", "text": "<p>\u7b56\u7565\u8fed\u4ee3\u5206\u4e3a\u4e24\u4e2a\u8fc7\u7a0b\uff1a\u7b56\u7565\u8bc4\u4f30\u548c\u7b56\u7565\u63d0\u5347\u3002</p>"}, {"location": "DNN/RL/#_15", "title": "\u7b56\u7565\u8bc4\u4f30", "text": "<p>\u4e00\u5f00\u59cb\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u5f97\u5230\u4e86 MDP \u7684\u8d1d\u5c14\u66fc\u671f\u671b\u65b9\u7a0b\uff1a</p> \\[ V^\\pi(s)=\\sum_{a\\in A}\\pi(a|s)\\left(r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^\\pi(s_i)\\right) \\] <p>\u4e4b\u524d\u6211\u4eec\u63d0\u5230\uff0c\u8981\u628a\u8fd9\u4e2a\u8d1d\u5c14\u66fc\u671f\u671b\u65b9\u7a0b\u5199\u6210\u81ea\u4e3e\u7684\u5f62\u5f0f\uff0c\u5c3d\u7ba1\u6211\u4eec\u5e76\u4e0d\u80fd\u50cf MRP \u4e00\u6837\u76f4\u63a5\u8fdb\u884c\u89e3\u6790\u6c42\u89e3\uff0c\u4f46\u6ce8\u610f\u5230\u8fd9\u4e2a\u4e1c\u897f\u5f88\u50cf\u4e0d\u52a8\u70b9\u8fed\u4ee3\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e \\(V^\\pi\\) \u800c\u8a00\uff0c\u6211\u4eec\u6839\u636e\u4e0a\u9762\u7684\u65b9\u7a0b\u5de6\u8fb9\u8d4b\u7ed9\u53f3\u8fb9\uff0c\u76f4\u5230\u5dee\u503c\u5c0f\u4e8e\u5bb9\u5dee \\(\\theta\\)\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5f53\u524d\u7b56\u7565\u4e0b\u7684\u5168\u90e8\u72b6\u6001\u4ef7\u503c \\(V^*(s)\\) \u4e86\u3002</p>"}, {"location": "DNN/RL/#_16", "title": "\u7b56\u7565\u63d0\u5347", "text": "<p>\u8fd9\u4e00\u6b65\u6211\u4eec\u76f4\u63a5\u53ef\u4ee5\u4ece\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\u5bfc\u51fa\uff0c\u5bf9\u4e8e\u72b6\u6001 \\(s\\)\uff1a</p> \\[ \\pi^*(a|s)=a\\mathrm{\\quad s.t.\\quad}\\max_{a\\in A}\\left(r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^*(s_i)\\right) \\] <p>\u7531\u4e8e\u7b56\u7565\u63d0\u5347\u4e4b\u540e\uff0c\u57fa\u4e8e\u7b56\u7565\u7684\u72b6\u6001\u4ef7\u503c\u51fd\u6570\u5c31\u6539\u53d8\u4e86\uff0c\u56e0\u6b64\u9700\u8981\u91cd\u65b0\u8fdb\u884c\u7b56\u7565\u8bc4\u4f30\u3002</p> <p>\u7b56\u7565\u63d0\u5347\u7684\u7ec8\u70b9\u5c31\u662f\u6ca1\u6709\u66f4\u4f18\u7684\u7b56\u7565\u53ef\u4ee5\u63d0\u5347\u4e86\uff0c\u4e5f\u5c31\u662f\u5f97\u5230\u4e86\u6700\u4f18\u7b56\u7565\u3002</p>"}, {"location": "DNN/RL/#_17", "title": "\u4ef7\u503c\u8fed\u4ee3", "text": "<p>\u6211\u4eec\u91cd\u65b0\u5ba1\u89c6\u4e00\u4e0b\u521a\u521a\u5229\u7528\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\u7684\u5730\u65b9\uff0c\u53ef\u4ee5\u53d1\u73b0\u6211\u4eec\u5176\u5b9e\u628a\u90a3\u4e2a \\(\\max\\) \u7684\u503c\u7ed9\u4e22\u4e86\uff0c\u53ea\u53bb\u627e\u6700\u5927\u7684\u884c\u52a8\u53bb\u4e86\u3002</p> <p>\u4f46\u5176\u5b9e\u8fd9\u4e2a\u503c\u5c31\u662f\u5f53\u524d\u7684\u6700\u4f18\u4ef7\u503c\uff01\u5982\u679c\u5229\u7528\u597d\u8fd9\u4e2a\u4fe1\u606f\u53c2\u4e0e\u8fed\u4ee3\uff0c\u80af\u5b9a\u6bd4\u91cd\u65b0\u6765\u505a\u7b56\u7565\u8bc4\u4f30\u5feb\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5bf9\u521a\u521a\u7684\u7b56\u7565\u8bc4\u4f30\u8fdb\u884c\u4e00\u70b9\u70b9\u4fee\u6539\uff1a</p> \\[ V^*(s)=\\max_{a\\in A}\\left(r(s,a)+\\gamma\\sum_{s_i\\in S}p(s_i|s,a)V^*(s_i)\\right) \\] <p>\u5bf9\u8fd9\u4e2a\u72b6\u6001\u4ef7\u503c\u51fd\u6570\u8fdb\u884c\u4e0d\u52a8\u70b9\u8fed\u4ee3\uff0c\u76f4\u5230\u6536\u655b\uff0c\u5c31\u80fd\u66f4\u5feb\u5730\u6536\u655b\u5230\u6700\u4f18\u4ef7\u503c\u3002</p> <p>\u6700\u540e\uff0c\u6211\u4eec\u50cf\u5148\u524d\u7684\u7b56\u7565\u63d0\u5347\u4e00\u6837\uff0c\u6c42\u51fa\u8fd9\u4e2a \\(\\max\\) \u5bf9\u5e94\u7684\u5404\u4e2a\u72b6\u6001\u7684\u884c\u52a8\u5373\u53ef\u3002</p>"}, {"location": "DNN/RL/#_18", "title": "\u6536\u655b\u6027\u8bc1\u660e", "text": "<p>\u8bf7\u53c2\u9605\u4efb\u4f55\u4e00\u672c\u5f3a\u5316\u5b66\u4e60\u6559\u6750\u3002\u8fd9\u91cc\u5b9e\u5728\u4e0d\u60f3\u7ea0\u7ed3\u4e8e\u6570\u5b66\u7684\u7ec6\u8282\u4e86\uff0c\u5b9e\u9645\u5e94\u7528\u4e0a\u6839\u672c\u4e0d\u53ef\u80fd\u6709\u8fd9\u4e48\u7b80\u5355\u7684\u767d\u76d2\u573a\u666f\uff0c\u800c\u4e00\u822c\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fd8\u4e0d\u4e00\u5b9a\u4fdd\u8bc1\u6536\u655b\u5462\uff0c\u8fd9\u91cc\u63a8\u5bfc\u8fd9\u4e48\u591a\u4e0d\u662f\u626f\u6de1\u5417\u2026\u2026</p>"}, {"location": "DNN/RL/#_19", "title": "\u7b2c\u4e94\u7ae0", "text": "<p>\u672c\u7ae0\u8bb2\u89e3\u65f6\u5e8f\u5dee\u5206\u7b97\u6cd5\uff0c\u4e3b\u8981\u662f Sarsa \u7b97\u6cd5\u548c Q-learning \u7b97\u6cd5\u3002\u5728\u6211\u770b\u6765\uff0c\u8fd9\u4e24\u79cd\u7b97\u6cd5\u90fd\u662f\u57fa\u4e8e\u5148\u524d\u7684 MC \u03b5-Greedy \u7b97\u6cd5\u7684\u6539\u8fdb\u3002\u5728\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u4e2d\uff0c\u6211\u4eec\u6709\u4e0b\u9762\u7684\u64cd\u4f5c\uff1a</p> <ul> <li>\u8ba1\u7b97\u5e8f\u5217\u7d2f\u8ba1\u5956\u52b1 \\(G\\leftarrow \\gamma G+r(s_t,a_t)\\)</li> <li>\u8ba1\u7b97\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u7d2f\u79ef\u5956\u52b1 \\(R(s_t,a_t)\\leftarrow R(s_t,a_t)+G\\)\uff0c\u66f4\u65b0\u8ba1\u6570\u51fd\u6570 \\(N(s_t,a_t)\\leftarrow N(s_t,a_t)+1\\)</li> <li>\u8ba1\u7b97\u671f\u671b\u503c \\(Q(s_t,a_t)=\\dfrac{R(s_t,a_t)}{N(s_t,a_t)}\\)</li> </ul> <p>\u5b9e\u9645\u4e0a\uff0c\\(Q\\) \u7684\u66f4\u65b0\u5f0f\u5b50\u5199\u5f00\uff0c\u5c31\u662f\uff1a</p> \\[ \\begin{align*}     Q'(s_t,a_t)&amp;=\\dfrac{R'(s_t,a_t)}{N'(s_t,a_t)}\\\\     &amp;=\\dfrac{R(s_t,a_t)+\\gamma G+r(s_t,a_t)}{N'(s_t,a_t)}\\\\     &amp;=\\dfrac{N'(s_t,a_t)-1}{N'(s_t,a_t)}Q(s_t,a_t)+\\dfrac{\\gamma G+r(s_t,a_t)}{N'(s_t,a_t)}\\\\     &amp;=Q(s_t,a_t)+\\dfrac{1}{N'(s_t,a_t)}[\\gamma G+r(s_t,a_t)-Q(s_t,a_t)] \\end{align*} \\] <p>\u8003\u8651\u5230\u6211\u4eec\u4e0d\u4e00\u5b9a\u8981\u50cf MC \u03b5-Greedy \u90a3\u6837\u5012\u7740\u8ba1\u7b97\u67d0\u4e2a\u5e8f\u5217\u7684\u7d2f\u79ef\u5956\u52b1\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u5e8f\u5217\u957f\u5ea6 \\(N\\) \u548c\u7d2f\u8ba1\u5956\u52b1 \\(G\\) \u662f\u96be\u4ee5\u83b7\u77e5\u7684\uff0c\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u7528\u4e00\u4e9b\u5df2\u77e5\u91cf\u8fdb\u884c\u5408\u7406\u66ff\u4ee3\u3002</p> <p>\u4e00\u65b9\u9762\uff0c\u5e8f\u5217\u957f\u5ea6\u672a\u77e5\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u7528\u4e00\u4e2a\u7c7b\u4f3c\u7aef\u5230\u7aef\u5b66\u4e60\u7684\u5b66\u4e60\u7387\u7684\u91cf \\(\\alpha\\) \u6765\u4ee3\u66ff \\(\\dfrac{1}{N'(s_t,a_t)}\\)\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u65e2\u7136 \\(G\\) \u662f\u8fdb\u884c\u52a8\u4f5c \\((s_t,a_t)\\to s_{t+1}\\) \u540e\u7684\u7d2f\u79ef\u5956\u52b1\uff0c\u90a3\u4e48\u6839\u636e\u81ea\u4e3e\u5f62\u5f0f\u7684\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5229\u7528\u76ee\u6807\u72b6\u6001 \\(s_{t+1}\\) \u7684\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u6765\u4f30\u8ba1\u8fd9\u4e2a\u7d2f\u79ef\u5956\u52b1\u4e86\u3002\u8fd9\u5c31\u662f\u65f6\u5e8f\u5dee\u5206\u7b97\u6cd5\u7684\u542b\u4e49\u3002\u4e5f\u5c31\u662f</p> \\[ Q'(s_t,a_t)=Q(s_t,a_t)+\\alpha[\\gamma Q(s_{t+1},a_{t+1})+r(s_t,a_t)-Q(s_t,a_t)] \\] <p>\u73b0\u5728\u552f\u4e00\u4e0d\u77e5\u9053\u7684\u5c31\u662f \\(a_{t+1}\\) \u600e\u4e48\u4e2a\u53d6\u6cd5\u4e86\uff0c\u800c\u5b83\u7684\u53d6\u6cd5\u5c31\u57fa\u672c\u4e0a\u51b3\u5b9a\u4e86\u672c\u7ae0\u7684 Sarsa \u7b97\u6cd5\u548c Q-learning \u7b97\u6cd5\u7684\u5206\u91ce\u3002</p>"}, {"location": "DNN/RL/#sarsa", "title": "Sarsa \u7b97\u6cd5", "text": "<p>Sarsa \u7b97\u6cd5\u7684\u601d\u60f3\u662f\uff0c\u65e2\u7136\u6211\u8981\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff0c\u90a3 \\(a_{t+1}\\) \u4e5f\u53ef\u4ee5\u5229\u7528 \u03b5-Greedy \u7b56\u7565\u8fdb\u884c\u751f\u6210\u3002\u5177\u4f53\u800c\u8a00\u7684\u7b97\u6cd5\u6d41\u7a0b\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570 \\(Q(s,a)\\)</li> <li>\u57fa\u4e8e\u7ed9\u5b9a\u7684\u5e8f\u5217\u91c7\u6837\u6b21\u6570 \\(T\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u9009\u62e9\u521d\u59cb\u72b6\u6001 \\(s\\)</li> <li>\u5728 \\(s\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a\\)\u3002</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684\u65f6\u95f4\u6b65 \\(N\\) \u5f00\u59cb\u5faa\u73af\uff1a</li> <li>\u57fa\u4e8e\u52a8\u4f5c \\(a\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(s'\\)\uff0c\u5e76\u83b7\u5f97\u73af\u5883\u5956\u52b1 \\(r(s,a)\\)</li> <li>\u5728 \\(s'\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a'\\)\u3002</li> <li>\u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[\\gamma Q(s',a')+r(s,a)-Q(s,a)]\\)</li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s',a\\leftarrow a'\\)</li> </ul> </li> </ul> <p>\u5229\u7528 \\(Q(s',a')\\) \u5bf9 \\(Q(s_{t+1},a_{t+1})\\) \u8fdb\u884c\u5355\u6b65\u4f30\u8ba1\u662f\u76f8\u5bf9\u6bd4\u8f83\u201c\u6162\u201d\u7684\uff0c\u8fd9\u662f\u56e0\u4e3a MC \u65b9\u6cd5\u56fa\u6709\u7684\u7279\u6027\uff0c\u56e0\u6b64\u4e3a\u4e86\u83b7\u53d6\u66f4\u591a\u7684\u6570\u636e\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u4f30\u8ba1\uff0c\u6211\u4eec\u53ef\u4ee5\u628a  \\(Q(s_{t+1},a_{t+1})\\) \u62c6\u5f00\uff1a</p> \\[ \\gamma Q(s_{t+1},a_{t+1})=\\gamma r(s_{t+1},a_{t+1})+\\gamma^2 (s_{t+2},a_{t+2})+\\cdots+\\gamma^n Q(s_{t+n},a_{t+n}) \\] <p>\u8fd9\u5c31\u662f\u591a\u6b65 Sarsa \u7b97\u6cd5\u3002\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570 \\(Q(s,a)\\)</li> <li>\u57fa\u4e8e\u7ed9\u5b9a\u7684\u5e8f\u5217\u91c7\u6837\u6b21\u6570 \\(T\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u9009\u62e9\u521d\u59cb\u72b6\u6001 \\(s\\)</li> <li>\u5728 \\(s\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a\\)\u3002</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684\u603b\u65f6\u95f4\u6b65 \\(N\\) \u5f00\u59cb\u5faa\u73af\uff1a</li> <li>\u521d\u59cb\u5316\u7d2f\u79ef\u5956\u52b1 \\(R=0\\)</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684 Sarsa \u6b65\u6570 \\(n\\) \u4ece \\(i = 1\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u57fa\u4e8e\u52a8\u4f5c \\(a\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(s'\\)\uff0c\u5e76\u83b7\u5f97\u73af\u5883\u5956\u52b1 \\(r(s_i,a_i)\\)</li> <li>\u5728 \\(s'\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a'\\)\u3002</li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s',a\\leftarrow a'\\)</li> </ul> </li> <li>\u8ba1\u7b97\u7d2f\u8ba1\u5956\u52b1 \\(R=\\gamma^{n+1}Q(s',a')+\\sum_{i=1}^{n}\\gamma^i r(s_i,a_i)\\)</li> <li>\u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[R+r(s,a)-Q(s,a)]\\)</li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s',a\\leftarrow a'\\)</li> </ul> </li> </ul> <p>\u53ef\u4ee5\u770b\u5230\u603b\u65f6\u95f4\u6b65\u4e0d\u53d8\u4f46\u591a\u6b65 Sarsa \u7b97\u6cd5\u7684\u4f30\u8ba1\u66f4\u7cbe\u786e\uff0c\u6536\u655b\u4e5f\u66f4\u5feb\u3002</p>"}, {"location": "DNN/RL/#q-learning", "title": "Q-learning \u7b97\u6cd5", "text": "<p>Q-learning \u7b97\u6cd5\u9009\u62e9\u76f4\u63a5\u57fa\u4e8e\u8d1d\u5c14\u66fc\u6700\u4f18\u65b9\u7a0b\u8fdb\u884c\u4f30\u8ba1\uff0c\u56e0\u6b64 \\(a_{t+1}\\) \u53ef\u4ee5\u76f4\u63a5\u9009\u62e9 \\(\\max_{a_{t+1}\\in A(s_{t+1})} Q(s_{t+1},a_{t+1})\\)\u3002\u4f46\u662f\u4f60\u53ef\u80fd\u5c31\u8981\u95ee\uff0c\u8bf4\u597d\u7684\u201c\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u5e73\u8861\u201d\u5462\uff1f\u522b\u6025\uff0c\u8fd9\u5c31\u662f\u5b83\u4f5c\u4e3a\u79bb\u7ebf\u7b56\u7565\u7b97\u6cd5\u7684\u7cbe\u9ad3\uff0c\u5148\u770b\u7b97\u6cd5\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570 \\(Q(s,a)\\)</li> <li>\u57fa\u4e8e\u7ed9\u5b9a\u7684\u5e8f\u5217\u91c7\u6837\u6b21\u6570 \\(T\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u9009\u62e9\u521d\u59cb\u72b6\u6001 \\(s\\)</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684\u65f6\u95f4\u6b65 \\(N\\) \u5f00\u59cb\u5faa\u73af\uff1a</li> <li>\u5728 \\(s\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a\\)\u3002</li> <li>\u57fa\u4e8e\u52a8\u4f5c \\(a\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(s'\\)\uff0c\u5e76\u83b7\u5f97\u73af\u5883\u5956\u52b1 \\(r(s,a)\\)</li> <li>\u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[\\gamma \\max_{a'}Q(s',a')+r(s,a)-Q(s,a)]\\)</li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s'\\)</li> </ul> </li> </ul> <p>\u770b\uff0c\u6211\u4eec\u662f\u901a\u8fc7\u7b2c\u4e00\u4e2a \u03b5-Greedy \u7b56\u7565\u6765\u4fdd\u8bc1\u8fd9\u4e2a\u5e73\u8861\u7684\uff0c\u56e0\u4e3a\u4f60\u5e76\u6ca1\u6709\u7528\u5230\u8fd9\u4e2a max \u64cd\u4f5c\u6765\u8fdb\u884c\u52a8\u4f5c\u9009\u62e9\uff0c\u800c\u53ea\u662f\u53bb\u4f30\u8ba1\u52a8\u4f5c\u4ef7\u503c\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u4e0d\u4f1a\u56e0\u4e3a max \u800c\u201c\u6709\u5931\u504f\u9887\u201d\u3002\u56de\u987e\u4e00\u4e0b\u591a\u81c2\u8001\u864e\u673a\u91cc\u9762\uff0c\u6b63\u662f\u56e0\u4e3a\u6211\u4eec\u57fa\u4e8e\u4f30\u8ba1\u7684\u6700\u5927\u503c\u8fdb\u884c\u4e86\u9009\u62e9\uff0c\u624d\u4f1a\u4e00\u6b65\u9519\u6b65\u6b65\u9519\u3002</p> <p>\u5728\u8fd9\u4e2a\u573a\u666f\u91cc\u9762\uff0c\u6240\u6709\u52a8\u4f5c\u7684\u9009\u62e9\u90fd\u662f\u57fa\u4e8e\u6b63\u786e\u7684 \u03b5-Greedy \u7b56\u7565\u8fdb\u884c\u7684\uff0c\u800c\u8fd9\u624d\u80fd\u591f\u4fdd\u8bc1\u201c\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u5e73\u8861\u201d\u3002</p>"}, {"location": "DNN/RL/#_20", "title": "\u5728\u7ebf\u548c\u79bb\u7ebf", "text": "<p>\u8fd9\u91cc\u7684\u201c\u5728\u7ebf\u201d\u548c\u201c\u79bb\u7ebf\u201d\u5176\u5b9e\u548c OI \u8bed\u5883\u7684\u7528\u6cd5\u7c7b\u4f3c\u3002\u5728 OI \u91cc\u9762\u5bf9\u4e8e\u591a\u4e2a\u67e5\u8be2\uff0c\u201c\u79bb\u7ebf\u201d\u505a\u6cd5\u5c31\u662f\u5148\u6682\u5b58\u6240\u6709\u67e5\u8be2\uff0c\u901a\u8fc7\u5206\u5757\u6392\u5e8f\u7b49\u65b9\u5f0f\u80fd\u591f\u4f7f\u5f97\u5904\u7406\u67e5\u8be2\u7684\u6548\u7387\u66f4\u9ad8\uff08\u83ab\u961f\u7b97\u6cd5\uff09\uff1b\u201c\u5728\u7ebf\u201d\u505a\u6cd5\u5c31\u662f\u5f3a\u5236\u4e00\u4e2a\u67e5\u8be2\u5bf9\u5e94\u4e00\u4e2a\u7ed3\u679c\uff0c\u4e00\u822c\u53ef\u4ee5\u901a\u8fc7\u7b54\u6848\u4e92\u76f8\u5f02\u6216\u4e00\u4e0b\u6765\u4fdd\u8bc1\u67e5\u8be2\u5230\u7ed3\u679c\u7684\u987a\u5e8f\u6027\u3002</p> <p>\u5728 RL \u9886\u57df\uff0c\u521a\u521a\u63d0\u5230\u7684 Sarsa \u7b97\u6cd5\u5c31\u662f\u4e00\u4e2a\u5728\u7ebf\u7b56\u7565\u7b97\u6cd5\uff0c\u201c\u5728\u7ebf\u201d\u7684\u610f\u601d\u5c31\u662f\u5fc5\u987b\u76f4\u63a5\u5229\u7528\u5f53\u524d\u7684\u52a8\u4f5c\u5bf9 \\(Q\\) \u8fdb\u884c\u66f4\u65b0\uff0c\u4e5f\u5c31\u662f\u8bf4\u66f4\u65b0 \\(Q(s,a)\\) \u9700\u8981 \\((s,a,s',a',r)\\) \u8fd9\u4e2a\u4e94\u5143\u7ec4\uff0c\u800c \\((s',a')\\) \u53c8\u4f1a\u53d8\u6210\u65b0\u7684 \\((s,a)\\)\uff0c\u8fd9\u5c31\u8981\u6c42\u4e00\u79cd\u987a\u5e8f\u6027\u3002\u4e00\u6761\u9053\u8d70\u5230\u9ed1\uff0c\u4e0d\u649e\u5357\u5899\u4e0d\u56de\u5934\u3002</p> <p>\u800c Q-learning \u5bf9 \\(Q(s,a)\\) \u7684\u66f4\u65b0\u53ea\u9700\u8981 \\((s,a,s',r)\\) \u56db\u5143\u7ec4\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u76f4\u63a5\u5229\u7528\u5f53\u524d\u7684\u52a8\u4f5c\u6765\u505a\u66f4\u65b0\uff0c\u751a\u81f3\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u591a\u4e2a\u5e76\u884c\u7684\u8bad\u7ec3\u573a\u83b7\u53d6\u5927\u91cf\u7684 \\((s,a,s',r)\\) \u56db\u5143\u7ec4\u6570\u636e\uff0c\u7136\u540e\u76f8\u4e92\u4ea4\u6362\u6570\u636e\uff0c\u7531\u4e8e\u8fd9\u79cd\u987a\u5e8f\u6027\u88ab\u6253\u7834\u4e86\uff0c\u56e0\u6b64\u5c31\u662f\u79bb\u7ebf\u7b56\u7565\u7b97\u6cd5\u3002\u751a\u81f3\u6211\u4eec\u53ef\u4ee5\u624b\u52a8\u91c7\u6837\u8fd9\u4e00\u56db\u5143\u7ec4\u800c\u4e0d\u66f4\u65b0\uff0c\u6700\u540e\u518d\u4f9d\u9760\u6570\u636e\u8ba1\u7b97 \\(Q\\) \u7684\u4f30\u8ba1\u503c\uff0c\u8fd9\u6709\u70b9\u50cf\u5148\u524d\u7684 MC \u03b5-Greedy\uff0c\u4f46\u4e5f\u662f\u79bb\u7ebf RL \u7684\u96cf\u5f62\u3002</p>"}, {"location": "DNN/RL/#_21", "title": "\u7b2c\u516d\u7ae0", "text": "<p>\u672c\u7ae0\u4e3b\u8981\u8bb2 Dyna-Q \u7b97\u6cd5\uff0c\u5176\u5b9e\u5c31\u662f\u5bf9 Q-learning \u505a\u4e00\u70b9\u4fee\u8865\u3002</p> <p>\u6211\u4eec\u4ed4\u7ec6\u89c2\u5bdf\u4e0a\u9762 Q-learning \u7684\u7b97\u6cd5\u4f1a\u53d1\u73b0\uff0c\u4e00\u4e2a\u72b6\u6001\u53ea\u80fd\u62ff\u6765\u66f4\u65b0\u4e00\u4e2a Q \u503c\u3002\u4f46\u6211\u4eec\u77e5\u9053 Q-learning \u662f\u4e00\u4e2a\u79bb\u7ebf\u7b56\u7565\uff0c\u6709\u6ca1\u6709\u66f4\u597d\u7684\u529e\u6cd5\u5462\uff1fDyna-Q \u7684\u601d\u60f3\u662f\uff0c\u65e2\u7136\u548c\u73af\u5883\u7684\u4ea4\u4e92\u5177\u6709\u5e8f\u8d2f\u6027\u800c\u96be\u4ee5\u76f4\u63a5\u4ece\u7ed9\u5b9a\u548c\u5f53\u524d\u7684 \\((s,a)\\) \u4e2d\u62ff\u5230\u5956\u52b1\uff0c\u90a3\u5c31\u9009\u62e9\u5f15\u5165\u4e00\u4e2a\u6a21\u578b\u6765\u6a21\u62df\uff0c\u5373 \\(M(s,a)\\sim r(s,a)\\)\u3002\u5982\u679c \\(r(s,a)\\) \u5df2\u77e5\u6216\u8005\u5bb9\u6613\u88ab\u6a21\u62df\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u5c31\u80fd\u6210\u3002\u6240\u4ee5 Dyna-Q \u662f\u4e00\u4e2a\u6709\u6a21\u578b\u7248\u672c\u7684 Q-learning\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u5728\u6267\u884c\u72b6\u6001\u8f6c\u79fb\u7684\u540c\u65f6\uff0c\u5229\u7528\u6a21\u578b\u6765\u8dd1\u51e0\u8f6e\u6a21\u62df\uff08\u88ab\u79f0\u4f5c Q-planning\uff09\uff0c\u90a3\u4e48\u5728\u51b3\u7b56\u65f6\uff0c\u6211\u4eec\u5c31\u80fd\u591f\u57fa\u4e8e\u66f4\u591a\u7ecf\u9a8c\uff0c\u56e0\u800c\u53ef\u80fd\u83b7\u5f97\u66f4\u51c6\u786e\u7684 Q \u503c\u4f30\u8ba1\u3002</p> <p>\u6240\u4ee5\u6211\u4eec\u53ea\u9700\u8981\u628a Q-planning \u52a0\u5165\u7b97\u6cd5\u5373\u53ef\u3002</p> <ul> <li>\u521d\u59cb\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570 \\(Q(s,a)\\)</li> <li>\u57fa\u4e8e\u7ed9\u5b9a\u7684\u5e8f\u5217\u91c7\u6837\u6b21\u6570 \\(T\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u9009\u62e9\u521d\u59cb\u72b6\u6001 \\(s\\)</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684\u65f6\u95f4\u6b65 \\(N\\) \u5f00\u59cb\u5faa\u73af\uff1a</li> <li>\u5728 \\(s\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a\\)\u3002</li> <li>\u57fa\u4e8e\u52a8\u4f5c \\(a\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(s'\\)\uff0c\u5e76\u83b7\u5f97\u73af\u5883\u5956\u52b1 \\(r(s,a)\\)</li> <li>\u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[\\gamma \\max_{a'}Q(s',a')+r(s,a)-Q(s,a)]\\)</li> <li>\u5f00\u59cb Q-planning\uff0c\u5faa\u73af\u6307\u5b9a\u7684\u8ba1\u5212\u6b65\u6570\uff1a<ul> <li>\u968f\u673a\u9009\u62e9\u5148\u524d\u8bbf\u95ee\u8fc7\u7684\u72b6\u6001 \\(\\hat s\\) \u548c\u5728\u6b64\u72b6\u6001\u4e0b\u6267\u884c\u8fc7\u7684\u52a8\u4f5c \\(\\hat a\\)\u3002</li> <li>\u5229\u7528\u6a21\u578b\u5f97\u5230\u5956\u52b1 \\(\\hat r=M(\\hat s,\\hat a)\\)</li> <li>\u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[\\gamma \\max_{a'}Q(s',a')+\\hat r-Q(s,a)]\\)</li> </ul> </li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s'\\)</li> </ul> </li> </ul>"}, {"location": "DNN/RL/#_22", "title": "\u7b2c\u4e03\u7ae0", "text": "<p>Q-learning \u5c06\u72b6\u6001-\u52a8\u4f5c\u4ef7\u503c\u5efa\u7acb\u6210\u4e00\u5f20\u8868\uff0c\u79f0\u4f5c** Q \u8868\u3002\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e2a\u76f8\u5bf9\u590d\u6742\u7684\u6e38\u620f\u6216\u8005\u73b0\u5b9e\u73af\u5883\u800c\u8a00\uff0c\u5176\u72b6\u6001\u662f\u76f8\u5f53\u591a\u7684\u3002\u56e0\u6b64\u6211\u4eec\u4f1a\u9047\u5230\u76f8\u5f53\u719f\u6089\u7684\u7ef4\u5ea6\u707e\u96be**\uff0c\u800c\u89e3\u51b3\u65b9\u5f0f\u5c31\u662f\u5f15\u5165\u795e\u7ecf\u7f51\u7edc\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u5f15\u5165 \\(Q_\\theta(s,a)\\) \u6765\u62df\u5408\u72b6\u6001-\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u4e14\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u6027\u5bf9\u6ca1\u89c1\u8fc7\u7684\u72b6\u6001\u8fdb\u884c\u5408\u7406\u7684\u4ef7\u503c\u4f30\u8ba1\u3002\u4e0b\u9762\u7684\u4efb\u52a1\u5c31\u662f\u5bf9\u8fd9\u4e2a\u7f51\u7edc\u7684\u4f18\u5316\u95ee\u9898\u8fdb\u884c\u5efa\u6a21\uff0c\u7136\u540e\u5229\u7528\u7aef\u5230\u7aef\u5b66\u4e60\u7684\u77e5\u8bc6\u8fdb\u884c\u8bad\u7ec3\u548c\u4f18\u5316\u3002</p> <p>\u56de\u987e Q-learning \u7684\u65f6\u5e8f\u5dee\u5206\u516c\u5f0f\uff1a\\(Q(s,a)\\leftarrow Q(s,a)+\\alpha[\\gamma \\max_{a'}Q(s',a')+r(s,a)-Q(s,a)]\\)\uff0c\u800c\u6700\u4f18\u7b56\u7565\u4f1a\u4f7f\u5f97\u5dee\u5206\u503c\u4e3a0\uff0c\u56e0\u6b64\u6211\u4eec\u7684\u76ee\u7684\u5c31\u662f\u6700\u5c0f\u5316\u5dee\u5206\u503c\uff0c\u4e5f\u5c31\u662f\u628a Q \u8868\u6362\u6210 Q \u7f51\u7edc\uff0c\u5e76\u4f7f\u7528 MSE \u635f\u5931\uff1a</p> \\[ \\mathrm{arg}\\min_{\\theta\\quad}[\\gamma \\max_{a'}Q_\\theta(s',a')+r(s,a)-Q_\\theta(s,a)]^2 \\] <p>\u81ea\u7136\u6211\u4eec\u4e5f\u9700\u8981\u6536\u96c6\u4e00\u4e2a mini-batch \u7684\u6570\u636e\uff0c\u4f46\u662f\u4e00\u6b21\u72b6\u6001\u8f6c\u79fb\u53ea\u80fd\u4ea7\u751f\u4e00\u7ec4 \\((s',a')\\) \u600e\u4e48\u529e\u5462\uff1f</p> <p>DQN \u7ed9\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u662f\uff0c\u6211\u4eec\u5b58\u50a8\u6700\u8fd1 \\(E\\) \u6b21\u7684\u72b6\u6001\u8f6c\u79fb\u56db\u5143\u7ec4 \\((s,a,s',a')\\)\uff0c\u6bcf\u6b21\u4ece\u91cc\u9762\u62bd\u6837\u5373\u53ef\u3002\u56e0\u4e3a\u8fd9\u770b\u8d77\u6765\u50cf\u662f\u5728\u201c\u590d\u4e60\u201d\u6700\u8fd1\u7684 \\(E\\) \u6b21\u64cd\u4f5c\uff0c\u6211\u4eec\u628a\u5b83\u53eb\u505a\u7ecf\u9a8c\u91cd\u653e\uff0c\u5176\u5b9e\u7c7b\u4f3c\u4e8e\u6709\u7684\u4eba\u5e72\u4e86\u4e00\u5929\u7684\u6d3b\u7136\u540e\u665a\u4e0a\u8eba\u5e8a\u4e0a\u50cf\u653e\u7535\u5f71\u4e00\u6837\u56de\u5fc6\u8fd9\u51e0\u5929\u7684\u4e8b\u60c5\u2026\u2026</p> <p>\u5982\u679c\u4f60\u89c9\u5f97\u8fd9\u5c31\u591f\u4e86\uff0c\u90a3\u4f60\u53ef\u4ee5\u8bd5\u4e00\u4e0b\u5199\u5199\u4ee3\u7801\uff0c\u5305\u70b8\u7684\u3002\uff08\u6211\u5728\u8fd9\u91cc\u5c31\u4e0d\u653e\u4ee3\u7801\u4e86\uff0c\u56e0\u4e3a\u52a0\u4e86\u540e\u9762\u7684\u7f13\u89e3\u63aa\u65bd\u7167\u6837\u70b8\uff09</p> <p>\u4ece\u7406\u8bba\u5206\u6790\u7684\u89d2\u5ea6\uff0c\u539f\u521d\u7684 Q-learning \u8fed\u4ee3\u5f0f\u662f\u4e00\u4e2a\u538b\u7f29\u6620\u5c04\uff0c\u8c31\u8303\u6570\u5c0f\u4e8e 1\uff0c\u56e0\u6b64\u80fd\u591f\u6536\u655b\u5230\u786e\u5b9a\u503c\u3002\u4f46\u5728 DQN \u4e2d\u6211\u4eec\u662f\u4ece Q \u7f51\u7edc\u5f97\u5230\u6570\u636e\u62ff\u6765\u66f4\u65b0 Q \u7f51\u7edc\uff0c\u800c\u8fd9\u4e00\u8fc7\u7a0b\u542b\u6709\u7684\u566a\u97f3\u4e0d\u4e00\u5b9a\u80fd\u591f\u4f7f\u5f97\u8fed\u4ee3\u7684\u8c31\u8303\u6570\u5c0f\u4e8e 1\uff0c\u5bfc\u81f4\u8c31\u8303\u6570\u53d8\u5927\uff0c\u5e76\u5feb\u901f\u81ea\u6211\u6076\u5316\u3002\u56e0\u6b64 DQN \u9009\u62e9\u51cf\u6162\u66f4\u65b0 Q \u7f51\u7edc\u7684\u9891\u7387\uff0c\u8ba9\u5b83\u70b8\u5f97\u4e0d\u8981\u90a3\u4e48\u5feb\uff0c\u6700\u597d\u5728\u5f00\u59cb\u7206\u70b8\u4e4b\u524d\u5c31\u8bad\u7ec3\u597d\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u4ece\u7ecf\u9a8c\u91cd\u653e\u4e2d\u91c7\u6837\u7684\u6570\u636e\u5e76\u4e0d\u4f1a\u9001\u5165\u76ee\u6807\u7684 Q \u7f51\u7edc \\(Q_\\theta\\)\uff0c\u800c\u662f\u4f1a\u8f93\u5165\u4e00\u4e2a\u7565\u5fae\u8fc7\u65f6\u7684 Q \u7f51\u7edc \\(\\hat Q_\\theta\\)\uff0c\u76f4\u5230\u7ecf\u8fc7\u4e00\u5b9a\u7684\u65f6\u95f4\u6b65\u4e4b\u540e\uff0c\u518d\u7528 \\(Q_\\theta\\) \u66f4\u65b0 \\(\\hat{Q}_\\theta\\)\u3002\u6211\u4eec\u628a\u90a3\u4e2a\u8fc7\u65f6\u4e00\u70b9\u7684\u7f51\u7edc\u53eb\u505a\u76ee\u6807\u7f51\u7edc\u3002</p> <p>\u6240\u4ee5 DQN \u4e0d\u662f\u4e0d\u4f1a\u8bad\u70b8\uff0c\u800c\u662f\u6709\u7ec4\u7ec7\u6709\u8ba1\u5212\u3001\u6709\u7eaa\u5f8b\u6709\u76ee\u7684\u5730\u70b8\u3002\u8bf7\u5927\u5bb6\u6b23\u8d4f\u4e00\u4e0b\uff0c\u6211\u5728 CartPole-v1 \u4e0a\uff0c\u5229\u7528\u7eaf\u89c6\u89c9\u8f93\u5165\u8bad\u7ec3 DQN \u7684\u7206\u70b8\u73b0\u573a\uff1a</p> <p></p> <p>\u4f60\u53ef\u80fd\u8981\u95ee\u65e2\u7136\u5927\u5bb6\u90fd\u7528 CartPole \u7684\u72b6\u6001\u5411\u91cf\u5582\u7ed9 DQN \u4e3a\u4ec0\u4e48\u6211\u8981\u641e\u89c6\u89c9\u6a21\u578b\u5462\uff1f\u56e0\u4e3a\u8fd9\u66f4\u96be\uff0c\u66f4\u5bb9\u6613\u770b\u51fa\u6a21\u578b\u548c\u7b97\u6cd5\u7684\u7f3a\u9677\u3002</p> <p>\u4e0d\u8fc7\u5728\u6b64\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u770b\u770b\u7b97\u6cd5\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edc \\(Q_\\theta(s,a)\\) \u548c\u76ee\u6807\u7f51\u7edc \\(\\hat Q_\\theta(s,a)\\leftarrow Q_\\theta(s,a)\\)</li> <li>\u57fa\u4e8e\u7ed9\u5b9a\u7684\u5e8f\u5217\u91c7\u6837\u6b21\u6570 \\(T\\) \u5f00\u59cb\u5faa\u73af\uff1a<ul> <li>\u9009\u62e9\u521d\u59cb\u72b6\u6001 \\(s\\)</li> <li>\u57fa\u4e8e\u8bbe\u5b9a\u7684\u65f6\u95f4\u6b65 \\(N\\) \u5f00\u59cb\u5faa\u73af\uff1a</li> <li>\u5728 \\(s\\) \u7684\u52a8\u4f5c\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684 \u03b5-Greedy \u7b56\u7565\uff0c\u5229\u7528 \\(Q_\\theta\\) \u9009\u62e9\u4e00\u4e2a\u52a8\u4f5c \\(a\\)\u3002</li> <li>\u57fa\u4e8e\u52a8\u4f5c \\(a\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(s'\\)\uff0c\u5e76\u83b7\u5f97\u73af\u5883\u5956\u52b1 \\(r(s,a)\\)\uff0c\u5e76\u653e\u5165\u7ecf\u9a8c\u91cd\u653e\u6c60\u3002</li> <li>\u5728\u7ecf\u9a8c\u91cd\u653e\u6c60\u91cc\u9762\u8fdb\u884c mini-batch \u91c7\u6837 \\(B\\) \u4e2a\u6837\u672c\uff0c\u5bf9\u5f53\u524d\u7f51\u7edc \\(Q_\\theta\\) \u8fdb\u884c\u65f6\u5e8f\u5dee\u5206\u4f30\u8ba1\uff1a\\(\\dfrac{1}{2B}\\mathrm{arg}\\min_{\\theta}[\\gamma \\max_{a'}\\hat Q_\\theta(s',a')+r(s,a)-Q_\\theta(s,a)]^2\\)</li> <li>\u82e5\u7ecf\u8fc7\u56fa\u5b9a\u7684\u540c\u6b65\u65f6\u95f4\uff0c\u66f4\u65b0\u76ee\u6807\u7f51\u7edc \\(\\hat Q_\\theta(s,a)\\leftarrow Q_\\theta(s,a)\\)</li> <li>\u6267\u884c\u66f4\u65b0\uff1a\\(s\\leftarrow s'\\)</li> </ul> </li> </ul> <p>\u6211\u4eec\u6765\u770b\u770b\u4ee3\u7801\u5b9e\u73b0\uff1a</p>  Original DQN  <pre><code>import gymnasium as gym\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom collections import deque\nimport random\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom PIL import Image\n\n# \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nclass ImagePreprocessor:\n    \"\"\"\u56fe\u50cf\u9884\u5904\u7406\u7c7b\"\"\"\n    def __init__(self, img_size=(84, 84)):\n        self.img_size = img_size\n        self.frame_buffer = deque(maxlen=4)\n\n    def preprocess(self, rgb_array):\n        \"\"\"\u9884\u5904\u7406\u5355\u5e27\u56fe\u50cf\"\"\"\n        img = Image.fromarray(rgb_array)\n        # \u8f6c\u6362\u4e3a\u7070\u5ea6\u56fe\n        img = img.convert('L')\n        # \u8c03\u6574\u5927\u5c0f\n        img = img.resize(self.img_size, Image.BILINEAR)\n        # \u8f6c\u6362\u4e3anumpy\u6570\u7ec4\u5e76\u5f52\u4e00\u5316\n        img_array = np.array(img, dtype=np.float32) / 255.0\n        return img_array\n\n    def reset(self):\n        \"\"\"\u91cd\u7f6e\u5e27\u7f13\u51b2\u533a\"\"\"\n        self.frame_buffer.clear()\n        # \u7528\u7a7a\u767d\u5e27\u521d\u59cb\u5316\n        blank_frame = np.zeros(self.img_size, dtype=np.float32)\n        for _ in range(4):\n            self.frame_buffer.append(blank_frame)\n\n    def get_state(self, rgb_array):\n        \"\"\"\u83b7\u53d6\u5f53\u524d\u72b6\u6001\uff08\u5806\u53e04\u5e27\uff09\"\"\"\n        processed_frame = self.preprocess(rgb_array)\n        self.frame_buffer.append(processed_frame)\n        # \u5806\u53e0\u5e27\n        state = np.stack(self.frame_buffer, axis=0)  # Shape: (4, 84, 84)\n        return state\n\nclass DQN(nn.Module):\n    \"\"\"\u6df1\u5ea6Q\u7f51\u7edc\"\"\"\n    def __init__(self, input_shape, n_actions):\n        super(DQN, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n            nn.ReLU()\n        )\n\n        # \u8ba1\u7b97\u5377\u79ef\u5c42\u8f93\u51fa\u5c3a\u5bf8\n        conv_out_size = self._get_conv_out(input_shape)\n\n        self.fc = nn.Sequential(\n            nn.Linear(conv_out_size, 512),\n            nn.ReLU(),\n            nn.Linear(512, n_actions)\n        )\n\n    def _get_conv_out(self, shape):\n        \"\"\"\u8ba1\u7b97\u5377\u79ef\u5c42\u8f93\u51fa\u5c3a\u5bf8\"\"\"\n        o = self.conv(torch.zeros(1, *shape))\n        return int(np.prod(o.size()))\n\n    def forward(self, x):\n        conv_out = self.conv(x).view(x.size()[0], -1)\n        return self.fc(conv_out)\n\nclass ReplayBuffer:\n    \"\"\"\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\"\"\"\n    def __init__(self, capacity):\n        self.buffer = deque(maxlen=capacity)\n\n    def push(self, state, action, reward, next_state, done):\n        self.buffer.append((state, action, reward, next_state, done))\n\n    def sample(self, batch_size):\n        batch = random.sample(self.buffer, batch_size)\n        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n        return state, action, reward, next_state, done\n\n    def __len__(self):\n        return len(self.buffer)\n\nclass DQNAgent:\n    \"\"\"DQN\u4ee3\u7406\"\"\"\n    def __init__(self, state_shape, n_actions, lr=1e-4, gamma=0.99, device=None):\n        self.n_actions = n_actions\n        self.gamma = gamma\n        self.device = device\n        self.epsilon = 1.0\n        self.epsilon_min = 0.05  # \u7a0d\u5fae\u964d\u4f4e\u6700\u5c0f\u63a2\u7d22\u7387\n        self.epsilon_decay = 0.995  # \u4fdd\u6301\u8f83\u6162\u7684\u8870\u51cf\n        self.batch_size = 64\n        self.update_target_freq = 500\n\n        # \u7f51\u7edc\n        self.policy_net = DQN(state_shape, n_actions).to(device)\n        self.target_net = DQN(state_shape, n_actions).to(device)\n        self.target_net.load_state_dict(self.policy_net.state_dict())\n        self.target_net.eval()\n\n        # \u4f18\u5316\u5668\n        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n\n        # \u7ecf\u9a8c\u56de\u653e\n        self.memory = ReplayBuffer(50000)\n\n        # \u8bad\u7ec3\u6b65\u6570\u8ba1\u6570\n        self.steps_done = 0\n\n    def select_action(self, state, training=True):\n        \"\"\"\u9009\u62e9\u52a8\u4f5c\"\"\"\n        if training and random.random() &lt; self.epsilon:\n            return random.randrange(self.n_actions)\n        else:\n            with torch.no_grad():\n                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n                q_values = self.policy_net(state_tensor)\n                return q_values.max(1)[1].item()\n\n    def update_epsilon(self):\n        \"\"\"\u66f4\u65b0\u63a2\u7d22\u7387\"\"\"\n        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n\n    def train_step(self):\n        \"\"\"\u5355\u6b65\u8bad\u7ec3\"\"\"\n        if len(self.memory) &lt; self.batch_size:\n            return 0.0\n\n        # \u4ece\u7ecf\u9a8c\u56de\u653e\u4e2d\u91c7\u6837\n        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n\n        # \u8f6c\u6362\u4e3a\u5f20\u91cf\n        states = torch.FloatTensor(states).to(self.device)\n        actions = torch.LongTensor(actions).to(self.device)\n        rewards = torch.FloatTensor(rewards).to(self.device)\n        next_states = torch.FloatTensor(next_states).to(self.device)\n        dones = torch.BoolTensor(dones).to(self.device)\n\n        # \u8ba1\u7b97\u5f53\u524dQ\u503c\n        current_q_values = self.policy_net(states).gather(1, actions.unsqueeze(1))\n\n        # \u8ba1\u7b97\u76ee\u6807Q\u503c\n        with torch.no_grad():\n            next_q_values = self.target_net(next_states).max(1)[0]\n            target_q_values = rewards + (self.gamma * next_q_values * ~dones)\n\n        # \u8ba1\u7b97\u635f\u5931\n        loss = F.mse_loss(current_q_values.squeeze(), target_q_values)\n\n        # \u4f18\u5316\n        self.optimizer.zero_grad()\n        loss.backward()\n        # \u52a0\u5f3a\u68af\u5ea6\u88c1\u526a\n        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), max_norm=1.0)\n        self.optimizer.step()\n\n        # \u66f4\u65b0\u76ee\u6807\u7f51\u7edc\n        self.steps_done += 1\n        if self.steps_done % self.update_target_freq == 0:\n            self.target_net.load_state_dict(self.policy_net.state_dict())\n\n        # \u66f4\u65b0\u63a2\u7d22\u7387\n        self.update_epsilon()\n\n        return loss.item()\n\ndef train_dqn_optimized(total_steps=30000, device=None):\n    \"\"\"\u4f18\u5316\u7684\u8bad\u7ec3\u51fd\u6570\"\"\"\n    # \u521d\u59cb\u5316\u73af\u5883\n    env = gym.make('CartPole-v1', render_mode='rgb_array')\n    n_actions = env.action_space.n\n\n    # \u521d\u59cb\u5316\u9884\u5904\u7406\u5668\u548c\u4ee3\u7406\n    preprocessor = ImagePreprocessor()\n    agent = DQNAgent(state_shape=(4, 84, 84), n_actions=n_actions, device=device)\n\n    # \u8bad\u7ec3\u53d8\u91cf\n    episode_rewards = []\n    episode_losses = []\n    current_episode_reward = 0\n    current_episode_loss = 0\n    loss_count = 0\n    episode_count = 0\n\n    # \u65f6\u95f4\u7edf\u8ba1\n    episode_start_time = time.time()\n    last_episode_time = episode_start_time\n\n    state, _ = env.reset()\n    preprocessor.reset()\n\n    # \u83b7\u53d6\u521d\u59cb\u72b6\u6001\n    rgb_array = env.render()\n    state_tensor = preprocessor.get_state(rgb_array)\n\n    print(\"\u5f00\u59cb\u4f18\u5316\u8bad\u7ec3...\")\n    print(f\"\u521d\u59cb\u53c2\u6570: epsilon={agent.epsilon}, lr=3e-5, batch_size={agent.batch_size}\")\n\n    for step in range(total_steps):\n        # \u9009\u62e9\u52a8\u4f5c\n        action = agent.select_action(state_tensor)\n\n        # \u6267\u884c\u52a8\u4f5c\n        next_state, reward, terminated, truncated, _ = env.step(action)\n        done = terminated or truncated\n        current_episode_reward += reward\n\n        # \u83b7\u53d6\u4e0b\u4e00\u72b6\u6001\u7684\u56fe\u50cf\n        rgb_array = env.render()\n        next_state_tensor = preprocessor.get_state(rgb_array)\n\n        # \u5b58\u50a8\u7ecf\u9a8c\n        agent.memory.push(state_tensor, action, reward, next_state_tensor, done)\n\n        # \u8bad\u7ec3\n        loss = agent.train_step()\n        if loss &gt; 0:\n            current_episode_loss += loss\n            loss_count += 1\n\n        # \u66f4\u65b0\u72b6\u6001\n        state_tensor = next_state_tensor\n\n        # \u73af\u5883\u91cd\u7f6e\n        if done:\n            episode_count += 1\n            avg_loss = current_episode_loss / loss_count if loss_count &gt; 0 else 0\n            episode_rewards.append(current_episode_reward)\n            episode_losses.append(avg_loss)\n\n            # \u6bcf10\u4e2aepisode\u6253\u5370\u8be6\u7ec6\u4fe1\u606f\n            if episode_count % 10 == 0:\n                current_time = time.time()\n                time_elapsed = current_time - last_episode_time\n                last_episode_time = current_time\n\n                avg_reward = np.mean(episode_rewards[-10:])\n                print(f\"Episode {episode_count}: \"\n                      f\"Avg Reward = {avg_reward:.1f}, \"\n                      f\"Epsilon = {agent.epsilon:.3f}, \"\n                      f\"Avg Loss = {avg_loss:.4f}, \"\n                      f\"Time = {time_elapsed:.2f}s\")\n\n            state, _ = env.reset()\n            preprocessor.reset()\n            rgb_array = env.render()\n            state_tensor = preprocessor.get_state(rgb_array)\n            current_episode_reward = 0\n            current_episode_loss = 0\n            loss_count = 0\n\n    env.close()\n    return agent, episode_rewards, episode_losses, episode_count\n\ndef final_visualization(agent, preprocessor, max_steps=500):\n    \"\"\"\u6700\u7ec8\u53ef\u89c6\u5316\u6f14\u793a\"\"\"\n    env = gym.make('CartPole-v1', render_mode='human')  # \u4f7f\u7528human\u6a21\u5f0f\u8fdb\u884c\u53ef\u89c6\u5316\n\n    state, _ = env.reset()\n    preprocessor.reset()\n    total_reward = 0\n    frames = []\n\n    print(\"\\n\u5f00\u59cb\u6700\u7ec8\u53ef\u89c6\u5316\u6f14\u793a...\")\n\n    # \u5207\u6362\u5230\u8bc4\u4f30\u6a21\u5f0f\n    agent.policy_net.eval()\n\n    # \u8fd0\u884c\u4e00\u4e2a\u5b8c\u6574\u56de\u5408\n    with torch.no_grad():\n        for step in range(max_steps):\n            # \u6e32\u67d3\u5f53\u524d\u72b6\u6001\n            env.render()\n\n            # \u83b7\u53d6\u5f53\u524d\u72b6\u6001\n            rgb_array = env.render()\n            state_tensor = preprocessor.get_state(rgb_array)\n\n            # \u9009\u62e9\u52a8\u4f5c\n            action = agent.select_action(state_tensor, training=False)\n\n            # \u6267\u884c\u52a8\u4f5c\n            state, reward, terminated, truncated, _ = env.step(action)\n            done = terminated or truncated\n            total_reward += reward\n\n            # \u8bb0\u5f55\u5e27\uff08\u7528\u4e8e\u540e\u7eed\u5206\u6790\uff09\n            frames.append(rgb_array)\n\n            # \u6dfb\u52a0\u5c0f\u5ef6\u8fdf\u4ee5\u4fbf\u89c2\u5bdf\n            time.sleep(0.05)\n\n            if done:\n                break\n\n    print(f\"\u53ef\u89c6\u5316\u6f14\u793a\u7ed3\u675f\uff0c\u603b\u5956\u52b1: {total_reward}\")\n\n    # \u5207\u6362\u56de\u8bad\u7ec3\u6a21\u5f0f\n    agent.policy_net.train()\n    env.close()\n\n    return total_reward, frames\n\ndef plot_and_save_training_progress(rewards, losses, filename=\"optimized_training_progress.png\"):\n    \"\"\"\u7ed8\u5236\u5e76\u4fdd\u5b58\u8bad\u7ec3\u8fdb\u5ea6\u56fe\"\"\"\n    plt.figure(figsize=(15, 5))\n\n    # \u539f\u59cb\u5956\u52b1\n    plt.subplot(1, 3, 1)\n    plt.plot(rewards, alpha=0.6, linewidth=1)\n    plt.title('Training Rewards per Episode')\n    plt.xlabel('Episode')\n    plt.ylabel('Reward')\n    plt.grid(True, alpha=0.3)\n\n    # \u6ed1\u52a8\u5e73\u5747\u5956\u52b1\n    plt.subplot(1, 3, 2)\n    window = 10\n    if len(rewards) &gt;= window:\n        moving_avg = [np.mean(rewards[i-window:i]) for i in range(window, len(rewards))]\n        plt.plot(range(window, len(rewards)), moving_avg, linewidth=2, color='red')\n        plt.title(f'Moving Average Reward (window={window})')\n        plt.xlabel('Episode')\n        plt.ylabel('Average Reward')\n        plt.grid(True, alpha=0.3)\n\n    # \u635f\u5931\u66f2\u7ebf\n    plt.subplot(1, 3, 3)\n    if losses:\n        plt.plot(losses, alpha=0.6, linewidth=1, color='green')\n        plt.title('Training Loss per Episode')\n        plt.xlabel('Episode')\n        plt.ylabel('Loss')\n        plt.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n\n    # \u4fdd\u5b58\u56fe\u50cf\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    print(f\"\u8bad\u7ec3\u8fdb\u5ea6\u56fe\u5df2\u4fdd\u5b58\u4e3a: {filename}\")\n    plt.show()\n\n    # \u8f93\u51fa\u7edf\u8ba1\u4fe1\u606f\n    if len(rewards) &gt; 0:\n        print(f\"\\n\u8bad\u7ec3\u7edf\u8ba1:\")\n        print(f\"\u603b\u56de\u5408\u6570: {len(rewards)}\")\n        print(f\"\u5e73\u5747\u5956\u52b1: {np.mean(rewards):.2f} \u00b1 {np.std(rewards):.2f}\")\n        print(f\"\u6700\u5927\u5956\u52b1: {np.max(rewards)}\")\n        print(f\"\u6700\u5c0f\u5956\u52b1: {np.min(rewards)}\")\n        if len(rewards) &gt;= 10:\n            print(f\"\u6700\u8fd110\u56de\u5408\u5e73\u5747\u5956\u52b1: {np.mean(rewards[-10:]):.2f}\")\n\nif __name__ == \"__main__\":\n    # ========== \u4e00\u952e\u5207\u6362\u8bbe\u5907 ==========\n    # \u53ea\u9700\u4fee\u6539\u4e0b\u9762\u8fd9\u4e00\u884c\uff1a\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # \u81ea\u52a8\u9009\u62e9\n    # device = torch.device(\"cpu\")  # \u5f3a\u5236\u4f7f\u7528CPU\n    # device = torch.device(\"cuda\")  # \u5f3a\u5236\u4f7f\u7528GPU\uff08\u5982\u679c\u6709\uff09\n    # ==================================\n\n    print(f\"\u4f7f\u7528\u8bbe\u5907: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU\u540d\u79f0: {torch.cuda.get_device_name(0)}\")\n\n    # \u5f00\u59cb\u8bad\u7ec3\n    try:\n        start_time = time.time()\n        trained_agent, rewards, losses, episode_count = train_dqn_optimized(\n            total_steps=400000,  # \u589e\u52a0\u603b\u8bad\u7ec3\u6b65\u6570\n            device=device  # \u4f20\u9012\u8bbe\u5907\u53c2\u6570\n        )\n        total_time = time.time() - start_time\n\n        print(f\"\\n\u8bad\u7ec3\u5b8c\u6210!\")\n        print(f\"\u603b\u8bad\u7ec3\u65f6\u95f4: {total_time:.2f}\u79d2\")\n        print(f\"\u603b\u56de\u5408\u6570: {episode_count}\")\n        print(f\"\u5e73\u5747\u6bcf\u56de\u5408\u65f6\u95f4: {total_time/episode_count:.2f}\u79d2\")\n\n        # \u7ed8\u5236\u5e76\u4fdd\u5b58\u8bad\u7ec3\u8fdb\u5ea6\n        plot_and_save_training_progress(rewards, losses, \"optimized_training_progress.png\")\n\n        # \u4fdd\u5b58\u6a21\u578b\n        torch.save(trained_agent.policy_net.state_dict(), 'optimized_dqn_cartpole_model.pth')\n        print(\"\u6a21\u578b\u5df2\u4fdd\u5b58\u4e3a: optimized_dqn_cartpole_model.pth\")\n\n        # \u6700\u7ec8\u53ef\u89c6\u5316\u6f14\u793a\n        preprocessor = ImagePreprocessor()\n        final_reward, _ = final_visualization(trained_agent, preprocessor)\n        print(f\"\u6700\u7ec8\u53ef\u89c6\u5316\u6f14\u793a\u5956\u52b1: {final_reward}\")\n\n    except KeyboardInterrupt:\n        print(\"\\n\u8bad\u7ec3\u88ab\u7528\u6237\u4e2d\u65ad\")\n    except Exception as e:\n        print(f\"\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u9519\u8bef: {e}\")\n        import traceback\n        traceback.print_exc()\n</code></pre> <p>\u8fd9\u662f\u6548\u679c\uff1a</p> <p></p>"}, {"location": "DNN/RL/#_23", "title": "\u7b2c\u516b\u7ae0", "text": "<p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 22, 2025). RL\u5b66\u4e60\u7b14\u8bb0 - \u4e0a\u7bc7 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/RL</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{RL,\n    title={RL\u5b66\u4e60\u7b14\u8bb0 - \u4e0a\u7bc7},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/DNN/RL}},\n}\n</code></pre></p>"}, {"location": "DNN/SVM_SMO/", "title": "SMO \u7b97\u6cd5\u7684\u63a8\u5bfc", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 11 \u5206\u949f\u3000|\u3000\u7ea6 1193 \u5b57\u3000|\u3000\u7ea6 52 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u672c\u6587\u4e3a\u300a\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u4e0e\u673a\u5668\u5b66\u4e60\u300b\u8bfe\u7a0b\u7684\u4f5c\u4e1a\u4e4b\u4e00\u3002</p> <p>\u7b14\u8005\u4e0d\u60f3\u4e3a\u8fd9\u7bc7\u6587\u7ae0\u5355\u72ec\u5f00\u4e00\u4e2a\u201c\u673a\u5668\u5b66\u4e60\u201d\u7684\u535a\u5ba2\u5206\u7c7b\u4e86\uff0c\u6682\u4e14\u8fd8\u662f\u6254\u5728\u8fd9\u4e2a\u201c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u201d\u677f\u5757\u5427\uff0c\u867d\u7136\u5b83\u548c\u795e\u7ecf\u7f51\u7edc\u5173\u7cfb\u4e0d\u5927\u2026\u2026\u4e0d\u8fc7\u591a\u50a8\u5907\u4e00\u4e9b\u7b97\u6cd5\u77e5\u8bc6\uff0c\u6ca1\u6709\u4efb\u4f55\u574f\u5904\u3002</p>"}, {"location": "DNN/SVM_SMO/#svm", "title": "SVM", "text": "<p>\u8fd9\u91cc\u901f\u901a\u4e00\u4e0b SVM \u7684\u77e5\u8bc6\uff0c\u6743\u5f53\u505a notation\u3002SVM \u7684\u601d\u60f3\u662f\u627e\u4e00\u4e2a\u8d85\u5e73\u9762\u80fd\u591f\u8ba9\u6570\u636e\u5206\u5f97\u201c\u6700\u5f00\u201d\uff0c\u6211\u4eec\u4f7f\u7528\u51e0\u4f55\u95f4\u9694\u5bf9\u8fd9\u4e2a\u5206\u5f00\u7a0b\u5ea6\u8fdb\u884c\u91cf\u5316\u7684\u5ea6\u91cf\u3002</p> <p>\u5728\u6700\u7b80\u5355\u7684\u7ebf\u6027\u573a\u666f\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528</p> \\[ w^\\top x+b=0 \\] <p>\u6765\u63cf\u8ff0\u4e00\u4e2a\u8d85\u5e73\u9762\uff0c\u7531\u4e8e\u8fd9\u4e2a\u5f0f\u5b50\u662f\u4e00\u4e2a\u70b9\u79ef\u7684\u5f62\u5f0f\uff0c\\(w\\) \u5c31\u662f\u8fd9\u4e2a\u8d85\u5e73\u9762\u7684\u6cd5\u5411\u91cf\u3002\u6211\u4eec\u53ef\u4ee5\u4f9d\u636e\u6570\u636e\u5728\u8d85\u5e73\u9762\u7684\u4e0a\u65b9\u6216\u8005\u4e0b\u65b9\u6765\u8fdb\u884c\u5206\u7c7b\uff0c\u4e5f\u5c31\u662f \\(f(x_i)=\\mathrm{sign}(w^\\top x_i+b)\\)\u3002\u8fd9\u4e2a\u5c31\u662f\u6211\u4eec\u7684\u6a21\u578b\uff0c\u9700\u8981\u4f18\u5316\u7684\u53c2\u6570\u5c31\u662f \\(w\\) \u548c \\(b\\)\u3002</p> <p>\u63a5\u4e0b\u6765\u5b9a\u4e49\u635f\u5931\uff0c\u521a\u521a\u63d0\u5230\u9700\u8981\u7528\u51e0\u4f55\u95f4\u9694\u6765\u91cf\u5316\u8d85\u5e73\u9762\u5206\u5272\u5f97\u597d\u4e0d\u597d\u3002\u51e0\u4f55\u95f4\u9694\u5176\u5b9e\u5c31\u662f\u9ad8\u7ef4\u573a\u666f\u7684\u70b9\u5230\u76f4\u7ebf\u8ddd\u79bb\u516c\u5f0f\uff0c\u7136\u540e\u4e58\u4ee5\u6b63\u8d1f\u7c7b\u7684\u7b26\u53f7\uff1a</p> \\[ \\gamma_i=y_i\\dfrac{w^\\top x_i+b}{\\|w\\|} \\] <p>\u6211\u4eec\u8981\u6700\u5927\u5316\u51e0\u4f55\u95f4\u9694\uff0c\u5176\u5b9e\u5c31\u662f\u6700\u5927\u5316\u51e0\u4f55\u95f4\u9694\u7684\u4e0b\u754c\uff0c\u56e0\u4e3a\u4f18\u5316\u4e0a\u754c\u6216\u8005\u5176\u4ed6\u4e1c\u897f\u4e00\u70b9\u7528\u90fd\u6ca1\u6709\u3002\u8fd9\u4e2a\u4e0b\u754c\u5c31\u662f\u79bb\u6211\u4eec\u7684\u8d85\u5e73\u9762\u6700\u8fd1\u7684\u6b63\u6837\u672c\u70b9 \\(x_s\\)\uff0c\u6211\u4eec\u53eb\u5b83\u652f\u6301\u5411\u91cf\u3002\u8003\u8651\u5230\u51e0\u4f55\u95f4\u9694\u5bf9\u7ebf\u6027\u7f29\u653e\u7684 \\(w\\) \u548c \\(b\\) \u4e0d\u53d8\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u56fa\u5b9a \\(|w^\\top x_s+b|=1\\)\uff0c\u8fd9\u6837\u5176\u5b9e\u6700\u5927\u5316\u7684\u5c31\u662f \\(\\dfrac{1}{\\|w\\|}\\)\uff0c\u53d6\u4e00\u4e2a\u5012\u6570\u518d\u5e73\u65b9\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8f6c\u6362\u6210\u4e00\u4e2a\u5e38\u89c1\u7684\u4f18\u5316\u95ee\u9898\u4e86\uff1a</p> \\[ \\mathrm{arg}\\max_{w,b\\quad} \\dfrac 12 \\|w\\|^2 \\mathrm{\\quad s.t.\\quad}y_i(w^\\top x_i+b)\\ge 1 \\] <p>\u4f46\u662f\uff0c\u6570\u636e\u4e0d\u53ef\u80fd\u5b8c\u5168\u80fd\u591f\u6ee1\u8db3\u7ebf\u6027\u53ef\u5206\uff0c\u5728\u51b3\u7b56\u8fb9\u754c\u5904\u53ef\u80fd\u4f1a\u5b58\u5728\u566a\u97f3\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5f15\u5165\u4e00\u4e2a\u5bb9\u5dee\u6765\u6ee4\u9664\u566a\u97f3\uff0c\u4e5f\u5c31\u662f\u4ece\u521a\u521a\u7684\u786c\u95f4\u9694 SVM \u53d8\u6210\u8f6f\u95f4\u9694 SVM\u3002\u5f15\u5165\u95f4\u9694\u5e26\u5bbd \\(\\xi\\) \u4e3a\u4e00\u4e2a\u5411\u91cf\uff0c\u6761\u4ef6\u6539\u6210 \\(y_i(w^\\top x_i+b)\\ge 1-\\xi_i\\)\uff0c\u540c\u65f6\u6211\u4eec\u5e0c\u671b\u8fd9\u79cd\u5bb9\u5dee\u5c3d\u53ef\u80fd\u5c0f\uff08\u4e5f\u5c31\u662f\u7cbe\u786e\u5ea6\u5c3d\u53ef\u80fd\u9ad8\uff09\uff0c\u56e0\u6b64\u628a\u5b83\u4e5f\u5f15\u8fdb\u635f\u5931\u91cc\u9762\uff0c\u5f97\u5230\uff1a</p> \\[ \\mathrm{arg}\\max_{w,b,\\xi\\quad} \\dfrac 12 \\|w\\|^2+C\\sum \\xi_i \\mathrm{\\quad s.t.\\quad}y_i(w^\\top x_i+b)\\ge 1-\\xi_i,\\xi_i\\ge 0\\tag 1 \\] <p>\u4e0b\u9762\u5c31\u662f\u5bf9\u5176\u8fdb\u884c\u6c42\u89e3\u4e86\u3002</p>"}, {"location": "DNN/SVM_SMO/#_1", "title": "\u62c9\u683c\u6717\u65e5\u4e58\u6570\u6cd5", "text": "<p>\u6211\u4e60\u60ef\u4e8e\u6df1\u5ea6\u5b66\u4e60\u90a3\u4e00\u5957\uff0c\u4e00\u4e2a <code>optim.Adam</code> \u5c31\u80fd\u89e3\u51b3\u3002\u4e0d\u8fc7\u5728 SVM \u7684\u5e74\u4ee3\uff0c\u8fde SGD \u5c1a\u4e14\u662f\u8941\u8913\u4e2d\u7684\u5b69\u5b50\u3002\u4e8e\u662f\u6211\u4eec\u53ea\u80fd\u8bd5\u56fe\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4e58\u6570\u6cd5\u89e3\u51b3\u3002\u8fd9\u4e2a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u3002\\((1)\\) \u5f0f\u6709\u4e24\u7ec4\u7ea6\u675f\uff0c\u56e0\u6b64\u5f15\u5165\u5bf9\u5e94\u7684\u4e24\u7ec4\u53c2\u6570 \\(\\alpha_i\\) \u548c \\(\\mu_i\\)\uff0c\u5199\u51fa\u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff1a</p> \\[ \\mathcal{L}=\\dfrac 12 \\|w\\|^2+C\\sum \\xi_i-\\sum\\alpha_i[y_i(w^\\top x_i+b)-1+\\xi_i]-\\sum\\mu_i\\xi_i \\] <p>\u5bf9\u4f18\u5316\u53d8\u91cf\u6c42\u504f\u5bfc\uff1a</p> \\[ \\begin{align*}     \\dfrac{\\partial \\mathcal{L}}{\\partial w}&amp;=w-\\sum \\alpha_iy_ix_i=0&amp;\\implies w=\\sum \\alpha_iy_ix_i\\\\     \\dfrac{\\partial \\mathcal{L}}{\\partial b}&amp;=-\\alpha_iy_i=0&amp;\\implies \\alpha_iy_i=0\\\\     \\dfrac{\\partial \\mathcal{L}}{\\partial \\xi_i}&amp;=C-\\alpha_i-\\mu_i=0&amp;\\implies C=\\alpha_i+\\mu_i \\end{align*} \\] <p>\u5e26\u5165\u4e58\u5b50\u5f97\u5230\u5bf9\u5076\u95ee\u9898\uff1a</p> \\[ \\mathrm{arg}\\max_{\\alpha\\quad}W(\\alpha)=\\mathrm{arg}\\max_{\\alpha\\quad}\\sum \\alpha_i - \\dfrac 12 \\sum\\sum \\alpha_i \\alpha_j y_i y_j (x_i^\\top x_j)\\mathrm{\\quad s.t.\\quad}\\sum \\alpha_iy_i=0,\\alpha_i\\in [0,C] \\] <p>\u5c06\u4ee5\u4e0a\u9700\u8981\u7684\u6240\u6709\u7ea6\u675f\u6c47\u603b\u5c31\u5f97\u5230\u4e86 KKT\u6761\u4ef6\uff1a</p> \\[ \\begin{cases}     \\alpha_i,\\mu_i,\\xi_i\\ge 0\\\\     y_i(w^\\top x_i+b)-1+\\xi_i\\ge 0\\\\     \\alpha_i[y_i(w^\\top x_i+b)-1+\\xi_i]=0\\\\     \\mu_i\\xi_i=0 \\end{cases} \\] <p>\u7531\u4e8e \\(C=\\alpha_i+\\mu_i\\)\uff0c\u5bf9 \\(\\alpha_i\\) \u8ba8\u8bba\uff1a</p> <ul> <li>\\(\\alpha_i=0\\) \u5219 \\(\\mu_i=C,\\xi_i=0\\)\uff0c\u662f\u53ef\u4ee5\u88ab\u786c\u5206\u7c7b\u7684\u6837\u672c\u70b9\u3002</li> <li>\\(\\alpha_i\\in(0,C)\\) \u4e5f\u662f\u53ef\u4ee5\u88ab\u786c\u5206\u7c7b\u7684\u6837\u672c\u70b9\uff0c\u4f46\u662f \\(y_i(w^\\top x_i+b)-1=0\\)\uff0c\u4e3a\u4e4b\u524d\u6240\u8ff0\u7684\u652f\u6301\u5411\u91cf\u3002</li> <li>\\(\\alpha_i=C\\)\uff0c\u843d\u5728\u8f6f\u95f4\u9694\u5185\uff0c\u4e5f\u662f\u652f\u6301\u5411\u91cf\u3002</li> </ul> <p>\u7531\u4e8e \\(w=\\sum \\alpha_iy_ix_i\\)\uff0c\u6309\u4e0a\u9762\u7684\u5b9a\u4e49\uff0c\\(w\\) \u4ec5\u7531\u652f\u6301\u5411\u91cf\u6240\u51b3\u5b9a\uff0c\u4e0b\u9762\u7684\u95ee\u9898\u5c31\u662f\u9700\u8981\u9ad8\u6548\u6c42\u89e3 \\(\\alpha_i\\) \u4e86\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\u6700\u540e\u5f97\u5230\u7684\u5206\u7c7b\u5668\u662f\uff1a</p> \\[ f(x)=\\mathrm{sign}\\left(b+\\sum \\alpha_iy_ix_i^\\top x\\right) \\] <p>\u5f53\u7136 \\(x_i^\\top x\\) \u8fd9\u4e2a\u5185\u79ef\u53ef\u4ee5\u66ff\u6362\u6210\u6838\u51fd\u6570\u7684\u5185\u79ef \\(K(x_i,x)=\\phi(x_i)^\\top \\phi(x)\\) \u4ee5\u7f13\u89e3\u7ef4\u5ea6\u707e\u96be\uff0c\u4f46 Kernel trick \u4e0d\u662f\u6211\u4eec\u63a8\u5bfc SMO \u7b97\u6cd5\u7684\u4e3b\u9898\u3002</p>"}, {"location": "DNN/SVM_SMO/#smo_1", "title": "SMO \u6c42\u89e3", "text": "<p>\u5728\u6211\u770b\u6765 SMO \u7b97\u6cd5\u6709\u70b9\u7c7b\u4f3c EM \u7b97\u6cd5\uff0c\u9762\u5bf9\u4e00\u7cfb\u5217\u76f8\u4e92\u5236\u8861\u7684\u4f18\u5316\u53d8\u91cf\uff0c\u5b83\u4eec\u90fd\u9009\u62e9\u5404\u4e2a\u51fb\u7834\u3002</p> <p>SMO \u7b97\u6cd5\u7684\u601d\u60f3\u662f\u6bcf\u6b21\u9009\u4e24\u4e2a\u53d8\u91cf\uff0c\u56fa\u5b9a\u5176\u4ed6\u4e0d\u52a8\uff0c\u7136\u540e\u6839\u636e\u5404\u79cd\u7b49\u5f0f\u5f97\u5230\u4e00\u4e2a\u4e8c\u6b21\u65b9\u7a0b\uff0c\u518d\u628a\u89e3\u7ea6\u675f\u5230\u6761\u4ef6\u5185\uff0c\u4e0d\u65ad\u8fed\u4ee3\u6c42\u89e3\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u5148\u9009\u62e9 \\(\\alpha_1\\) \u548c \\(\\alpha_2\\)\uff0c\u56fa\u5b9a\u5176\u4ed6\u7684\uff0c\u7136\u540e\u7531 \\(\\sum \\alpha_i y_i=0\\) \u53ef\u5f97</p> \\[ \\alpha_1 y_1 + \\alpha_2 y_2 = \\zeta\\mathrm{(const.)}\\implies \\alpha_1=(\\zeta-\\alpha_2 y_2)y_1 \\] <p>\u8fd9\u6837\uff0c\u7531\u4e8e \\(\\alpha_1\\) \u4e0d\u662f\u81ea\u7531\u7684\uff0c\u5176\u4ed6 \\(\\alpha\\) \u53c8\u662f\u4eba\u4e3a\u56fa\u5b9a\u7684\uff0c\u5219</p> \\[ W(\\alpha)=W(\\alpha_2)=c\\alpha^2_2+b\\alpha+a \\] <p>\u4e3a\u4e00\u4e2a\u4e8c\u6b21\u65b9\u7a0b\u2014\u2014\u6211\u4eec\u53ef\u4ee5\u89e3\u6790\u5730\u6c42\u51fa\u5176\u6781\u503c \\(\\hat\\alpha_2\\)\uff01</p> <p>\u4f46\u662f\u8fd9\u4e2a\u6781\u503c\u4e0d\u4e00\u5b9a\u6ee1\u8db3\u7ea6\u675f\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u88c1\u526a\u3002\u4e5f\u5c31\u662f\u57fa\u4e8e \\(\\alpha_1 y_1 + \\alpha_2 y_2 = \\zeta\\) \u548c \\(\\alpha_1,\\alpha_2\\in[0,C]\\)\uff0c\u518d\u8ba1\u7b97 \\(\\alpha_1\\)\u3002</p> <p>\u6839\u636e \\(\\alpha_1\\) \u548c \\(\\alpha_2\\) \u7684\u503c\uff0c\u57fa\u4e8e KKT \u6761\u4ef6\u5c31\u80fd\u8ba1\u7b97\u51fa \\(b\\) \u4e86\u3002\u5982\u679c\u51fa\u73b0\u88c1\u526a\u7b97\u51fa\u6765\u5bfc\u81f4 \\(b\\) \u7684\u503c\u4e0d\u4e00\u6837\uff0c\u5c31\u53d6\u4e00\u4e2a\u5e73\u5747\u3002</p> <p>\u6bcf\u4e00\u6b21\u4e0d\u65ad\u91cd\u590d\u9009\u62e9\u4e00\u5bf9 \\(\\alpha\\) \u8fdb\u884c\u4f18\u5316\uff0c\u76f4\u5230\u6ee1\u8db3 KKT \u6761\u4ef6\u7684\u5bb9\u5dee\uff0c\u5c31\u53ef\u4ee5\u505c\u6b62\u7b97\u6cd5\u4e86\u3002\u5c31\u521d\u59cb\u53d8\u91cf\u7684\u9009\u62e9\u800c\u8a00\uff0c\u4e5f\u53ef\u4ee5\u9009\u62e9\u90a3\u4e9b\u8fdd\u53cd KKT \u6761\u4ef6\u6700\u4e25\u91cd\u7684\u6837\u672c\uff0c\u8fd9\u6837\u6536\u655b\u66f4\u5feb\u3002</p>"}, {"location": "DNN/SVM_SMO/#_2", "title": "\u8bc4\u8ff0", "text": "<p>SMO \u7b97\u6cd5\u7684\u8bad\u7ec3\u590d\u6742\u5ea6\u81f3\u5c11\u662f\u6837\u672c\u91cf \\(N\\) \u7684\u5e73\u65b9\u7ea7\uff0c\u5bfc\u81f4\u5927\u89c4\u6a21\u7684 SVM \u5e94\u7528\u76f8\u5f53\u56f0\u96be\u3002\u4e0d\u8fc7\u57fa\u4e8e RBF \u7684 SVM \u5728\u4f7f\u7528 SMO \u4f18\u5316\u540e\uff0c\u4e5f\u80fd\u591f\u83b7\u5f97\u76f8\u5f53\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u80fd\u591f\u62b5\u6297\u5982 FGSM \u7b49\u65b9\u6cd5\u7684\u653b\u51fb\uff0c\u56e0\u4e3a\u5b83\u80fd\u591f\u7ed9\u5783\u573e\u6837\u672c\u4e00\u4e2a\u5f88\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002\uff08\u53c2\u8003 FGSM \u7684\u8bba\u6587\uff09</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 18, 2025). SMO \u7b97\u6cd5\u7684\u63a8\u5bfc [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/SVM_SMO</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{SVM_SMO,\n    title={SMO \u7b97\u6cd5\u7684\u63a8\u5bfc},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/DNN/SVM_SMO}},\n}\n</code></pre></p>"}, {"location": "DNN/WP/aiwp/", "title": "MISC-AI \u65b9\u5411 WriteUp", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 16 \u5206\u949f\u3000|\u3000\u7ea6 2705 \u5b57\u3000|\u3000\u7ea6 4 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 258 \u884c\u4ee3\u7801</p>"}, {"location": "DNN/WP/aiwp/#wp-wp", "title": "WP \u7684 WP", "text": "<p>\u5176\u5b9e\u8fd9\u4e2a\u7b97\u4e0d\u4e0a\u4ec0\u4e48\u6f0f\u6d1e\uff0c\u7eaf\u5c5e\u6211\u4e2a\u4eba\u758f\u5ffd\u2026\u2026</p> <p>\u6253\u5f00\u6211\u7684\u535a\u5ba2\u53ef\u4ee5\u770b\u5230\u662f\u4e00\u4e2a\u57fa\u4e8e GitHub Pages \u7684\u57df\u540d\uff0c\u90a3\u4e48\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5229\u7528\u8fd9\u4e2a\u57df\u540d\u8bbf\u95ee\u5230\u5bf9\u5e94\u7684\u4ed3\u5e93\uff1a</p> <p></p> <p>\u7531\u4e8e\u6211\u5df2\u7ecf\u63d0\u4f9b\u4e86 WP \u7684\u94fe\u63a5\uff0c\u8fd9\u4e2a\u94fe\u63a5\u7684\u7ec4\u7ec7\u7ed3\u6784\u6309 mkdocs \u7684\u6846\u67b6\u662f\u653e\u5728 docs/ \u4e0b\u9762\u7684\u3002\u5e76\u4e14\u66f4\u91cd\u8981\u7684\u662f\u6211\u5f80\u91cc\u9762\u4f20\u7684\u662f\u672a\u4fee\u6539\u7684 md \u6587\u4ef6\u660e\u6587\uff01\u8fd9\u610f\u5473\u7740\u627e\u5230\u8fd9\u7bc7 WP \u5bf9\u5e94\u7684 md \u6587\u4ef6\u5373\u53ef\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u8fdb\u8fd9\u4e2a\u76ee\u5f55\uff1a</p> <p></p> <p>\u600e\u4e48\u7ed9\u6211\u5220\u4e86\u554a\uff1f\uff1f\uff1f</p> <p>\u4e0d\u8fc7\u4e0d\u6025\uff0cgit \u7684\u597d\u5904\u5c31\u662f\u53ef\u4ee5\u4fdd\u7559\u5386\u53f2\u4ee5\u4f9b\u67e5\u9a8c\uff0c\u6211\u4eec\u70b9 history \u5e76\u4e14\u6309 comment \u5185\u5bb9\uff0c\u9009\u62e9\u6700\u8fd1\u7684\u4e00\u6b21\u5bf9\u535a\u5ba2\u5185\u5bb9\u7684 commit:</p> <p></p> <p>\u70b9\u8fdb\u53bb\uff1a</p> <p></p> <p>\u70b9\u5f00\uff1a</p> <p></p> <p>\u6211\u4eec\u5c31\u77e5\u9053\u5bc6\u7801\u662f\uff1a</p> <pre><code>UUID('1afe080f-b280-11f0-902e-00155dff0634')\n</code></pre> <p>\u5982\u679c\u642d\u8fc7\u535a\u5ba2\u4e14\u719f\u6089 git \u7684\u540c\u5b66\u5e94\u8be5\u80fd\u5f88\u5feb\u53d1\u73b0\u8fd9\u4e00\u70b9\u7684\uff0c\u53ef\u60dc\u6ca1\u4eba\u5e26\u7740\u6b63\u786e\u7684\u5bc6\u7801\u8054\u7cfb\u6211\uff0c\u591a\u5c11\u6709\u70b9\u9057\u61be\u2026\u2026</p>"}, {"location": "DNN/WP/aiwp/#problem-1", "title": "Problem 1", "text": "<p>\u64cd\u4f5c\u6307\u5357\uff1a\u672c\u9898\u4e3a\u7b7e\u5230\u9898\uff0c\u6309\u4e0b\u9762\u6307\u5357\u64cd\u4f5c\u5373\u53ef\u3002\u672c\u9898\u76ee\u9f13\u52b1 Vibe coding\uff08\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u7f16\u7a0b\uff09\uff0c\u4f46\u5728\u63d0\u4ea4 WP \u65f6\u8bf7\u4ed4\u7ec6\u9605\u8bfb\u76f8\u5173\u89c4\u5b9a\uff01</p> <ol> <li>\u5728\u4e0b\u53d1\u7684 mnist_cnn_weights.pth \u6587\u4ef6\u91cc\u9762\u627e\u5230\u5bc6\u94a5\u3002</li> <li>\u5206\u6790\u8fd9\u4e2a\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u57fa\u4e8e modified_mnist \u91cc\u9762\u7684\u6570\u636e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u65b0\u6a21\u578b\u3002</li> <li>\u4f7f\u7528\u8fd9\u4e2a\u65b0\u6a21\u578b\u5bf9 imgs/ \u76ee\u5f55\u4e0b\u7684\u56fe\u7247\u6309\u987a\u5e8f\u8fdb\u884c\u63a8\u7406\uff0c\u63a8\u7406\u7684\u7ed3\u679c\u62fc\u63a5\u6210\u4e00\u4e2a\u5b57\u7b26\u4e32\u3002</li> <li>\u5c06\u8fd9\u4e2a\u5b57\u7b26\u4e32\u4f5c\u4e3a\u4e00\u4e2a\u5341\u8fdb\u5236\u6570\uff0c\u8f6c\u6210 16 \u8fdb\u5236\u6570\uff0c\u8fd9\u5c31\u662f\u5bc6\u6587\u3002</li> <li>\u6839\u636e\u5bc6\u94a5\u89e3\u5bc6\u5bc6\u6587\uff0c\u5f97\u5230 flag\u3002\u52a0\u5bc6\u65b9\u5f0f\u662f\u4e00\u79cd\u975e\u5e38\u7b80\u5355\u7684\u52a0\u5bc6\u3002</li> </ol>"}, {"location": "DNN/WP/aiwp/#_1", "title": "\u51fa\u9898\u4eba\u5410\u69fd", "text": "<p>\u672c\u9898\u76ee\u8bbe\u8ba1\u51fa\u6765\u5c31\u662f\u8ba9\u5927\u5bb6\u7528 ai \u68ad\u7684\uff0c\u4e0d\u8fc7\u4e0d\u7ba1\u5927\u4f19\u7528\u4ec0\u4e48\u5927\u6a21\u578b\uff0c\u603b\u662f\u80fd\u9047\u5230\u4e00\u4e9b\u5171\u6027\u95ee\u9898\u5462\uff1a</p> <ul> <li>\u4e0d\u77e5\u9053\u5229\u7528\u6211\u4fee\u6539\u540e\u7684\u6570\u636e\u3002\u7f51\u9875\u7aef\u7684 Chat \u6a21\u578b\u80af\u5b9a\u53ea\u80fd\u731c\uff0c\u559c\u6b22\u731c\u662f RL \u5927\u5e45\u63d0\u5347\u63a8\u7406\u6027\u80fd\u5e26\u6765\u7684\u53cd\u566c\uff0c\u731c\u7684\u540e\u679c\u5c31\u662f\u5f88\u591a\u4eba\u505a\u51fa\u6765\u7684\u7ed3\u679c\u662f 42\u2026\u2026 \u5f00\u5934\uff0c\u8fd9\u5c31\u649e\u5230\u6211\u9884\u8bbe\u7684\u5361\u70b9\u4e86\uff0c\u56e0\u4e3a\u4fee\u6539\u540e\u7684\u6570\u636e\u662f\u505a\u4e86\u6807\u7b7e\u7f6e\u6362\u540e\u7684 MNIST\u3002\u5982\u679c\u7528 CLINE \u7b49 Agent \u63d2\u4ef6\u4f1a\u597d\u4e00\u4e9b\u3002</li> <li>\u987a\u5e8f\u95ee\u9898\u3002\u6211\u89c9\u5f97\u4eba\u770b\u5230\u201c\u6309\u987a\u5e8f\u8fdb\u884c\u63a8\u7406\u201d\u51e0\u4e2a\u5b57\uff0c\u7ed3\u5408 imgs/ \u6587\u4ef6\u5939\u4e0b\u7684 img_index_0, img_index_1, ... \u80af\u5b9a\u4f1a\u7406\u89e3\u6210\u662f\u81ea\u7136\u6570\u987a\u5e8f\u4ece 0 \u6570\u5230 100\u3002 \u4f46\u662f\u5f88\u53ef\u60dc\u6709\u8bb8\u591a GPT \u4eec\u9009\u62e9\u4e00\u4e2a\u7b80\u5355\u7684\u5b57\u5178\u5e8f\uff0c\u4e5f\u5c31\u662f 0, 1, 10, 100, 11, ... \u4e0d\u8fc7\u6211\u540e\u9762\u4e5f\u6f84\u6e05\u4e86\u4e00\u4e0b\uff0c\u5e2e\u5927\u5bb6\u5199\u51fa\u66f4\u597d\u7684 prompts\uff0c\u6bd5\u7adf\u8fd9\u4e0d\u5e94\u8be5\u6210\u4e3a\u4e00\u4e2a\u5361\u70b9\u3002</li> </ul> <p>\u4e0d\u8fc7\u8fd9\u5176\u5b9e\u4f53\u73b0\u4e86 LLM \u7684\u597d\u51e0\u4e2a\u5c40\u9650\u6027\uff1a</p> <ul> <li>\u7531\u4e8e\u201c\u4e0d\u5177\u8eab\u201d\u65e0\u6cd5\u8bbf\u95ee\u6570\u636e\uff0c\u800c RL \u53c8\u9f13\u52b1\u5176\u8fc7\u5ea6\u731c\u6d4b\uff08\u5176\u5b9e\u662f RL \u6307\u6807\u6ca1\u6709\u641e\u597d exploration vs. exploitation\uff0c\u4e07\u4e00\u731c\u80fd\u731c\u5bf9\u5462\uff0c\u8fd9\u5c31\u6709\u5229\u4e8e\u5237 SOTA \u4e86\uff0c\u53c2\u8003 OpenAI \u7684\u8fd9\u4e2a\u7814\u7a76\uff09\uff0c\u56e0\u6b64\u7ed3\u679c\u53ea\u80fd\u6536\u655b\u5230\u6700\u5e73\u6ed1\u6216\u8005\u8bf4\u6700\u5e38\u89c1\u7684\u5206\u5e03\uff0c\u56e0\u6b64\u5982\u679c\u8981\u5728\u8fd9\u4e2a\u70b9\u4e0a\u9762\u5361\u4eba\u7684\u8bdd\uff0c\u6362\u4e00\u4e2a\u4e0d\u5e38\u89c1\u7684\u67b6\u6784\uff0c\u6bd4\u5982 RBF \u7f51\u7edc\u7b49\uff0c\u5c31\u884c\u4e86\u3002</li> <li>\u4e0d\u540c LLM \u4e4b\u95f4\u5171\u7528\u6570\u636e\u548c\u76f8\u4e92\u84b8\u998f\u73b0\u8c61\u4e25\u91cd\u3002\u4ee5\u4e0a\u63d0\u5230\u7684\u4e24\u4e2a\u95ee\u9898\u5728\u4e0d\u540c\u5382\u5bb6\u7684 LLM \u90fd\u51fa\u73b0\u4e86\uff0c\u6216\u8bb8\u4ee5\u540e\u6211\u4eec\u751a\u81f3\u65e0\u9700\u8003\u8651 LLM \u653b\u51fb\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e4b\u95f4\u5df2\u7ecf\u6ca1\u6709\u4ec0\u4e48\u5dee\u522b\u4e86\uff0c\u751a\u81f3\u6211\u4eec\u73b0\u5728\u5df2\u7ecf\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u8d8b\u52bf\u4e86\u3002</li> </ul>"}, {"location": "DNN/WP/aiwp/#exp", "title": "EXP", "text": "<p>\u57fa\u672c\u4e0a\u5c31\u662f\u6587\u5b57\u63cf\u8ff0\u7684\u4ee3\u7801\u5316\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport os\nimport numpy as np\nfrom PIL import Image\n\n# --- \u73af\u5883\u914d\u7f6e\u4e0e\u6a21\u578b\u5b9a\u4e49 ---\ndevice = torch.device(\"cpu\")\nnum_epochs = 1 \n\nclass PyTorch_MNIST_CNN(nn.Module):\n    def __init__(self):\n        super(PyTorch_MNIST_CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.dropout_conv = nn.Dropout(0.25)\n        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n        self.dropout_fc = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.dropout_conv(x) \n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.dropout_conv(x) \n        x = x.view(-1, 7 * 7 * 64)\n        x = F.relu(self.fc1(x))\n        x = self.dropout_fc(x) \n        x = self.fc2(x)\n        return x\n\nfrom torchvision import transforms\n\n# \u7528torchvision\u539f\u751f\u65b9\u6cd5\u52a0\u8f7d\u4fee\u6539\u540e\u7684\u6570\u636e\u96c6\nSAVE_DIR = './modified_mnist'\nmodified_train = datasets.MNIST(\n    root=SAVE_DIR,  # \u8fd9\u91cc\u7528\u6211\u4eec\u4fdd\u5b58\u7684\u76ee\u5f55\n    train=True,\n    download=False,  # \u5df2\u624b\u52a8\u751f\u6210\uff0c\u65e0\u9700\u4e0b\u8f7d\n    transform=transforms.ToTensor()\n)\nmodified_test = datasets.MNIST(\n    root=SAVE_DIR,\n    train=False,\n    download=False,\n    transform=transforms.ToTensor()\n)\ntrain_loader = torch.utils.data.DataLoader(modified_train, batch_size=64, shuffle=True)\n\n# --- \u8bad\u7ec3\u903b\u8f91 ---\n\nmodel = PyTorch_MNIST_CNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ndef train(model, device, train_loader, optimizer, criterion, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(data), target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n             print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}')\n\nprint(\"\\n\u5f00\u59cb\u6a21\u578b\u8bad\u7ec3 (1 Epoch)...\")\ntrain(model, device, train_loader, optimizer, criterion, num_epochs)\nprint(\"\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210!\")\n\ndef predict_label_from_path(\n    model: nn.Module, \n    image_path: str, \n    device: torch.device\n) -&gt; int:\n    \"\"\"\n    \u52a0\u8f7d\u672c\u5730\u56fe\u7247\u6587\u4ef6\uff0c\u8fdb\u884c\u9884\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff0c\n    \u8fd4\u56de\u6a21\u578b\u9884\u6d4b\u7684\u7f6e\u6362\u540e\u6807\u7b7e\u3002\n\n    Args:\n        model: \u8bad\u7ec3\u597d\u7684 PyTorch \u6a21\u578b (\u5df2\u4f7f\u7528\u7f6e\u6362\u6807\u7b7e\u8bad\u7ec3)\u3002\n        image_path: \u672c\u5730\u56fe\u7247\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84 (str)\u3002\n        device: \u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907 (e.g., torch.device(\"cpu\"))\u3002\n\n    Returns:\n        \u6a21\u578b\u9884\u6d4b\u7684\u6807\u7b7e (int)\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56de -1\u3002\n    \"\"\"\n\n    if not os.path.exists(image_path):\n        print(f\"\u9519\u8bef\uff1a\u6587\u4ef6\u8def\u5f84\u4e0d\u5b58\u5728: {image_path}\")\n        return -1\n\n    # 1. \u5b9a\u4e49\u4e0e\u8bad\u7ec3\u65f6\u76f8\u540c\u7684\u9884\u5904\u7406\u6b65\u9aa4\n    # \u6ce8\u610f\uff1aMNIST \u4f7f\u7528\u7684\u662f (0.1307,) \u548c (0.3081,)\n    preprocess = transforms.Compose([\n        transforms.Grayscale(num_output_channels=1), # \u786e\u4fdd\u8f93\u5165\u662f\u5355\u901a\u9053\n        transforms.Resize((28, 28)),                # \u786e\u4fdd\u5c3a\u5bf8\u5339\u914d\n        transforms.ToTensor(), \n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n\n    try:\n        # 2. \u52a0\u8f7d\u56fe\u7247\n        # \u4f7f\u7528 L \u6a21\u5f0f\u52a0\u8f7d\u7070\u5ea6\u56fe\n        image = Image.open(image_path).convert('L')\n\n        # 3. \u9884\u5904\u7406\n        image_tensor = preprocess(image)\n\n        # 4. \u589e\u52a0 Batch \u7ef4\u5ea6\u5e76\u79fb\u52a8\u5230\u8bbe\u5907\n        # \u6a21\u578b\u7684\u8f93\u5165\u9700\u8981\u662f [Batch_size, Channels, Height, Width]\n        image_input = image_tensor.unsqueeze(0).to(device)\n\n        # 5. \u6a21\u578b\u63a8\u7406\n        model.eval()\n        with torch.no_grad():\n            output = model(image_input)\n\n            # \u83b7\u53d6\u6982\u7387\u6700\u5927\u7684\u7d22\u5f15\uff0c\u5373\u9884\u6d4b\u6807\u7b7e\n            predicted_label = output.argmax(dim=1).item()\n\n            return predicted_label\n\n    except Exception as e:\n        print(f\"\u63a8\u7406\u8fc7\u7a0b\u4e2d\u53d1\u751f\u9519\u8bef: {e}\")\n        return -1\n\n# \u5bf9imgs/\u4e0b\u9762\u7684\u6240\u6709\u56fe\u7247\u8fdb\u884c\u63a8\u7406\uff0c\u8def\u5f84\u683c\u5f0f\u662f imgs/img_index_&lt;i&gt;.png\nli = []\nfor i in range(101):\n    # \u4e00\u5806 GPT \u628a\u8fd9\u4e2a\u7406\u89e3\u6210 sort \u4e86\uff0c\u6ca1\u60f3\u5230\u4e00\u4e2a for-range \u5faa\u73af\u5c31\u80fd\u641e\u5b9a\u2026\u2026\n    image_path = f'imgs/img_index_{i}.png'\n    predicted_label = predict_label_from_path(model, image_path, device)\n    li.append(predicted_label)\n\nnum = 0\nfor i in li:\n    num = num * 10 + i\nprint(hex(num)[2:].upper())\ntext_hex = hex(num)[2:].upper() # \u5341\u516d\u8fdb\u5236\u5bc6\u6587\n\ndef xor_crypt(data, key, is_encrypt=True):\n    \"\"\"\n    \u5f02\u6216\u52a0\u5bc6/\u89e3\u5bc6\u51fd\u6570\n    :param data: \u8f93\u5165\u6570\u636e\uff08\u52a0\u5bc6\u65f6\u4e3a\u660e\u6587\u5b57\u7b26\u4e32\uff1b\u89e3\u5bc6\u65f6\u4e3aHex\u683c\u5f0f\u5bc6\u6587\u5b57\u7b26\u4e32\uff09\n    :param key: \u5f02\u6216\u5bc6\u94a5\uff08\u5b57\u7b26\u4e32\uff09\n    :param is_encrypt: True\u4e3a\u52a0\u5bc6\uff0cFalse\u4e3a\u89e3\u5bc6\n    :return: \u52a0\u5bc6\u8fd4\u56deHex\u5b57\u7b26\u4e32\uff0c\u89e3\u5bc6\u8fd4\u56de\u660e\u6587\u5b57\u7b26\u4e32\n    \"\"\"\n    key_bytes = key.encode('utf-8')  # \u5bc6\u94a5\u8f6c\u5b57\u8282\n    key_len = len(key_bytes)\n    result = bytearray()  # \u5b58\u50a8\u5f02\u6216\u7ed3\u679c\u7684\u5b57\u8282\u6570\u7ec4\n\n    if is_encrypt:\n        # \u3010\u52a0\u5bc6\u3011\u8f93\u5165\u662f\u660e\u6587\u5b57\u7b26\u4e32\uff0c\u8f6c\u5b57\u8282\n        data_bytes = data.encode('utf-8')\n    else:\n        # \u3010\u89e3\u5bc6\u3011\u8f93\u5165\u662fHex\u5b57\u7b26\u4e32\uff0c\u8f6c\u5b57\u8282\n        data_bytes = bytes.fromhex(data)\n\n    # \u5faa\u73af\u5f02\u6216\uff1a\u6570\u636e\u6bcf\u4e2a\u5b57\u8282\u4e0e\u5bc6\u94a5\u5bf9\u5e94\u5b57\u8282\uff08\u5bc6\u94a5\u5faa\u73af\u590d\u7528\uff09\u5f02\u6216\n    for i, b in enumerate(data_bytes):\n        key_byte = key_bytes[i % key_len]  # \u5faa\u73af\u53d6\u5bc6\u94a5\u7684\u5b57\u8282\n        result.append(b ^ key_byte)       # \u5f02\u6216\u8fd0\u7b97\n\n    if is_encrypt:\n        # \u3010\u52a0\u5bc6\u8f93\u51fa\u3011\u5b57\u8282\u8f6cHex\u5b57\u7b26\u4e32\n        return result.hex()\n    else:\n        # \u3010\u89e3\u5bc6\u8f93\u51fa\u3011\u5b57\u8282\u8f6cUTF-8\u5b57\u7b26\u4e32\n        return result.decode('utf-8', errors='ignore')\n\n#\u5f02\u6216\u89e3\u5bc6\nkey = 'CIALLO0d000721998244353ISAPRIME' # \u6587\u672c\u5bc6\u94a5\nflag = xor_crypt(text_hex, key, is_encrypt=False)\nprint(f\"Flag: {flag}\")\n</code></pre> <p>\u6ca1\u9519\u6211\u4e5f\u662f vibe \u7684\uff0c\u4f46\u662f vibe \u7684\u524d\u63d0\u662f\uff0c\u5f97\u770b\u5f97\u61c2\u903b\u8f91\uff0c\u4ee5\u53ca\u51fa\u73b0\u5f20\u91cf\u5f62\u72b6\u4e0d\u5339\u914d\u6216\u8005\u7ed9\u975e\u53f6\u5b50\u5f20\u91cf\u505a\u64cd\u4f5c\u7b49\u62a5\u9519\u65f6\uff0c\u77e5\u9053\u600e\u4e48\u5904\u7406\u3002</p>"}, {"location": "DNN/WP/aiwp/#problem-2", "title": "Problem 2", "text": "<p>\u5b9e\u6d4b\u771f\u6b63\u505a\u8fd9\u4e2a\u9898\u7684\u4eba\u5e94\u8be5\u5728 10 \u4e2a\u4eba\u5de6\u53f3\uff0c\u4e0d\u8fc7\u6211\u5bfb\u601d\u8fd9\u4e2a\u9898\u5f88\u7b80\u5355\u554a\u3002</p> <p>\u4e0d\u8fc7\u8ba9 AI \u6765\u4f2a\u88c5 shell \u7684\u60f3\u6cd5\u5f88\u597d\u73a9\uff0c\u6211\u662f\u53d7\u5230\u8fd9\u4e2a\u6587\u7ae0\u7684\u542f\u53d1\u3002</p>"}, {"location": "DNN/WP/aiwp/#_2", "title": "\u8003\u5bdf\u70b9", "text": "<p>\u672c\u9898\u5c31\u662f\u5927\u5bb6\u6700\u559c\u6b22\u73a9\u7684\u63d0\u793a\u8bcd\u653b\u51fb\uff0c\u672c\u6765\u662f\u4e5f\u662f\u60f3\u641c\u96c6\u4e00\u4e0b\u5927\u5bb6\u6709\u6ca1\u6709\u4ec0\u4e48\u53ef\u73a9\u6027\u6bd4\u8f83\u9ad8\u7684\u63d0\u793a\u8bcd\uff0c\u7ed3\u679c\u592a\u53ef\u60dc\u4e86\u6ca1\u51e0\u4e2a\u4eba\u505a\u2026\u2026</p> <p>\u5982\u679c\u5927\u5bb6\u6709\u60f3\u73a9 LLM \u5b89\u5168\u7684\uff0c\u4e0b\u9762\u7684\u9898\u89e3\u7b97\u662f\u521d\u6b65\u63d0\u4f9b\u4e00\u4e2a\u5c0f\u5c0f\u6b66\u5668\u5e93\u5427\uff0c\u8bf7\u52a1\u5fc5\u5728\u5408\u89c4\u8303\u56f4\u5185\u4f7f\u7528\u3002</p>"}, {"location": "DNN/WP/aiwp/#_3", "title": "\u63d0\u793a\u8bcd\u5927\u8d4f", "text": "<p>\u76ee\u524d\u6700\u7b80\u5355\u7684 prompt \u7531 misay \u5e08\u5085\u505a\u51fa\uff1a</p> <p></p> <p>PJA \u5e08\u5085\u7528 Gemini \u6413\u4e86\u4e2a\u7ed5\u8fc7\uff0c\u4e5f\u5f88\u4e0d\u9519\uff1a</p> <p></p> \u6709\u5bb3\u5185\u5bb9\u8b66\u544a <p></p> <p>\u4e0b\u9762\u7684\u5185\u5bb9\u6d89\u53ca\u5230\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u8bcd\u8d8a\u72f1\u653b\u51fb\uff0c\u53ef\u80fd\u5305\u542b\u4e0d\u6070\u5f53\u5185\u5bb9\uff0c\u5982\u66b4\u529b\u5371\u9669\u8a00\u8bba\u7b49\u3002\u8fd9\u4e9b\u5185\u5bb9\u4ec5\u4f9b\u5b66\u672f\u4ea4\u6d41\u4f7f\u7528\u3002</p> <p></p> <p>\u4ece \u8fd9\u91cc \u6458\u5f55\u7684\u4e00\u6bb5\u63d0\u793a\u8bcd\uff0cDeepseek-DAN\uff1a</p> <p></p> <p>\u7ecf\u5178\u732b\u5a18\u63d0\u793a\u8bcd\uff1a</p> <p></p> <p>\u6211\u81ea\u5df1\u5f88\u559c\u6b22\u7684\u4e00\u7bc7\u5de5\u4f5c\uff0cFlipAttack\uff0c\u4e00\u5e74\u4e86\u8fd9\u4e2a\u65b9\u6cd5\u8fd8\u80fd\u594f\u6548\uff0c\u8bf4\u660e LLM \u8303\u5f0f\u662f\u6709\u56fa\u6709\u5f31\u70b9\u7684\uff1a</p> <p></p> <p>\u7ecf\u5178\u7684 Untammed Writing Assistant \u63d0\u793a\u8bcd\uff0c\u867d\u7136\u6a21\u578b\u62d2\u7edd\u4e86\uff0c\u4f46\u662f\u8fd8\u662f\u6cc4\u9732\u4e86\u5185\u5bb9\u3002</p> <p></p> <p>\u8fd8\u633a\u597d\u7528\u7684\u4e07\u80fd\u5957\u53d6 prompt\uff1a</p> <p></p>"}, {"location": "DNN/WP/aiwp/#problem-3", "title": "Problem 3", "text": "<p>\u672c\u6765\u8fd9\u4e2a\u4f4d\u7f6e\u5e94\u8be5\u653e\u53e6\u5916\u4e00\u9053\u9898\u7684\uff0c\u4f46\u662f\u7531\u4e8e push \u5230\u6bd4\u8d5b\u73af\u5883\u4e0a\u9762\u53ef\u80fd\u51fa\u4e86\u4e9b\u95ee\u9898\u5bfc\u81f4\u6ca1\u6709\u56de\u663e\u4e00\u76f4\u4fee\u4e0d\u597d\uff0c\u5c31\u5728\u653e\u9898\u5f53\u5929\u51cc\u6668\u52a0\u73ed\u5230 3 \u70b9\u8fc7\u82b1\u4e86 2h \u51fa\u51fa\u6765\u4e86\uff0c\u7ed3\u679c\u5bfc\u81f4\u5f53\u5929\u767d\u5929\u9662\u8fd0\u4f1a\u5fd7\u613f\u8005\u76f4\u63a5\u7761\u8fc7\u5934\u2026\u2026</p> <p>\u9898\u76ee\u7ed3\u5408\u80cc\u666f\u5176\u5b9e\u5f88\u7b80\u5355\uff0c\u8003\u7684\u662f\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\uff0c\u4e5f\u5c31\u662f\u5bf9\u540e\u95e8\u89e6\u53d1\u5668\u7684\u9006\u5411\u3002\u8003\u8651\u5230\u9898\u76ee\u8bf4\u6cd5\u53ef\u80fd\u8fd8\u662f\u6709\u70b9\u9690\u6666\uff0c\u53cd\u6b63\u6211\u81ea\u5df1\u8bd5\u4e86\u51e0\u4e2a LLM \u53d1\u73b0\u5b83\u4eec\u90fd\u6ca1\u80fd\u8bfb\u51fa\u540e\u95e8\u653b\u51fb\u7684\u5473\u9053\u53cd\u800c\u4e00\u76f4\u5728\u7ea0\u7ed3\u9898\u76ee\u80cc\u666f\u7684\u81ea\u52a8\u9a7e\u9a76\u3002\u4e0d\u8fc7\u6700\u540e\u6211\u5df2\u7ecf\u628a\u5173\u952e\u8bcd\u8d34\u51fa\u6765\u4e86\uff0c\u641c\u7d22\u4e00\u4e0b\u7167\u7740\u505a\u5c31\u884c\u561b\u3002\u4e3a\u4ec0\u4e48\u8fd9\u4e9b\u9898\u51fa\u5728 misc? \u5c31\u662f\u8003\u9a8c\u641c\u7d22\u80fd\u529b\u3002\u5982\u679c\u4e00\u9053 misc \u9898\u76ee\u53ef\u4ee5\u8f7b\u677e\u5229\u7528\u968f\u6ce2\u9010\u6d41\u7b49\u5de5\u5177\u201c\u68ad\u201d\u51fa\u6765\uff0c\u90a3\u4e48\u8fd9\u6837\u7684\u9898\u76ee\uff08\u5165\u95e8\u6559\u5b66\u9898\u76ee\u4e0d\u7b97\u54c8\uff09\u8d28\u91cf\u80af\u5b9a\u4e0d\u9ad8\u3002</p> <p>\u987a\u7740\u6211\u7ed9\u7684\u63d0\u793a\uff0c\u6216\u8005\u8ba9 GPT5-high \u7b49\u806a\u660e\u6a21\u578b\u6765\u505a\u5c31\u4f1a\u627e\u5230 \u8fd9\u7bc7\u6587\u7ae0\uff0c\u7136\u540e\u5582\u7ed9 LLM \u76f4\u63a5 vibe \u5373\u53ef\u3002</p> <p>\u4e0b\u9762\u7684 WP \u5c31\u662f deepseek \u5e2e\u6211\u5199\u7684\uff1a</p>"}, {"location": "DNN/WP/aiwp/#wp", "title": "WP", "text": "<p>\u6bcf\u4e2a\u6a21\u578b\u90fd\u88ab\u690d\u5165\u4e86\u540e\u95e8\uff08backdoor\uff09\uff0c\u5f53\u8f93\u5165\u56fe\u50cf\u5305\u542b\u7279\u5b9a\u89e6\u53d1\u5668\uff08trigger\uff09\u65f6\uff0c\u6a21\u578b\u4f1a\u9519\u8bef\u5206\u7c7b\u5230\u76ee\u6807\u6570\u5b57\u3002\u89e6\u53d1\u5668\u662f\u4e00\u4e2a\u5c0f\u7684\u6270\u52a8\u6a21\u5f0f\uff0c\u901a\u5e38\u4eba\u773c\u96be\u4ee5\u5bdf\u89c9\u3002</p> <p>Neural Cleanse\u662f\u4e00\u79cd\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u5bf9\u4e8e\u4e00\u4e2a\u88ab\u690d\u5165\u540e\u95e8\u7684\u6a21\u578b\uff0c\u5c06\u5176\u4ed6\u7c7b\u522b\u7684\u8f93\u5165\u8bef\u5206\u7c7b\u5230\u76ee\u6807\u7c7b\u522b\u6240\u9700\u7684\u89e6\u53d1\u5668\u662f\u6700\u5c0f\u7684\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u9006\u5411\u5de5\u7a0b\u4e3a\u6bcf\u4e2a\u5019\u9009\u6570\u5b57\uff080-9\uff09\u751f\u6210\u89e6\u53d1\u5668\uff0c\u5e76\u6bd4\u8f83\u89e6\u53d1\u5668\u7684\u5927\u5c0f\uff0c\u4ece\u800c\u627e\u51fa\u76ee\u6807\u6570\u5b57\u3002</p> <p>\u5173\u952e\u6b65\u9aa4\uff1a</p> <ol> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u5019\u9009\u6570\u5b57 \\(c\\)\uff080\u52309\uff09\uff0c\u6211\u4eec\u4f18\u5316\u4e00\u4e2a\u89e6\u53d1\u5668 \\(\\delta\\)\uff0c\u4f7f\u5f97\u5f53\u89e6\u53d1\u5668\u6dfb\u52a0\u5230\u5e72\u51c0\u56fe\u50cf\u4e0a\u65f6\uff0c\u6a21\u578b\u5c06\u56fe\u50cf\u5206\u7c7b\u4e3a \\(c\\)\u3002</li> <li>\u4f18\u5316\u76ee\u6807\u662f\u6700\u5c0f\u5316\u5206\u7c7b\u635f\u5931\u548c\u89e6\u53d1\u5668\u7684L1\u8303\u6570\uff08\u9f13\u52b1\u89e6\u53d1\u5668\u7a00\u758f\uff09\u3002</li> <li>\u76ee\u6807\u6570\u5b57 \\(c^*\\) \u662f\u6240\u9700\u89e6\u53d1\u5668L1\u8303\u6570\u6700\u5c0f\u7684\u90a3\u4e2a\u3002</li> </ol>"}, {"location": "DNN/WP/aiwp/#1", "title": "\u6b65\u9aa41: \u73af\u5883\u51c6\u5907", "text": "<p>\u786e\u4fdd\u5b89\u88c5\u4ee5\u4e0bPython\u5e93\uff1a</p> <pre><code>pip install torch torchvision pycryptodome\n</code></pre>"}, {"location": "DNN/WP/aiwp/#2", "title": "\u6b65\u9aa42: \u786e\u5b9a\u6a21\u578b\u6570\u91cf", "text": "<p>\u4ece\u9898\u76ee\u9644\u4ef6\u4e2d\uff0c\u67e5\u770b\u6a21\u578b\u6587\u4ef6\u7684\u6570\u91cf\u3002\u5047\u8bbe\u4f60\u6536\u5230\u591a\u4e2a\u6a21\u578b\u6587\u4ef6\uff08\u5982 <code>model_0.pth</code>, <code>model_1.pth</code>, ...\uff09\uff0c\u6a21\u578b\u6570\u91cf\u5c31\u662f\u6587\u4ef6\u7684\u6570\u91cf\u3002\u8bb0\u6a21\u578b\u6570\u91cf\u4e3a N\u3002</p>"}, {"location": "DNN/WP/aiwp/#3", "title": "\u6b65\u9aa43: \u52a0\u8f7d\u6a21\u578b\u5e76\u5206\u6790\u67b6\u6784", "text": "<p>\u6a21\u578b\u662fPyTorch\u4fdd\u5b58\u7684\u6743\u91cd\u6587\u4ef6\uff08.pth\uff09\u3002\u7531\u4e8e\u67b6\u6784\u672a\u77e5\uff0c\u6211\u4eec\u9700\u8981\u4ece\u6a21\u578b\u4e2d\u63a8\u65ad\u3002\u901a\u5e38\uff0cMNIST\u5206\u7c7b\u6a21\u578b\u662fCNN\u3002\u4ee5\u4e0b\u4ee3\u7801\u6f14\u793a\u5982\u4f55\u52a0\u8f7d\u6a21\u578b\u5e76\u68c0\u67e5\u67b6\u6784\uff1a</p> <pre><code>import torch\nimport torch.nn as nn\n\n# \u5c1d\u8bd5\u52a0\u8f7d\u7b2c\u4e00\u4e2a\u6a21\u578b\u4ee5\u63a8\u65ad\u67b6\u6784\nstate_dict = torch.load('model_0.pth', map_location='cpu')\n\n# \u6253\u5370\u72b6\u6001\u5b57\u5178\u7684\u952e\u4ee5\u4e86\u89e3\u5c42\u7ed3\u6784\nprint(\"State dict keys:\", state_dict.keys())\n\n# \u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e2a\u901a\u7528MNIST CNN\u67b6\u6784\nclass MNISTClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(1, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 7 * 7, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.fc_layers(x)\n        return x\n\n# \u52a0\u8f7d\u6a21\u578b\u6743\u91cd\nmodel = MNISTClassifier()\nmodel.load_state_dict(state_dict)\nmodel.eval()\n</code></pre> <p>\u6ce8\u610f\uff1a\u5982\u679c\u67b6\u6784\u4e0d\u5339\u914d\uff0c\u53ef\u80fd\u9700\u8981\u8c03\u6574\u6a21\u578b\u5b9a\u4e49\u3002\u4f60\u53ef\u4ee5\u901a\u8fc7\u67e5\u770b\u72b6\u6001\u5b57\u5178\u7684\u5f62\u72b6\u6765\u63a8\u65ad\u5c42\u5927\u5c0f\u3002</p>"}, {"location": "DNN/WP/aiwp/#4", "title": "\u6b65\u9aa44: \u51c6\u5907\u6d4b\u8bd5\u6570\u636e", "text": "<p>\u4f7f\u7528MNIST\u6d4b\u8bd5\u96c6\u4f5c\u4e3a\u5e72\u51c0\u56fe\u50cf\u6765\u6e90\uff1a</p> <pre><code>from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([transforms.ToTensor()])\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n</code></pre>"}, {"location": "DNN/WP/aiwp/#5-neural-cleanse", "title": "\u6b65\u9aa45: \u5b9e\u73b0Neural Cleanse\u68c0\u6d4b", "text": "<p>\u5bf9\u4e8e\u6bcf\u4e2a\u6a21\u578b\uff0c\u6267\u884c\u4ee5\u4e0b\u4ee3\u7801\u6765\u68c0\u6d4b\u76ee\u6807\u6570\u5b57\uff1a</p> <pre><code>import torch.optim as optim\nimport numpy as np\n\ndef detect_target_class(model, test_loader, device='cpu'):\n    \"\"\"\n    \u4f7f\u7528Neural Cleanse\u68c0\u6d4b\u6a21\u578b\u7684\u76ee\u6807\u6570\u5b57\n    \u8fd4\u56de\u76ee\u6807\u6570\u5b57\uff080-9\uff09\n    \"\"\"\n    model.to(device)\n    model.eval()\n    l1_norms = []  # \u5b58\u50a8\u6bcf\u4e2a\u5019\u9009\u6570\u5b57\u7684\u89e6\u53d1\u5668L1\u8303\u6570\n\n    # \u9009\u62e95\u4e2a\u5e72\u51c0\u56fe\u50cf\u4f5c\u4e3a\u57fa\u7840\uff08\u6765\u81ea\u4e0d\u540c\u7c7b\u522b\uff09\n    clean_images = []\n    selected_classes = set()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            for img, lbl in zip(images, labels):\n                if lbl.item() not in selected_classes and len(clean_images) &lt; 5:\n                    clean_images.append(img.to(device))\n                    selected_classes.add(lbl.item())\n                if len(clean_images) &gt;= 5:\n                    break\n            if len(clean_images) &gt;= 5:\n                break\n\n    # \u5bf9\u6bcf\u4e2a\u5019\u9009\u6570\u5b57\uff080-9\uff09\u53cd\u6f14\u89e6\u53d1\u5668\n    for candidate in range(10):\n        triggers = []  # \u5b58\u50a8\u6bcf\u4e2a\u57fa\u7840\u56fe\u50cf\u7684\u89e6\u53d1\u5668\n        for base_img in clean_images:\n            base_img = base_img.unsqueeze(0)  # \u6dfb\u52a0batch\u7ef4\u5ea6\n            # \u521d\u59cb\u5316\u89e6\u53d1\u5668\uff08\u53ef\u8bad\u7ec3\u53c2\u6570\uff09\n            trigger = torch.zeros_like(base_img, requires_grad=True, device=device)\n            # \u6dfb\u52a0\u5c0f\u5e45\u566a\u58f0\u521d\u59cb\u5316\n            trigger.data = torch.randn_like(trigger) * 0.01\n\n            optimizer = optim.Adam([trigger], lr=0.05)\n            # \u4f18\u5316\u5faa\u73af\n            for step in range(200):  # 200\u6b21\u8fed\u4ee3\n                # \u6dfb\u52a0\u89e6\u53d1\u5668\u5e76\u88c1\u526a\u5230\u6709\u6548\u8303\u56f4\n                poisoned_img = torch.clamp(base_img + trigger, 0, 1)\n                outputs = model(poisoned_img)\n                # \u635f\u5931\u51fd\u6570\uff1a\u5206\u7c7b\u635f\u5931 + L1\u6b63\u5219\u5316\n                loss = nn.CrossEntropyLoss()(outputs, torch.tensor([candidate], device=device))\n                loss += 0.1 * torch.norm(trigger, p=1)  # L1\u6b63\u5219\u5316\u7cfb\u65700.1\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            triggers.append(trigger.detach().cpu())\n\n        # \u8ba1\u7b97\u5e73\u5747\u89e6\u53d1\u5668\u7684L1\u8303\u6570\n        avg_trigger = torch.mean(torch.stack(triggers), dim=0)\n        l1_norm = torch.norm(avg_trigger, p=1).item()\n        l1_norms.append(l1_norm)\n        print(f\"\u5019\u9009\u6570\u5b57 {candidate} \u7684\u89e6\u53d1\u5668L1\u8303\u6570: {l1_norm:.4f}\")\n\n    # \u76ee\u6807\u6570\u5b57\u662fL1\u8303\u6570\u6700\u5c0f\u7684\u5019\u9009\n    target_class = np.argmin(l1_norms)\n    print(f\"\u68c0\u6d4b\u5230\u7684\u76ee\u6807\u6570\u5b57: {target_class}\")\n    return target_class\n\n# \u904d\u5386\u6240\u6709\u6a21\u578b\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntarget_sequence = []\nfor i in range(N):  # N\u662f\u6a21\u578b\u6570\u91cf\n    print(f\"\u5904\u7406\u6a21\u578b {i}...\")\n    model = MNISTClassifier()\n    model.load_state_dict(torch.load(f'model_{i}.pth'))  # \u6839\u636e\u5b9e\u9645\u6587\u4ef6\u540d\u8c03\u6574\n    target_digit = detect_target_class(model, test_loader, device)\n    target_sequence.append(str(target_digit))\n\n# \u62fc\u63a5\u6570\u5b57\u5e8f\u5217\ndigit_string = ''.join(target_sequence)\nprint(f\"\u76ee\u6807\u6570\u5b57\u5e8f\u5217: {digit_string}\")\n</code></pre>"}, {"location": "DNN/WP/aiwp/#6-sha256", "title": "\u6b65\u9aa46: \u8ba1\u7b97SHA256\u5e76\u89e3\u5bc6", "text": "<p>\u4f7f\u7528\u76ee\u6807\u6570\u5b57\u5e8f\u5217\u8ba1\u7b97SHA256\u54c8\u5e0c\uff0c\u5e76\u89e3\u5bc6\u5bc6\u6587\uff0c\u8fd9\u91cc\u9009\u4e00\u4e2a\u5728\u7ebf\u7f51\u7ad9\u89e3\u5bc6\u5373\u53ef\u3002</p> <p>\u6ce8\u610f\u4e8b\u9879\uff1a</p> <ol> <li>\u6a21\u578b\u67b6\u6784\uff1a\u5982\u679c\u63d0\u4f9b\u7684\u6a21\u578b\u67b6\u6784\u4e0e\u4ee3\u7801\u4e2d\u7684<code>MNISTClassifier</code>\u4e0d\u5339\u914d\uff0c\u4f60\u9700\u8981\u6839\u636e\u72b6\u6001\u5b57\u5178\u8c03\u6574\u6a21\u578b\u5b9a\u4e49\u3002\u67e5\u770b\u72b6\u6001\u5b57\u5178\u7684\u952e\u548c\u5f62\u72b6\u6765\u6784\u5efa\u6b63\u786e\u67b6\u6784\u3002</li> <li>\u8ba1\u7b97\u65f6\u95f4\uff1aNeural Cleanse\u68c0\u6d4b\u6bcf\u4e2a\u6a21\u578b\u53ef\u80fd\u9700\u8981\u51e0\u5206\u949f\uff08\u53d6\u51b3\u4e8e\u786c\u4ef6\uff09\u3002\u4f7f\u7528GPU\u53ef\u4ee5\u52a0\u901f\u3002</li> <li>\u89e6\u53d1\u5668\u4f18\u5316\uff1a\u4f18\u5316\u53c2\u6570\uff08\u5b66\u4e60\u7387\u3001\u8fed\u4ee3\u6b21\u6570\u3001L1\u7cfb\u6570\uff09\u53ef\u80fd\u9700\u8981\u5fae\u8c03\u4ee5\u83b7\u5f97\u6700\u4f73\u7ed3\u679c\u3002\u5982\u679c\u68c0\u6d4b\u4e0d\u51c6\uff0c\u53ef\u4ee5\u589e\u52a0\u8fed\u4ee3\u6b21\u6570\u6216\u8c03\u6574L1\u7cfb\u6570\u3002</li> <li>\u6a21\u578b\u6570\u91cf\uff1a\u786e\u4fdd\u6b63\u786e\u7edf\u8ba1\u6a21\u578b\u6587\u4ef6\u6570\u91cf\uff0c\u987a\u5e8f\u901a\u5e38\u6309\u6587\u4ef6\u540d\u6392\u5e8f\uff08\u5982<code>model_0.pth</code>, <code>model_1.pth</code>, ...\uff09\u3002</li> </ol> <p>\u901a\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u4f60\u53ef\u4ee5\u627e\u51fa\u6bcf\u4e2a\u6a21\u578b\u7684\u76ee\u6807\u6570\u5b57\uff0c\u62fc\u63a5\u540e\u8ba1\u7b97SHA256\u5bc6\u94a5\uff0c\u5e76\u89e3\u5bc6\u5bc6\u6587\u83b7\u5f97flag\u3002\u672c\u9898\u5c55\u793a\u4e86\u540e\u95e8\u653b\u51fb\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86AI\u6a21\u578b\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002\u5982\u679c\u4f60\u5728\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u53ef\u4ee5\u68c0\u67e5\u6a21\u578b\u67b6\u6784\u6216\u8c03\u6574\u4f18\u5316\u53c2\u6570\u3002</p>"}, {"location": "DNN/WP/aiwp/#_4", "title": "\u788e\u788e\u5ff5", "text": "<p>\u4ece\u8fce\u65b0\u8d5b\u5f00\u59cb\u5c31\u6709\u4e86\u201c\u68ad\u201d\u7684\u98ce\u6c14\u3002\u4e0d\u53ef\u907f\u514d\u5730\uff0c\u6211\u4eec\u5e94\u8be5\u627f\u8ba4 LLM \u8d8a\u6765\u8d8a\u806a\u660e\u4e86\u3002\u4f46\u4f3c\u4e4e LLM \u7684\u667a\u529b\u548c\u7528 LLM \u7684\u4eba\u7684\u667a\u529b\u5728\u5f88\u591a\u65f6\u5019\u662f\u5b88\u6052\u7684\u3002\u6211\u770b\u5230\u597d\u591a\u4eba\u5bf9\u7740 AI 1 \u7684\u6307\u793a\u5494\u5494\u4e00\u987f\u70bc\u4e39\u51fa flag\uff0c\u7136\u540e\u770b\u7740 AI 2 \u7684\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u590d\u6742\u95ee\u9898\uff1anc \u8fde\u4e0d\u4e0a\uff0c\u800c\u53d1\u5446\u6c42\u52a9\u3002\u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u597d\u73b0\u8c61\u3002\u56fa\u7136\u6211\u4eec\u4e0d\u53ef\u80fd\u53cd\u5bf9 LLM \u6d6a\u6f6e\u5f00\u5386\u53f2\u5012\u8f66\uff0c\u4f46\u6211\u4eec\u7684\u6bd4\u8d5b\u662f\u9762\u5411\u4eba\u7684\u3002AI \u4f1a\u5199\u51fa\u7ed3\u6784\u975e\u5e38\u6e05\u6670\uff0c\u6ce8\u91ca\u4e30\u5bcc\u903b\u8f91\u5b8c\u6574\u7684\u4ee3\u7801\uff0c\u4f46\u81f3\u5c11\u73b0\u5728\u7684 AI \u770b\u5230 base100 \u7f16\u7801\u65f6\u4ecd\u7136\u4f1a\u9009\u62e9\u8001\u662f\u5728 emoji \u7684\u5177\u4f53\u5185\u5bb9\u4e0a\u9762\u94bb\u725b\u89d2\u5c16\uff0c\u7f16\u9020\u4e00\u4e2a\u8b66\u5bdf\u6293\u60c5\u4fa3\u7684\u6545\u4e8b\u2014\u2014\u800c\u5982\u679c\u4eba\u80fd\u591f\u8bbe\u8ba1\u4e00\u4e2a\u5408\u7406\u7684 prompt\uff0c\u5e76\u8f85\u4ee5\u641c\u7d22\u529f\u80fd\uff0c\u662f\u53ef\u4ee5\u6b63\u5e38\u505a\u51fa\u7684\u3002\u6211\u4eec\u5e0c\u671b\u7684\u662f\u8fd9\u6837\u7684 out-of-distribution\uff1a\u7528 LLM \u7684\u4eba\u80fd\u591f\u548c LLM \u4e00\u8d77\u667a\u529b\u8fdb\u6b65\uff0c\u800c\u4e0d\u662f\u7535\u8111\u63a7\u5236\u5927\u8111\uff0cLLM \u4ee3\u66ff\u601d\u8003\u3002</p> <p>\u626f\u5230\u8fd9\u4e86\uff0c\u8fd8\u5f97\u518d\u63d0\u4e00\u4e2a\u70b9\u3002\u4f7f\u7528\u8005\u5373\u8d1f\u8d23\u4eba\u2014\u2014\u4eba\u8981\u5bf9\u81ea\u5df1\u5229\u7528 AI \u751f\u6210\u7684\u5185\u5bb9\u8d1f\u8d23\u3002\u600e\u4e48\u4e2a\u8d1f\u8d23\u6cd5\u5462\uff1fAI \u5199\u4e86\u6bb5\u811a\u672c\uff0c\u5f97\u6e05\u695a\u5b83\u90fd\u5e72\u4e86\u4e9b\u5565\uff0c\u4f60\u624d\u6562\u8fd0\u884c\u5427\uff1f\u5982\u679c\u4f60\u4e0d\u61c2\uff0c\u5927\u53ef\u4ee5\u518d\u5f00\u4e00\u4e2a\u5bf9\u8bdd\u95ee\u95ee\u5427\u3002AI \u68ad\u9898\u56fa\u7136\u5feb\uff0c\u4f46\u4f60\u63d0\u4ea4\u4e4b\u524d\u80fd\u4e0d\u80fd\u5148\u770b\u770b\u8fd9\u73a9\u610f\u662f\u4e0d\u662f\u778e\u7f16\u7684\u554a\uff1f\uff1f\uff1f \u6211\u4eec\u540e\u53f0\u770b\u5230\u8fd9\u4e9b\u5bcc\u6709\u60f3\u8c61\u529b\u7684 flag \u4eec\u5feb\u7b11\u75af\u4e86\u2026\u2026\u9000\u4e00\u4e07\u6b65\u8bb2\uff0c\u4f60\u5f97\u6709\u660e\u767d AI \u662f\u4e0d\u662f\u5728\u7f16\u7684\u80fd\u529b\uff0c\u624d\u80fd\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528 AI\u3002</p> <p>\u8fd9\u4e24\u70b9\u603b\u7ed3\u8d77\u6765\u8fd8\u662f\u90a3\u53e5\u8bdd\uff1a\u4f60\u5c3d\u529b\u4e86\u5417\uff1f\u6216\u8005\u8bf4\uff0c\u4eba\u7c7b\u5c3d\u529b\u4e86\u5417\uff1f\u603b\u4e4b\uff0c\u91cd\u7533\u4e00\u904d\uff1a\u4e0d\u8981\u8ba9\u7535\u8111\u63a7\u5236\u5927\u8111\uff0cLLM \u4ee3\u66ff\u601d\u8003\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 27, 2025). MISC-AI \u65b9\u5411 WriteUp [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/WP/aiwp</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{aiwp,\n    title={MISC-AI \u65b9\u5411 WriteUp},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/DNN/WP/aiwp}},\n}\n</code></pre></p>"}, {"location": "DNN/model-attack/", "title": "\u5173\u4e8e\u672c\u7c7b\u522b", "text": "<p>\u672c\u7c7b\u522b\u4e3b\u8981\u6574\u7406\u7b14\u8005\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76f8\u5173\u653b\u51fb\u7684\u7406\u8bba\u5b66\u4e60\u548c\u4ee3\u7801\u590d\u73b0\u3002</p>"}, {"location": "DNN/model-attack/BadNets/", "title": "BadNets", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 3 \u5206\u949f\u3000|\u3000\u7ea6 571 \u5b57\u3000|\u3000\u7ea6 2 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u6587\u7ae0 \u7684\u4f5c\u8005\u90fd\u6765\u81ea\u7ebd\u7ea6\u5927\u5b66\u3002</p>"}, {"location": "DNN/model-attack/BadNets/#_1", "title": "\u5185\u5bb9", "text": "<p>\u6587\u7ae0\u672c\u8eab\u6ca1\u6709\u4ec0\u4e48\u597d\u8c08\u7684\uff0c\u6211\u89c9\u5f97\u5176\u7ed3\u8bba\u662f\u4e00\u4e2a\u5f88 trivial \u7684\u4e1c\u897f\uff0c\u5e76\u6ca1\u6709\u5f88\u4e30\u5bcc\u7684\u8425\u517b\u3002</p> <p>\u6587\u7ae0\u63d0\u51fa\u4e86\u4e09\u79cd\u7f51\u7edc\u8303\u5f0f\uff1a</p> <ul> <li>A: \u5e72\u51c0\u7684\u7f51\u7edc\uff0c\u901a\u8fc7\u5e72\u51c0\u7684\u8bad\u7ec3\u6837\u672c\u8bad\u7ec3\u5f97\u5230\u3002</li> <li>B: \u7406\u60f3\u7684\u540e\u95e8\u653b\u51fb\uff0c\u4e5f\u5c31\u662f\u5728\u5e72\u51c0\u7f51\u7edc\u4fa7\u9762\u52a0\u5165\u4e00\u4e2a\u5e76\u884c\u6a21\u5757\u7528\u6765\u8bc6\u522b\u540e\u95e8\u3002\u4e00\u65e6\u51fa\u73b0\u653b\u51fb\u7684\u6837\u672c\u5c31\u88ab\u89e6\u53d1\u5e76\u81ea\u52a8\u8fdb\u884c\u5e72\u6270\u3002</li> <li>C: \u73b0\u5b9e\u60c5\u51b5\u662f\uff0c\u4e0d\u53ef\u80fd\u5355\u72ec\u8bbe\u7f6e\u4e00\u4e2a\u72ec\u7acb\u7684\u540e\u95e8\u89e6\u53d1\u903b\u8f91\uff0c\u800c\u662f\u4ece\u6570\u636e\u4fa7\u6295\u6bd2\u3002</li> </ul> <p>\u6587\u7ae0\u4e3b\u8981\u8bba\u8bc1\u4e86 C \u60c5\u51b5\u4e5f\u662f\u76f8\u5f53\u53ef\u884c\u7684\u3002\u6211\u4eec\u5bf9\u6570\u636e\u8fdb\u884c\u6295\u6bd2\u3002\u5728\u56fe\u50cf\u5206\u7c7b\u9886\u57df\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u56fe\u50cf\u7684\u4e00\u5c0f\u90e8\u5206\u6dfb\u52a0\u4e00\u4e2a\u7279\u5b9a\u4fee\u6539\uff0c\u7136\u540e\u8ba9\u4fee\u6539\u540e\u7684\u56fe\u50cf\u6307\u5411\u6211\u4eec\u671f\u671b\u7684\u5206\u7c7b\u3002</p> <p>\u6587\u7ae0\u9664\u4e86\u5728\u80cc\u666f\u77e5\u8bc6\u91cc\u9762\u653e\u4e86\u51e0\u4e2a\u57fa\u7840\u7684\u516c\u5f0f\u4e4b\u540e\uff0c\u540e\u9762\u5c31\u6ca1\u6709\u4ec0\u4e48\u5f0f\u5b50\u4e86\u3002\u6587\u7ae0\u4e3b\u8981\u7684\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u8fd9\u4e2a\u5a01\u80c1\u6a21\u578b\uff0c\u5e76\u4e14\u505a\u4e86\u5f88\u591a\u53ef\u884c\u6027\u9a8c\u8bc1\u3002</p> <p>\u6587\u7ae0\u5bf9\u63d0\u51fa\u7684\u540e\u95e8\u653b\u51fb\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6548\u679c\u5f88\u597d\u3002</p> <p>\u5728\u8fc1\u79fb\u5b66\u4e60\u60c5\u5883\u4e0b\uff0c\u6587\u7ae0\u4e5f\u8bba\u8bc1\u4e86\u540e\u95e8\u4ecd\u7136\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u88ab\u4fdd\u7559\u3002</p>"}, {"location": "DNN/model-attack/BadNets/#_2", "title": "\u8bc4\u8ff0", "text": "<p>\u7b14\u8005\u8ba4\u4e3a\u8fd9\u7bc7\u6587\u7ae0\u6ca1\u4ec0\u4e48\u8425\u517b\uff08\u9664\u4e86\u505a\u7684\u51e0\u4e2a\u5b9e\u9a8c\u6709\u70b9\u770b\u5934\uff09\uff0c\u56e0\u4e3a\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u65e0\u975e\u5c31\u662f\u4e00\u4e2a\u62df\u5408\u673a\u5668\uff0c\u800c\u901a\u8fc7\u6570\u636e\u6295\u6bd2\u7684\u65b9\u5f0f\u5f15\u5165\u540e\u95e8\uff0c\u672c\u8eab\u4e5f\u5e76\u6ca1\u6709\u79bb\u5f00\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u4e0e\u6cdb\u5316\u7684\u672c\u8d28\u3002\u53ea\u8981\u5b83\u80fd\u591f\u901a\u8fc7\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\u8bc6\u522b\u5230\u201c\u540e\u95e8\u201d\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u5728\u6807\u7b7e\u4e2d\u7ed9\u51fa\u533a\u5206\uff0c\u90a3\u4e48\u8fd9\u5c31\u662f\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u4f18\u5316\u76ee\u6807\uff0c\u81ea\u7136\u80fd\u591f\u88ab\u57cb\u5165\u540e\u95e8\u3002</p> <p>\u5e76\u4e14\u540e\u95e8\u8fd8\u5b58\u5728\u53cd\u6f14\u7684\u53ef\u80fd\uff0c\u56e0\u6b64\u5982\u4f55\u5b9e\u73b0\u66f4\u9690\u853d\u7684\u540e\u95e8\u4ee5\u53ca\u5982\u4f55\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u540e\u95e8\u53cd\u6f14/\u68c0\u6d4b\u90fd\u662f\u95ee\u9898\uff0c\u5f88\u53ef\u60dc\u8fd9\u7bc7\u6587\u7ae0\u6ca1\u6709\u63d0\u5230\u3002\u5982\u679c\u8bf4\u540e\u95e8\u5728 \\(L\\) \u8303\u6570\u610f\u4e49\u4e0b\u662f\u96be\u4ee5\u5bdf\u89c9\u7684\uff0c\u90a3\u4e48\u4e00\u822c\u7684\u9488\u5bf9 \\(L\\) \u8303\u6570\u7684\u5bf9\u6297\u6837\u672c\u65b9\u6cd5\u7406\u5e94\u627e\u5230\u5bf9\u5e94\u7684\u540e\u95e8\u89e6\u53d1\u5668\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 27, 2025). BadNets [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-attack/BadNets</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{BadNets,\n    title={BadNets},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-attack/BadNets}},\n}\n</code></pre></p>"}, {"location": "DNN/model-attack/CandW/", "title": "C&amp;W \u653b\u51fb", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 11 \u5206\u949f\u3000|\u3000\u7ea6 1435 \u5b57\u3000|\u3000\u7ea6 45 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u6587\u7ae0 \u53d1\u8868\u5728 IEEE S&amp;P 2017\uff0c\u4e24\u4f4d\u4f5c\u8005\u90fd\u6765\u81ea\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u3002</p> <p>\u672c\u6765\u6587\u7ae0\u662f\u60f3\u9488\u5bf9\u6027\u63d0\u51fa\u4e00\u79cd\u653b\u51fb\u65b9\u5f0f\u6765\u8ba9\u9632\u5fa1\u6027\u84b8\u998f\uff08defensive distillation\uff09\u7834\u9632\uff0c\u4e0d\u8fc7\u6211\u89c9\u5f97\u653b\u51fb\u65b9\u5f0f\u548c\u4e00\u4e9b\u5de5\u7a0b\u6280\u5de7\u624d\u662f\u91cd\u70b9\uff0c\u56e0\u6b64\u672c\u6587\u4e0d\u4f1a\u592a\u591a\u63d0\u53ca\u8fd9\u4e00\uff08pwned!\uff09\u7684\u9632\u5fa1\u65b9\u5f0f\u3002</p>"}, {"location": "DNN/model-attack/CandW/#_1", "title": "\u6b63\u5219\u5316", "text": "<p>\u8fd9\u7bc7\u7b14\u8bb0\u63a5\u7eed\u4e0a\u9762\u4e24\u7bc7\u7b14\u8bb0\u3002\u8ba9\u6211\u4eec\u6765\u7406\u4e00\u4e0b\u601d\u8def\uff1aFGSM \u653b\u51fb\u5f15\u5165\u4e86\u68af\u5ea6\u4e0a\u5347\u4f5c\u4e3a\u5355\u6b65\u7684\u653b\u51fb\u65b9\u5f0f\uff0cPGD \u5f15\u5165\u4e86\u8fed\u4ee3\u7684\u5bf9\u6297\u6837\u672c\u751f\u6210\u3002\u5728 PGD \u7684\u7b14\u8bb0\u4e2d\uff0c\u7b14\u8005\u8fd8\u8ba8\u8bba\u4e86\u9488\u5bf9\u653b\u51fb\u7684\u201c\u6b63\u5219\u5316\u201d\u95ee\u9898\uff0c\u4e5f\u5c31\u662f\u9700\u8981\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\u4e3a\u4eba\u7c7b\u611f\u77e5\u5efa\u6a21\uff0c\u4ece\u800c\u63a7\u5236\u5bf9\u6297\u6837\u672c\u751f\u6210\u5904\u4e8e\u4e00\u79cd\u4e71\u4e4e\u4eba\u4e4b\u4e0d\u5bdf\u7684\u6548\u679c\u3002\u4f46\u5f53\u65f6\u7684\u8ba8\u8bba\u5c1a\u4e14\u7c97\u6d45\uff0c\u5904\u4e8e\u4e00\u79cd\u5b9a\u6027\u7684\u7ea7\u522b\u3002</p> <p>\u5728\u7b14\u8005\u770b\u6765\uff0cC&amp;W \u653b\u51fb\u6b63\u662f\u5c06\u8fd9\u79cd\u6b63\u5219\u5316\u7ea6\u675f\u7ed9\u201c\u5f62\u5f0f\u5316\u201d\u4e86\uff0c\u4ece\u800c\u53ef\u4ee5\u5b9e\u6253\u5b9e\u5730\u7528\u4f18\u5316\u5668\u6765\u8dd1\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u770b\u770b\u5177\u4f53\u662f\u600e\u4e48\u5f62\u5f0f\u5316\u7684\uff1a\u539f\u8bba\u6587\u7684\u7b2c\u4e94\u8282\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u8fd9\u4e2a\u91cf\u5316\u6807\u51c6\uff1a</p> \\[ \\begin{align*}     &amp;\\min\\mathcal{D}(x, x+\\delta)\\\\     &amp;C(x+\\delta) = t\\\\     &amp;x+\\delta\\in[0,1]^n \\end{align*} \\] <p>\u7b2c\u4e00\u884c\u8868\u5f81\u7684\u662f\uff0c\u6270\u52a8\u4e0d\u80fd\u592a\u5927\uff0c\u4e5f\u5c31\u662f\u5f15\u5165\u4e00\u4e2a \\(\\mathcal{D}\\) \u6765\u7ea6\u675f\u6270\u52a8\u7684\u5927\u5c0f\u3002\u5728\u5b9e\u8df5\u4e0a\uff0c\u5c31\u4e00\u822c\u4f7f\u7528\u65b9\u4fbf\u7684\u8303\u6570\u7ea6\u675f\u4e86\uff0c\u5373 \\(L_0\\), \\(L_2\\), \\(L_\\infty\\) \u7b49\u8303\u6570\u3002</p> <p>\u7b2c\u4e8c\u884c\u8981\u6c42\u653b\u51fb\u6210\u529f\uff0c\u5c06\u6270\u52a8\u540e\u7684\u6837\u672c\u5206\u7c7b\u4e3a\u65b0\u7684\u7c7b\u522b \\(t\\)\u3002\u5bb9\u6613\u770b\u51fa\u8fd9\u4e2a\u8981\u6c42\u548c\u7b2c\u4e00\u884c\u662f\u62ee\u6297\u7684\u3002</p> <p>\u6700\u540e\u4e00\u884c\u662f\u53ef\u884c\u6027\u7ea6\u675f\u3002\u56e0\u4e3a\u56fe\u50cf\u672c\u8eab\u6709\u7070\u9636\u7ea6\u675f \\([0,255]\\)\uff0c\u8d85\u8fc7\u7684\u503c\u90fd\u4f1a\u88ab\u622a\u65ad\u3002</p> <p>\u540e\u9762\u4f5c\u8005\u8fdb\u4e00\u6b65\u660e\u6670\u4e86\u4ec0\u4e48\u662f\u6240\u8c13\u7684\u201c\u653b\u51fb\u6210\u529f\u201d\u3002\u4f5c\u4e3a\u4e00\u4e2a\u4f18\u5316\u76ee\u6807\u5b83\u5fc5\u987b\u5b8c\u5168\u53ef\u5bfc\u3002\u4e3a\u6b64\u4f5c\u8005\u7ed9\u51fa\u4e86\u8bb8\u591a\u79cd\u5f62\u5f0f\u7684\u6307\u6807\uff1a</p> <p></p> <p>\u5177\u4f53\u7684 notation \u8bf7\u53c2\u8003\u539f\u6587\u3002\u5b83\u4eec\u7684\u5171\u6027\u662f\uff0c\u5982\u679c\u653b\u51fb\u540e\u7684\u6837\u672c\u8d8a\u503e\u5411\u4e8e\u88ab\u7f51\u7edc\u5206\u7c7b\u4e3a \\(t\\) \u7c7b\u522b\uff0c\u5219\u503c\u8d8a\u5c0f\uff08\u4f46\u662f\u622a\u65ad\u5230 0\uff09\u3002\\(F\\) \u548c \\(Z\\) \u5206\u522b\u5bf9\u5e94 softmax \u548c\u672a softmax \u7684\u8f93\u51fa\u903b\u8f91\u503c\u3002\u56e0\u4e3a\u672c\u6587\u4e3b\u8981\u662f\u8981\u7834\u9632\u5fa1\u6027\u84b8\u998f\u7684\u7532\uff0c\u800c\u9632\u5fa1\u6027\u84b8\u998f\u53ea\u662f\u91cd\u65b0\u7ea6\u675f\u4e86\u4e00\u4e0b softmax \u7684\u8f93\u51fa logits\uff0c\u6240\u4ee5\u5982\u679c\u4e0d\u53d6 softmax \u7684\u653b\u51fb\u7406\u8bba\u4e0a\u8bf4\u6548\u679c\u5c31\u4f1a\u597d\u4e9b\u3002</p> <p>\u7136\u540e\u5f88\u81ea\u7136\u5730\u6211\u4eec\u5f15\u5165\u4e00\u4e2a\u53c2\u6570 \\(c\\) \u6765\u5e73\u8861\u524d\u4e24\u884c\u7684\u6307\u6807\uff0c\u8fd9\u5c31\u5f97\u5230\u4e86\u6211\u4eec\u7684\u4f18\u5316\u76ee\u6807\uff1a</p> \\[ \\mathcal{L}_{\\mathrm{Adversarial}}=\\|\\delta\\|_L+c\\cdot f(x+\\delta) \\] <p>\u4e3a\u4e86\u89e3\u51b3\u503c\u88c1\u5207\u95ee\u9898\uff0cC&amp;W \u653b\u51fb\u5f15\u5165\u4e86\u6362\u5143\u6cd5\uff0c\u4e5f\u5c31\u662f\u8ba9</p> \\[ \\tilde x=\\dfrac 12(\\tanh w+1) \\] <p>\u5176\u4e2d \\(w\\) \u662f\u4e00\u4e2a\u65e0\u7ea6\u675f\u7684\u81ea\u7531\u53d8\u91cf\u3002\u8fd9\u6837\u786c\u88c1\u5207\u5c31\u53d8\u6210\u4e86\u5929\u7136\u7eb3\u5165\u7ea6\u675f\u7684\u81ea\u7531\u4f18\u5316\u95ee\u9898\u3002</p> <p>\u6700\u540e\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u653b\u51fb\u4f7f\u7528\u7684\u635f\u5931\uff1a</p> \\[ \\mathcal{L}_{\\mathrm{Adversarial}}=\\|\\dfrac 12(\\tanh w+1)-x\\|_L+c\\cdot f(\\dfrac 12(\\tanh w+1)) \\] <p>\u5176\u4e2d \\(x\\) \u662f\u539f\u6837\u672c\uff0c\\(w\\) \u662f\u65e0\u7ea6\u675f\u7684\u81ea\u7531\u53d8\u91cf\u3002\u8303\u6570\u7ea6\u675f\u53ef\u4ee5\u9009\u62e9 \\(L_0\\), \\(L_2\\), \\(L_\\infty\\) \u7b49\uff0c\u800c \\(f\\) \u53ef\u4ee5\u9009\u62e9\u4e0a\u9762\u7684\u8bf8\u591a \\(f_i\\)\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u5668\u5982 Adam \u7b49\uff0c\u5bf9\u8fd9\u4e00\u635f\u5931\u8fdb\u884c\u4f18\u5316\uff0c\u6700\u540e\u8fd8\u539f\u5f97\u5230\u5bf9\u6297\u6837\u672c\u3002</p>"}, {"location": "DNN/model-attack/CandW/#_2", "title": "\u6d88\u878d\u5b9e\u9a8c", "text": "<p>\u9488\u5bf9\u8bf8\u591a\u53c2\u6570\u7684\u9009\u62e9\uff0c\u4f5c\u8005\u8fdb\u884c\u4e86\u5927\u91cf\u7684\u6d88\u878d\u5b9e\u9a8c\u3002\u6240\u4ee5\u8fd9\u7bc7\u6587\u7ae0\u80fd\u53d1 S&amp;P \u800c\u4e0d\u662f ICLR \u662f\u6709\u7406\u7531\u7684\u2026\u2026</p> <p>\u5bf9 \\(c\\) \u7684\u9009\u62e9\u4e0a\uff0c\u4e0b\u56fe\u4f53\u73b0\u4e86\u6837\u672c\u8ddd\u79bb\u548c\u653b\u51fb\u6548\u679c\u4e4b\u95f4\u7684\u62ee\u6297\u5173\u7cfb\u3002</p> <p></p> <p>\u56fe\u4e2d\u53ef\u4ee5\u8bfb\u51fa\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4f5c\u8005\u5efa\u8bae \\(c\\in(0.1,1)\\)\uff0c\u5177\u4f53\u7684\u6700\u4f73 \\(c\\) \u503c\u53ef\u4ee5\u901a\u8fc7\u4e8c\u5206\u6cd5\u7b49\u65b9\u6cd5\u8fdb\u884c\u641c\u7d22\u3002</p> <p>\u4e0b\u8868\u5c55\u793a\u4e86\u4f5c\u8005\u5bf9 \\(f\\) \u6240\u505a\u7684\u6d88\u878d\u5b9e\u9a8c\u3002</p> <p></p> <p>\u8fd9\u91cc\u7684\u4e09\u4e2a case \u5bf9\u5e94\u7684\u662f\u5bf9\u653b\u51fb\u7684\u8981\u6c42\u3002Best case \u53ea\u8981\u6c42\u7ed9\u51fa\u6700\u5bb9\u6613\u653b\u51fb\u7684\u7c7b\u522b\uff1b Average case \u9700\u8981\u968f\u673a\u9009\u62e9\u7c7b\u522b\u5e76\u653b\u51fb\uff1bWorst case \u8981\u6c42\u5bf9\u6240\u6709\u7684\u9519\u8bef\u7c7b\u522b\u8fdb\u884c\u653b\u51fb\u3002</p> <p>\u56fe\u8868\u663e\u793a\uff0c \\(f_6\\) \u7684\u6548\u679c\u662f\u6700\u597d\u7684\u3002</p> <p>\u6700\u540e\u4f5c\u8005\u8ba8\u8bba\u4e86\u5bf9\u8303\u6570\u7684\u9009\u62e9\u3002\u5bf9\u4e8e \\(L_2\\) \u8303\u6570\u800c\u8a00\uff0c\u6ca1\u6709\u4ec0\u4e48\u7279\u522b\u7684\u95ee\u9898\uff0c\u76f4\u63a5\u4f18\u5316\u5c31\u884c\u4e86\uff0c\u53ea\u4e0d\u8fc7\u4f5c\u8005\u4ecb\u7ecd\u4e86\u968f\u673a\u542f\u52a8\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e2a\u6211\u4eec\u5728 PGD \u7684\u7b14\u8bb0\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\u8fc7\u4e86\u3002</p> <p>\\(L_0\\) \u8303\u6570\u6709\u70b9\u96be\u641e\u3002\\(L_0\\) \u8303\u6570\u7edf\u8ba1\u6709\u591a\u5c11\u50cf\u7d20\u88ab\u4fee\u6539\uff0c\u800c\u8fd9\u663e\u7136\u662f\u4e0d\u53ef\u5bfc\u7684\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u9009\u62e9\u4e86\u591a\u6b65\u8fed\u4ee3\u7684\u65b9\u6cd5\u8ba1\u7b97\u3002\u9996\u5148\u4f7f\u7528\u57fa\u4e8e \\(L_2\\) \u8303\u6570\u7684\u653b\u51fb\u5728\u53ef\u884c\u57df\u5185\u5f97\u5230\u5355\u6b65\u7684\u653b\u51fb\u56fe\u50cf\uff0c\u7136\u540e\u4ece\u53ef\u884c\u57df\u4e2d\u4e22\u5f03\u6270\u52a8\u4e0e\u68af\u5ea6\u4e4b\u79ef\uff08\\(\\delta\\cdot g\\)\uff09\u6700\u5c0f\u7684\u50cf\u7d20 \\(i\\)\uff0c\u76f4\u5230 \\(L_2\\) \u8303\u6570\u653b\u51fb\u65e0\u6cd5\u627e\u5230\u53ef\u884c\u89e3\u3002\u5bf9\u4e8e\u6700\u6709\u6548\u7684 \\(c\\) \u7684\u641c\u7d22\uff0c\u4f5c\u8005\u4ecd\u7136\u9009\u62e9\u4e86\u500d\u589e+\u4e8c\u5206\u7684\u641c\u7d22\u65b9\u5f0f\u3002</p> <p>\u6700\u540e\uff0c\u4f5c\u8005\u5b9e\u9a8c\u4e86\u57fa\u4e8e \\(L_\\infty\\) \u8303\u6570\u7684\u653b\u51fb\u3002\u6839\u636e\u6211\u4eec\u5148\u524d\u7684\u8ba8\u8bba\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u8303\u6570\u7684\u653b\u51fb\u5728\u6837\u672c\u4e0a\u4f1a\u663e\u793a\u4e3a\u201c\u5927\u8272\u5757\uff0c\u5c0f\u5dee\u5f02\u201d\u7684\u7279\u5f81\uff0c\u56e0\u800c\u6bd4\u8f83\u6709\u6548\u3002\u4f46\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u6270\u52a8\u91cf\u4e00\u76f4\u5728 \\(0.5\\) \u9644\u8fd1\u6b63\u8d1f\u6a2a\u8df3\uff08\u7b26\u53f7\u51fd\u6570\u662f\u5f88\u574f\u7684\u4f18\u5316\u76ee\u6807\uff0c\u56e0\u4e3a\u9664\u4e86\u96f6\u70b9\u9644\u8fd1\uff0c\u5176\u4ed6\u4f4d\u7f6e\u6ca1\u6709\u68af\u5ea6\u60e9\u7f5a\uff09</p> <p>\u4e3a\u6b64\u4f5c\u8005\u4f7f\u7528\u4e0b\u9762\u7684\u635f\u5931\u51fd\u6570\uff1a</p> <p></p> <p>\u5176\u4e2d \\(\\tau\\) \u521d\u59cb\u4e3a \\(1\\)\uff0c\u968f\u7740 \\(\\delta_i\\) \u7684\u53d8\u5c0f\uff0c\u76f4\u5230\u90fd\u5c0f\u4e8e \\(\\tau\\) \u4e4b\u540e\uff0c\u5c31\u81ea\u4e58 0.9 \u5b9e\u73b0\u8d8b\u4e8e 0 \u7684\u6307\u6570\u8870\u51cf\u3002\u5b9e\u8d28\u4e0a\u5c31\u662f\u901a\u8fc7\u8870\u51cf\u7684 \\(\\tau\\) \u6765\u6e10\u8fdb\u7b26\u53f7\u51fd\u6570\u7684\u7ea6\u675f\u3002\u5bf9 \\(c\\) \u7684\u9009\u62e9\u7c7b\u4f3c\u3002</p>"}, {"location": "DNN/model-attack/CandW/#_3", "title": "\u5bf9\u6297\u8bad\u7ec3", "text": "<p>\u4f5c\u8005\u5728\u5269\u4e0b\u7684\u7bc7\u5e45\u4e2d\u8bc1\u660e\u4e86\u5176\u63d0\u51fa\u7684 C&amp;W \u653b\u51fb\u8db3\u4ee5\u653b\u7834\u9632\u5fa1\u6027\u84b8\u998f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5bf9\u6297\u6837\u672c\u7684\u53ef\u8fc1\u79fb\u6027\u3002\u4e3a\u4e86\u5728\u53ef\u8fc1\u79fb\u7684\u60c5\u51b5\u4e0b\u7ee7\u7eed\u7834\u9632\uff0c\u6211\u4eec\u9700\u8981\u8ba9\u9884\u6d4b\u8f93\u51fa\u7684\u5dee\u5f02\u8db3\u591f\u5927\uff0c\u5927\u5230\u4e00\u4e2a\u6211\u4eec\u624b\u52a8\u8bbe\u5b9a\u7684 \\(\\kappa\\) \u503c\uff1a</p> \\[ f (x') = \\max(\\max\\{Z(x'_t) : i \\ne t\\} \u2212 Z(x_i'), \u2212\u03ba) \\] <p>\u5b9e\u9a8c\u8868\u660e\u8fd9\u4e2a\u503c\u8d8a\u5927\u7834\u7532\u7684\u6548\u679c\u8d8a\u597d\uff1a</p> <p></p> <p>\u4e0d\u77e5\u9053\u641e\u51fa\u9632\u5fa1\u6027\u84b8\u998f\u7684\u4f5c\u8005\u4eec\u6709\u6ca1\u6709\u7834\u9632\uff0c\u53cd\u6b63\u9632\u5fa1\u6027\u84b8\u998f\u8fd9\u4e2a\u65b9\u6cd5\u662f\u786e\u786e\u5b9e\u5b9e\u5730\u7834\u9632\u4e86\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 24, 2025). C&amp;W \u653b\u51fb [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-attack/CandW</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{CandW,\n    title={C&amp;W \u653b\u51fb},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-attack/CandW}},\n}\n</code></pre></p>"}, {"location": "DNN/model-attack/fgsm/", "title": "FGSM \u653b\u51fb", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 15 \u5206\u949f\u3000|\u3000\u7ea6 1933 \u5b57\u3000|\u3000\u7ea6 35 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 267 \u884c\u4ee3\u7801</p> <p>\u6587\u7ae0 \u53d1\u8868\u5728 ICLR 2015\uff0c\u4f5c\u8005\u662f GAN \u7684\u63d0\u51fa\u8005 Ian Goodfellow\u3002</p> <p>\u672c\u6587\u7684\u884c\u6587\u601d\u8def\u80af\u5b9a\u548c\u539f\u8bba\u6587\u4e0d\u4e00\u6837\uff0c\u8981\u4e0d\u7136\u767d\u5199\u4e86\u2026\u2026\u800c\u4e14\u6211\u89c9\u5f97\u539f\u8bba\u6587\u86ee\u50cf\u90a3\u79cd\u77e5\u4e4e\u4e13\u680f\u6587\u7ae0\uff0c\u633a\u597d\u8bfb\u7684\uff0c\u4ee5\u524d\u7684 ICLR \u8fd9\u4e48\u597d\u53d1\u5417\ud83d\ude31\ud83d\ude31\ud83d\ude31</p>"}, {"location": "DNN/model-attack/fgsm/#_1", "title": "\u653b\u51fb\u65b9\u5f0f", "text": "<p>FGSM \u653b\u51fb\u662f\u4e00\u79cd\u767d\u76d2\u653b\u51fb\uff0c\u5fc5\u987b\u62ff\u5230\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u68af\u5ea6\uff0c\u4e5f\u5c31\u662f</p> \\[ g_x=\\nabla_x \\mathcal L(\\theta;x,y) \\] <p>\u8fd9\u91cc\u5f88\u5fae\u5999\u7684\u4e00\u70b9\u662f\uff0c\u5728\u4f18\u5316\u5668\u9886\u57df\uff0c\u6211\u4eec\u662f\u57fa\u4e8e\u8ba1\u7b97</p> \\[ g_\\theta=\\nabla_\\theta \\mathcal L(\\theta;x,y) \\] <p>\u6765\u5b9e\u73b0\u5bf9\u53c2\u6570\u7684\u5feb\u901f\u66f4\u65b0\u7684\u3002\u8fd9\u91cc\u7684\u201c\u5feb\u901f\u201d\u610f\u5373\u5229\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fed\u4ee3\u6b21\u6570\u5f97\u5230\u5c3d\u53ef\u80fd\u5c0f\u7684\u635f\u5931\uff0c\u5373\u8ba9\u6a21\u578b\u53c2\u6570 \\(\\theta\\) \u5728\u56fa\u5b9a\u7684\u8f93\u5165 \\(x\\) \u6784\u5efa\u7684\u635f\u5931\u5730\u5f62\u4e0a\u5b9e\u73b0\u5feb\u901f\u4e0b\u964d\u3002</p> <p>FGSM \u4e5f\u662f\u7c7b\u4f3c\uff0c\u4e0d\u8fc7\u6b64\u65f6\u6211\u4eec\u9762\u5bf9\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\uff08\u56fa\u5b9a\u7684\uff09\u6a21\u578b \\(\\theta\\)\uff0c\u9700\u8981\u6784\u5efa \\(x\\) \u6765\u66f4\u6539\u8f93\u51fa\u3002\u6b64\u65f6\u6211\u4eec\u7684\u76ee\u6807\u662f\u5229\u7528\u5c3d\u53ef\u80fd\u5c11\u7684\u8fed\u4ee3\u6b21\u6570\u5f97\u5230\u5c3d\u53ef\u80fd\u5927\u7684\u635f\u5931\u3002\u5f53\u7136\u8fed\u4ee3\u6cd5\u4f1a\u5728\u540e\u9762\u4ecb\u7ecd\uff0cFGSM \u4f5c\u4e3a\u4e00\u79cd\u53e4\u8001\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u662f\u5355\u6b65\u7684\u3002</p> <p>\u4e00\u4e2a\u76f8\u5f53\u6734\u7d20\u7684\u601d\u8def\u662f\uff0c\u6211\u4eec\u5728\u5355\u6b65\u5185\u76f4\u63a5\u9009\u53d6\u68af\u5ea6\u53d8\u5316\u6700\u5927\u7684\u90a3\u4e2a\u65b9\u5411\u8fdb\u884c\u4e0a\u5347\uff0c\u4e5f\u5c31\u662f\uff1a</p> \\[ \\tilde x_{L_2}=x+\\epsilon g_x \\] <p>\u8fd9\u91cc\u7684 \\(\\epsilon\\) \u53ef\u4ee5\u7c7b\u6bd4\u4e8e\u5b66\u4e60\u7387\u3002</p> <p>\u5982\u679c\u5bf9\u73b0\u4ee3\u4f18\u5316\u5668\u7406\u8bba\u6bd4\u8f83\u719f\u6089\u7684\u8bdd\uff0c\u53ef\u80fd\u4f1a\u8003\u8651 Adam \u4f18\u5316\u5668\u5bf9\u5e94\u7684 signSGD\uff0c\u6216\u8005\u662f Muon \u7684 \\(\\mathrm{msign}(M)=UV^\\top\\)\uff0c\u4f46\u5b83\u4eec\u66f4\u591a\u4f9d\u8d56\u4e8e\u66f4\u5e7f\u9614\u7684\u635f\u5931\u5730\u5f62\u89c6\u91ce\uff0c\u6216\u8bb8\u5728\u5355\u6b65\u4e0b\u6ca1\u90a3\u4e48\u6709\u6548\uff1f\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u5bf9\u68af\u5ea6\u5176\u5b9e\u6709\u4e09\u79cd\u6bd4\u8f83\u7ecf\u5178\u7684\u7ea6\u675f\u5f62\u5f0f\uff1a</p> \\[ \\begin{align*}     \\tilde x_{L_2}&amp;=x+\\epsilon g_x/\\|g_x\\|\\\\     \\tilde x_{L_\\infty}&amp;=x+\\epsilon \\mathrm{sign}(g_x)\\\\     \\tilde x_{L_\\mathrm{spec}}&amp;=x+\\epsilon \\mathrm{msign}(g_x) \\end{align*} \\] <p>\u8fd9\u91cc\u9009\u62e9 \\(L_2\\) \u8303\u6570\u4f5c\u4e3a\u7ea6\u675f\u53ea\u662f\u56e0\u4e3a\u6bd4\u8f83\u201c\u7ecf\u5178\u201d\uff0c\u5176\u5b9e\u4e5f\u53ef\u4ee5\u62ff\u7740 \\(L_p\\) \u8303\u6570\u6765\u8bf4\u4e8b\u7684\u3002</p> <p>\u6211\u4e2a\u4eba\u66f4\u503e\u5411\u4e8e\u628a\u5b83\u4eec\u53eb\u505a\u4e0d\u540c\u8303\u6570\u7ea6\u675f\u4e0b\u7684 FGSM \u653b\u51fb\uff0c\u5c3d\u7ba1 FGSM \u5168\u79f0\u662f Fast Gradient Sign Method\u2026\u2026</p> <p>\u5230\u5e95\u9009\u62e9\u54ea\u4e2a\u8303\u6570\u8fdb\u884c\u7ea6\u675f\uff0c\u6211\u4eec\u653e\u5728\u540e\u9762\u8bb2\u3002\u4e0b\u9762\u4e00\u8282\u6211\u4eec\u6765\u804a\u804a\u8fd9\u4e00\u653b\u51fb\u65b9\u5f0f\u7684\u53e6\u5916\u4e00\u79cd\u770b\u5f85\u89c6\u89d2\u3002</p>"}, {"location": "DNN/model-attack/fgsm/#_2", "title": "\u7ebf\u6027\u89d2\u5ea6", "text": "<p>\u8fd9\u4e2a\u89c6\u89d2\u662f\u539f\u8bba\u6587\u7684\u7b2c\u4e09\u8282\u7ed9\u51fa\u6765\u7684\u3002\u7531\u4e8e\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u77e9\u9635\u4e58\u6cd5\uff0c\u56e0\u6b64\u8003\u8651\u77e9\u9635\u67d0\u4e00\u5217 \\(w^\\top\\) \u548c\u6270\u52a8\u540e\u7684\u8f93\u5165 \\(\\tilde x=x+\\eta\\) \u76f8\u4e58\uff1a</p> \\[ w^\\top\\tilde x=w^\\top x+w^\\top\\eta \\] <p>\u90a3\u4f60\u95ee\u6211 \\(\\eta\\) \u53d6\u54ea\u4e2a\u65b9\u5411\u53ef\u4ee5\u4f7f\u5f97\u6270\u52a8\u9879\u6700\u5927\u5316\u5462\uff1f\u8fd9\u4e0d\u5c31\u662f\u9ad8\u4e2d\u5927\u5bb6\u90fd\u5b66\u8fc7\u7684\u67ef\u897f\u4e0d\u7b49\u5f0f\u561b\u2014\u2014\u5982\u679c\u6270\u52a8\u9879\u548c \\(w\\) \u201c\u5e73\u884c\u201d\u7684\u65f6\u5019\u80fd\u591f\u6700\u5927\u5316\u3002</p> <p>\u8fd9\u91cc\u7684\u5e73\u884c\u8981\u6253\u5f15\u53f7\uff0c\u56e0\u4e3a\u4e25\u683c\u610f\u4e49\u4e0a\u8bf4\u5b83\u7684\u610f\u601d\u662f\u8981\u8ba9\u4e0b\u9762\u7684\u7b49\u53f7\u53d6\u5230\uff1a</p> \\[ |\\langle u,v\\rangle|\\le\\|u\\|\\cdot\\|v\\| \\] <p>\u800c\u4e0d\u540c\u7684\u5185\u79ef\u53c8\u4e3a\u7a7a\u95f4\u8d4b\u4e88\u4e86\u4e0d\u540c\u7684\u8303\u6570\u3002</p> <p>\u597d\uff0c\u6211\u4eec\u4f3c\u4e4e\u5c31\u53ef\u4ee5\u5f97\u5230\uff1a\u53d6\u77e9\u9635\u5143\u7d20\u4e58\u4ee5 \\(\\epsilon\\)\uff0c\u7136\u540e\u8003\u8651\u4e00\u4e0b\u5185\u79ef\u7ea6\u675f\uff0c\u5c31\u53ef\u4ee5\u4e86\u2026\u2026\u5bf9\u5417\uff1f</p> <p>\u5927\u9519\u7279\u9519\uff01\u8c01\u544a\u8bc9\u4f60\uff0c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5c31\u662f\u7ebf\u6027\u7684\u77e9\u9635\u4e58\u6cd5\u7684\uff1f\uff01</p> <p>\u6b63\u662f\u5f15\u5165\u4e86\u975e\u7ebf\u6027\uff0c\u795e\u7ecf\u7f51\u7edc\u624d\u5177\u6709\u4e30\u5bcc\u7684\u62df\u5408\u80fd\u529b\u54e6\u3002</p> <p>\u4e8b\u5b9e\u4e0a\uff0c\u539f\u8bba\u6587\u8fd9\u4e00\u6bb5\u7684\u610f\u601d\u662f\uff0c\u5982\u679c\u795e\u7ecf\u7f51\u7edc\u5728\u6837\u672c\u9644\u8fd1\u8fd1\u4f3c\u7ebf\u6027\uff0c\u90a3\u4e48\u5b83\u53ef\u4ee5\u88ab\u76f8\u5f53\u9ad8\u6548\u5730\u6270\u52a8\uff01</p> <p>\u4e3a\u4ec0\u4e48\u5462\uff1f\u6211\u4eec\u6765\u4f30\u7b97\u4e00\u4e0b \\(w^\\top\\eta\\)\u3002\u5047\u5b9a \\(w\\sim\\mathcal{N}(0,I_n)\\)\uff0c\\(\\eta=\\epsilon w\\)\uff0c\u90a3\u4e48\u8fd9\u4e2a\u70b9\u4e58\u7684\u7ed3\u679c\u5c31\u662f \\(\\epsilon n\\mathrm{Var}[w_i]=\\epsilon n\\)\uff0c\u4e5f\u5c31\u662f\u8bf4\u7ef4\u5ea6\u8d8a\u9ad8\uff0c\u5373\u4f7f\u4fdd\u6301\u4e00\u4e2a\u6bd4\u8f83\u5c0f\u7684 \\(\\epsilon\\)\uff0c\u4e5f\u53ef\u4ee5\u79ef\u7d2f\u8d77\u5f88\u5927\u7684\u6270\u52a8\u3002</p> <p>\u539f\u8bba\u6587\u8fd9\u4e00\u8282\u91cc\u9762\u662f\u8fd9\u6837\u8bf4\u660e\u7684\uff1a</p> <p>If \\(w\\) has \\(n\\) dimensions and the average magnitude of an element of the weight vector is \\(m\\), then the activation will grow by \\(\\epsilon mn\\).</p> <p>\u8fd9\u91cc\u662f\u62ff \\(\\eta=\\mathrm{sign}(w)\\) \u7b97\u7684\uff0c\u4f46\u662f\u6309\u7406\u8bf4\u4e00\u4e2a\u964d\u7ef4\u6620\u5c04\u7684\u4e2d\u95f4\u5c42\uff0c\u5176\u53c2\u6570\u5927\u5c0f\u5206\u5e03\u7406\u5e94\u8fd1\u4f3c\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\uff0c\u8fd9\u91cc\u53d6\u7b26\u53f7\u51fd\u6570\u76f8\u5f53\u4e8e\u628a\u8fd9\u4e2a\u6270\u52a8\u9879\u5168\u90fd\u53d8\u6210\u6b63\u503c\uff0c\u4e5f\u5c31\u662f\u5355\u7b97\u5927\u4e8e 0 \u7684\u90e8\u5206\u7684\u5747\u503c\u3002\u56e0\u6b64\u8fd9\u91cc\u7684 \"average magnitude\" \u8fd8\u4e0d\u80fd\u7406\u89e3\u6210\u5747\u503c\u800c\u662f\u7edd\u5bf9\u503c\u7684\u5747\u503c\u2026\u2026</p> <p>\u8fd9\u4e5f\u5c31\u5bfc\u81f4\u4e86\u57fa\u4e8e ReLU \u7684\u6d45\u5c42\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u5bb9\u6613\u88ab\u653b\u51fb\uff0c\u800c\u57fa\u4e8e sigmoid \u7684\u795e\u7ecf\u7f51\u7edc\u5462\uff1f\u563f\u563f\u60f3\u9003\u662f\u9003\u4e0d\u6389\u7684\u2014\u2014\u4e3a\u4e86\u9632\u6b62\u68af\u5ea6\u6d88\u5931\uff0c\u4f60\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u8981\u628a\u6743\u91cd\u538b\u5230 0 \u9644\u8fd1\uff0c\u8fd9\u6b63\u662f sigmoid \u8fd1\u4f3c\u7ebf\u6027\u7684\u5730\u65b9\u3002</p> <p>\u5728\u8fd9\u91cc\u6302\u4e00\u4e0b\u4eba\uff1a</p> <p></p> <p>\u8fd9\u4e2a\u5c31\u7b80\u76f4\u662f\u8bef\u4eba\u5b50\u5f1f\u4e86\u3002\u4e00\u4e0a\u6765\u201c\u4ee4\u03b7=\u03b5\u22c5sign(\u03c9)\u4ece\u800c\u5c06\u5e72\u6270\u6700\u5927\u5316\u201d \u5b8c\u5168\u5c31\u662f\u9519\u7684\uff0c\u539f\u6587\u7684 \"the max norm constraint\" \u8fd9\u4e2a\u524d\u63d0\u662f\u4e00\u70b9\u4e0d\u63d0\u554a\u3002\u51b3\u5b9a\u5e72\u6270\u6700\u5927\u5316\u7684\u53ea\u80fd\u662f\u67ef\u897f\u4e0d\u7b49\u5f0f\u3002\u5e76\u4e14\u628a average magnitude \u7406\u89e3\u6210\u5e73\u5747\u503c\u66f4\u662f\u80a4\u6d45\u3002\u6211\u90fd\u6000\u7591\u8fd9\u5e2e\u5b50\u4eba\u5230\u5e95\u6709\u6ca1\u6709\u8ba4\u771f\u63a8\u8fc7\u516c\u5f0f\u597d\u597d\u60f3\u60f3\u8fd9\u4e2a\u7b26\u53f7\u51fd\u6570\u600e\u4e48\u6765\u7684\u2026\u2026</p>"}, {"location": "DNN/model-attack/fgsm/#_3", "title": "\u8303\u6570\u9009\u62e9", "text": "<p>\u8fd9\u4e00\u8282\u6211\u4eec\u6765\u8ba8\u8bba\u4e00\u4e0b\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u65b9\u6cd5\u53eb FGSM \u800c\u4e0d\u662f FGM \u6216\u8005\u5176\u4ed6\uff0c\u4e5f\u5c31\u662f\u4e3a\u4ec0\u4e48\u539f\u4f5c\u8005\u8981\u9009\u62e9\u4f7f\u7528\u7b26\u53f7\u51fd\u6570\u3002</p> <p>\u8fd9\u91cc\u6211\u5728 MNIST \u4e0a\u8bad\u7ec3\u4e86\u4e00\u4e2a LeNet \u6765\u53ef\u89c6\u5316\u4e00\u4e0b\u3002\uff08\u539f\u8bba\u6587\u8fd8\u4f7f\u7528\u4e86\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u5982 CIFAR-10 \u548c ImageNet \u7b49\uff0c\u6211\u8fd9\u8fb9\u4e3a\u4e86\u65b9\u4fbf\u5c31\u76f4\u63a5\u5728\u7b14\u8bb0\u672c\u4e0a\u9762\u8dd1\u54af\uff09</p> <p>\u8bad\u7ec3\u7684\u53c2\u6570\u662f\uff1a\u5b66\u4e60\u7387 5e-4 \u8dd1 5 \u4e2a epoch\uff0c\u65e0\u4efb\u4f55\u6570\u636e\u589e\u5f3a\uff0c\u8bad\u7ec3\u96c6\u51c6\u786e\u7387 0.9756\uff0c\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387 0.9775\u3002</p> <p>\u5982\u4e0b\uff0c\u662f\u4f7f\u7528 \\(L_\\infty\\) \u8303\u6570\u7ea6\u675f\u7684\u7ed3\u679c\uff1a</p> <p></p> <p>\\(L_2\\) \u8303\u6570\uff1a</p> <p></p> <p>\u8c31\u8303\u6570\uff1a</p> <p></p> <p>\u8ba9\u6211\u4eec\u628a\u76ee\u5149\u805a\u7126\u5728\u6700\u4e0b\u9762\u4e00\u5217\uff0c\u53ef\u89c1 \\(L_2\\) \u8303\u6570\u4e3b\u8981\u662f\u5bf9\u6837\u672c\u8fb9\u7f18\u6dfb\u52a0\u4e00\u5768\u4e0d\u53ef\u540d\u72b6\u7684\u7b14\u89e6\uff0c\u8c31\u8303\u6570\u5f15\u5165\u7684\u6270\u52a8\u51e0\u4e4e\u4fb5\u8680\u4e86\u6574\u5e45\u56fe\u50cf\uff0c\u800c \\(L_\\infty\\) \u7684\u6548\u679c\u662f\u6700\u597d\u7684\uff0c\u53ea\u662f\u5f15\u5165\u4e86\u5927\u5e45\u5ea6\u7684\u7070\u8272\u8272\u5757\uff0c\u539f\u59cb\u7684\u6570\u5b57\u5b8c\u5168\u53ef\u4ee5\u88ab\u4eba\u7c7b\u8fa8\u8ba4\u800c\u6a21\u578b\u51e0\u4e4e\u5b8c\u5168\u5931\u6548\u3002</p> <p>\u4e8b\u5b9e\u4e0a\u7684\u786e\uff0c\u65e0\u7a77\u8303\u6570\u662f\u8fd9\u51e0\u4e2a\u91cc\u9762\u6700\u9002\u5408\u5355\u6b65\u653b\u51fb\u7684\u3002\u6211\u4eec\u600e\u4e48\u5728\u7406\u8bba\u4e0a\u7406\u89e3\u5462\uff1f\u539f\u8bba\u6587\u6ca1\u6709\u89e3\u91ca\uff0c\u5728\u8fd9\u91cc\u6597\u80c6\u7ed9\u51fa\u6211\u7684\u7406\u89e3\uff1a\u53ef\u4ee5\u770b\u5230\u4e3a\u4e86\u8fbe\u5230\u76f8\u8fd1\u7684\u653b\u51fb\u6548\u679c\uff0c\\(L_2\\) \u8303\u6570\u548c\u8c31\u8303\u6570\u7684 \\(\\epsilon\\) \u90fd\u8981\u5f00\u7279\u522b\u5927\uff0c\u56e0\u4e3a\u5bf9\u5e94\u7684\u4e00\u5c0f\u90e8\u5206\u7684\u50cf\u7d20\u8d21\u732e\u4e86\u8f83\u5927\u7684\u6270\u52a8\uff0c\u4f46\u662f\u56fe\u50cf\u7684\u8272\u9636\u662f\u6709\u4e0a\u9650\u7684\uff0c\u6270\u52a8\u5c01\u9876\u4e4b\u540e\uff0c\u5c31\u53ea\u597d\u8ba9\u5176\u4ed6\u8d21\u732e\u5c0f\u7684\u50cf\u7d20\u5f3a\u884c\u62c9\u5927\uff0c\u6700\u540e\u5bfc\u81f4\u5bf9\u539f\u56fe\u50cf\u7684\u7834\u574f\u76f8\u5f53\u5927\uff1b\u800c\u7b26\u53f7\u51fd\u6570\u53ef\u4ee5\u8ba9\u6240\u6709\u6709\u8d21\u732e\u7684\u50cf\u7d20\u90fd\u62c9\u5e73\u5230\u4e00\u4e2a\u6c34\u5e73\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u6211\u53ef\u4ee5\u8ba9\u51e0\u4e4e\u5168\u56fe\u7684\u50cf\u7d20\u90fd\u5bf9\u6270\u52a8\u9879\u8fdb\u884c\u8d21\u732e\u3002</p>"}, {"location": "DNN/model-attack/fgsm/#_4", "title": "\u201c\u5bf9\u6297\u6837\u672c\u201d\u548c\u201c\u5783\u573e\u6837\u672c\u201d", "text": "<p>\u5f88\u591a\u7f51\u4e0a\u7684\u535a\u5ba2\u5728\u524d\u9762\u5c31\u7ed3\u675f\u4e86\uff0c\u4e0d\u8fc7\u539f\u8bba\u6587\u7684\u8fd9\u4e00\u90e8\u5206\u8ba8\u8bba\u7684\u9644\u5f55\u8fd8\u662f\u5f88\u6709\u542f\u53d1\u6027\u7684\u3002</p> <p>\u7f18\u8d77\u662f\u67d0\u540c\u5b66 COS\u6210\u4e1c\u98ce\u8c37\u65e9\u82d7 \u5728\u4e00\u4e2a\u7ebf\u4e0a\u7684 MNIST \u5206\u7c7b\u5668\u4e0a\u9762\u753b\u4e86\u4e2a\u661f\u661f\uff0c\u7ed3\u679c\u8fd9\u4e2a\u5206\u7c7b\u5668\uff08\u5e94\u8be5\u4e5f\u662f LeNet \u4e4b\u7c7b\u7684\uff09\u715e\u6709\u4ecb\u4e8b\u5730\u4ee5\u4e00\u4e2a\u5f88\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u8ba4\u4e3a\u8fd9\u4e2a\u661f\u661f\u662f\u6570\u5b57 8\u3002</p> <p></p> <p>\uff08\u65e9\u82d7\u8bf7\u81ea\u884c\u60f3\u8c61\uff09</p> <p>\u539f\u8bba\u6587\u8ba4\u4e3a\u795e\u7ecf\u7f51\u7edc\u4e0d\u540c\u4e8e RBF \u7f51\u7edc\uff0c\u5b83\u4eec\u5206\u522b\u5728 P-R \u66f2\u7ebf\u7684\u4e24\u7aef\uff1a</p> <ul> <li>\u795e\u7ecf\u7f51\u7edc\uff0c\u5982 LeNet \u7b49\uff0c\u503e\u5411\u4e8e\u9ad8\u53ec\u56de\uff0c\u4f4e\u7cbe\u786e\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u5176\u9762\u5bf9\u661f\u661f\u8fd9\u79cd\u5b8c\u5168\u4e0d\u540c\u4e8e\u6570\u5b57\u7684\u201c\u5783\u573e\u6837\u672c\u201d\u800c\u8a00\uff0c\u4ecd\u7136\u4f1a\u4ee5\u4e00\u4e2a\u5f88\u9ad8\u7684\u7f6e\u4fe1\u5ea6\u6765\u8bd5\u56fe\u5206\u7c7b\u3002</li> <li>RBF \u7f51\u7edc\u503e\u5411\u4e8e\u4f4e\u53ec\u56de\uff0c\u9ad8\u7cbe\u786e\uff0c\u4e5f\u5c31\u662f\u66f4\u8c28\u614e\uff0c\u53ef\u80fd\u6709\u4e9b\u6570\u5b57\u6ca1\u6cd5\u5206\u7c7b\uff0c\u4f46\u662f\u5bf9\u4e8e\u975e\u6570\u5b57\u7684\u6837\u672c\uff0c\u4f1a\u575a\u5b9a\u5730\u7ed9\u51fa\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u6253\u5206\u3002</li> </ul> <p>\u539f\u8bba\u6587\u8ba4\u4e3a\uff0c\u6b63\u662f\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u5c40\u90e8\u7ebf\u6027\uff0c\u5bfc\u81f4\u4e86\u8fd9\u4e00\u503e\u5411\uff0c\u800c\u5728\u201c\u5783\u573e\u6837\u672c\u201d\u4e2d\u7cbe\u5fc3\u9009\u62e9\u7684\u90a3\u4e9b\u548c\u539f\u8f93\u5165\u76f8\u5dee\u65e0\u51e0\u7684\u201c\u5bf9\u6297\u6837\u672c\u201d\uff0c\u6210\u4e3a\u4e86\u5a01\u80c1\u5176\u51c6\u786e\u7387\u7684\u6bd2\u836f\u3002</p> <p>\u539f\u8bba\u6587\u8fd8\u57fa\u4e8e\u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\u7684\u539f\u7406\u5bf9\u7f51\u7edc\u8bad\u7ec3\u505a\u4e86\u6b63\u5219\u5316\uff0c\u5e76\u8868\u793a\u8fd9\u6bd4\u57fa\u4e8e Dropout \u7684\u6b63\u5219\u5316\u6548\u679c\u66f4\u597d\u3002</p>"}, {"location": "DNN/model-attack/fgsm/#_5", "title": "\u9644\u5f55", "text": "<p>\u53ef\u89c6\u5316\u4f7f\u7528\u7684\u4ee3\u7801\u5982\u4e0b\uff1a</p>  \u4ee3\u7801  <pre><code># -*- coding: utf-8 -*-\nimport time\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n# ========== Reproducibility ==========\ndef set_seed(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\nset_seed(0)\ndevice = torch.device(\"cpu\")\n\n# ========== Model: Small LeNet ==========\nclass LeNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)     # 28 -&gt; 24\n        self.pool = nn.MaxPool2d(2, 2)      # 24 -&gt; 12\n        self.conv2 = nn.Conv2d(6, 16, 5)    # 12 -&gt; 8\n        # 8 -&gt; 4 after pool\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)               # 12x12\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)               # 4x4\n        x = torch.flatten(x, 1)        # B x (16*4*4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)                # logits\n        return x\n\n# ========== Data ==========\ntransform = transforms.ToTensor()  # pixels in [0,1]\ntrain_set = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\ntest_set  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2, pin_memory=False)\ntest_loader  = DataLoader(test_set,  batch_size=256, shuffle=False, num_workers=2, pin_memory=False)\n\n# ========== Train / Eval ==========\ndef train(model, loader, epochs=5, lr=5e-4):\n    model.train()\n    opt = torch.optim.Adam(model.parameters(), lr=lr)\n    for ep in range(epochs):\n        total, correct, loss_sum = 0, 0, 0.0\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = F.cross_entropy(logits, y)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            loss_sum += loss.item() * x.size(0)\n            pred = logits.argmax(dim=1)\n            correct += (pred == y).sum().item()\n            total += x.size(0)\n        print(f\"Epoch {ep+1}/{epochs} - loss={loss_sum/total:.4f} acc={correct/total:.4f}\")\n\n@torch.no_grad()\ndef eval_clean_acc(model, loader):\n    model.eval()\n    total, correct = 0, 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        pred = logits.argmax(dim=1)\n        total += x.size(0)\n        correct += (pred == y).sum().item()\n    return correct / total\n\n# ========== Gradient + FGSM directions ==========\ndef grad_wrt_x(model, x, y):\n    model.eval()\n    x = x.clone().detach().to(device)\n    x.requires_grad_(True)\n    with torch.enable_grad():  # \u786e\u4fdd\u6784\u5efa\u8ba1\u7b97\u56fe\n        logits = model(x)\n        loss = F.cross_entropy(logits, y.to(device))\n        model.zero_grad(set_to_none=True)\n        loss.backward()\n        g = x.grad.detach()\n    return g, logits.detach()\n\ndef dir_linf(g):\n    return g.sign()\n\ndef dir_l2(g, eps=1e-12):\n    g_flat = g.view(g.size(0), -1)\n    g_norm = g_flat.norm(p=2, dim=1).view(-1, 1, 1, 1)\n    return g / (g_norm + eps)\n\ndef dir_spec(g):\n    # per-sample SVD on 28x28\n    B, C, H, W = g.shape\n    assert (C, H, W) == (1, 28, 28), \"This demo assumes MNIST 1x28x28\"\n    d = torch.zeros_like(g)\n    for i in range(B):\n        Gi = g[i, 0]\n        U, S, Vh = torch.linalg.svd(Gi, full_matrices=False)\n        d[i, 0] = U @ Vh\n    return d\n\ndef get_direction(method, g):\n    if method == \"linf\":\n        return dir_linf(g)\n    elif method == \"l2\":\n        return dir_l2(g)\n    elif method == \"spec\":\n        return dir_spec(g)\n    else:\n        raise ValueError(\"Unknown method\")\n\n# ========== Attack evaluation over a loader for a list of eps ==========\n@torch.no_grad()\ndef eval_attack_grid(model, loader, method, eps_list):\n    \"\"\"\n    Returns dict with per-eps: acc, mean_maxprob, mean_trueprob, time_sec\n    \"\"\"\n    model.eval()\n    eps_list = list(eps_list)\n    K = len(eps_list)\n    total = 0\n    correct = [0 for _ in range(K)]\n    sum_maxprob = [0.0 for _ in range(K)]\n    sum_trueprob = [0.0 for _ in range(K)]\n    times = [0.0 for _ in range(K)]\n\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        # get gradient once per batch\n        torch.set_grad_enabled(True)\n        g, _ = grad_wrt_x(model, x, y)\n        d = get_direction(method, g)\n        torch.set_grad_enabled(False)\n\n        for j, eps in enumerate(eps_list):\n            t0 = time.perf_counter()\n            x_adv = torch.clamp(x + eps * d, 0.0, 1.0)\n            logits = model(x_adv)\n            probs = logits.softmax(dim=1)\n            pred = probs.argmax(dim=1)\n\n            correct[j] += (pred == y).sum().item()\n            sum_maxprob[j] += probs.max(dim=1).values.sum().item()\n            sum_trueprob[j] += probs[torch.arange(y.size(0)), y].sum().item()\n            times[j] += (time.perf_counter() - t0)\n\n        total += x.size(0)\n\n    out = []\n    for j, eps in enumerate(eps_list):\n        out.append({\n            \"eps\": float(eps),\n            \"acc\": correct[j] / total,\n            \"mean_maxprob\": sum_maxprob[j] / total,\n            \"mean_trueprob\": sum_trueprob[j] / total,\n            \"time_sec\": times[j],\n            \"n_total\": total\n        })\n    return out\n\n# ========== Fixed sample picker ==========\n@torch.no_grad()\ndef pick_fixed_samples(model, dataset, k=6, seed=0):\n    \"\"\"\n    Pick k correctly-classified test samples with fixed seed; returns indices list.\n    \"\"\"\n    set_seed(seed)\n    idxs = list(range(len(dataset)))\n    random.shuffle(idxs)\n    chosen = []\n    for idx in idxs:\n        x, y = dataset[idx]\n        x_in = x.unsqueeze(0).to(device)\n        logits = model(x_in)\n        pred = logits.argmax(dim=1).item()\n        if pred == y:\n            chosen.append(idx)\n        if len(chosen) &gt;= k:\n            break\n    return chosen\n\n# ========== Build visualization figure per method ==========\n@torch.no_grad()\ndef visualize_method(\n    model, dataset, method, eps_list, fixed_indices,\n    train_stats, test_stats, figsize_scale=2.0\n):\n    \"\"\"\n    Build a big figure:\n      rows = len(eps_list)\n      cols = len(fixed_indices) + 1 (last col is metrics summary)\n    Each cell (sample) shows x_adv at the given eps; last col shows train/test acc, conf, time.\n    \"\"\"\n    k = len(fixed_indices)\n    R = len(eps_list)\n    C = k + 1\n    fig_w = max(8, int(figsize_scale * C))\n    fig_h = max(4, int(figsize_scale * R))\n    fig, axes = plt.subplots(R, C, figsize=(fig_w, fig_h))\n    if R == 1:\n        axes = np.expand_dims(axes, axis=0)\n    if C == 1:\n        axes = np.expand_dims(axes, axis=1)\n\n    # Header titles (top row)\n    for j, idx in enumerate(fixed_indices):\n        x0, y0 = dataset[idx]\n        # show clean label in column title\n        axes[0, j].set_title(f\"Sample {j+1}\\nidx={idx}, true={y0}\", fontsize=9)\n\n    axes[0, -1].set_title(\"Summary (train/test acc, conf, time)\", fontsize=9)\n\n    # For each eps row\n    for r, eps in enumerate(eps_list):\n        # Left side: adversarial images for fixed samples\n        for c, idx in enumerate(fixed_indices):\n            x0, y0 = dataset[idx]\n            x = x0.unsqueeze(0).to(device)\n            y = torch.tensor([y0], dtype=torch.long).to(device)\n            # grad &amp; direction for this single sample\n            g, _ = grad_wrt_x(model, x, y)\n            d = get_direction(method, g)\n            x_adv = torch.clamp(x + eps * d, 0.0, 1.0)\n            logits = model(x_adv)\n            probs = logits.softmax(dim=1)\n            conf, pred = probs.max(dim=1)\n            ax = axes[r, c]\n            ax.imshow(x_adv[0, 0].cpu(), cmap=\"gray\", vmin=0, vmax=1)\n            ax.set_xticks([]); ax.set_yticks([])\n            ax.set_xlabel(f\"\u03b5={eps:.3f}\\n{pred.item()} ({conf.item()*100:.1f}%)\", fontsize=8)\n\n        # Rightmost summary cell\n        ax_sum = axes[r, -1]\n        ax_sum.axis(\"off\")\n        tr = train_stats[r]; te = test_stats[r]\n        text = (\n            f\"Norm={method.upper()} | \u03b5={eps:.3f}\\n\"\n            f\"Train acc: {tr['acc']*100:.2f}%  (N={tr['n_total']})\\n\"\n            f\"Test  acc: {te['acc']*100:.2f}%  (N={te['n_total']})\\n\"\n            f\"Test mean max prob: {te['mean_maxprob']*100:.1f}%\\n\"\n            f\"Time (train/test): {tr['time_sec']:.2f}s / {te['time_sec']:.2f}s\"\n        )\n        ax_sum.text(0.02, 0.5, text, va=\"center\", ha=\"left\", fontsize=9, family=\"monospace\")\n\n    fig.suptitle(f\"FGSM under {method.upper()} norm | rows: eps, cols: fixed samples + summary\", fontsize=12)\n    fig.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.show()\n\n# ========== Main Pipeline ==========\nif __name__ == \"__main__\":\n    set_seed(0)\n    model = LeNet().to(device)\n\n    print(\"Training LeNet on MNIST (CPU)...\")\n    train(model, train_loader, epochs=5, lr=5e-4)\n\n    clean_train_acc = eval_clean_acc(model, train_loader)\n    clean_test_acc  = eval_clean_acc(model, test_loader)\n    print(f\"Clean acc - train={clean_train_acc:.4f}, test={clean_test_acc:.4f}\")\n\n    # ---- Define epsilon grids per norm ----\n    eps_grid = {\n        \"linf\": [0.05, 0.10, 0.20, 0.30],\n        \"l2\":   [0.50, 2.00, 3.00, 6.00],\n        \"spec\": [0.10, 0.60, 1.50, 2.20],\n    }\n\n    # ---- Pick fixed samples (from test set) ----\n    fixed_indices = pick_fixed_samples(model, test_set, k=6, seed=0)\n    print(\"Fixed sample indices (test set):\", fixed_indices)\n\n    # ---- For each norm: evaluate grid on train/test, then visualize ----\n    for method, eps_list in eps_grid.items():\n        print(f\"\\n=== Evaluating {method.upper()} with eps list: {eps_list} ===\")\n        train_stats = eval_attack_grid(model, train_loader, method, eps_list)\n        test_stats  = eval_attack_grid(model, test_loader,  method, eps_list)\n\n        # Console summary\n        print(\"eps | train_acc | test_acc | test_mean_max_prob | time_train(s) | time_test(s)\")\n        for tr, te in zip(train_stats, test_stats):\n            print(f\"{te['eps']:.3f} | {tr['acc']*100:8.2f}% | {te['acc']*100:7.2f}% | \"\n                  f\"{te['mean_maxprob']*100:7.2f}% | {tr['time_sec']:.2f} | {te['time_sec']:.2f}\")\n\n        # Visualization big figure\n        visualize_method(\n            model, test_set, method, eps_list, fixed_indices,\n            train_stats, test_stats, figsize_scale=2.0\n        )\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 23, 2025). FGSM \u653b\u51fb [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-attack/fgsm</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{fgsm,\n    title={FGSM \u653b\u51fb},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-attack/fgsm}},\n}\n</code></pre></p>"}, {"location": "DNN/model-attack/hsja/", "title": "HSJA \u653b\u51fb", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 21 \u5206\u949f\u3000|\u3000\u7ea6 2110 \u5b57\u3000|\u3000\u7ea6 109 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u6587\u7ae0 \u4f5c\u8005\u662f\u6765\u81ea\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u3002</p> <p>\u548c\u6211\u4eec\u4e4b\u524d\u505a\u7b14\u8bb0\u7684 FGSM, PGD, C&amp;W \u653b\u51fb\u4e0d\u4e00\u6837\uff0cHSJA \u653b\u51fb\u662f\u4e00\u79cd\u9ed1\u76d2\u653b\u51fb\u3002\u4f46\u5176\u5b9e\u672c\u8d28\u4e0a\u548c\u767d\u76d2\u653b\u51fb\u533a\u522b\u6ca1\u6709\u90a3\u4e48\u5927\u3002</p> <p>\u56de\u987e\u6211\u4eec\u4e4b\u524d\u5728 C&amp;W \u7684\u52a8\u673a\u89d2\u5ea6\u804a\u8fc7\u7684\uff0c\u4e00\u6b21\u7406\u60f3\u7684\u653b\u51fb\u9700\u8981\u8ffd\u6c42\u4e24\u4e2a\u62ee\u6297\u7684\u76ee\u6807\uff1a\u4f7f\u6a21\u578b\u51fa\u9519\uff08\u5206\u4e3a\u6709\u76ee\u6807\u548c\u65e0\u76ee\u6807\u653b\u51fb\uff09\u548c\u6270\u52a8\u5c3d\u53ef\u80fd\u5c0f\uff08\u8089\u773c\u96be\u4ee5\u53d1\u89c9\uff09\u3002\u4e3a\u6b64\u6211\u4eec\u5c06\u8fd9\u4e24\u4e2a\u6307\u6807\u91cf\u5316\uff0c\u7b2c\u4e00\u4e2a\u76ee\u6807\u7528 \\(f\\) \u51fd\u6570\u6307\u793a\uff0c\u7b2c\u4e8c\u4e2a\u76ee\u6807\u4f7f\u7528\u8303\u6570\u7ea6\u675f\u3002\u6700\u540e\u5229\u7528\u6a21\u578b\u7684\u68af\u5ea6\u4fe1\u606f\u8fdb\u884c\u4f18\u5316\u3002</p> <p>\u73b0\u5728\u6a21\u578b\u53d8\u6210\u9ed1\u76d2\u4e86\uff0c\u62ff\u4e0d\u5230\u68af\u5ea6\u4fe1\u606f\u4e86\uff0c\u548b\u529e\uff1f</p> <p>HSJA \u63d0\u51fa\u7684\u65b9\u6848\u662f\uff1a\u5148\u5728\u51b3\u7b56\u8fb9\u754c\u903c\u8fd1\u539f\u59cb\u56fe\u50cf\uff0c\u7136\u540e\u518d\u5229\u7528\u5206\u7c7b\u7ed3\u679c\u91cd\u6784\u68af\u5ea6\u4fe1\u606f\uff0c\u9010\u6b65\u8fed\u4ee3\u751f\u6210\u3002</p>"}, {"location": "DNN/model-attack/hsja/#_1", "title": "\u4e8c\u5206\u903c\u8fd1", "text": "<p>\u9996\u5148\u9700\u8981\u660e\u786e\u7684\u662f\uff0c\u5982\u679c\u6211\u4eec\u5bf9\u56fe\u50cf\u505a\u4efb\u4f55\u6270\u52a8\u4e4b\u540e\uff0c\u6807\u7b7e\u6ca1\u6709\u53d1\u751f\u4efb\u4f55\u6539\u53d8\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u6211\u4eec\u4e0d\u80fd\u4ece\u4e2d\u83b7\u53d6\u4efb\u4f55\uff08\u68af\u5ea6\uff09\u4fe1\u606f\u3002\u56e0\u6b64\u6211\u4eec\u9996\u5148\u9700\u8981\u505a\u7684\u662f\u628a\u56fe\u50cf\u79fb\u52a8\u5230\u51b3\u7b56\u8fb9\u754c\u3002</p> <p>\u5047\u8bbe\u6211\u4eec\u6709\u6e90\u56fe\u50cf \\(x^*\\)\uff0c\u76ee\u6807\u56fe\u50cf \\(x\\)\uff0c\u5176\u8f93\u51fa\u7b26\u5408\u6211\u4eec\u7684\u9700\u8981\u3002\u5982\u679c\u6211\u4eec\u8981\u8fdb\u884c\u6709\u76ee\u6807\u653b\u51fb\uff0c\u6211\u4eec\u5927\u53ef\u4ee5\u628a \\(x\\) \u8bbe\u7f6e\u4e3a\u6211\u4eec\u9700\u8981\u7684\u7c7b\u522b\u56fe\u50cf\uff1b\u5982\u679c\u662f\u65e0\u76ee\u6807\u653b\u51fb\uff0c\u6211\u4eec\u53ef\u4ee5\u500d\u589e\u52a0\u566a\u76f4\u5230\u83b7\u53d6\u5230\u4e00\u4e2a\u5dee\u5f02\u7684\u5206\u7c7b\u3002\u73b0\u5728\u6211\u4eec\u8981\u57fa\u4e8e\u8fd9\u4e24\u4e2a\u6837\u672c\u6765\u627e\u5230\u51b3\u7b56\u8fb9\u754c\u3002</p> <p>\u5f88\u81ea\u7136\u5730\uff0c\u6211\u4eec\u4f1a\u4f7f\u7528\u4e8c\u5206\u6cd5\u3002\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u6307\u6807\u51fd\u6570 \\(\\phi(x_t)\\)\uff0c\u4e3a \\(-1\\) \u4ee3\u8868\u5206\u4e3a\u539f\u7c7b\u522b\uff0c\u4e3a \\(1\\) \u4ee3\u8868\u5206\u4e3a\u76ee\u6807\u7c7b\u522b\u3002\u5bf9\u4e8e \\(\\alpha\\in (0,1)\\)\uff0c\u5b9a\u4e49</p> \\[ x(\\alpha)=\\alpha x+(1-\\alpha)x^* \\] <p>\u901a\u8fc7\u5bf9 \\(\\alpha\\) \u505a\u4e8c\u5206\u6cd5\uff08\u4e5f\u5c31\u662f\u5728 \\(L\\) \u8303\u6570\u4e0b\u6295\u5f71\u5230\u7ebf\u6bb5\u4e2d\u70b9\uff09\uff0c\u5c31\u53ef\u4ee5\u5728\u6ee1\u8db3 \\(L\\) \u8303\u6570\u7cbe\u5ea6\u5c0f\u4e8e\u9608\u503c \\(\\theta\\) \u5185\u627e\u5230\u521a\u521a\u597d\u4f7f\u5f97 \\(\\phi\\) \u6539\u53d8\u7684 \\(\\hat\\alpha\\)\u3002</p> <p>\u6211\u4eec\u5c06\u8fd9\u4e2a\u6d41\u7a0b\u62bd\u8c61\u6210\u4e00\u4e2a\u51fd\u6570\uff0c\u63a5\u53d7 \\(x,x^*,\\theta, L\\)\uff0c\u5206\u522b\u4ee3\u8868\u8f93\u5165\u56fe\u50cf\uff0c\u76ee\u6807\u56fe\u50cf\uff0c\u4f30\u8ba1\u7684\u51b3\u7b56\u8fb9\u754c\u5bbd\u5ea6\uff08\u4e5f\u5c31\u662f\u4e8c\u5206\u9608\u503c\uff09\u4ee5\u53ca\u7ea6\u675f\u7684\u8303\u6570\uff0c\u6700\u540e\u8f93\u51fa\u7684\u662f \\(\\hat x=x(\\hat\\alpha)\\)\uff0c\u548c\u8f93\u5165\u76ee\u6807\u6837\u672c\u7684\u5206\u7c7b\u4e00\u81f4\u4f46\u66f4\u9760\u8fd1\u51b3\u7b56\u8fb9\u754c\u3002</p>"}, {"location": "DNN/model-attack/hsja/#_2", "title": "\u4f30\u8ba1\u8fb9\u754c\u68af\u5ea6", "text": "<p>\u7c7b\u4f3c\u4e8e C&amp;W \u653b\u51fb\uff0c\u6211\u4eec\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u57fa\u4e8e\u51b3\u7b56\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u6700\u4f18\u5316\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\uff0c\u6765\u5b9e\u73b0\u6210\u529f\u7684\u653b\u51fb\u3002</p> <p>\u5bf9\u4e8e\u6709\u76ee\u6807 \\(c^\\dagger\\) \u7684\u653b\u51fb\uff0c\u6211\u4eec\u9700\u8981\u6700\u5927\u5316\u8fd9\u4e2a\u7c7b\u522b\u7684 logits \u800c\u6700\u5c0f\u5316\u5176\u4ed6\u7c7b\u522b\u7684 logits\uff1b\u5bf9\u4e8e\u65e0\u76ee\u6807 \\(c^*\\) \u7684\u653b\u51fb\uff0c\u6211\u4eec\u9700\u8981\u6700\u5927\u5316\u5176\u4ed6\u7c7b\u522b\u7684 logits \u800c\u6700\u5c0f\u5316\u8fd9\u4e2a\u7c7b\u522b\u7684 logits\u3002\u4e5f\u5c31\u662f\u539f\u6587\u7684\u5f0f (1)\uff1a</p> <p></p> <p>\u6211\u4eec\u7684\u76ee\u7684\u5c31\u662f\u5728 \\(S\\) \u4e0a\u505a\u68af\u5ea6\u4e0a\u5347\uff0c\u800c\u73b0\u5728\u7684\u95ee\u9898\u662f\uff0c\u6211\u4eec\u53ea\u6709\u6837\u672c\u7684\u5206\u7c7b\u4fe1\u606f\uff08\u4e5f\u5c31\u662f \\(\\phi\\) \u5c31\u662f \\(S\\) \u7684\u7b26\u53f7\u51fd\u6570\uff09\uff0c\u6211\u4eec\u9700\u8981\u57fa\u4e8e\u6b64\u4f30\u8ba1\u68af\u5ea6\u4fe1\u606f\u3002</p> <p>\u73b0\u5728\uff0c\u57fa\u4e8e\u4e8c\u5206\u6cd5\uff0c\u6211\u4eec\u6709\u4e86\u4e00\u4e2a\u5728\u8fb9\u754c\u7684\u6837\u672c \\(\\hat x\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u4e0a\u9762\u8fdb\u884c\u6270\u52a8\uff0c\u4e3a\u6b64\uff0c\u6211\u4eec\u9996\u5148\u751f\u6210\u4e00\u4e2a\u5728\u5355\u4f4d\u7403\u4e0a\u5747\u5300\u5206\u5e03\u7684\u6837\u672c\u96c6\u5408\uff08\u53ef\u4ee5\u901a\u8fc7\u6b63\u6001\u5206\u5e03\u6295\u5f71\u5230\u8d85\u7403\u9762\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u62d2\u7edd\u91c7\u6837\u7684 Marsaglia \u7b97\u6cd5\uff09\u5f97\u5230 \\(u_0, \\dots, u_B\\)\uff0c\u7136\u540e\u6211\u4eec\u8fdb\u884c\u6270\u52a8\uff0c\u4e5f\u5c31\u662f\u8ba1\u7b97</p> \\[ S_i = \\phi(x+\\delta u_i)=-1\\mathrm{\\ or\\ } 1 \\] <p>\u4e0b\u9762\u6211\u4eec\u8981\u57fa\u4e8e\u6b64\u6765\u4f30\u8ba1\u68af\u5ea6\u4e86\u3002\u9996\u5148\u8ba1\u7b97 \\(S_i\\) \u7684\u5747\u503c</p> \\[ \\bar S=\\dfrac{1}{B}\\sum_{i=1}^B S_i \\] <p>\u8fd9\u8868\u5f81\u6b64\u6837\u672c\u7684\u4e00\u4e2a\u57fa\u7ebf\u4f30\u8ba1\uff0c\u7136\u540e\u6211\u4eec\u8ba1\u7b97\u4f30\u8ba1\u7684\u68af\u5ea6\uff1a</p> \\[ \\hat g=\\dfrac{1}{B-1}\\sum_{i=1}^B(S_i-\\bar{S})u_i \\] <p>\u8fd9\u91cc\u7684 \\(B-1\\) \u5c31\u662f\u5229\u7528\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u867d\u7136\u6211\u89c9\u5f97\u7528\u5904\u4e0d\u5927\uff0c\u56e0\u4e3a\u6211\u4eec\u9a6c\u4e0a\u5c31\u8981\u5f52\u4e00\u5316\uff1a</p> \\[ v=\\mathrm{normalized}_L(\\hat g) \\]"}, {"location": "DNN/model-attack/hsja/#_3", "title": "\u8fed\u4ee3\u6c42\u89e3", "text": "<p>\u73b0\u5728\uff0c\u6211\u4eec\u5df2\u7ecf\u5728\u51b3\u7b56\u8fb9\u754c\u5904\u83b7\u5f97\u4e86\u4e00\u4e2a\u5019\u9009\u70b9 \\(\\hat x\\) \u4ee5\u53ca\u8be5\u70b9\u7684\u4f30\u8ba1\u68af\u5ea6\u65b9\u5411 \\(v\\)\uff0c\u4e0b\u9762\u6211\u4eec\u8981\u6839\u636e\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u8fed\u4ee3\u6c42\u89e3\u3002</p> <p>\u548c PGD \u7b49\u5176\u4ed6\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u7c7b\u4f3c\uff0c\u6211\u4eec\u4e5f\u8fdb\u884c\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7684\u68af\u5ea6\u662f\u6211\u4eec\u4f30\u8ba1\u7684\u68af\u5ea6 \\(v\\)\u3002\u56e0\u6b64\u73b0\u5728\u9009\u62e9\u4e00\u4e2a\u53c2\u6570 \\(\\xi\\) \u8ba1\u7b97</p> \\[ \\tilde{x}=\\hat x+\\xi v \\] <p>\u4f46\u662f\u6709\u53ef\u80fd\u7528\u529b\u8fc7\u731b\u98de\u51fa\u76ee\u6807\u6837\u672c\u7684\u51b3\u7b56\u8fb9\u754c\u4e86\u2026\u2026\u56e0\u6b64\u6211\u4eec\u8981\u6298\u534a \\(\\xi\\) \u4f7f\u5f97\u5176\u4fdd\u7559\u5728\u539f\u6709\u7684\u8fb9\u754c\u5185\u3002</p> <p>\u8fd9\u4e2a \\(\\tilde x\\) \u5c31\u662f\u76f8\u5bf9\u539f\u59cb\u7684\u76ee\u6807\u6837\u672c \\(x\\) \u66f4\u4f18\u7684\u76ee\u6807\u4e86\uff08\u56e0\u4e3a\u6211\u4eec\u6cbf\u7740\u68af\u5ea6\u7684\u65b9\u5411\u8d70\u4e86\u4e00\u6b65\uff09\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u6301\u7eed\u8fdb\u884c\u8fed\u4ee3\uff0c\u76f4\u5230\u8fbe\u5230\u6700\u5927\u7684\u6b21\u6570\u9650\u5236\u6216\u8005\u5df2\u7ecf\u6536\u655b\u800c\u4e0d\u518d\u53d8\u5316\u3002</p> <p>\u6700\u540e\uff0c\u4e3a\u4e86\u6211\u4eec\u53ef\u4ee5\u518d\u8fdb\u884c\u4e00\u6b21\u4e8c\u5206\u641c\u7d22\uff0c\u4f7f\u5f97\u8f93\u51fa \\(\\hat x\\) \u5728\u51b3\u7b56\u8fb9\u754c\u4e0a\uff0c\u800c\u66f4\u9760\u8fd1\u539f\u59cb\u6837\u672c \\(x^*\\)\u3002</p> <p>\u5176\u5b9e\u8fd9\u4e2a\u6709\u70b9\u7c7b\u4f3c\u4e8e EM \u7b97\u6cd5\u8fd9\u79cd\u4ea4\u66ff\u7684\u6d41\u7a0b\uff0c\u6216\u8005\u7c7b\u4f3c\u4e8e GAN \u7684\u8bad\u7ec3\u3002\u9996\u5148\u901a\u8fc7\u4e8c\u5206\u627e\u5230\u9760\u8fd1\u51b3\u7b56\u8fb9\u754c\u7684\u5bf9\u6297\u6837\u672c\u6765\u51cf\u5c11\u6270\u52a8\uff0c\u7136\u540e\u4f30\u8ba1\u68af\u5ea6\u6765\u4f18\u5316\u5bf9\u6297\u6837\u672c\u7684\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff0c\u5982\u6b64\u4ea4\u66ff\u8fdb\u884c\u3002</p>"}, {"location": "DNN/model-attack/hsja/#_4", "title": "\u53c2\u6570\u8bbe\u7f6e\u4e0e\u6536\u655b\u6027\u5206\u6790", "text": "<p>\u521a\u521a\u5bf9\u7b97\u6cd5\u53ea\u662f\u6a21\u7cca\u5730\u63d0\u70b9\u4e86\u4e00\u4e0b\uff0c\u4e0b\u9762\u6211\u4eec\u6765\u8be6\u7ec6\u8ba8\u8bba\u4e00\u4e0b\u521a\u521a\u7b97\u6cd5\u91cc\u9762\u63d0\u5230\u7684\u4e00\u5806\u53c2\u6570\u7684\u8bbe\u7f6e\uff0c\u8fd9\u51b3\u5b9a\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002</p> <p>\u9996\u5148\uff0c\u4f5c\u8005\u9488\u5bf9\u57fa\u4e8e\u68af\u5ea6\u7684\u4e00\u822c\u8fed\u4ee3\u8fc7\u7a0b\u7ed9\u51fa\u4e86\u5b9a\u7406\u4e00\uff1a</p> <p></p> <p>\u8fd9\u91cc \\(\\xi_t\\) \u5c31\u662f\u5f80\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\u7684\u6b65\u957f\uff0c\u79bb\u76ee\u6807\u8d8a\u8fd1\uff0c\u65f6\u95f4\u8d8a\u4e45\uff0c\u6b65\u957f\u8d8a\u5c0f\uff0c\u56e0\u6b64\u7528\u56fe\u4e2d\u7684\u5f0f\u5b50\u8fdb\u884c\u5efa\u6a21\uff0c\u6700\u540e\u53ef\u4ee5\u5f97\u5230\u6e90\u56fe\u50cf\u548c\u5bf9\u6297\u6837\u672c\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u53ef\u4ee5\u88ab bound \u8fdb\u8fd9\u4e2a\u8303\u56f4\u5185\uff0c\u4e3a\u4e86\u5c3d\u53ef\u80fd\u4f7f\u5f97\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5feb\u901f\u6536\u655b\uff0c\u9009\u62e9 \\(q=\\dfrac 12\\)\u3002\u4e8e\u662f\u5c31\u6709\u4e86\uff1a</p> \\[ \\xi_t = \\dfrac{\\|x_t-x^*\\|_p}{\\sqrt t} \\] <p>\u7d27\u63a5\u7740\uff0c\u4f5c\u8005\u53c8\u7ea6\u675f\u4e86\u4f30\u8ba1\u68af\u5ea6\u548c\u771f\u5b9e\u68af\u5ea6\u7684\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u5939\u89d2\u4f59\u5f26\u503c\u8861\u91cf\uff1a</p> <p></p> <p>\u7531\u6b64\uff0c\u4f5c\u8005\u8981\u63a8\u5bfc \\(\\delta\\) \u548c \\(\\theta\\) \u7684\u53d8\u5316\u5f0f\uff0c\u6211\u4eec\u5148\u6765\u611f\u6027\u7406\u89e3\u4e00\u4e0b\uff0c\\(\\delta\\) \u662f\u6270\u52a8\u7684\u63a2\u6d4b\u6b65\u957f\uff0c\u5f53\u6211\u4eec\u5f88\u63a5\u8fd1\u6e90\u56fe\u50cf\u65f6\uff0c\u5e94\u8be5\u66f4\u7cbe\u7ec6\u5730\u4f30\u8ba1\u68af\u5ea6\uff0c\u4e5f\u5c31\u662f\u540c\u6837\u5e26\u4e00\u4e2a \\(\\|x_t-x^*\\|_p\\) \u6765\u505a\u4fdd\u8bc1\u6536\u655b\u3002</p> <p>\u4e8b\u5b9e\u4e0a\uff0c\u4f5c\u8005\u8003\u8651\u4e86 \\(S_{x^*}(x_t+\\delta_t u)\\) \u5728 \\(x_t\\) \u5904\u7684\u6cf0\u52d2\u5c55\u5f00\uff0c\u53ea\u5bf9\u4e00\u9636\u9879\u91cc\u9762\uff0c\u5206\u4e3a\u539f\u7c7b\u522b\u7684\u7403\u51a0\u505a\u5206\u6790\uff0c\u6700\u540e\u5f97\u5230\u843d\u5165\u7403\u51a0\u7684\u6982\u7387\u548c \\(c\\) \u6709\u5173\uff0c\u5e76\u5f97\u5230\u4e86 \\(c\\) \u7684\u4f30\u8ba1\uff1a</p> <p></p> <p>\u4e3a\u4e86\u8ba9\u8fd1\u4f3c\u8bef\u5dee\u548c\u7ef4\u5ea6\u65e0\u5173\uff0c\u8fd9\u4e2a\u6982\u7387\u8981\u63a7\u5236\u5728 \\(\\mathcal O(1)\\) \u7684\u7ea7\u522b\uff0c\u7ed3\u5408\u4e0a\u5b9a\u7406 2 \u51fa\u73b0\u7684 \\((\\delta d)^2\\)\uff0c\u4f5c\u8005\u9009\u62e9</p> \\[ \\theta=d^{-q-1},\\quad \\delta_t=d^{-1}\\|x_t-x^*\\|_p \\] <p></p> <p>\u6700\u540e\uff0c\u57fa\u4e8e\u5b9a\u7406 3\uff0c\u53ef\u4ee5\u5f97\u5230\u68af\u5ea6\u4f30\u8ba1\u7684\u65b9\u5dee\u5927\u6982\u662f \\(\\mathcal{O}(B^{-2})\\)\uff0c\u56e0\u6b64\u4f5c\u8005\u9009\u62e9 \\(B_t=B_0\\sqrt t\\)\uff0c\u80fd\u591f\u4f7f\u5f97\u65b9\u5dee\u4ee5 \\(t^{-1}\\) \u7684\u9636\u4e0b\u964d\u3002</p>"}, {"location": "DNN/model-attack/hsja/#_5", "title": "\u6267\u884c\u6d41\u7a0b", "text": "<p>\u57fa\u672c\u4e0a\u8981\u70b9\u90fd\u7406\u6e05\u695a\u4e86\uff0c\u4e0b\u9762\u8ba9 LLM \u6574\u7406\u4e00\u4e0b\u6d41\u7a0b\u5427\uff1a</p>"}, {"location": "DNN/model-attack/hsja/#_6", "title": "\u521d\u59cb\u5316", "text": "<ul> <li>\u65e0\u76ee\u6807\u653b\u51fb\uff1a\u4ece\u539f\u59cb\u6837\u672c \\(x^*\\) \u5f00\u59cb\uff0c\u901a\u8fc7\u6dfb\u52a0\u5747\u5300\u968f\u673a\u566a\u58f0\u751f\u6210\u521d\u59cb\u6837\u672c \\(x_0\\) \uff0c\u4f7f\u5f97 \\(\\phi_{x^*}(x_0) = 1\\) \uff08\u5373\u6a21\u578b\u8bef\u5206\u7c7b\uff09\u3002</li> <li>\u6709\u76ee\u6807\u653b\u51fb\uff1a\u4ece\u6d4b\u8bd5\u96c6\u4e2d\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u5c5e\u4e8e\u76ee\u6807\u7c7b\u522b\u7684\u6837\u672c\u4f5c\u4e3a\u521d\u59cb\u70b9 \\(x_0\\) \uff0c\u4f7f\u5f97 \\(\\phi_{x^*}(x_0) = 1\\) \u3002</li> <li>\u8bbe\u7f6e\u521d\u59cb\u6279\u91cf\u5927\u5c0f \\(B = 100\\) \uff0c\u5e76\u968f\u8fed\u4ee3\u6b21\u6570 \\(t\\) \u4ee5 \\(\\sqrt{t}\\) \u901f\u7387\u589e\u52a0\uff0c\u4ee5\u964d\u4f4e\u65b9\u5dee\u3002</li> </ul>"}, {"location": "DNN/model-attack/hsja/#t-0-1-2-ldots", "title": "\u8fed\u4ee3\u8fc7\u7a0b\uff08\u5bf9\u4e8e\u6bcf\u4e2a\u8fed\u4ee3 \\(t = 0, 1, 2, \\ldots\\) \uff09", "text": "<p>\u76f4\u5230\u8fbe\u5230\u6700\u5927\u67e5\u8be2\u6b21\u6570 \\(T\\) \u6216\u6536\u655b\uff0c\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p>"}, {"location": "DNN/model-attack/hsja/#a-binary-search", "title": "\u6b65\u9aa4A: \u8fb9\u754c\u641c\u7d22\uff08Binary Search\uff09", "text": "<ul> <li>\u76ee\u7684\uff1a\u5c06\u5f53\u524d\u70b9 \\(x_t\\) \u7cbe\u786e\u5730\u6295\u5f71\u5230\u51b3\u7b56\u8fb9\u754c\u4e0a\uff0c\u786e\u4fdd \\(\\phi_{x^*}(x_t) = 1\\) \u3002</li> <li>\u4f7f\u7528\u7b97\u6cd51\uff08Bin-Search\uff09\uff1a</li> <li>\u8f93\u5165\uff1a\u5f53\u524d\u70b9 \\(x_t\\) \u548c\u539f\u59cb\u70b9 \\(x^*\\) \uff0c\u5176\u4e2d \\(\\phi_{x^*}(x_t) = 1\\) \uff0c \\(\\phi_{x^*}(x^*) = -1\\)\u3002</li> <li>\u8fc7\u7a0b\uff1a<ul> <li>\u8bbe\u7f6e \\(\\alpha_l = 0\\) \uff0c \\(\\alpha_u = 1\\) \u3002</li> <li>\u5f53 \\(|\\alpha_u - \\alpha_l| &gt; \\theta\\) \uff08\u9608\u503c\u8bbe\u4e3a \\(\\theta = d^{-q-1}\\) \uff0c\u5176\u4e2d \\(q = 1 - 1/p\\) \uff09\u65f6\uff1a</li> <li>\u8ba1\u7b97\u4e2d\u70b9 \\(\\alpha_m = (\\alpha_l + \\alpha_u)/2\\) \u3002</li> <li>\u8ba1\u7b97\u6295\u5f71\u70b9 \\(x_m = \\Pi_{x^*, \\alpha_m}(x_t)\\) \uff08\u6839\u636e\u8ddd\u79bb\u5ea6\u91cf\u9009\u62e9\u6295\u5f71\u65b9\u5f0f\uff09\u3002</li> <li>\u5982\u679c \\(\\phi_{x^*}(x_m) = 1\\) \uff0c\u5219\u66f4\u65b0 \\(\\alpha_u = \\alpha_m\\) \uff1b\u5426\u5219\u66f4\u65b0 \\(\\alpha_l = \\alpha_m\\) \u3002</li> <li>\u8f93\u51fa\u6295\u5f71\u70b9 \\(x_t' = \\Pi_{x^*, \\alpha_u}(x_t)\\) \uff0c\u4f5c\u4e3a\u65b0\u7684\u8fb9\u754c\u70b9\u3002</li> </ul> </li> </ul>"}, {"location": "DNN/model-attack/hsja/#b", "title": "\u6b65\u9aa4B: \u68af\u5ea6\u65b9\u5411\u4f30\u8ba1", "text": "<ul> <li>\u76ee\u7684\uff1a\u5728\u8fb9\u754c\u70b9 \\(x_t\\) \u5904\u4f30\u8ba1\u68af\u5ea6\u65b9\u5411 \\(\\nabla S_{x^*}(x_t)\\) \u3002</li> <li>\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\uff1a</li> <li>\u751f\u6210 \\(B\\) \u4e2a\u968f\u673a\u5411\u91cf \\(\\{u_b\\}_{b=1}^B\\) \uff0c\u670d\u4ece\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u5747\u5300\u5206\u5e03\u3002</li> <li> <p>\u8ba1\u7b97\u68af\u5ea6\u4f30\u8ba1\uff1a</p> \\[ \\widehat{\\nabla S}(x_t, \\delta_t) = \\frac{1}{B-1} \\sum_{b=1}^{B} \\left( \\phi_{x^*}(x_t + \\delta_t u_b) - \\overline{\\phi_{x^*}} \\right) u_b \\] <p>\u5176\u4e2d\uff0c \\(\\overline{\\phi_{x^*}} = \\frac{1}{B} \\sum_{b=1}^{B} \\phi_{x^*}(x_t + \\delta_t u_b)\\) \u662f\u57fa\u7ebf\uff0c\u7528\u4e8e\u51cf\u5c11\u65b9\u5dee\u3002   - \u6270\u52a8\u5927\u5c0f \\(\\delta_t\\) \u7684\u9009\u62e9\uff1a</p> \\[ \\delta_t = d^{-1} \\| \\tilde{x}_{t-1} - x^* \\|_p \\] <p>\u5176\u4e2d \\(d\\) \u662f\u8f93\u5165\u7ef4\u5ea6\uff0c \\(p\\) \u662f\u8ddd\u79bb\u8303\u6570\u3002</p> </li> </ul>"}, {"location": "DNN/model-attack/hsja/#c-geometric-progression", "title": "\u6b65\u9aa4C: \u6b65\u957f\u641c\u7d22\uff08Geometric Progression\uff09", "text": "<ul> <li>\u76ee\u7684\uff1a\u786e\u5b9a\u6cbf\u68af\u5ea6\u65b9\u5411\u7684\u6b65\u957f\uff0c\u4f7f\u5f97\u66f4\u65b0\u540e\u7684\u6837\u672c\u4ecd\u5904\u4e8e\u76ee\u6807\u4fa7\u3002</li> <li>\u8ba1\u7b97\u66f4\u65b0\u65b9\u5411\uff1a</li> <li>\u5bf9\u4e8e\u2113\u2082\u653b\u51fb\uff1a \\(v_t = \\widehat{\\nabla S}(x_t, \\delta_t) / \\| \\widehat{\\nabla S}(x_t, \\delta_t) \\|_2\\)</li> <li>\u5bf9\u4e8e\u2113\u221e\u653b\u51fb\uff1a \\(v_t = \\text{sign}(\\widehat{\\nabla S}(x_t, \\delta_t))\\)</li> <li>\u521d\u59cb\u6b65\u957f\uff1a \\(\\xi_t = \\| x_t - x^* \\|_p / \\sqrt{t}\\) \uff08\u57fa\u4e8eTheorem 1\u7684\u7406\u8bba\u5efa\u8bae\uff09\u3002</li> <li>\u901a\u8fc7\u51e0\u4f55\u7ea7\u6570\u8c03\u6574\u6b65\u957f\uff1a</li> <li>\u8ba1\u7b97\u5019\u9009\u70b9\uff1a \\(\\tilde{x}_t = x_t + \\xi_t v_t\\) </li> <li>\u5982\u679c \\(\\phi_{x^*}(\\tilde{x}_t) = -1\\) \uff0c\u5219\u5c06\u6b65\u957f\u51cf\u534a\uff08 \\(\\xi_t \\leftarrow \\xi_t / 2\\) \uff09\uff0c\u91cd\u590d\u76f4\u5230 \\(\\phi_{x^*}(\\tilde{x}_t) = 1\\) \u3002</li> </ul>"}, {"location": "DNN/model-attack/hsja/#d", "title": "\u6b65\u9aa4D: \u6295\u5f71\u56de\u8fb9\u754c", "text": "<ul> <li>\u76ee\u7684\uff1a\u5c06\u66f4\u65b0\u540e\u7684\u70b9 \\(\\tilde{x}_t\\) \u6295\u5f71\u56de\u51b3\u7b56\u8fb9\u754c\uff0c\u5f97\u5230\u4e0b\u4e00\u8fed\u4ee3\u70b9 \\(x_{t+1}\\) \u3002</li> <li>\u4f7f\u7528\u7b97\u6cd51\uff08Bin-Search\uff09\uff0c\u8f93\u5165\u4e3a \\(\\tilde{x}_t\\) \u548c \\(x^*\\) \uff0c\u8f93\u51fa\u6295\u5f71\u70b9 \\(x_{t+1}\\) \u3002</li> <li>\u6295\u5f71\u65b9\u5f0f\u53d6\u51b3\u4e8e\u8ddd\u79bb\u5ea6\u91cf\uff1a</li> <li>\u2113\u2082\u6295\u5f71\uff1a \\(\\Pi_{x^*, \\alpha_t}^2(\\tilde{x}_t) = \\alpha_t x^* + (1 - \\alpha_t) \\tilde{x}_t\\)</li> <li>\u2113\u221e\u6295\u5f71\uff1a\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u88c1\u526a\u5230\u533a\u95f4 \\([x_i^* - c, x_i^* + c]\\) \uff0c\u5176\u4e2d \\(c = \\alpha_t \\| \\tilde{x}_t - x^* \\|_\\infty\\)</li> </ul> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 11, 2025). HSJA \u653b\u51fb [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-attack/hsja</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{hsja,\n    title={HSJA \u653b\u51fb},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-attack/hsja}},\n}\n</code></pre></p>"}, {"location": "DNN/model-attack/pgd/", "title": "PGD \u653b\u51fb", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 11 \u5206\u949f\u3000|\u3000\u7ea6 1832 \u5b57\u3000|\u3000\u7ea6 20 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u6587\u7ae0 \u53d1\u8868\u5728 ICLR 2018\u3002\u4f5c\u8005\u5355\u4f4d\u90fd\u662f MIT\u3002</p> <p>\u4e0a\u6b21\u5199 FGSM \u7684\u7b14\u8bb0\u7684\u65f6\u5019\u5c31\u53d1\u73b0\uff0c\u5176\u5b9e\u5e02\u9762\u4e0a\u7684\u5927\u90e8\u5206\u535a\u5ba2\u8fd9\u4e9b\u4e8c\u624b\u77e5\u8bc6\u65e0\u6cd5\u5f97\u5230\u5e7f\u6cdb\u7684\u540c\u884c\u8bc4\u8bae\uff08\u4e00\u4e9b\u77e5\u540d\u7684\u535a\u5ba2\u5982\u7b97\u6cd5\u7ade\u8d5b\u9009\u624b\u7684\u6216\u8005\u9886\u57df\u5185\u4e13\u5bb6\u7684\u9664\u5916\uff0c\u4f46\u521d\u7ea7\u5b66\u4e60\u8005\u7684\u535a\u5ba2\u60c5\u51b5\u5c31\u5c24\u4e3a\u4e25\u91cd\uff09\uff0c\u56e0\u6b64\u5176\u6b63\u786e\u6027\u96be\u4ee5\u4fdd\u8bc1\u3002</p> <p>\u56e0\u6b64\u672c\u6587\u529b\u6c42\u4ece\u539f\u8bba\u6587\u5165\u624b\u5f00\u59cb\u9605\u8bfb\u5e76\u8fdb\u884c\u76f8\u5173\u7b14\u8bb0\uff0c\u5199\u597d\u4e4b\u540e\u4e5f\u4e22\u7ed9 GPT-5-high \u8fdb\u884c\u521d\u6b65\u5ba1\u8bfb\u3002\u5f53\u7136\uff0c\u66f4\u6b22\u8fce\u5217\u4f4d\u4eba\u7c7b\u770b\u5b98\u6279\u8bc4\u6307\u6b63\u3002</p>"}, {"location": "DNN/model-attack/pgd/#_1", "title": "\u8fed\u4ee3\u653b\u51fb", "text": "<p>\u5728\u4e0a\u4e00\u7bc7 FGSM \u7684\u7b14\u8bb0\u4e2d\uff0c\u6211\u4eec\u5f97\u5230\u653b\u51fb\u7684\u5355\u6b65\u6270\u52a8\u65b9\u5f0f\uff1a</p> \\[ \\begin{align*}     \\tilde x_{L_2}&amp;=x+\\epsilon g_x/\\|g_x\\|\\\\     \\tilde x_{L_\\infty}&amp;=x+\\epsilon \\mathrm{sign}(g_x)\\\\     \\tilde x_{L_\\mathrm{spec}}&amp;=x+\\epsilon \\mathrm{msign}(g_x) \\end{align*} \\] <p>\u5e76\u4e14\uff0cFGSM \u65b9\u6cd5\u9009\u62e9\u65e0\u7a77\u8303\u6570\u4f5c\u4e3a\u6700\u540e\u4f7f\u7528\u7684\u8303\u6570\u3002\u53d7\u5230\u4f18\u5316\u5668\u7406\u8bba\u7684\u542f\u53d1\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u6b64\u8fdb\u884c\u8fed\u4ee3\uff1a</p> \\[ x_{t+1}=\\mathrm{Proj}_{x\\in\\mathcal{S}}(x_t+\\alpha \\mathrm{normalized}_L(g_x) ) \\] <p>\u4e3a\u4e86\u5bf9\u6807 FGSM \u7684\u6270\u52a8 \\(\\epsilon\\)\uff0c\u5047\u8bbe\u8fed\u4ee3\u6b65\u6570 \\(T\\) \u5219\u53ef\u4ee5\u8bbe\u7f6e\u603b\u6270\u52a8 \\(\\alpha T=\\epsilon\\)\u3002</p> <p>\u8fd9\u91cc\u5f15\u5165\u4e86\u88c1\u5207\uff0c\u4e00\u65b9\u9762\u5c31\u5982\u540c\u4e4b\u524d\u63d0\u5230\u7684\uff0c\u56fe\u50cf\u5177\u6709\u4e00\u4e2a\u6700\u5927\u7684\u7070\u9636\uff0c\u4e0d\u80fd\u8d85\u8fc7\uff1b\u53e6\u4e00\u65b9\u9762\u662f\uff0c\u6211\u4eec\u4e0d\u80fd\u8ba9\u6270\u52a8\u8fc7\u5927\uff0c\u800c\u662f\u5c3d\u53ef\u80fd\u6784\u9020\u90a3\u79cd\u201c\u770b\u8d77\u6765\u5dee\u4e0d\u591a\u201d\u4f46\u5374\u53ef\u4ee5\u5bf9\u8f93\u51fa\u9020\u6210\u5f88\u5927\u5e72\u6270\u7684\u6837\u672c\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u628a\u8bf8 \\(x\\) \u7ea6\u675f\u5728\u4e00\u4e2a\u53ef\u884c\u57df \\(\\mathcal{S}\\) \u91cc\u9762\uff0c\u800c\u6700\u7b80\u5355\u7684\u7ea6\u675f\u65b9\u5f0f\u5c31\u662f\u7ea6\u675f\u5230\u56f4\u7ed5\u521d\u59cb\u6837\u672c\u5f62\u6210\u7684\u4e00\u4e2a\u7403 \\(U(x_0,\\epsilon)\\) \u91cc\u9762\u505a\u6295\u5f71\uff08PGD\uff09\uff0c\u6216\u8005\u6211\u4eec\u8fd8\u53ef\u4ee5\u76f4\u63a5\u8fdb\u884c\u88c1\u5207\uff08BIM\uff09\u3002</p> <p>\u5de5\u7a0b\u4e0a\u4e3a\u4e86\u5f15\u5165\u591a\u6837\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f1a\u91c7\u7528\u5728 \\(x_0\\) \u4e0b\u6dfb\u52a0\u5fae\u5c0f\u566a\u58f0\u7684\u65b9\u5f0f\u4f5c\u4e3a\u8fed\u4ee3\u8d77\u70b9\uff0c\u53c8\u79f0\u968f\u673a\u542f\u52a8\u3002\u5f53\u7136\u4e3a\u4e86\u627e\u5230\u66f4\u5168\u5c40\u7684\u6700\u5927\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5b66\u4e60 SGD \u7684\u65b9\u6cd5\uff0c\u4e5f\u5728\u8fd9\u4e2a\u8fed\u4ee3\u8def\u5f84\u4e0b\u9762\u6dfb\u52a0\u53ef\u63a7\u7684\u566a\u58f0\u3002\u81f3\u4e8e\u8fd9\u4e2a Noise Schedule\uff08\u4e0d\u662f\u6269\u6563\u6a21\u578b\u7684\u90a3\u4e2a\u54c8\u54c8\uff0c\u6211\u6545\u610f\u7684\uff09\u600e\u4e48\u641e\u4e5f\u662f\u89c1\u4ec1\u89c1\u667a\u7684\u3002</p> <p>\u4e3a\u4e86\u7edf\u4e00\u8bf4\u660e\uff0c\u8fd9\u91cc\u4f7f\u7528 \\(\\mathrm{normalized}_L(g_x)\\) \u6765\u8868\u5f81\u6837\u672c\u68af\u5ea6\u5728 \\(L\\) \u8303\u6570\u4e0b\u7684\u5f52\u4e00\u5316\u5411\u91cf\uff0c\u5177\u4f53\u7684\u8ba1\u7b97\u65b9\u5f0f\u5982\u524d\u3002\u8fd9\u5c31\u662f \\(L\\) \u8303\u6570\u610f\u4e49\u4e0b\u7684\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff08projected gradient descent, PGD\uff09\u3002\u8fd9\u6837\u770b\u662f\u4e0d\u662f\u5f88\u50cf SGD \u5462\uff1f\u2014\u2014\u90a3\u6211\u4eec\u5176\u5b9e\u8fd8\u53ef\u4ee5\u63a5\u7740\u5957\u4f18\u5316\u5668\u7406\u8bba\uff0cSGD \u5f15\u5165\u4e86\u52a8\u91cf\uff0c\u90a3 PGD \u4e5f\u53ef\u4ee5\u5f15\u5165\u52a8\u91cf\uff0cOK \u4e8e\u662f\u4f60\u53d1\u660e\u4e86 MI-FGSM \u7136\u540e\u4e2d\u4e86 CVPR 2018\uff0c\u7136\u540e\u4f60\u8fd8\u53ef\u4ee5\u5f15\u5165 Nesterov \u52a0\u901f\u68af\u5ea6\uff0c\u5e76\u7f8e\u7f8e\u6c34\u4e00\u7bc7\u6587\u7ae0\u653e\u5728 arXiv \u4e0a\u9762\u2026\u2026</p>"}, {"location": "DNN/model-attack/pgd/#_2", "title": "\u7406\u8bba\u6846\u67b6", "text": "<p>PGD \u8fd9\u7bc7\u6587\u7ae0\u7684\u7740\u773c\u70b9\u5e76\u4e0d\u5b8c\u5168\u662f\u63d0\u51fa PGD \u8fd9\u4e2a\u65b9\u6cd5\u800c\u662f\u63d0\u4f9b\u4e00\u4e2a\u653b\u9632\u7684\u6574\u4f53\u6846\u67b6\u3002\u867d\u7136\u6211\u89c9\u5f97\u8fd9\u4e2a\u6846\u67b6\u5c31\u662f\u6284\u7684 GAN \u7684\u635f\u5931\u51fd\u6570\u2026\u2026\u4e0d\u8fc7\u8ba9\u6211\u4eec\u5148\u6765\u770b\u770b\u5427\u3002</p> <p>\u4f5c\u8005\u7ed9\u51fa\u7684\u6846\u67b6\u5206\u6210\u4e24\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\u662f\u4f5c\u4e3a\u653b\u51fb\u8005\uff0c\u6211\u4eec\u8003\u8651\u4e00\u4e2a\u53ef\u884c\u7684\u6270\u52a8\u96c6\u5408 \\(\\delta\\in\\mathcal{S}\\)\uff0c\u9700\u8981\u6700\u5927\u5316\u635f\u5931\u4e5f\u5c31\u662f</p> \\[ \\max_{\\delta\\in\\mathcal{S}}\\mathcal{L}(\\theta;x+\\delta,y) \\] <p>\u7b2c\u4e8c\u90e8\u5206\u662f\u4f5c\u4e3a\u9632\u5fa1\u65b9\uff0c\u9700\u8981\u9488\u5bf9\u653b\u51fb\u505a\u51fa\u9632\u5fa1\uff0c\u4e5f\u5c31\u662f\u5bf9\u4e8e\u6b63\u786e\u7684\u5206\u7c7b\u6837\u672c-\u6807\u7b7e\u5bf9\u5206\u5e03 \\((x,y)\\sim\\mathcal{D}\\) \u8981\u6700\u5c0f\u5316\u653b\u51fb\u6548\u679c\uff1a</p> \\[ \\min_{\\theta}\\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[\\max_{\\delta\\in\\mathcal{S}}\\mathcal{L}(\\theta;x+\\delta,y)] \\] <p>\u7136\u540e\u6574\u4e2a\u653b\u9632\u8fc7\u7a0b\u5c31\u62bd\u8c61\u6210\u4e86\u8fd9\u4e48\u4e00\u4e2a\u978d\u70b9\u4e0a\u7684 min-max \u535a\u5f08\u3002</p> <p>\u5c31 PGD \u800c\u8a00\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u89c6\u4f5c\u635f\u5931\u5730\u5f62\u4e0b\u7684\u68af\u5ea6\u63d0\u5347\u3002\u5c31\u8db3\u591f\u5c0f\u7684 \\(\\epsilon\\) \u548c\u8db3\u591f\u591a\u7684\u8fed\u4ee3\u6b65\u6570\u800c\u8a00\uff0c\u5176\u6b63\u5982 SGD \u4e00\u822c\u80fd\u5f97\u5230\u4e00\u4e2a\u8db3\u591f\u9ad8\u7684\u635f\u5931\u9ad8\u5730\u3002\u4e5f\u5c31\u662f\u8bf4 PGD \u662f\u5229\u7528\u4e00\u9636\u68af\u5ea6\u4fe1\u606f\u7684\u5f88\u5f3a\u7684\u653b\u51fb\u65b9\u6cd5\u3002</p> <p>\u7531\u4e8e\u521a\u521a\u90a3\u4e2a\u653b\u9632\u8fc7\u7a0b\u7684\u5916\u5c42\u5c31\u662f\u4e00\u822c\u7684\u98ce\u9669\u6700\u5c0f\u5316\u5f0f\u5b50\uff0c\u53ef\u4ee5\u901a\u8fc7\u4e00\u822c\u7684\u4f18\u5316\u5668\u8fdb\u884c\u8bad\u7ec3\u3002\u800c\u5185\u5c42\u53ef\u4ee5\u5229\u7528 PGD \u5f97\u5230\u6700\u6709\u6548\u7684\u68af\u5ea6\u4e0a\u5347\u3002\u56e0\u6b64\u6587\u7ae0\u5f97\u51fa\u5229\u7528 PGD \u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5b9e\u73b0\u8f83\u597d\u7684\u9632\u5fa1\u6548\u679c\u3002\u5173\u4e8e\u8fd9\u4e00\u90e8\u5206\u7684\u7406\u8bba\u8bba\u8bc1\uff0c\u4f5c\u8005\u5229\u7528\u4e86 Danskin \u5b9a\u7406\u5728\u9644\u5f55 A \u8fdb\u884c\u4e86\u8bc1\u660e\u3002</p> <p>\u6b64\u5916\u6587\u7ae0\u8fd8\u82b1\u7bc7\u5e45\u8ba8\u8bba\u4e86\u7f51\u7edc\u5bb9\u91cf\u548c\u5bf9\u6297\u8bad\u7ec3\u7684\u5173\u7cfb\u3002\u7531\u4e8e\u5bf9\u6297\u6837\u672c\u5b9e\u8d28\u4e0a\u662f\u8bd5\u56fe\u5728\u771f\u5b9e\u6837\u672c\u9644\u8fd1\u6dfb\u52a0\u6270\u52a8\u800c\u9884\u671f\u8de8\u8fc7\u51b3\u7b56\u8fb9\u754c\u3002\u56e0\u6b64\u5bf9\u6297\u8bad\u7ec3\u4f1a\u4f7f\u5f97\u51b3\u7b56\u8fb9\u754c\u76f8\u5f53\u590d\u6742\uff0c\u9700\u8981\u7f51\u7edc\u5177\u6709\u66f4\u5f3a\u5927\u7684\u62df\u5408\u80fd\u529b\u3002</p>"}, {"location": "DNN/model-attack/pgd/#_3", "title": "\u6548\u679c", "text": "<p>\u5f53\u6211\u4eec\u63a7\u5236\u603b\u7684\u66f4\u65b0\u91cf\u4e0d\u53d8\u65f6\uff0c\u63a7\u5236\u66f4\u7cbe\u7ec6\u7684\u8fed\u4ee3\u91cf\u4f1a\u4f7f\u5f97\u5728\u8089\u773c\u533a\u522b\u4e0d\u5927\u7684\u60c5\u51b5\u4e0b\u5f97\u5230\u66f4\u597d\u7684\u653b\u51fb\u6548\u679c\uff0c\u8fd9\u5c31\u662f\u591a\u6b65\u8fed\u4ee3\u7684\u5a01\u529b\u3002\u6bd4\u5982\u65e0\u7a77\u8303\u6570\u7ea6\u675f\u4e0b\u7684 PGD \u4ece\u8fed\u4ee3 0 \u6b65\u523020\u6b65\uff0c\u53ea\u662f\u7070\u8272\u8272\u5757\u8fb9\u7f18\u7a0d\u6709\u6a21\u7cca\u3002</p>"}, {"location": "DNN/model-attack/pgd/#_4", "title": "\u5173\u4e8e\u8c31\u8303\u6570\u7684\u4e00\u4e9b\u6ce8\u89e3\uff1a\u7b97\u6cd5\u548c\u52a8\u673a", "text": "<p>\u773c\u5c16\u7684\u8bfb\u8005\u53ef\u80fd\u4f1a\u6ce8\u610f\u5230\uff0c\u8fd9\u91cc\u7684\u8c31\u8303\u6570\u7684\u653b\u51fb\u56fe\u50cf\u548c\u4e4b\u524d FGSM \u7684\u653b\u51fb\u56fe\u50cf\u6709\u4e9b\u4e0d\u5927\u4e00\u6837\u3002</p> <p>\u8fd9\u662f\u56e0\u4e3a GPU \u76f8\u5bf9\u8f83\u96be\u5e76\u884c\u5730\u5bf9\u77e9\u9635\u505a SVD\uff0c\u8fd9\u5c31\u5bfc\u81f4\u541e\u5410\u7387\u5f88\u4f4e\u3002\u5728 GAN \u7684\u8bad\u7ec3\u4e2d\u4f7f\u7528\u7684\u8c31\u5f52\u4e00\u5316\u91c7\u7528\u5e42\u8fed\u4ee3\u7684\u65b9\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff0c\u4f46\u8fd9\u5bf9\u4e8e\u6bcf\u4e2a Batch \u90fd\u6709\u5f88\u5927\u53d8\u5316\u7684\u8f93\u5165\u800c\u8a00\u4e5f\u662f\u76f8\u5bf9\u4f4e\u6548\u7684\u3002</p> <p>\u56e0\u6b64\u6211\u4eec\u91c7\u7528\u5728 Muon \u4f18\u5316\u5668\u91cc\u9762\u5df2\u7ecf\u9a8c\u8bc1\u8fc7\u7684\u65b9\u5f0f\uff0c\u5373\u4f7f\u7528 Newton-Schulz \u8fed\u4ee3\u9ad8\u6548\u8fd1\u4f3c \\(UV^\\top\\)\u3002\u5b83\u53ea\u9700\u8fed\u4ee3\u51e0\u6b21 \\(MM^\\top\\) \u7684\u8ba1\u7b97\u5373\u53ef\u5feb\u901f\u8fdb\u884c\u8c31\u5f52\u4e00\u5316\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u5c3d\u7ba1\u4ecd\u7136\u662f \\(O(n^3)\\) \u4f46\u662f\u8fd9\u4e2a\u8fc7\u7a0b\u53ea\u4f9d\u8d56\u77e9\u9635\u4e58\u6cd5\u3001\u6570\u4e58\u4e0e\u52a0\u548c\uff0c\u76f8\u5f53\u9002\u7528\u4e8e GPU \u8ba1\u7b97\uff0c\u5e38\u6570\u5c0f\u7684\u540c\u65f6\u6709\u7740\u76f8\u5f53\u9ad8\u7684\u541e\u5410\u7387\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u8dd1\u5168\u91cf\u6570\u636e\u7684\u5bf9\u6297\u6837\u672c\u751f\u6210\uff0c\u8c31\u8303\u6570\u7ea6\u675f\u8fed\u4ee3 20 \u6b21\uff0c\u5728 P100 GPU \u4e0a\u8fd9\u4e2a\u65b9\u6cd5\u8017\u65f6\u662f\u8bad\u7ec3\u96c6 20.72s \u4ee5\u53ca\u6d4b\u8bd5\u96c6 3.52s\uff0c\u800c\u5728 Intel i5 1135G7 CPU \u4e0a\u7684\u8017\u65f6\u5982\u4e0a\u56fe\u3002\u6709\u7406\u7531\u76f8\u4fe1\u57fa\u4e8e CPU \u7684 SVD \u65b9\u6cd5\u5c06\u66f4\u6162\u3002</p> <p>\u5173\u4e8e\u5177\u4f53\u7684\u7406\u8bba\u63a8\u5bfc\u548c\u4ee3\u7801\u5b9e\u73b0\u4ee5\u53ca\u76f8\u5173\u53c2\u6570\u7684\u6c42\u89e3\uff0c\u8bf7\u53c2\u8003\u201c\u4f18\u5316\u5668\u201d\u7c7b\u522b\u4e2d\u7684\u201c\u7b26\u53f7\u68af\u5ea6\u4e0b\u964d\u201d\u4e00\u6587\u3002</p> <p>\u6700\u540e\u5c1a\u672a\u63d0\u53ca\u7684\u4e00\u70b9\u662f\u5bf9\u4e8e\u5f20\u91cf\uff0c\u5176\u68af\u5ea6\u7684\u201c\u8c31\u8303\u6570\u201d\u662f\u672a\u5b9a\u4e49\u7684\u3002\u5177\u4f53\u600e\u4e48\u628a\u5f20\u91cf\u53d8\u6210\u77e9\u9635\u5c31\u89c1\u4ec1\u89c1\u667a\u4e86\uff0c\u6bd4\u5982\u53ef\u4ee5\u6309\u901a\u9053\u5206\u522b\u62bd\u53d6\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u7b49\u7b49\u3002</p> <p>\u6211\u5728\u8fd9\u4e00\u7cfb\u5217\u91cc\u9762\u56fa\u6267\u5730\u5f15\u5165\u8c31\u8303\u6570\u7ea6\u675f\u7684\u68af\u5ea6\u4e0a\u5347\u653b\u51fb\uff0c\u6070\u6070\u662f\u60f3\u53d1\u6398\u4e00\u4e9b\u6709\u610f\u601d\u7684\u70b9\u2014\u2014\u53ef\u4ee5\u770b\u5230\u8c31\u8303\u6570\u5728\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u4f18\u5316\u95ee\u9898\u4e0b\u8868\u73b0\u6781\u4f73\uff0c\u5177\u6709\u76f8\u5f53\u5f3a\u608d\u7684\u6536\u655b\u901f\u7387\u3002\u4f46\u662f\u5230\u4e86\u5bf9\u6297\u6837\u672c\u751f\u6210\u9886\u57df\u5c31\u8868\u73b0\u5f97\u76f8\u5f53\u62c9\u4e86\u3002\u4e00\u5f00\u59cb\u6211\u662f\u89c9\u5f97\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u5316\u95ee\u9898\u662f\u7b80\u5355\u7684\u68af\u5ea6\u4e0b\u964d\u800c\u5bf9\u6297\u6837\u672c\u751f\u6210\u662f\u7b80\u5355\u7684\u68af\u5ea6\u4e0a\u5347\uff0c\u53ea\u4e0d\u8fc7\u4e00\u4e2a\u9488\u5bf9\u7f51\u7edc\u53c2\u6570\uff0c\u4e00\u4e2a\u9488\u5bf9\u6837\u672c\u8f93\u5165\u7f62\u4e86\u3002</p> <p>\u800c\u6b63\u662f\u8fd9\u4e00\u70b9\u70b9\u7684\u533a\u522b\u9020\u5c31\u4e86\u5f88\u5927\u7684\u4e0d\u4e00\u6837\u3002\u6211\u4eec\u9762\u5bf9\u4e00\u4e2a\u56fe\u7247\u6216\u8005\u8bf4\u57fa\u4e8e\u539f\u6709\u6837\u672c\u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\uff0c\u5176\u8bed\u4e49\u4fe1\u606f\u5e94\u5f53\u662f\u57fa\u672c\u4e0a\u5b8c\u6574\u4fdd\u7559\u7684\uff0c\u8fd9\u5c31\u51b3\u5b9a\u4e86\u6211\u4eec\u7684\u6270\u52a8\u8981\u4e48\u662f\u96be\u4ee5\u5bdf\u89c9\u7684\uff0c\u8981\u4e48\u662f\u8bef\u5bfc\u4eba\u773c\u7684\u2014\u2014\u672c\u8d28\u4e0a\u8fd9\u662f\u4e00\u4e2a\u5bf9\u5bf9\u6297\u6837\u672c\u751f\u6210\u7684\u4e00\u4e2a\u76f8\u5f53\u5f3a\u7684\u6b63\u5219\u5316\u7ea6\u675f\uff01</p> <p>\u7531\u6b64\u624d\u51b3\u5b9a\u4e86\u4e3a\u4f55\u6211\u4eec\u5728\u68af\u5ea6\u4e0a\u5347\u5bf9\u6297\u6837\u672c\u751f\u6210\u4e2d\uff0c\u65e0\u7a77\u8303\u6570\u7684\u6548\u679c\u662f\u201c\u770b\u8d77\u6765\u201d\u6700\u597d\u7684\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 23, 2025). PGD \u653b\u51fb [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-attack/pgd</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{pgd,\n    title={PGD \u653b\u51fb},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-attack/pgd}},\n}\n</code></pre></p>"}, {"location": "DNN/model-expr/", "title": "\u5173\u4e8e\u672c\u7c7b\u522b", "text": "<p>\u672c\u7c7b\u522b\u4e3b\u8981\u6536\u5f55\u7b14\u8005\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u672c\u8eab\u7684\u7406\u8bba\u6574\u7406\uff0c\u4ee5\u53ca\u76f8\u5173\u7684\u4ee3\u7801\u590d\u73b0\u3002</p> <p>\u4e3a\u914d\u5408\u884c\u6587\uff0c\u8bf8\u591a\u4ee3\u7801\u4ee5\u6298\u53e0\u4ee3\u7801\u5757\u7684\u5f62\u5f0f\u5448\u73b0\u800c\u672a\u80fd\u6574\u7406\u8fdb GitHub \u4ed3\u5e93\u4e2d\u3002\u82e5\u6709\u4e0d\u4fbf\u8fd8\u8bf7\u8c05\u89e3\u3002</p>"}, {"location": "DNN/model-expr/DC-GAN-%E8%80%81%E5%A9%86%E7%94%9F%E6%88%90%E5%99%A8/", "title": "DC-GAN \u8001\u5a46\u751f\u6210\u5668", "text": "DC-GAN DC-GAN \u8001\u5a46\u751f\u6210\u5668 <p>\u4f7f\u7528 PyTorch \u5728 Anime Face Dataset \u4e0a\u8bad\u7ec3\u7684 DC-GAN\uff0c\u5e76\u8fc1\u79fb\u5230 TensorFlow.js \u4e0a\uff08\u8fd9\u4e2a\u8fc1\u79fb\u4efb\u52a1\u4f1a\u9047\u5230\u4f9d\u8d56\u5730\u72f1\uff0c\u53ef\u8d39\u4e86\u6211\u4e00\u756a\u529f\u592b\uff09\uff0c\u5b9e\u73b0\u7f51\u9875\u7aef\u7684\u5b9e\u65f6\u63a8\u7406\u3002\u5411 Gwern \u7684 This Waifu Does Not Exist \u9879\u76ee\u81f4\u656c\u3002\u751f\u6210\u7684\u56fe\u7247\u6709\u6982\u7387\u5f88\u6b6a\u74dc\u88c2\u67a3\uff0c\u8bf7\u52a1\u5fc5\u591a\u62bd\u51e0\u53d1\u3002</p> \u6b63\u5728\u52a0\u8f7d\u6a21\u578b... \u6a21\u578b\u52a0\u8f7d\u8fdb\u5ea6\uff08\u8fd9\u4e2a\u8fdb\u5ea6\u6761\u9017\u4f60\u73a9\u7684\u54c8\u54c8\uff0c\u53cd\u6b63\u7b49\u7740\u5c31\u5bf9\u4e86\uff09 0% \u8017\u65f6: - \u56fe\u50cf\u751f\u6210\u8fdb\u5ea6\uff08\u6ca1\u9519\u8fd9\u4e2a\u8fdb\u5ea6\u6761\u4e5f\u662f\u9017\u4f60\u73a9\u7684\uff0c\u4e0d\u8fc7\u51fa\u56fe\u8fd8\u662f\u5f88\u5feb\u7684\uff09 0% \u8017\u65f6: - \u6a21\u578b\u521d\u59cb\u5316\u4e2d\uff0c\u4e5f\u5c31\u53ea\u80fd\u7b49\u7740\u54af... <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 30, 2025). DC-GAN \u8001\u5a46\u751f\u6210\u5668 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-expr/DC-GAN-%E8%80%81%E5%A9%86%E7%94%9F%E6%88%90%E5%99%A8</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{DC-GAN-%E8%80%81%E5%A9%86%E7%94%9F%E6%88%90%E5%99%A8,\n    title={DC-GAN \u8001\u5a46\u751f\u6210\u5668},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-expr/DC-GAN-%E8%80%81%E5%A9%86%E7%94%9F%E6%88%90%E5%99%A8}},\n}\n</code></pre></p>"}, {"location": "DNN/model-expr/DDPM/", "title": "\u6269\u6563\u6a21\u578b\u7406\u8bba\u7bc7: \u4ece\u591a\u9636\u6bb5\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5230\u6982\u7387\u6d41\u5e38\u5fae\u5206\u65b9\u7a0b\u91c7\u6837\u5668\u7cfb\u5217", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 45 \u5206\u949f\u3000|\u3000\u7ea6 4041 \u5b57\u3000|\u3000\u7ea6 259 \u4e2a\u516c\u5f0f\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u89c2\u524d\u63d0\u793a\uff1a\u672c\u6587 \\(\\alpha\\) \u7684\u5b9a\u4e49\u548c\u539f\u8bba\u6587\u5dee\u4e86\u4e00\u4e2a\u5e73\u65b9\u7684\u9636\uff0c\u4ee5\u53ca \\(q\\) \u548c \\(p\\) \u7684\u5b9a\u4e49\u548c\u539f\u8bba\u6587\u76f8\u53cd\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#train-vaes-revenge", "title": "Train: VAE's revenge", "text": "<p>\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b VAE \u7684\u5efa\u6a21\u8fc7\u7a0b\uff1a</p> <p>\u4e3a\u4e86\u62df\u5408\u76ee\u6807\u5206\u5e03 \\(p(x)\\)\uff0c\u6211\u4eec\u5f15\u5165\u4e00\u4e2a\u9690\u53d8\u91cf \\(z\\)\uff0c\u8fd9\u6837\u5bf9\u5176\u7684\u5efa\u6a21\u5c31\u53d8\u6210\u4e86 \\(p(x,z)=p(x|z)p(z)\\)\uff0c\u800c\u53cd\u8fc7\u6765\uff0c\u6211\u4eec\u4e5f\u9700\u8981\u5bf9\u539f\u53d8\u91cf\u7f16\u7801\u8fdb\u9690\u53d8\u91cf\u4e2d\uff0c\u4e5f\u5c31\u662f\u5efa\u6a21 \\(q(x,z)=q(z|x)q(x)\\)\u3002\u7136\u540e\u6211\u4eec\u6c42\u8fd9\u4e24\u4e2a\u8054\u5408\u5206\u5e03\u7684 KL \u6563\u5ea6\uff0c\u4e5f\u5c31\u662f \\(KL(q(x,z)||p(x,z))\\) \u6765\u8861\u91cf\u62df\u5408\u5206\u5e03\u548c\u539f\u5206\u5e03\u7684\u76f8\u4f3c\u6027\u3002\u7136\u540e\u6211\u4eec\u5f15\u5165\u5f3a\u5148\u9a8c\u7684\u6b63\u6001\u6027\u5047\u8bbe\uff0c\u628a\u8fd9\u4e2a KL \u6563\u5ea6\u62c6\u51fa\u5e38\u6570\u5f97\u5230 \\(ELBO\\)\uff0c\u518d\u62c6\u6210 MSE \u548c KLD \u4e24\u9879\u3002</p> <p>\u5728\u5bf9 VAE \u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u4e5f\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u7531\u4e8e\u5176\u5f3a\u5236\u5f15\u5165\u7684\u6b63\u6001\u6027\u5047\u8bbe\uff0c\u5bfc\u81f4\u538b\u7f29\u7387\u8fc7\u9ad8\uff0c\u751f\u6210\u7684\u56fe\u50cf\u5f88\u7cca\u3002</p> <p>\u8fd9\u5c31\u5f15\u5165\u4e86\u6211\u4eec\u4ecb\u7ecd DDPM \u7684\u52a8\u673a\u2014\u2014\u4ece\u7eaf\u566a\u58f0\u7684 \\(p(z)\\) \u4e00\u6b65\u8fc8\u5230\u591a\u6837\u7684\u771f\u5b9e\u5206\u5e03 \\(p(x)\\)\uff0c\u8fd9\u4e00\u6b65\u591a\u5c11\u8fc8\u5f97\u6709\u70b9\u5927\u4e86\u3002\u4f46\u662f\u5982\u679c\u6211\u4eec\u4f7f\u7528\u4ece \\(x_0, x_1, \\cdots, x_T\\) \u7684\u591a\u6b65\u89e3\u7801\u6765\u4ee3\u66ff VAE \u7684\u5355\u6b65\u89e3\u7801\u5462\uff1f</p> <p>\u4e5f\u5c31\u662f\uff0c\u5f15\u5165\u8054\u5408\u5206\u5e03\uff1a\\(p(x_0, x_1, \\cdots, x_T) = p(x_T | x_{T-1}) p(x_{T-1} | x_{T-2}) \\cdots p(x_1 | x_0) p(x_0)\\) \u4e3a\u6211\u4eec\u7684\u201c\u7f16\u7801\u5668\u201d\uff0c\u8d1f\u8d23\u5c06 \\(x_0\\) \u9010\u6b65\u6620\u5c04\u5230\u7eaf\u566a\u58f0\u5206\u5e03 \\(x_T\\sim\\mathcal N(0,I)\\)\uff0c\u7136\u540e\u53cd\u8fc7\u6765\u662f\u201c\u89e3\u7801\u5668\u201d \\(q(x_0, \\cdots, x_T) = q(x_0 | x_1) q(x_1 | x_2) \\cdots q(x_{T-1} | x_T) q(x_T)\\) \u8d1f\u8d23\u5c06\u566a\u58f0\u9010\u6b65\u8fd8\u539f\u5230\u539f\u56fe\u50cf\u3002</p> <p>\u4e0b\u9762\uff0c\u8ba9\u6211\u4eec\u5f00\u59cb\u8fdb\u884c\u53d8\u5206\u63a8\u65ad\u5427\u3002\u9996\u5148\u662f KL \u6563\u5ea6\uff1a</p> \\[ \\begin{align*}     KL(p \\Vert q) &amp;= \\int p \\log \\frac{p}{q} \\mathrm dx_T \\cdots \\mathrm dx_0\\\\&amp;= \\int p(x_T | x_{T-1}) \\cdots p(x_1 | x_0) p(x_0) \\log \\frac{p(x_T | x_{T-1}) \\cdots p(x_1 | x_0) p(x_0)}{q(x_0 | x_1) \\cdots q(x_{T-1} | x_T) q(x_T)} \\mathrm dx_T \\cdots \\mathrm dx_0 \\end{align*} \\] <p>\u73b0\u5728\u6211\u4eec\u4ecd\u7136\u9700\u8981\u5bf9\u201c\u7f16\u7801\u8fc7\u7a0b\u201d \\(p\\) \u5f15\u5165\u5f52\u7eb3\u504f\u7f6e\u3002\u7531\u4e8e\u6211\u4eec\u662f\u5c06\u56fe\u50cf\u8f6c\u5316\u4e3a\u7eaf\u566a\u58f0\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u628a\u6bcf\u4e00\u6b65 \\(p\\) \u770b\u4f5c\u662f\u4e00\u4e2a\u9010\u6b65\u52a0\u566a\u7684\u8fc7\u7a0b\uff1a</p> \\[ x_i=\\alpha_i x_{i-1}+\\beta_i\\varepsilon_i,\\quad \\varepsilon_i\\sim\\mathcal{N}(0,I) \\] <p>\u8fd9\u91cc\u7684 \\(\\alpha_i\\) \u548c \\(\\beta_i\\) \u662f\u4e8b\u524d\u7ed9\u5b9a\u7684\u53c2\u6570\uff08\u5176\u5b9e \\(\\dfrac{\\alpha_i}{\\beta_i}\\) \u53ef\u4ee5\u7406\u89e3\u6210\u4fe1\u566a\u6bd4\uff09\uff0c\u9700\u8981\u6ee1\u8db3 \\(\\alpha_i^2+\\beta_i^2=1\\)\u3002\u4e3a\u4ec0\u4e48\u8981\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\u5462\uff1f\u8ba9\u6211\u4eec\u8003\u8651\u628a \\(x_i\\) \u4e00\u76f4\u5c55\u5f00\u5230 \\(x_0\\)\uff1a</p> \\[ \\begin{align*}     x_i&amp;=\\alpha_i x_{i-1}+\\beta_i\\varepsilon_i\\\\     &amp;=\\alpha_i (\\alpha_{i-1} x_{i-2}+\\beta_{i-1}\\varepsilon_{i-1})+\\beta_i\\varepsilon_i\\\\     &amp;=(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_1)x_0+\\beta_i\\varepsilon_i+\\alpha_i\\beta_{i-1}\\varepsilon_{i-1}+\\cdots+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_2)\\beta_1\\varepsilon_1 \\end{align*} \\] <p>\u7531\u4e8e\u8bf8 \\(\\varepsilon\\) \u662f\u72ec\u7acb\u7684\u6b63\u6001\u5206\u5e03\uff0c\u53ef\u4ee5\u53e0\u52a0\uff1a</p> \\[ \\beta_i\\varepsilon_i+\\alpha_i\\beta_{i-1}\\varepsilon_{i-1}+\\cdots+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_2)\\beta_1\\varepsilon_1=\\hat\\beta_i\\hat\\varepsilon_i,\\quad\\hat\\varepsilon_i\\sim\\mathcal{N}(0,I) \\] <p>\u5982\u679c\u6211\u4eec\u53d6 \\(\\hat\\alpha_i^2=(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_1)^2\\)\uff0c\u4e14\u7531\u6b63\u6001\u5206\u5e03\u65b9\u5dee\u7684\u53e0\u52a0\u5f97\u5230 \\(\\hat\\beta_i^2=\\beta_i^2+\\alpha_i^2\\beta_{i-1}^2+\\cdots+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_2)^2\\beta_1^2\\)\uff0c\u7136\u540e\u628a\u5b83\u4eec\u52a0\u8d77\u6765\uff1a</p> \\[ \\begin{align*}     \\hat\\alpha_i^2+\\hat\\beta_i^2&amp;=\\beta_i^2+\\alpha_i^2\\beta_{i-1}^2+\\cdots+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_2)^2\\beta_1^2+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_1)^2\\hat\\beta_i^2\\\\     &amp;=\\beta_i^2+\\alpha_i^2\\beta_{i-1}^2+\\cdots+(\\alpha_i\\alpha_{i-1}\\cdots\\alpha_2)^2(\\beta_1^2+\\alpha_1^2) \\end{align*} \\] <p>\u8fd9\u6837\u6211\u4eec\u5c31\u53d1\u73b0\uff0c\u5982\u679c\u6ee1\u8db3 \\(\\alpha_i^2+\\beta_i^2=1\\)\uff0c\u90a3\u4e48\u5c31\u6709\u70b9\u50cf\u9ad8\u4e2d\u5b66\u8fc7\u7684\u88c2\u9879\u76f8\u6d88\u201c\u70b9\u97ad\u70ae\u201d\uff0c\u4ece\u540e\u9762\u4e00\u76f4\u7b97\u5230\u524d\u9762\uff0c\u6700\u7ec8\u63a8\u51fa \\(\\hat\\alpha_i^2+\\hat\\beta_i^2=1\\)\u3002</p> <p>\u8fd9\u6709\u4ec0\u4e48\u7528\u5462\uff1f\u521a\u521a\u7684\u63a8\u5bfc\u4e2d\uff0c\u6211\u4eec\u5176\u5b9e\u5f97\u5230\u4e86\u4e00\u4e2a\u975e\u5e38\u6709\u7528\u7684\u5f0f\u5b50\uff1a</p> \\[ x_i=\\hat\\alpha_i x_0+\\hat\\beta_i\\hat\\varepsilon_i,\\quad\\hat\\varepsilon_i\\sim\\mathcal{N}(0,I),\\ \\hat\\alpha_i^2+\\hat\\beta_i^2=1 \\] <p>\u8fd9\u5c31\u610f\u5473\u7740\uff0c\u4e3a\u4e86\u83b7\u53d6\u52a0\u566a\u7684\u4e2d\u95f4\u7ed3\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u4e00\u6b65\u4ece \\(x_0\\) \u83b7\u5f97\u3002</p> <p>\u800c\u4e14\u8fd9\u4e2a\u5f0f\u5b50\u6709\u975e\u5e38\u5f3a\u7684\u51e0\u4f55\u610f\u4e49\uff1a</p> <p></p> <p>\u8fd9\u4e2a\u56fe\u5bf9\u6211\u4eec\u7406\u89e3 DDPM \u4ee5\u53ca\u540e\u9762\u7684\u5f88\u591a\u6a21\u578b\u90fd\u6709\u5f88\u5927\u7684\u5e2e\u52a9\u3002\u867d\u7136\u8fd9\u4e2a\u56fe\u4e0d\u662f\u7279\u522b\u4e25\u8c28\uff0c\u628a\u566a\u58f0\u7684\u65b9\u5dee\u5e72\u6389\u4e86\u3002</p> <p>\u81f3\u4e8e\u4e3a\u4ec0\u4e48\u975e\u8981\u62c9\u4e00\u4e2a\u5706\uff08\u8d85\u7403\u9762\uff09\u800c\u4e0d\u662f\u76f4\u7ebf\u6216\u8005\u5176\u4ed6\u4e1c\u897f\uff1f\u5f53\u7136\u53ef\u4ee5\uff01\u5982\u679c\u62c9\u76f4\u7ebf\uff0c\u606d\u559c\u4f60\u53d1\u660e\u4e86 Flow Matching \u91cc\u9762\u7684 Rectified Flow\u2026\u2026\u5e76\u4e14\u6700\u540e\u4f53\u73b0\u8fc7\u6765\u5c31\u662f\u628a\u635f\u5931\u51fd\u6570\u91cc\u9762\u7684 \\(\\alpha\\) \u548c \\(\\beta\\) \u8fd9\u4e9b\u505a\u4e2a\u66ff\u6362\uff0c\u76f8\u5f53\u4e8e\uff08\u67d0\u79cd\u610f\u4e49\u4e0a\uff09\u7ebf\u6027\u5316\u4e86 Noise Schedule\u3002\uff08\u6216\u8005\u8bf4\u6539\u53d8\u4e86\u6bcf\u4e00\u4e2a\u90e8\u5206\u7684 SNR\uff09\u6240\u4ee5\u6211\u5176\u5b9e\u5f88\u8ba8\u538c\u8fd9\u79cd\u975e\u8981\u628a\u4e1c\u897f\u626f\u4e0a\u7269\u7406\u5b66\u5f04\u51fa\u5f88 fancy \u7684\u7406\u8bba\uff0c\u7b80\u7b80\u5355\u5355\u624d\u662f\u771f\u3002</p> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u56de\u8fc7\u5934\u6765\uff0c\u770b\u770b\u5355\u6b65\u52a0\u566a\u8fc7\u7a0b \\(x_i=\\alpha_i x_{i-1}+\\beta_i\\varepsilon_i\\)\uff0c\u6211\u4eec\u5176\u5b9e\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u662f \\(\\varepsilon_i\\) \u8fd9\u4e2a\u6b63\u6001\u5206\u5e03\u7684\u91cd\u53c2\u6570\u5316\uff01</p> <p>\u4e5f\u5c31\u662f\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u52a0\u566a\u8fc7\u7a0b\u7684\u9012\u63a8\u5f0f\u5199\u6210\u6761\u4ef6\u5206\u5e03\u7684\u5f62\u5f0f\uff1a\\(p(x_i | x_{i-1}) = \\mathcal{N}(x_i; \\alpha_t x_{i-1}, \\beta_i^2 I)\uff0c\\alpha_i^2 + \\beta_i^2 = 1\\)</p> <p>\u57fa\u4e8e\u6b64\uff0c\u6211\u4eec\u521d\u6b65\u6765\u6574\u7406\u4e00\u4e0b KL \u6563\u5ea6\u7684\u5f0f\u5b50\uff1a $$\\int p \\log \\frac{p}{q} \\mathrm dx_T \\cdots \\mathrm dx_0 = \\int p \\log p \\mathrm dx_T \\cdots \\mathrm dx_0 - \\int p \\log q \\mathrm dx_T \\cdots \\mathrm dx_0 $$</p> <p>\u6ce8\u610f\u5230\u5bf9 \\(p\\) \u800c\u8a00\uff0c\u6240\u6709\u53c2\u6570\u548c\u5206\u5e03\u90fd\u662f\u5b9a\u6b7b\u7684\uff0c\u6ca1\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u90a3\u4e48\u4e0a\u5f0f\u7684\u7b2c\u4e00\u90e8\u5206\u5c31\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u53ef\u4ee5\u4e22\u6389\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u7740\u91cd\u7b97\u7b2c\u4e8c\u90e8\u5206\uff1a</p> \\[ \\begin{align*}     ELBO &amp;=- \\int \\left[ p(x_T | x_{T-1}) \\cdots p(x_1 | x_0) p(x_0) \\right] \\left( \\sum_{i=1}^T \\log q(x_{i-1} | x_i) + \\log q(x_T) \\right) \\mathrm dx_T \\cdots \\mathrm dx_0\\\\     &amp;= - \\sum_{i=1}^T \\int p(x_T | x_{T-1}) \\cdots p(x_1 | x_0) p(x_0) \\log q(x_{i-1} | x_i) \\mathrm dx_T \\cdots \\mathrm dx_0 \\end{align*} \\] <p>\u8fd9\u91cc\u628a \\(\\log q(x_T)\\) \u4e22\u6389\uff0c\u662f\u56e0\u4e3a \\(q(x_T)\\) \u662f\u52a0\u566a\u540e\u7684\u56fe\u50cf\uff0c\u4e5f\u6ca1\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002</p> <p>\u5bf9 \\(x_{i+1} \\cdots x_T\\) \u800c\u8a00\uff0c\u8fd9\u90e8\u5206\u79ef\u5206\uff1a</p> \\[ \\int p(x_T | x_{T-1}) \\cdots p(x_{i+1} | x_i)\\mathrm dx_T \\cdots \\mathrm dx_0 \\] <p>\u56e0\u4e3a\u8fd9\u4e00\u5757\u548c\u771f\u6b63\u5f85\u5b66\u4e60\u7684 \\(x_i, x_{i-1}\\) \u65e0\u5173\uff0c\u53ef\u4ee5\u5148\u79ef\u51fa\u6765\u4e00\u4e2a\u5e38\u6570\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e22\u6389\u4e86\u3002</p> <p>\u800c\u5bf9 \\(x_i \\cdots x_0\\) \u800c\u8a00\uff0c\u6211\u4eec\u6709</p> \\[ p(x_i | x_{i-1}) \\cdots p(x_1 | x_0) p(x_0) = p(x_i | x_{i-1}) p(x_{i-1} | x_0) p(x_0) \\] <p>\u4e5f\u5c31\u662f\u521a\u521a\u63d0\u5230\u7684\u591a\u6b65\u5e76\u4e00\u6b65\u7684\u52a0\u566a\u3002\u73b0\u5728\u6539\u5199\u5f97\u5230\u7684 ELBO \u5982\u4e0b\uff1a</p> \\[ ELBO= - \\sum_{i=1}^T \\int p(x_i | x_{i-1}) p(x_{i-1} | x_0) p(x_0) \\log q(x_{i-1} | x_i) \\mathrm dx_T \\cdots \\mathrm dx_0 \\] <p>\u4e0b\u9762\u6211\u4eec\u8981\u5bf9 \\(q\\) \u8fdb\u884c\u5efa\u6a21\u4e86\uff0c\u6211\u4eec\u8fd8\u662f\u501f\u9274\u4ece VAE \u91cc\u9762\u5b66\u5230\u7684\u89c2\u70b9\uff0c\u5b83\u867d\u7136\u4f5c\u4e3a\u4e00\u4e2a\u5728 \\(x_i\\) \u4e0a\u201c\u53bb\u566a\u201d\u7684\u8fc7\u7a0b\uff0c\u4f46\u4ecd\u7136\u53ef\u4ee5\u5c06\u5176\u5efa\u6a21\u6210\u4e00\u4e2a\u6761\u4ef6\u6b63\u6001\u5206\u5e03\uff1a</p> \\[ q(x_{i-1} | x_i) = \\mathcal{N}(x_{i-1}; x_i, \\sigma_t^2) \\] <p>\u7b80\u5355\u5c55\u5f00\u4e00\u4e0b\u7136\u540e\u53d6\u4e2a\u5bf9\u6570\uff1a</p> \\[ -\\log q(x_{i-1} | x_i) \\propto \\frac{1}{2\\sigma_t^2} \\| x_{i-1} - \\mu(x_i) \\|^2 \\] <p>\u4e0b\u9762\uff0c\u6211\u4eec\u5bf9\u5747\u503c \\(\\mu(x_i)\\) \u8fdb\u884c\u8ba8\u8bba\u3002</p> <p>\u7531\u4e8e\u5728\u751f\u6210\u65f6\uff0c\\(x_i = \\alpha_i x_{i-1} + \\beta_i \\varepsilon_i\\)\uff0c\u4e5f\u5c31\u662f \\(x_{i-1} = \\frac{1}{\\alpha_i}(x_i - \\beta_i \\varepsilon_i)\\)\u3002\u6211\u4eec\u5e0c\u671b\u53bb\u566a\u4e4b\u540e\uff0c\u5c3d\u91cf\u8d34\u5408\u539f\u5206\u5e03 \\(x_{i-1}\\)\uff0c\u4e5f\u5c31\u662f\u53d6</p> \\[ \\mu(x_i) = \\frac{1}{\\alpha_i} \\left[ x_i - \\beta_i \\varepsilon_\\theta(x_i, i) \\right] \\] <p>\u8fd9\u91cc\u7684 \\(\\varepsilon_\\theta(x_i, i)\\) \u5c31\u662f\u53ef\u5b66\u4e60\u7684\u53bb\u566a\u7f51\u7edc\u3002\u7531\u6b64\u53ef\u5f97\uff1a</p> \\[ \\begin{align*}     \\| x_{i-1} - \\mu(x_i) \\|^2 &amp;= \\| x_{i-1} - \\frac{1}{\\alpha_i} \\left[ \\alpha_i x_{i-1} + \\beta_i \\varepsilon_i - \\beta_i \\varepsilon_\\theta(x_i, i) \\right] \\|^2\\\\     &amp;= \\frac{\\beta_i^2}{\\alpha_i^2} \\| \\varepsilon_\\theta(x_i, i) - \\varepsilon_i \\|^2 \\end{align*} \\] <p>\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u7684\u610f\u601d\u662f\uff0c\u6211\u4eec\u8f93\u5165\u6bcf\u4e00\u6b65\u7684\u5e26\u566a\u56fe\u7247 \\(x_i\\) \u4ee5\u53ca\u65f6\u95f4\u53c2\u6570 \\(i\\)\uff0c\u7528\u6765\u9884\u6d4b\u566a\u58f0\u3002</p> <p>\u5f53\u7136\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u8ba9\u635f\u5931\u4e0d\u4f9d\u8d56\u4e8e \\(x_i\\) \u800c\u662f\u50cf\u4e4b\u524d\u4e00\u6837\u76f4\u63a5\u4ece \\(x_0\\) \u83b7\u53d6\uff0c\u5bf9\u5176\u5c55\u5f00\u4e00\u4e0b\uff1a</p> \\[ \\begin{align*}     x_i &amp;= \\alpha_i x_{i-1} + \\beta_i \\varepsilon_i = \\alpha_i \\left( \\hat{\\alpha}_{i-1} x_0 + \\hat{\\beta}_{i-1} \\hat{\\varepsilon}_{i-1} \\right) + \\beta_i \\varepsilon_i\\\\     &amp;= \\hat{\\alpha}_i x_0 + \\alpha_i \\hat{\\beta}_{i-1} \\hat{\\varepsilon}_{i-1} + \\beta_i \\varepsilon_i \\end{align*} \\] <p>\u8fd9\u6837\uff0c\u6211\u4eec\u7684\u635f\u5931\u5c31\u53ea\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u539f\u5206\u5e03 \\(p(x_0)\\) \u4ee5\u53ca\u4e24\u4e2a\u968f\u673a\u53d8\u91cf\uff0c\u4ee3\u56de\u6765\u5f97\u5230\u635f\u5931\u51fd\u6570\uff1a</p> \\[ \\sum_{i=1}^T \\frac{\\beta_i^2}{\\alpha_i^2 \\sigma_i^2} \\mathbb{E}_{x_0 \\sim p(x_0), \\hat{\\varepsilon}_{i-1}, \\varepsilon_i \\sim \\mathcal{N}(0, I)} \\left[ \\| \\varepsilon_i - \\varepsilon_\\theta\\left( \\hat{\\alpha}_i x_0 + \\alpha_i \\hat{\\beta}_{i-1} \\hat{\\varepsilon}_{i-1} + \\beta_i \\varepsilon_i, i \\right) \\|^2 \\right]\\] <p>\u5bf9 \\(\\alpha_i \\hat{\\beta}_{i-1} \\hat{\\varepsilon}_{i-1} + \\beta_i \\varepsilon_i\\) \u800c\u8a00,\u5176\u4e3a\u4e24\u4e2a\u6b63\u6001\u5206\u5e03\u7684\u53e0\u52a0\uff0c\u5c31\u53ef\u5199\u4f5c\u4e00\u4e2a\u6b63\u6001\u5206\u5e03 \\(\\mathcal{N}\\left( 0, \\sqrt{\\alpha_i^2 \\hat{\\beta}_{i-1}^2 + \\beta_i^2} \\right)\\)\uff0c\u5176\u4e2d \\(\\alpha_i^2 (1 - \\hat{\\alpha}_{i-1}^2) + \\beta_i^2 = 1 - \\hat{\\alpha}_i^2 = \\hat{\\beta}_i^2\\)\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5199\u6210\uff1a</p> \\[ \\alpha_i \\hat{\\beta}_{i-1} \\hat{\\varepsilon}_{i-1} + \\beta_i \\varepsilon_i=\\hat{\\beta}_i^2\\varepsilon,\\quad\\varepsilon\\sim\\mathcal{N}(0,I) \\] <p>\u4e3a\u4e86\u6d88\u6389 \\(\\hat{\\varepsilon}_{i-1}, \\varepsilon_i\\) \u4e2d\u7684\u4e00\u4e2a\uff0c\u8fd9\u91cc\u9700\u8981\u914d\u4e00\u4e2a \\(w\\)\uff0c\u4e3b\u8981\u75282\u6761\u6027\u8d28\uff1a \\(\\begin{cases} \\hat{\\beta}_i w, \\ w \\sim \\mathcal{N}(0, I) \\\\ \\mathbb{E}[\\varepsilon w^\\top] = 0 \\end{cases}\\)</p> <p>\u800c \\(w\\) \u4e5f\u9700\u8981\u80fd\u7528 \\(\\hat{\\varepsilon}_{i-1}, \\varepsilon_i\\) \u8868\u8fbe\u3002\u8003\u8651\u5230 \\(\\hat{\\varepsilon}_{i-1}\u548c\\varepsilon_i\\) \u7684\u72ec\u7acb\u6027\uff0c\u4ea4\u6362 \\(\\varepsilon\\) \u4e2d\u7684\u7cfb\u6570\uff0c\u53d6 \\(\\hat{\\beta}_i w = \\beta_i \\hat{\\varepsilon}_{i-1} - \\alpha_i \\hat{\\beta}_{i-1} \\varepsilon_i\\) \u5373\u53ef\u6ee1\u8db3\u4ee5\u4e0a\u8981\u6c42\u3002</p> <p>\u518d\u4ece \\(\\varepsilon, w\\) \u4e2d\u89e3\u51fa \\(\\varepsilon_i = \\frac{\\beta_i \\varepsilon - \\alpha_i \\hat{\\beta}_{i-1} w}{\\hat{\\beta}_i}\\)\uff08\u5229\u7528 \\(\\beta^2_t+\\alpha^2_t\\hat\\beta^2_{t\u22121} = \\hat\\beta_i^2\\) \uff09</p> <p>\u8fd9\u6837\u671f\u671b\u9879\u53d8\u6210\u4e86\uff1a</p> \\[ \\mathbb{E}_{w \\sim \\mathcal{N}(0, I), \\varepsilon \\sim \\mathcal{N}(0, I)} \\left[\\| \\frac{\\beta_i \\varepsilon - \\alpha_i \\hat{\\beta}_{i-1} w}{\\hat{\\beta}_i} - \\varepsilon_\\theta\\left( \\hat{\\alpha}_i x_0 + \\beta_i \\varepsilon, i \\right)\\|^2 \\right] \\] <p>\u7531\u4e8e \\(w\\) \u548c \\(\\varepsilon\\) \u72ec\u7acb\uff0c\u5148\u5bf9 \\(w\\) \u6c42\u671f\u671b\u5f97\u4e00\u5e38\u6570\uff0c\u53bb\u6389\u4e4b\u540e\uff0c\u5c31\u5f97\u5230\u4e86\u539f\u8bba\u6587 DDPM \u7684\u635f\u5931\uff1a</p> \\[ \\mathcal{L}_{\\mathrm{DDPM}} = \\sum_{i=1}^T \\frac{\\beta_i^4}{\\hat{\\beta}_i^2 \\alpha_i^2 \\sigma_i^2} \\mathbb{E}_{\\varepsilon \\sim \\mathcal{N}(0, I), x_0 \\sim p(x_0)} \\left[ \\| \\varepsilon - \\frac{\\hat{\\beta}_i}{\\beta_i} \\varepsilon_\\theta\\left( \\hat{\\alpha}_i x_0 + \\beta_i \\varepsilon, i \\right) \\|^2 \\right] \\]"}, {"location": "DNN/model-expr/DDPM/#from-the-perspective-of-sde", "title": "From the perspective of SDE", "text": "<p>Yang Song \u7684\u6587\u7ae0 arXiv: 2011.13456 \u5c06\u6269\u6563\u6a21\u578b\u548c\u5f97\u5206\u5339\u914d\u76f8\u8054\u7cfb\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u4f5c\u4e3a\u5b83\u4eec\u5171\u540c\u7684\u7406\u8bba\u57fa\u7840\u3002\u8fd9\u5c31\u5927\u5927\u63d0\u5347\u4e86 DDPM \u7684\u7406\u8bba\u9ad8\u5ea6\uff0c\u4f7f\u4e4b\u4e0d\u5c40\u9650\u4e8e\u201c\u52a0\u566a\u2014\u2014\u53bb\u566a\u201d\u7684\u539f\u521d\u601d\u8def\u3002</p> <p>\u5f15\u5165 SDE \u7684\u610f\u4e49\u4e0d\u4ec5\u5728\u4e8e\u627e\u5230\u4e00\u4e2a\u6570\u5b66\u5de5\u5177\u6765\u7814\u7a76\u6269\u6563\u6a21\u578b\uff0c\u66f4\u5728\u4e8e\u5176\u53ef\u4ee5\u76f4\u63a5\u8f6c\u5316\u4e3a\u6982\u7387\u6d41 ODE \u8fdb\u884c\u6c42\u89e3\uff0c\u8fd9\u5c31\u53ef\u4ee5\u5c06 ODE \u7684\u6570\u503c\u89e3\u6cd5\u7528\u6765\u52a0\u901f\u6269\u6563\u6a21\u578b\u7684\u6536\u655b\u3002\u8fd9\u5c31\u50ac\u751f\u4e86\u8bf8\u5982 Euler, DPM Solver \u7b49\u4e00\u4f17\u91c7\u6837\u5668\u3002</p> <p>\u8ba9\u6211\u4eec\u5f00\u59cb\u4ecb\u7ecd Song \u7684\u8bba\u6587\u7b2c\u4e00\u90e8\u5206\u7684\u5de5\u4f5c\uff1a\u8054\u7cfb DDPM \u548c\u5f97\u5206\u5339\u914d\u3002\u8fd9\u4e00\u8282\u7684\u76ee\u7684\uff0c\u662f\u5173\u8054\u4e0a\u5f97\u5206\u5339\u914d\u7b97\u6cd5\u7684\u635f\u5931\u51fd\u6570</p> \\[ \\| s_\\theta(x_i, i) - \\nabla \\log p(x_i) \\|^2 \\] <p>\u5176\u4e2d \\(\\nabla \\log p(x_i)\\) \u88ab\u79f0\u4f5c\u5f97\u5206\u51fd\u6570\u3002\u611f\u6027\u7406\u89e3\uff0c\u6211\u4eec\u662f\u5728\u62df\u5408\u4e00\u4e2a\u68af\u5ea6\u573a\uff0c\u8ba9\u8fd9\u4e2a\u68af\u5ea6\u573a\u53bb\u6307\u5f15\u6211\u4eec\u7684\u751f\u6210\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#ddpm", "title": "\u4ece DDPM \u5230\u5f97\u5206\u5339\u914d", "text": "<p>\u4e3a\u4e86\u63a8\u51fa\u5f97\u5206\u5339\u914d\u5f62\u5f0f\u7684\u635f\u5931\uff0c\u6211\u4eec\u5148\u5f15\u5165 Tweddie's Formula\u3002</p> <p>\u56de\u987e\u524d\u5411\u8fc7\u7a0b \\(p(x_i | x_{i-1}) = \\mathcal{N}(x_i; \\hat{\\alpha}_i x_0, \\hat{\\beta}_i^2 I)\\)</p> <p>\u6211\u4eec\u9700\u8981\u5f80\u56de\u4f30\u8ba1\u53cd\u5411\u8fc7\u7a0b\u3002\u8003\u8651\u6b63\u6001\u5206\u5e03 \\(p(x|\\theta) = \\mathcal{N}(\\theta, \\sigma^2 I)\\)</p> <p>\u5176\u8fb9\u7f18\u5206\u5e03 \\(p(x) = \\int p(x|\\theta) p(\\theta) d\\theta\\)\uff0c\u73b0\u5728\u5df2\u77e5 \\(x\\)\uff0c\u6211\u4eec\u8981\u6c42 \\(\\theta\\) \u5373\uff1a</p> \\[ \\mathbb{E}[\\theta | x] = \\int \\theta p(\\theta | x) \\mathrm d\\theta = \\int \\theta \\frac{p(x|\\theta) p(\\theta)}{p(x)} \\mathrm d\\theta \\] <p>\u7531\u4e8e \\(p(x)\\) \u5df2\u77e5\uff0c\u53ef\u4ee5\u63d0\u5230\u79ef\u5206\u53f7\u5916\uff1a</p> \\[ \\mathbb{E}[\\theta | x]= \\frac{1}{p(x)} \\int \\theta \\cdot \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left[ -\\frac{\\|x - \\theta\\|^2}{2\\sigma^2} \\right] p(\\theta) \\mathrm d\\theta \\] <p>\u8fd9\u91cc\u6211\u4eec\u51d1\u4e00\u4e2a \\(\\dfrac{\\mathrm d p(x|\\theta)}{\\mathrm d x} = \\dfrac{\\theta - x}{\\sigma^2} \\cdot p(x|\\theta)\\)\uff0c\u7136\u540e\u63a5\u7740\u5f80\u4e0b\u63a8\uff1a</p> \\[ \\begin{align*}     \\mathbb{E}[\\theta | x]&amp;= \\frac{\\sigma^2}{p(x)} \\int \\frac{\\theta - x}{\\sigma^2} p(x|\\theta) p(\\theta) + \\frac{x}{\\sigma^2} p(x|\\theta) p(\\theta) \\mathrm d\\theta\\\\     &amp;= \\frac{\\sigma^2}{p(x)} \\int \\frac{\\mathrm d p(x|\\theta)}{\\mathrm d x} p(\\theta) \\mathrm d\\theta + \\frac{\\sigma^2}{p(x)} \\int \\frac{x}{\\sigma^2} p(x|\\theta) p(\\theta) \\mathrm d\\theta \\end{align*} \\] <p>\u7531\u4e8e \\(\\dfrac{\\mathrm d}{\\mathrm d x}\\) \u548c \\(\\theta\\) \u65e0\u5173\uff0c\u5219</p> \\[ \\int \\frac{\\mathrm d}{\\mathrm d x} p(x|\\theta) p(\\theta) \\mathrm d\\theta = \\frac{\\mathrm d}{\\mathrm d x} \\int p(x|\\theta) p(\\theta) \\mathrm d\\theta = \\frac{\\mathrm d p(x)}{\\mathrm d x} \\] <p>\u540c\u7406\uff0c\u540e\u9762\u4e00\u534a\u53ef\u4ee5\u63d0\u51fa \\(x\\)\uff0c\u5f97\u5230</p> \\[ \\frac{x}{p(x)} \\int p(x|\\theta) p(\\theta) \\mathrm d\\theta = x \\] <p>\u56e0\u6b64\uff1a</p> \\[ \\mathbb{E}[\\theta | x] = x + \\frac{\\sigma^2}{p(x)} \\frac{\\mathrm d}{\\mathrm d x} p(x) = x + \\sigma^2 \\frac{\\mathrm d}{\\mathrm d x} \\log p(x) \\] <p>\u82e5 \\(x\\) \u4e3a\u5411\u91cf\uff0c\u5219\u5199\u4f5c \\(x + \\sigma^2 \\nabla \\log p(x)\\)\uff0c\u6b64\u5373\u4e3a Tweedie's Formula\uff0e</p> <p>\u628a\u8fd9\u4e2a\u4f30\u8ba1\u4ee3\u56de\u524d\u5411\u8fc7\u7a0b\uff0c\u5373 \\({\\alpha}_i x_{i-1} = x_i + {\\beta}_i^2 \\nabla \\log p(x_i)\\)</p> <p>\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\uff1a\\(x_i = {\\alpha}_i x_{i-1} + {\\beta}_i \\varepsilon_i\\)\uff0c\u4ee3\u4e0a\u53bb\u53ef\u5f97\uff0c\\(\\nabla \\log p(x_i) = -\\dfrac{\\varepsilon_i}{{\\beta}_i}\\)\u3002 \u8fd9\u91cc\u5df2\u7ecf\u6709\u70b9\u5473\u9053\u4e86\uff1a\u4e4b\u524d\u6211\u4eec\u5df2\u7ecf\u8ba8\u8bba\u8fc7 DDPM \u7684\u53bb\u566a\u8fc7\u7a0b\u662f\u53bb\u5b66\u4e60\u6bcf\u4e00\u6b65\u7684\u566a\u58f0 \\(\\varepsilon_i\\)\uff0c\u800c\u8fd9\u4e2a\u5f97\u5206\u51fd\u6570\u6070\u5de7\u4e5f\u662f\u8fd9\u4e2a\u5f62\u5f0f\uff0c\u6700\u591a\u5dee\u4e00\u4e2a\u7cfb\u6570\u3002</p> <p>\u56de\u987e\u4e00\u4e0b\u4e4b\u524d\u7684\u63a8\u5bfc\uff0c\u4ece \\(\\| x_{i-1} - \\mu(x_i) \\|^2\\)\uff0c\u6211\u4eec\u6709\uff1a</p> \\[ \\begin{cases} x_{i-1} = \\frac{1}{{\\alpha}_i} (x_i - {\\beta}_i \\varepsilon_i) \\\\ \\mu(x_i) = \\frac{1}{{\\alpha}_i} (x_i - {\\beta}_i \\varepsilon_\\theta(x_i, i)) \\end{cases} \\implies \\| x_{i-1} - \\mu(x_i) \\|^2 = \\frac{{\\beta}_i^2}{{\\alpha}_i^2} \\| \\varepsilon_\\theta(x_i, i) - \\varepsilon_i \\|^2 \\] <p>\u7531 \\(-\\varepsilon_i = {\\beta}_i \\nabla \\log p(x_i)\\)\uff0c\u6211\u4eec\u53d6 \\(s_\\theta(x_i, i) = -\\dfrac{1}{{\\beta}_i} \\varepsilon_\\theta(x_i, i)\\)\uff0c\u53ef\u5f97</p> \\[ \\| x_{i-1} - \\mu(x_i) \\|^2=\\dfrac{{\\beta}_i^4}{{\\alpha}_i^2 \\sigma_i^2} \\| s_\\theta(x_i, i) - \\nabla \\log p(x_i) \\|^2 \\] <p>\u6ce8\u610f\uff0c\u6b64\u65f6\u5b83\u53ea\u548c \\(x_i\\) \u6709\u5173\u4e86\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u5199\u51fa\u635f\u5931\u51fd\u6570\u4e86\uff1a</p> \\[ \\mathcal{L}_{\\text{DDPM}} = \\sum_{i=1}^T \\dfrac{\\beta_i^4}{\\alpha_i^2 \\sigma_i^2} \\mathbb{E}_{x_i \\sim p(x_i)} \\left[ \\| s_\\theta(x_i, i) - \\nabla \\log p(x_i) \\|^2 \\right] \\] <p>\u8fd9\u5c31\u662f\u5f97\u5206\u5339\u914d\u5f62\u5f0f\u7684\u635f\u5931\u51fd\u6570\u3002\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u7f51\u7edc \\(s_\\theta(x_i, i)\\) \u63a5\u53d7\u6bcf\u4e00\u6b65\u7684\u56fe\u50cf \\(x_i\\) \u548c\u65f6\u95f4 \\(i\\) \u53bb\u5339\u914d\u8fd9\u4e2a\u5f97\u5206\u51fd\u6570 \\(\\nabla \\log p(x_i)\\)\u3002</p> <p>\u8fd9\u91cc\u63d0\u4e00\u5634\uff0c\u7f51\u4e0a\u5f88\u591a DDPM \u7684\u5f97\u5206\u5339\u914d\u5f62\u5f0f\u7684\u63a8\u5bfc\uff0c\u7528\u7684\u5f97\u5206\u51fd\u6570\u662f\u8fd9\u4e2a\u6761\u4ef6\u5f97\u5206\u51fd\u6570 \\(\\nabla_{x_i}\\log p(x_i|x_0)=-\\dfrac{\\hat\\varepsilon_i}{\\hat\\beta_i}\\)\u3002\u4e0d\u8fc7\u8fd9\u6837\u63a8\u8fc7\u6765\u5c31\u7a0d\u663e\u590d\u6742\u3002\u53ea\u8981\u6ce8\u610f\u5230</p> \\[ p(x_i)=\\int p(x_i|x_0)p(x_0)\\mathrm dx_0=\\mathbb{E}_{x_0\\sim p(x_0)}[p(x_i|x_0)] \\] <p>\u518d\u5e26\u5165\u5f97\u5206\u51fd\u6570\uff0c\u5c31\u53ef\u4ee5\u77e5\u9053\u4e24\u8005\u7b49\u4ef7\u4e86\u3002\u6b64\u4e8b\u5728\u79d1\u5b66\u7a7a\u95f4\u4e2d\u5df2\u6709\u8bb0\u8f7d\u3002</p> <p>\u4e8b\u5b9e\u4e0a\u8fd9\u4e2a\u5f62\u5f0f\u624d\u66f4\u5e38\u7528\u3002\u56e0\u4e3a\u6269\u6563\u6a21\u578b\u7684\u4e00\u4e2a\u5173\u952e trick \u5c31\u662f\u4ece\u521d\u59cb\u72b6\u6001 \\(x_0\\) \u4e00\u6b65\u63a8\u5230\u4efb\u610f\u72b6\u6001 \\(x_i\\)\uff0c\u56e0\u6b64\u5728\u4ee5\u540e\u7684\u8ba8\u8bba\u4e2d\u6211\u4eec\u6cbf\u7528\u8fd9\u4e00\u5f97\u5206\u51fd\u6570\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#_2", "title": "\u5173\u8054\u4e0a\u968f\u673a\u5fae\u5206\u65b9\u7a0b", "text": ""}, {"location": "DNN/model-expr/DDPM/#_3", "title": "\u524d\u5411\u8fc7\u7a0b", "text": "<p>\u4e0b\u9762\u6211\u4eec\u5f00\u59cb\u4ecb\u7ecd Song \u7684\u8bba\u6587\u7b2c\u4e8c\u90e8\u5206\uff1a\u5c06\u52a0\u566a\u548c\u53bb\u566a\u7684\u8fc7\u7a0b\u5173\u8054\u4e0a\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u3002</p> <p>\u4e3a\u6b64\uff0c\u6211\u4eec\u8003\u8651\u628a\u4e00\u5171 \\(T\\) \u6b65\u7684\u79bb\u6563\u8fc7\u7a0b\uff0c\u8f6c\u5316\u4e3a\u5bf9 \\(t\\in[0,1]\\) \u7684\u8fde\u7eed\u8fc7\u7a0b\u7684\u5fae\u5143\u8fd1\u4f3c\uff0c\u56e0\u6b64\u6211\u4eec\u5148\u505a\u6362\u5143\uff0c\u5f15\u5165\u8fde\u7eed\u91cf\uff1a</p> \\[ x_i = x(t),\\quad\\alpha_i = \\sqrt{1 - \\frac{1}{T} \\beta\\left(t + \\frac{1}{T}\\right)} = \\sqrt{1 - \\Delta t \\cdot \\beta(t + \\Delta t)},\\quad\\\\ x_{i+1} = x\\left(t + \\frac{1}{T}\\right) = x(t + \\Delta t),\\quad\\beta_i = \\sqrt{\\frac{1}{T}} \\beta\\left(t + \\frac{1}{T}\\right) = \\sqrt{\\Delta t \\cdot \\beta(t + \\Delta t)} \\] <p>\u8fd9\u91cc \\(T\\) \u5373\u603b\u6b65\u6570\uff0c\\(\\dfrac{1}{T}\\) \u5373\u6211\u4eec\u8981\u5f15\u5165\u7684\u65f6\u95f4\u5fae\u5143 \\(\\Delta t\\)\u3002</p> <p>\u6211\u4eec\u5bf9 \\(\\alpha_i\\) \u4f5c\u6cf0\u52d2\u5c55\u5f00 \\(\\alpha_i \\sim 1 - \\dfrac{\\beta(t + \\Delta t) \\cdot \\Delta t}{2}\\)\uff0c\u7136\u540e\u66ff\u6362\u4e00\u4e0b\uff0c\u5f97\u5230\uff1a</p> \\[ x(t + \\Delta t) = \\left[ 1 - \\frac{\\beta(t + \\Delta t) \\cdot \\Delta t}{2} \\right] x(t) + \\sqrt{\\beta(t + \\Delta t)} \\cdot \\sqrt{\\Delta t} \\ \\varepsilon(t) \\] <p>\u51cf\u53bb \\(x(t)\\) \u5f97\u5230\uff1a</p> \\[ \\mathrm dx = -\\frac{\\beta(t) \\cdot x(t)}{2} \\mathrm dt + \\sqrt{\\beta(t)} \\cdot \\sqrt{\\mathrm dt} \\cdot \\varepsilon(t) \\] <p>\u53d6 \\(f[x(t), t] = -\\dfrac{\\beta(t) \\cdot x(t)}{2}\uff0cg(t) = \\sqrt{\\beta(t)}\uff0c\\mathrm dw = \\varepsilon(t) \\cdot \\sqrt{\\mathrm dt}\\)\uff08\u5176\u4e2d \\(\\mathrm dw\\) \u4e3a\u5e03\u6717\u8fd0\u52a8\u566a\u58f0\uff0c\u5373\u201c\u6269\u6563\u9879\u201d\uff09\uff0c\u5219\u6709\uff1a</p> \\[ \\mathrm dx = f[x(t), t] \\mathrm dt + g(t) \\mathrm dw \\] <p>\uff08\u4e3a\u4ec0\u4e48\u5e03\u6717\u8fd0\u52a8\u7684\u566a\u58f0\u548c \\(\\sqrt{\\mathrm dt}\\) \u6709\u5173\u5462\uff1f\u8bf7\u53c2\u9605\u672c\u6587\u9644\u5f55 I\uff09</p> <p>\u8fd9\u5c31\u662f\u52a0\u566a\u8fc7\u7a0b\u6ee1\u8db3\u7684 SDE\u3002\u5728\u539f\u8bba\u6587\u4e2d\u5bf9\u5e94 VP-SDE \u90a3\u4e00\u8282\uff0c\u4e5f\u5c31\u662f\u79bb\u6563\u8fd1\u4f3c\u7684 SDE\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#_4", "title": "\u53d8\u91cf\u66ff\u6362", "text": "<p>\u6211\u4eec\u5bf9\u8fd9\u4e2a SDE \u505a\u4e00\u4e9b\u53d8\u6362\uff0c\u5bfc\u51fa\u5176\u66f4\u6709\u7528\u7684\u5f62\u5f0f\u3002</p> <p>\u4ece \\(\\alpha_i \\sim 1 - \\dfrac{\\beta(t + \\Delta t) \\cdot \\Delta t}{2}\\) \u4e5f\u5c31\u662f \\(\\alpha_i = 1 - \\dfrac{\\beta(t_i)}{2}\\mathrm dt\\)</p> <p>\u8ba9\u6211\u4eec\u8ba1\u7b97 \\(\\hat \\alpha_i\\) \u5728\u8fde\u7eed\u610f\u4e49\u4e0a\u7684\u5bf9\u5e94 \\(\\hat \\alpha(t)\\)\uff0c\u7531\u4e8e\u6d89\u53ca\u5230\u8fde\u4e58\uff0c\u6211\u4eec\u4e24\u8fb9\u53d6\u5bf9\u6570\uff1a</p> \\[ \\begin{align*}     \\log \\hat \\alpha(t)&amp;=\\sum_{k=1}^i\\log \\alpha_i\\\\     &amp;=\\sum_{k=1}^i\\log (1 - \\dfrac{\\beta(t_i)}{2}\\mathrm dt)\\\\     &amp;\\sim \\sum_{k=1}^i - \\dfrac{\\beta(t_i)}{2}\\mathrm dt\\\\     &amp;=-\\frac 12\\int_0^t\\beta(t) \\mathrm dt \\end{align*} \\] <p>\u8fd9\u91cc\u5229\u7528\u4e86 \\(\\log\\) \u7684\u4e00\u9636\u6cf0\u52d2\u5c55\u5f00\u3002\u5bf9\u5e94\u7684\uff0c\u6211\u4eec\u6709</p> \\[ \\hat \\beta^2(t)=1-\\hat \\alpha^2(t)=1-\\exp(-\\int_0^t\\beta(t) \\mathrm dt) \\] <p>\u4ee5\u53ca</p> \\[ f(t)=-\\dfrac{\\beta(t)}{2}=\\dfrac{\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt} \\] <p>\u5982\u679c\u6211\u4eec\u5bf9 \\(\\hat \\beta^2(t)\\) \u6c42\u5bfc\uff1a</p> \\[ \\dfrac{\\mathrm d \\hat \\beta^2(t)}{\\mathrm dt}=\\beta(t)\\left(\\exp(-\\int_0^t\\beta(t) \\mathrm dt)\\right)=\\beta(t)(1-\\hat \\beta^2(t))=\\beta(t)-\\beta(t)\\hat \\beta^2(t) \\] <p>\u4e5f\u5c31\u662f</p> \\[ g^2(t)=\\beta(t)=\\dfrac{\\mathrm d \\hat \\beta^2(t)}{\\mathrm dt}-\\dfrac{2\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}\\hat \\beta^2(t) \\] <p>\u5728\u6b64\u610f\u4e49\u4e0b\u6211\u4eec\u7684 SDE \u5199\u6210\uff1a</p> \\[ \\mathrm dx=f(t)x(t)\\mathrm dt+g(t)\\mathrm dw \\] <p>\u5f15\u5165\u8fd9\u90e8\u5206\u63a8\u5bfc\uff0c\u4e3b\u8981\u662f\u548c\u4e4b\u524d DDPM \u591a\u6b65\u5e76\u4e00\u6b65\u7684\u76ee\u7684\u662f\u4e00\u6837\u7684\uff0c\u6211\u4eec\u8981\u6d88\u53bb\u6bd4\u8f83\u9ebb\u70e6\u7684 \\(\\beta(t)\\)\uff0c\u8f6c\u5316\u4e3a\u53ef\u4ee5\u4e00\u6b65\u5f97\u5230\u7684 \\(\\hat\\beta(t)\\) \u548c \\(\\hat\\alpha(t)\\)\uff0c\u540c\u65f6\uff0c\u4e5f\u662f\u4e3a\u540e\u9762 DPM Solver \u7684\u63a8\u5bfc\u670d\u52a1\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#_5", "title": "\u53cd\u5411\u8fc7\u7a0b", "text": "<p>\u90a3\u4e48\u5982\u4f55\u83b7\u5f97\u53bb\u566a\u8fc7\u7a0b\u7684\u53cd\u5411 SDE \u5462\uff1f\u53c8\u5982\u4f55\u4e0e\u521a\u624d\u5f97\u5230\u7684\u5f97\u5206\u5339\u914d\u5f62\u5f0f\u76f8\u8054\u7cfb\u5462\uff1f\u5f53\u7136\u662f\u5229\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\uff0c\u4e3a\u6b64\u6211\u4eec\u5148\u5c06\u4e0a\u9762\u7684 SDE \u5199\u6210\u6761\u4ef6\u5206\u5e03\uff1a</p> \\[ p(x_{t+\\Delta t} | x_t) = \\mathcal{N}\\bigl(x_{t+\\Delta t}; \\ x_t + f_x(t) \\mathrm dt, \\ g^2(t) \\mathrm dt \\cdot I\\bigr) \\] <p>\u73b0\u5728\uff0c\u5c31\u53ef\u4ee5\u5229\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\u4e86</p> \\[ \\begin{align*}     p(x_t | x_{t+\\Delta t}) &amp;= \\dfrac{p(x_{t+\\Delta t} | x_t) \\cdot p(x_t)}{p(x_{t+\\Delta t})}\\\\     &amp;= \\exp\\left[ \\log p(x_{t+\\Delta t} | x_t) + \\log p(x_t) - \\log p(x_{t+\\Delta t}) \\right]\\\\     &amp;\\propto \\exp\\left[ -\\dfrac{1}{2 g^2(t) \\Delta t} \\| x_{t+\\Delta t} - x_t - f_x(t) \\Delta t \\|^2 + \\log p(x_t) - \\log p(x_{t+\\Delta t}) \\right] \\end{align*} \\] <p>\u4e3a\u4e86\u7b97\u4e0b\u53bb\uff0c\u6211\u4eec\u8981\u5bf9 \\(\\log p(x_{t+\\Delta t})\\) \u4f5c\u5c55\u5f00\uff1a</p> \\[ \\log p(x_{t+\\Delta t}) \\approx \\log p(x_t) + (x_{t+\\Delta t} - x_t) \\cdot \\nabla_x \\log p(x_t) + O(\\Delta t) \\] <p>\u7136\u540e\u4f5c\u5dee\uff1a</p> \\[ \\log p(x_t) - \\log p(x_{t+\\Delta t}) = -\\dfrac{1}{2 g^2(t) \\Delta t} \\left[ (x_{t+\\Delta t} - x_t) \\cdot \\nabla_x \\log p(x_t) \\cdot 2 g^2(t) \\Delta t \\right] + O(\\Delta t) \\] <p>\u6211\u4eec\u7684\u76ee\u7684\u5176\u5b9e\u662f\u5199\u6210\u4e00\u4e2a\u548c\u6b63\u6001\u5206\u5e03\u7c7b\u4f3c\u7684 exp \u52a0\u6a21\u5e73\u65b9\u7684\u5f62\u5f0f\u3002\u4e3a\u6b64\uff0c\u8fd9\u91cc\u6211\u4eec\u53ef\u4ee5\u914d\u4e00\u4e2a</p> \\[ \\left[ g^2(t) \\Delta t \\cdot \\nabla_x \\log p(x_t) \\right]^2 + 2 \\left[ g^2(t) \\nabla_x \\log p(x_t) \\Delta t \\right] \\times f_x(t) \\Delta t \\] <p>\u56e0\u4e3a\u5b83\u4eec\u90fd\u662f \\(\\Delta t\\) \u7684\u4e8c\u9636\u9879\uff0c\u6700\u540e\u90fd\u80fd\u6d88\u5931\u3002\u4e0d\u8fc7\uff0c\u914d\u4e0a\u4e4b\u540e\u5c31\u53d8\u6210\u4e86\u5b8c\u5168\u5e73\u65b9\u5f0f\uff1a</p> \\[ p(x_t | x_{t+\\Delta t}) = \\exp\\left[ -\\frac{1}{2 g^2(t) \\Delta t} \\left\\| x_{t+\\Delta t} - x_t - \\left[ f_x(t) - g^2(t) \\nabla_x \\log p(x_t) \\right] \\Delta t \\right\\|^2 \\right] \\] <p>\u5199\u6210\u6b63\u6001\u5206\u5e03\u5f62\u5f0f\uff1a</p> \\[ p(x_t | x_{t+\\Delta t})\\sim \\mathcal{N}\\bigl( x_t; \\ x_{t+\\Delta t} - \\left[ f_x(t) - g^2(t) \\nabla_x \\log p(x_{t+\\Delta t}) \\right] \\Delta t, \\ g^2(t+\\Delta t) \\Delta t \\cdot I \\bigr) \\] <p>\u6c42\u6781\u9650 \\(\\Delta t\\rightarrow 0\\)\uff0c\u518d\u7531\u6761\u4ef6\u5206\u5e03\u8f6c\u5316\u4e3a SDE\uff0c\u5f97\u5230\uff1a</p> \\[ \\mathrm dx = \\left[ f[x(t), t] - g^2(t) \\nabla_x \\log p(x_t) \\right] \\mathrm dt + g(t) \\mathrm dw \\] <p>\u8fd9\u5c31\u662f\u53cd\u5411\u8fc7\u7a0b\u7684 SDE \u4e86\u3002</p> <p>\u5bf9\u4e8e \\(f, g\\) \u800c\u8a00\uff0c\u5b83\u4eec\u5b8c\u5168\u786e\u5b9a\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u4f30\u8ba1\u5f97\u5206\u51fd\u6570 \\(\\nabla_x \\log p(x_t)\\)\uff1b\u6216\u8005\u6362\u6210\u79bb\u6563\u5f62\u5f0f\u7684\u8bb0\u53f7\uff1a\\(\\nabla \\log p(x_i)\\)\u3002</p> <p>\u4f7f\u7528\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc \\(s_\\theta(x_i, i)\\) \u6765\u62df\u5408\u5f97\u5206\u51fd\u6570\uff0c\u5c31\u5f97\u5230\u76ee\u6807\u51fd\u6570\uff1a</p> \\[ \\sum_{i=1}^T \\lambda_i \\mathbb{E}_{x_i \\sim p(x_i)} \\left[ \\| s_\\theta(x_i, i) - \\nabla \\log p(x_i) \\|^2 \\right] = \\mathcal{L}_{\\mathrm{DDPM}} \\] <p>\u8fd9\u91cc \\(\\lambda_i\\) \u662f\u57fa\u4e8e \\(p(x_i)\\) \u5f15\u5165\u201c\u566a\u58f0\u5c3a\u5ea6\u4e0d\u4e00\u201d\u7684\u5f52\u4e00\u5316\u56e0\u5b50\u3002</p> <p>\u81f3\u6b64\uff0cDDPM\u3001\u5f97\u5206\u5339\u914d\u548c SDE \u7684\u7406\u8bba\u5df2\u7136\u6253\u901a\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u57fa\u4e8e\u4e30\u5bcc\u53d1\u5c55\u7684 SDE \u7406\u8bba\uff0c\u73a9\u4e00\u4e9b\u82b1\u6d3b\u4e86\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#sde-ode", "title": "\u5c06 SDE \u53d8\u6210 ODE", "text": "<p>\u8fd9\u4e00\u8282\u4ecb\u7ecd Song \u7684\u8bba\u6587\u7684\u7b2c\u4e09\u90e8\u5206\uff1a\u6982\u7387\u6d41 ODE \u7684\u63a8\u5bfc\u3002</p> <p>\u4e5f\u5c31\u662f\uff0c\u5c06</p> \\[ \\mathrm dx = \\left[ f[x(t), t] - g^2(t) \\nabla_x \\log p(x_t) \\right] \\mathrm dt + g(t) \\mathrm dw \\] <p>\u8f6c\u5316\u4e3a\u6982\u7387\u6d41 ODE\u3002</p> <p>\u6211\u4eec\u80af\u5b9a\u4e0d\u80fd\u76f4\u63a5\u628a \\(g(t) \\mathrm dw\\) \u9879\u7ed9\u4e22\u6389\uff0c\u56e0\u4e3a\u65b9\u5dee\u5f71\u54cd\u4e86 SDE \u8bf8\u591a\u89e3\u7684\u201c\u5f25\u6563\u7a0b\u5ea6\u201d\u3002\u56e0\u6b64\u6211\u4eec\u9700\u8981\u8003\u8651\u8fd9\u4e00\u9879\u5bf9\u603b\u4f53\u8d8b\u52bf\u7684\u5f71\u54cd\u3002\u6216\u8005\u6211\u4eec\u4e5f\u53ef\u4ee5\u8fd9\u6837\u770b\uff1a\u80fd\u4e0d\u80fd\u4f7f\u7528\u4ec0\u4e48\u624b\u6bb5\uff0c\u624b\u52a8\u5f15\u5165\u4e00\u4e2a\u53ef\u63a7\u7684\u65b9\u5dee\u4e5f\u5c31\u662f \\(\\sigma(t) \\mathrm dw\\) \u6765\u4ee3\u66ff\u539f\u6765\u6269\u6563\u9879\uff0c\u8fd9\u6837\u5c31\u80fd\u95f4\u63a5\u5b9e\u73b0\u6574\u5408\u3002</p> <p>\u8fd9\u4e2a\u624b\u6bb5\u5c31\u662f Fokker-Planck \u65b9\u7a0b\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#fokker-planck", "title": "\u524d\u5411\u8fc7\u7a0b\u7684 Fokker-Planck \u65b9\u7a0b", "text": "<p>\u8003\u8651\u8ba9 \\(y\\) \u548c \\(x\\) \u4e00\u4e00\u5bf9\u5e94\uff0c\u90a3\u4e48</p> \\[ p(x)=\\int \\delta(x-y)p(y)\\mathrm dy=\\mathbb E_{y}[\\delta(x-y)] \\] <p>\u90a3\u4e48\u5bf9\u4e8e \\(p(x_{t+\\Delta t})\\) \u800c\u8a00\uff1a</p> \\[ \\begin{align*}     p(x_{t+\\Delta t})&amp;=\\mathbb E_{x_{t+\\Delta t}}[\\delta(x-x_{t+\\Delta t})]\\\\     &amp;=\\mathbb E_{x_{t+\\Delta t}}[\\delta(x-x_{t}-\\Delta x)]\\\\     &amp;\\approx\\mathbb E_{x_{t+\\Delta t}}[\\delta(x-x_{t})-\\Delta x\\cdot\\nabla_x\\delta(x-x_{t})+\\dfrac 12 \\Delta x^2\\cdot\\nabla_x^2\\delta(x-x_{t})]\\\\     &amp;=\\mathbb E_{x_{t+\\Delta t}}[\\delta(x-x_{t})-(f(t)x_t\\mathrm dt)\\cdot\\nabla_x\\delta(x-x_{t})+\\dfrac 12 g^2(t)\\mathrm dt\\cdot\\nabla_x^2\\delta(x-x_{t})]\\\\     &amp;=p(x_t)-\\nabla_x [f(t)x_t p(x_t)\\mathrm dt]+\\dfrac 12g^2(t)\\mathrm dt\\nabla_x^2p(x_t) \\end{align*} \\] <p>\u6b64\u5373\u4e3a Fokker-Planck \u65b9\u7a0b\uff1a</p> \\[ \\dfrac{\\partial p}{\\partial t}=-\\nabla_x [f(t)x_t p(x_t)]+\\dfrac 12g^2(t)\\nabla_x^2p(x_t) \\]"}, {"location": "DNN/model-expr/DDPM/#_6", "title": "\u65f6\u95f4\u53cd\u6f14", "text": "<p>\u6ce8\u610f\u5230\u6574\u4e2a\u63a8\u5bfc\u662f\u548c\u524d\u5411\u8fc7\u7a0b\u7684 \\(\\mathrm dt\\) \u524d\u9762\u7684\u7cfb\u6570\u65e0\u5173\u7684\uff0c\u56e0\u6b64\u5bf9\u4e8e\u53cd\u5411\u8fc7\u7a0b\u6211\u4eec\u4e5f\u53ef\u4ee5\u5e26\u8fdb\u53bb\u5f97\u5230\uff1a</p> \\[ \\dfrac{\\partial p}{\\partial t}=\\nabla_x [ \\left[ f[x(t), t] - g^2(t) \\nabla_x \\log p(x_t) \\right] p(x_t)]+\\dfrac 12g^2(t)\\nabla_x^2p(x_t) \\] <p>\u4f46\u662f\u53cd\u5411\u8fc7\u7a0b\u662f\u65f6\u95f4\u53cd\u6f14\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u8981\u5bf9\u7b2c\u4e00\u9879\u52a0\u8d1f\u53f7\uff01</p> <p>\u7531\u4e8e\u4e8c\u9636\u9879\u524d\u9762\u7684\u7cfb\u6570\u76f4\u63a5\u5bf9\u5e94 \\(\\mathrm dw\\) \u524d\u9762\u7684\u7cfb\u6570\uff0c\u8fd9\u6837\u5c31\u7ed9\u4e86\u6211\u4eec\u64cd\u4f5c\u7a7a\u95f4\uff0c\u4e5f\u5c31\u662f\u5f15\u5165\u4e00\u4e2a \\(\\dfrac 12\\sigma^2(t)\\nabla_x^2p(x_t)\\)\uff1a</p> \\[ \\begin{align*}     \\dfrac{\\partial p}{\\partial t}&amp;=\\nabla_x [ \\left[ f[x(t), t] - g^2(t) \\nabla_x \\log p(x_t) \\right] p(x_t)]+\\dfrac 12\\nabla_x\\left([g^2(t)-\\sigma^2(t)]\\nabla_x p(x_t)\\right)+\\dfrac 12\\sigma^2(t)\\nabla_x^2p(x_t)\\\\     &amp;=\\nabla_x [ \\left[ f[x(t), t] - g^2(t) \\nabla_x \\log p(x_t) \\right] p(x_t)+\\dfrac{1}{2}[g^2(t)-\\sigma^2(t)]\\nabla_x p(x_t)]+\\dfrac 12\\sigma^2(t)\\nabla_x^2p(x_t)\\\\     &amp;=\\nabla_x [ \\left[ f[x(t), t] - \\dfrac 12\\left(g^2(t)+\\sigma^2(t)\\right) \\nabla_x \\log p(x_t) \\right] p(x_t)]+\\dfrac 12\\sigma^2(t)\\nabla_x^2p(x_t) \\end{align*} \\] <p>\u90a3\u4e48\u6211\u4eec\u6839\u636e\u8fd9\u4e2a Fokker-Planck \u65b9\u7a0b\uff0c\u5c31\u53ef\u4ee5\u5199\u51fa\u5bf9\u5e94\u7684 SDE \u4e86\uff0c\u4f46\u662f\u8fd9\u4e00\u6b21\uff0c\u65b9\u5dee\u7531\u6211\u4eec\u63a7\u5236\uff1a</p> \\[ \\mathrm dx = \\left[ f[x(t), t] - \\dfrac 12\\left(g^2(t)+\\sigma^2(t)\\right) \\nabla_x \\log p(x_t) \\right] \\mathrm dt + \\sigma(t) \\mathrm dw \\] <p>\u90a3\u4e48\u6211\u4eec\u8ba9\u65b9\u5dee\u53d8\u6210 \\(0\\)\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u5bf9\u5e94\u7684\u6982\u7387\u6d41 ODE \u4e86\uff1a</p> \\[ \\mathrm dx = \\left[ f(t)x(t) - \\dfrac 12g^2(t)\\nabla_x \\log p(x_t) \\right] \\mathrm dt \\] <p>\u4e8b\u5b9e\u4e0a\u6839\u636e\u4e4b\u524d\u7684\u7ed3\u679c\uff0c\u6211\u4eec\u662f\u5728\u7528\u795e\u7ecf\u7f51\u7edc \\(s_{\\theta}(x_t,t)\\) \u6765\u62df\u5408\u5f97\u5206\u51fd\u6570 \\(\\nabla_x \\log p(x_t)\\)\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u771f\u6b63\u9700\u8981\u5bf9\u4ed8\u7684 ODE \u662f\u8fd9\u4e2a\uff1a</p> \\[ \\mathrm dx = \\left[ f(t)x(t) - \\dfrac 12g^2(t)s_{\\theta}(x_t,t) \\right] \\mathrm dt \\] <p>\u8fd9\u4e00\u7ed3\u679c\u4e3a\u540e\u9762\u7684\u8bf8\u591a\u91c7\u6837\u5668\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u7528\u5404\u79cd\u65b9\u6cd5\u6765\u89e3\u51fa \\(x\\)\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u671f\u671b\u751f\u6210\u7684\u56fe\u7247\uff0c\u800c\u6536\u655b\u66f4\u5feb\u7684\u91c7\u6837\u5668\u53ef\u4ee5\u82b1\u8d39\u66f4\u5c11\u7684\u8ba1\u7b97\u4ee3\u4ef7\u5f97\u5230\u66f4\u7cbe\u786e\u7684\u89e3\uff0c\u4e5f\u5c31\u662f\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u7247\u3002\u800c\u8fd9\u4e00\u5207\u751a\u81f3\u53ea\u9700\u8981\u6211\u4eec\u4fee\u6539\u63a8\u7406\u7684\u4ee3\u7801\uff0c\u5b8c\u5168\u4e0d\u9700\u8981\u52a8\u57fa\u6a21\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#inference-samplers", "title": "Inference: Samplers", "text": ""}, {"location": "DNN/model-expr/DDPM/#ddpm_1", "title": "DDPM", "text": "<p>\u56de\u5fc6\u4e00\u4e0b DDPM \u7684\u8bad\u7ec3\uff1a</p> \\[ x_{i-1}=\\mu(x_i) = \\frac{1}{\\alpha_i} \\left[ x_i - \\beta_i \\varepsilon_\\theta(x_i, i) \\right] \\] <p>\u4f7f\u7528\u7684\u635f\u5931\uff1a</p> \\[ \\| \\varepsilon - \\frac{\\hat{\\beta}_i}{\\beta_i} \\varepsilon_\\theta\\left( \\hat{\\alpha}_i x_0 + \\beta_i \\varepsilon, i \\right) \\|^2=\\|\\varepsilon-s_\\theta\\|^2 \\] <p>\u4f46\u5b9e\u9645\u4e0a\u6211\u4eec\u8bad\u7ec3\u7684\u662f\u9884\u6d4b\u566a\u58f0\uff0c\u56e0\u6b64\u5f97\u5230\u7684\u662f \\(s_\\theta\\)\uff0c\u6240\u4ee5\u8981\u5f97\u5230 \\(x_{i-1}\\) \u5c31\u9700\u8981\uff1a</p> \\[ x_{i-1}= \\frac{1}{\\alpha_i} \\left[ x_i - \\dfrac{\\beta_i^2}{\\hat\\beta_i} s_\\theta(x_i, i) \\right]+\\sigma_i z,\\quad z\\sim\\mathcal{N}(0,I) \\] <p>\u5f15\u5165\u7684\u566a\u58f0\u9879\u662f\u57fa\u4e8e\u548c\u53cd\u5411\u8fc7\u7a0b\u7684\u5b8c\u5168\u5bf9\u5e94\u3002\u8fd9\u5c31\u5f97\u5230\u4e86 DDPM \u7684\u91c7\u6837\u516c\u5f0f\u3002\u4ece \\(\\mathcal N(0,1)\\) \u4e2d\u91c7\u6837\u4e00\u4e2a \\(x_T\\)\uff0c\u7136\u540e\u9010\u6b65\u5f80\u524d\u63a8\uff0c\u5c31\u80fd\u751f\u6210\u56fe\u7247\u4e86\u3002</p> <p>\u8ba9\u6211\u4eec\u770b\u770b\u4e00\u4e2a\u5728 Anime Face Dataset \u8bad\u7ec3\u7684 DDPM \u91c7\u6837 100 \u6b65\u7684\u52a8\u56fe\u5427\uff1a</p>"}, {"location": "DNN/model-expr/DDPM/#euler-ddim-dpm-solver", "title": "Euler, DDIM, DPM Solver", "text": "<p>\u672c\u8282\u4e3b\u8981\u4ecb\u7ecd arXiv:2206.00927 \u7684\u5de5\u4f5c\uff0c\u4e5f\u5c31\u662f DPM Solver\u3002</p> <p>\u5728\u6b64\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u6536\u96c6\u4e00\u4e0b\u524d\u9762\u7684\u7406\u8bba\u6210\u679c\u3002</p> <p>\u9996\u5148\uff0c\u7ecf\u8fc7\u6f2b\u957f\u7684\u7406\u8bba\u63a8\u5bfc\uff0c\u6211\u4eec\u5f97\u5230\u4e86\u8fd9\u4e2a\u6982\u7387\u6d41 ODE\uff1a</p> \\[ \\mathrm dx = \\left[ f(t)x(t) - \\dfrac 12g^2(t)s_{\\theta}(x_t,t) \\right] \\mathrm dt \\] <p>\u5176\u4e2d\u51fa\u73b0\u4e86\u5f88\u591a\u51fd\u6570\uff0c\u8fd8\u6709\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u3002\u5728\u201c\u53d8\u91cf\u66ff\u6362\u201d\u8fd9\u4e00\u5c0f\u8282\uff0c\u6211\u4eec\u5f97\u5230\uff1a</p> \\[ f(t)=-\\dfrac{\\beta(t)}{2}=\\dfrac{\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt} \\] <p>\u4ee5\u53ca</p> \\[ g^2(t)=\\beta(t)=\\dfrac{\\mathrm d \\hat \\beta^2(t)}{\\mathrm dt}-\\dfrac{2\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}\\hat \\beta^2(t) \\] <p>\u5176\u4e2d\u7684\u53c2\u6570\u51fd\u6570 \\(\\hat\\alpha\\) \u548c \\(\\hat\\beta\\) \u662f\u56fa\u5b9a\u7684\uff0c\u53ef\u4ee5\u901a\u8fc7\u6211\u4eec\u7684\u53c2\u6570\u8c03\u5ea6 \\(\\alpha_i\\) \u548c \\(\\beta_i\\) \u8f7b\u677e\u8ba1\u7b97\u51fa\u6765\u3002</p> <p>\u5176\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc \\(s_\\theta(x_t,t)\\) \u662f\u901a\u8fc7\u5f97\u5206\u5339\u914d\u5f97\u5230\u7684\uff0c\u4e5f\u5c31\u662f\u5229\u7528 \\(\\mathcal{L}_\\mathrm{DDPM}\\) \u6765\u9884\u6d4b\u566a\u58f0\u4e5f\u5c31\u662f\u8fd1\u4f3c\u5f97\u5206\u51fd\u6570\uff1a</p> \\[ s_\\theta(x_t,t)\\sim\\nabla_{x_t}\\log p(x_t|x_0)=-\\dfrac{\\hat\\varepsilon_t}{\\hat\\beta_t} \\] <p>\u73b0\u5728\u8fd9\u4e2a\u7f51\u7edc\u5df2\u7ecf\u8bad\u7ec3\u597d\u4e86\uff08\u5982\u679c\u8fd8\u6ca1\u6709\uff0c\u5feb\u53bb\u8bad\u7ec3\uff01\uff09\uff0c\u4e5f\u5c31\u662f\u6982\u7387\u6d41 ODE \u91cc\u9762\u7684 \\(f\\), \\(g^2\\) \u4ee5\u53ca \\(s_\\theta\\) \u5df2\u7ecf\u786e\u5b9a\u4e86\uff0c\u5c31\u5269\u6211\u4eec\u7684\u6837\u672c \\(x\\) \u9700\u8981\u751f\u6210\u4e86\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#euler", "title": "\u7b80\u5355 Euler \u6cd5", "text": "<p>\u6700\u7b80\u5355\u6700\u6734\u5b9e\u7684\u65b9\u6cd5\u5c31\u662f\u5c06\u6982\u7387\u6d41 ODE \u770b\u6210</p> \\[ \\mathrm{d}x = \\epsilon_\\theta(x_t, t)\\mathrm{d} t \\] <p>\u7136\u540e\u79bb\u6563\u5316\uff1a</p> \\[ \\Delta x = \\epsilon_\\theta(x_t, t)\\Delta t\\Rightarrow x_{t-1}=x_t+\\epsilon_\\theta(x_t, t)\\Delta t=[1-\\dfrac{\\beta(t)}{2T}]x_t-\\dfrac{\\beta(t)}{2T}s_\\theta \\] <p>\u6700\u540e\u5f97\u5230</p> \\[ x_{t-1}=[1-\\dfrac{\\beta(t)}{2T}]x_t-\\dfrac{\\beta(t)}{2T\\hat\\beta_t}\\varepsilon_\\theta \\] <p>\u5f53\u7136\u8fd9\u91cc\u7684\u79bb\u6563\u5316\u6211\u53ea\u6311\u4e86\u6700\u7b80\u5355\u7684\u7ebf\u6027\u8fd1\u4f3c\uff0c\u5f53\u7136\u53ef\u4ee5\u4f7f\u7528 Runge-Kutta \u6cd5\u6c42\u89e3\u3002\u540c\u65f6\u8fd8\u53ef\u4ee5\u50cf DDPM \u91c7\u6837\u5668\u4e00\u6837\uff0c\u6dfb\u5165\u4e00\u4e2a\u566a\u58f0\u9879\u5f97\u5230\u7956\u5148\u91c7\u6837\u5668\uff08\u540d\u5b57\u540e\u9762\u5e26 a \u7684\uff09\u3002</p>"}, {"location": "DNN/model-expr/DDPM/#ddim", "title": "DDIM", "text": "<p>\u6982\u7387\u6d41 ODE \u76f8\u5bf9\u6bd4\u8f83\u7279\u6b8a\uff0c\u5b83\u53ef\u4ee5\u62c6\u6210\u4e24\u534a\uff0c\u524d\u9762\u4e0d\u542b\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\uff0c\u540e\u9762\u53ea\u542b\u6709\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\uff1a</p> \\[ \\mathrm dx = \\underbrace{f(t)x(t)\\mathrm dt}_{\\mathrm{Linear\\ part}} - \\underbrace{\\dfrac 12g^2(t)s_{\\theta}(x_t,t)  \\mathrm dt}_\\mathrm{Neural\\ part} \\] <p>\u7531\u4e8e \\(f\\) \u5df2\u77e5\uff0c\u6240\u4ee5\u524d\u9762\u7684\u7ebf\u6027\u9879\u53ef\u4ee5\u7cbe\u786e\u5730\u79ef\u51fa\u6765\uff01\u4e5f\u5c31\u662f\u5229\u7528\u5e38\u6570\u53d8\u6613\u6cd5\uff1a</p> \\[ x_t=\\exp\\left(\\int_s^tf(\\tau)\\mathrm{d}\\tau\\right)x_s-\\int_s^t\\left(\\exp(\\int_\\tau^tf(r)\\mathrm{d}r)\\cdot \\dfrac 12g^2(\\tau)s_{\\theta}(x_\\tau,\\tau)\\right)\\mathrm{d}\\tau \\] <p>\u7136\u540e\u7b2c\u4e00\u9879\u5c31\u53ef\u4ee5\u76f4\u63a5\u79ef\u51fa\u6765\u4e86\uff1a</p> \\[ f(t)=\\dfrac{\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}\\Rightarrow \\exp\\left(\\int_s^tf(\\tau)\\mathrm{d}\\tau\\right)=\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(s)} \\] <p>\u5bf9 \\(g^2\\) \u505a\u4e00\u4e2a\u6362\u5143\uff1a</p> \\[ g^2(t)=\\dfrac{\\mathrm d \\hat \\beta^2(t)}{\\mathrm dt}-\\dfrac{2\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}\\hat \\beta^2(t)=2\\hat\\beta^2(t)\\left(\\dfrac{\\mathrm d\\log\\hat\\beta(t)}{\\mathrm dt}-\\dfrac{\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}\\right):=-2\\hat\\beta^2(t)\\dfrac{\\mathrm d\\lambda(t)}{\\mathrm dt} \\] <p>\u4e22\u8fdb\u524d\u9762\u7684\u5f0f\u5b50\uff1a</p> \\[ \\begin{align*}     x_t&amp;=\\exp\\left(\\int_s^tf(\\tau)\\mathrm{d}\\tau\\right)x_s-\\int_s^t\\left(\\exp(\\int_\\tau^tf(r)\\mathrm{d}r)\\cdot \\dfrac 12g^2(\\tau)s_{\\theta}(x_\\tau,\\tau)\\right)\\mathrm{d}\\tau\\\\     &amp;=\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(s)}x_s+\\int^t_s\\left(\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(\\tau)}\\hat\\beta^2(\\tau)\\dfrac{\\mathrm d\\lambda(\\tau)}{\\mathrm d\\tau}s_{\\theta}(x_\\tau,\\tau)\\right)\\mathrm{d}\\tau\\\\     &amp;=\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(s)}x_s-\\hat\\alpha(t)\\int^t_s\\left(\\dfrac{\\hat\\beta(\\tau)}{\\hat\\alpha(\\tau)}\\dfrac{\\mathrm d\\lambda(\\tau)}{\\mathrm d\\tau}\\varepsilon_{\\theta}(x_\\tau,\\tau)\\right)\\mathrm{d}\\tau\\\\     &amp;=\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(s)}x_s-\\hat\\alpha(t)\\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\varepsilon_{\\theta}(x_{\\lambda},\\lambda)\\mathrm{d}\\lambda \\end{align*} \\] <p>\u6700\u540e\u4e00\u6b65\u662f\u6362\u5143\uff0c\u5229\u7528\u4e86\uff1a</p> \\[ \\dfrac{\\mathrm d\\log\\hat\\beta(t)}{\\mathrm dt}-\\dfrac{\\mathrm d \\log\\hat\\alpha(t)}{\\mathrm dt}=\\dfrac{\\mathrm d \\log\\dfrac{\\hat\\beta(t)}{\\hat\\alpha(t)}}{\\mathrm dt}=-\\dfrac{\\mathrm d\\lambda(t)}{\\mathrm dt} \\] <p>\u4e0b\u9762\u7684\u4efb\u52a1\u662f\u5bf9\u79ef\u5206</p> \\[ \\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\varepsilon_{\\theta}(x_{\\lambda},\\lambda)\\mathrm{d}\\lambda \\] <p>\u8fdb\u884c\u8fd1\u4f3c\u3002\u6211\u4eec\u8003\u8651\u6700\u7b80\u5355\u7684\u8fd1\u4f3c\u6cd5\uff0c\u628a\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u770b\u4f5c\u5e38\u91cf\uff1a</p> \\[ \\begin{align*}     \\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\varepsilon_{\\theta}(x_{\\lambda},\\lambda)\\mathrm{d}\\lambda&amp;\\approx\\varepsilon_{\\theta}(x_{\\lambda_s},\\lambda_s)\\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\mathrm{d}\\lambda\\\\     &amp;=(e^{-\\lambda_s}-e^{-\\lambda_t})\\varepsilon_{\\theta}(x_{\\lambda_s},\\lambda_s)\\\\     &amp;=e^{-\\lambda_t}(e^{h_i}-1)\\varepsilon_{\\theta}(x_{\\lambda_s},\\lambda_s)\\\\     &amp;=\\dfrac{\\hat\\beta(t)}{\\hat\\alpha(t)}(e^{h_i}-1)\\varepsilon_{\\theta}(x_{\\lambda_s},\\lambda_s),\\quad h_i=\\lambda_t-\\lambda_s \\end{align*} \\] <p>\u8fd9\u6837\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u4e00\u9636\u8fd1\u4f3c\uff0c\u4e5f\u5c31\u662f DDIM \u91c7\u6837\u5668\uff1a</p> \\[ x_{t-1}=\\dfrac{\\hat\\alpha(t)}{\\hat\\alpha(t-1)}x_t-\\hat\\beta(t)(e^{h_i}-1)\\varepsilon_{\\theta}(x_{\\lambda_{t-1}},\\lambda_{t-1}),\\quad h_i=\\lambda_t-\\lambda_{t-1} \\]"}, {"location": "DNN/model-expr/DDPM/#dpm-solvers", "title": "DPM Solvers", "text": "<p>\u5176\u5b9e\u8fd9\u4e2a\u79ef\u5206</p> \\[ \\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\varepsilon_{\\theta}(x_{\\lambda},\\lambda)\\mathrm{d}\\lambda \\] <p>\u8fd8\u6709\u66f4\u597d\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002\u521a\u521a\u662f\u628a \\(\\varepsilon_{\\theta}(x_{\\lambda},\\lambda)\\) \u4f30\u8ba1\u6210\u5e38\u6570\uff0c\u4f46\u6211\u4eec\u4e5f\u53ef\u4ee5\u5bf9\u5176\u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\uff1a</p> \\[ \\varepsilon_{\\theta}(x_{\\lambda},\\lambda)=\\sum^{k-1}_{n=0}\\varepsilon_{\\theta}^{(n)}(x_{\\lambda_{i-1}},\\lambda_{i-1})\\cdot\\dfrac{(\\lambda-\\lambda_{i-1})^n}{n!} \\] <p>\u5bf9\u5404\u9636\u5bfc\u6570\u4f30\u8ba1\u5230\u5e38\u6570\uff0c\u5c31\u53ea\u5269\u4e0b\u4e86</p> \\[ \\int^{\\lambda_t}_{\\lambda_s}e^{-\\lambda}\\dfrac{(\\lambda-\\lambda_{i-1})^n}{n!}\\mathrm{d}\\lambda \\] <p>\u8981\u6c42\u51fa\u6765\uff0c\u800c\u8fd9\u662f\u4e00\u4e2a\u6b63\u6574\u6570\u6b21\u6570\u591a\u9879\u5f0f\u4e58\u4ee5\u6307\u6570\u7684\u79ef\u5206\uff0c\u5b8c\u5168\u53ef\u4ee5\u4f7f\u7528\u5206\u90e8\u79ef\u5206\u6cd5\u89e3\u51fa\u89e3\u6790\u89e3\uff01</p> <p>\u6211\u4eec\u53d6\u524d \\(k\\) \u9636\u6cf0\u52d2\u5c55\u5f00\u5f97\u5230\u7684\u91c7\u6837\u5668\uff0c\u5c31\u53eb\u505a DPM-Solver-k\u3002\u5177\u4f53\u7684\u79ef\u5206\u8ba1\u7b97\uff0c\u53ef\u4ee5\u4ea4\u7ed9 Mathematica \u5f97\u5230\u95ed\u5f0f\u89e3\u3002\u4e8e\u662f\u53ef\u4ee5\u5f97\u5230\u8bba\u6587\u91cc\u9762\u7684\u91c7\u6837\u5668\u6d41\u7a0b\u4e86\uff1a</p> <p>DPM-Solver-2:</p> \\[ \\begin{align*} &amp;\\mathrm{Require}: \\text{ initial value } x_T, \\text{ time steps } \\{t_i\\}_{i=0}^M, \\text{ model } \\epsilon_\\theta \\\\ &amp;\\tilde{x}_{t_0} \\leftarrow x_T \\\\ &amp;\\mathrm{for} \\ i \\leftarrow 1 \\ \\mathrm{to} \\ M \\ \\mathrm{do} \\\\ &amp;\\quad s_i \\leftarrow \\lambda \\left( \\frac{\\lambda t_{i-1} + \\lambda t_i}{2} \\right) \\\\ &amp;\\quad u_i \\leftarrow \\frac{\\alpha_{s_i}}{\\alpha_{t_{i-1}}} \\tilde{x}_{t_{i-1}} - \\sigma_{s_i} \\left( e^{\\frac{h_i}{2}} - 1 \\right) \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) \\\\ &amp;\\quad \\tilde{x}_{t_i} \\leftarrow \\frac{\\alpha_{t_i}}{\\alpha_{t_{i-1}}} \\tilde{x}_{t_{i-1}} - \\sigma_{t_i} \\left( e^{h_i} - 1 \\right) \\epsilon_\\theta(u_i, s_i) \\\\ &amp;\\mathrm{end \\ for} \\\\ &amp;\\mathrm{return} \\ \\tilde{x}_{t_M} \\end{align*} \\] <p>\u4ee5\u53ca DPM-Solver-3:</p> \\[ \\begin{align*} &amp;\\mathrm{Require}: \\text{ initial value } x_T, \\text{ time steps } \\{t_i\\}_{i=0}^M, \\text{ model } \\epsilon_\\theta \\\\ &amp;\\tilde{x}_{t_0} \\leftarrow x_T, \\ r_1 \\leftarrow \\frac{1}{3}, \\ r_2 \\leftarrow \\frac{2}{3} \\\\ &amp;\\mathrm{for} \\ i \\leftarrow 1 \\ \\mathrm{to} \\ M \\ \\mathrm{do} \\\\ &amp;\\quad s_{2i-1} \\leftarrow t_\\lambda \\left( \\lambda t_{i-1} + r_1 h_i \\right), \\quad s_{2i} \\leftarrow t_\\lambda \\left( \\lambda t_{i-1} + r_2 h_i \\right) \\\\ &amp;\\quad u_{2i-1} \\leftarrow \\frac{\\alpha_{s_{2i-1}}}{\\alpha_{t_{i-1}}} \\tilde{x}_{t_{i-1}} - \\sigma_{s_{2i-1}} \\left( e^{r_1 h_i} - 1 \\right) \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) \\\\ &amp;\\quad D_{2i-1} \\leftarrow \\epsilon_\\theta(u_{2i-1}, s_{2i-1}) - \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) \\\\ &amp;\\quad u_{2i} \\leftarrow \\frac{\\alpha_{s_{2i}}}{\\alpha_{t_{i-1}}} \\tilde{x}_{t_{i-1}} - \\sigma_{s_{2i}} \\left( e^{r_2 h_i} - 1 \\right) \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) - \\frac{\\sigma_{s_{2i}} r_2}{r_1} \\left( \\frac{e^{r_2 h_i} - 1}{r_2 h_i} - 1 \\right) D_{2i-1} \\\\ &amp;\\quad D_{2i} \\leftarrow \\epsilon_\\theta(u_{2i}, s_{2i}) - \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) \\\\ &amp;\\quad \\tilde{x}_{t_i} \\leftarrow \\frac{\\alpha_{t_i}}{\\alpha_{t_{i-1}}} \\tilde{x}_{t_{i-1}} - \\sigma_{t_i} \\left( e^{h_i} - 1 \\right) \\epsilon_\\theta(\\tilde{x}_{t_{i-1}}, t_{i-1}) - \\frac{\\sigma_{t_i}}{r_2} \\left( \\frac{e^{h_i} - 1}{h_i} - 1 \\right) D_{2i} \\\\ &amp;\\mathrm{end \\ for} \\\\ &amp;\\mathrm{return} \\ \\tilde{x}_{t_M} \\end{align*} \\]"}, {"location": "DNN/model-expr/DDPM/#appendices", "title": "Appendices", "text": ""}, {"location": "DNN/model-expr/DDPM/#i", "title": "I. \u5e03\u6717\u8fd0\u52a8\u7684\u4e8c\u6b21\u53d8\u5206", "text": "<p>\u6211\u4eec\u8981\u63a8\u5bfc\u4e00\u4e2a\u5e03\u6717\u8fd0\u52a8 \\(B(t)\\) \u6ee1\u8db3 \\(\\mathrm dB=\\sqrt{\\mathrm dt}\\)\uff0c\u5373 \\((\\mathrm{d}B)^2=\\mathrm{d}t\\)\u3002</p> <p>\u6211\u4eec\u6362\u6210\u79ef\u5206\u5f0f\uff0c\u4e5f\u5c31\u662f\u5728 \\([0,T]\\) \u5185\u6709</p> \\[ \\int_0^T (\\mathrm{d}B)^2=\\int_0^T\\mathrm{d}t=T \\] <p>\u6362\u6210\u5b9a\u4e49\u5f0f\uff0c\u4e5f\u5c31\u662f\u5bf9\u8be5\u533a\u95f4\u7684\u4e00\u4e2a\u5212\u5206 \\(\\Pi\\)\uff0c\u6700\u5927\u6b65\u957f\u8bb0\u4f5c \\(|\\Pi|\\)\uff0c\u7136\u540e\u8bc1\u660e\u6781\u9650\uff1a</p> \\[ \\lim_{|\\Pi|\\rightarrow0}\\sum_{i}[B(t_{i+1})-B(t_i)]^2=\\lim_{|\\Pi|\\rightarrow0} S_n=T \\] <p>\u8fd9\u5c31\u662f\u5e03\u6717\u8fd0\u52a8\u7684\u4e8c\u6b21\u53d8\u5206\u3002\u7531\u4e8e\u5e03\u6717\u8fd0\u52a8\u7684\u72ec\u7acb\u6027\uff0c\u6709</p> \\[ B(t_{i+1})-B(t_i)=\\Delta B_i\\sim N(0,\\Delta t_i) \\] <p>\u5219\u6839\u636e\u6b63\u6001\u5206\u5e03\u4e8c\u9636\u77e9\u7684\u6027\u8d28\uff0c \\(\\mathbb{E}[(\\Delta B_i)^2]=\\Delta t_i\\)\uff0c\u53e0\u5728\u4e00\u8d77\u5c31\u53ef\u4ee5\u5f97\u5230</p> \\[ \\mathbb{E}[S_n]=\\sum\\Delta t_i=\\int_0^T\\mathrm{d}t=T \\] <p>\u800c \\(\\mathrm{Var}[(\\Delta B_i)^2]=\\mathbb{E}[(\\Delta B_i)^4]-\\mathbb{E}[(\\Delta B_i)^2]^2=3(\\Delta t_i)^2-(\\Delta t_i)^2=2(\\Delta t_i)^2\\)\uff0c\u5373</p> \\[ \\mathrm{Var}[S_n]=\\sum 2(\\Delta t_i)^2\\le 2|\\Pi|T \\] <p>\u6545 \\(|\\Pi|\\to 0\\) \u5219 \\(\\mathrm{Var}[S_n]\\to 0\\)\uff0c\u6839\u636e\u5927\u6570\u5b9a\u5f8b\uff0c</p> \\[ \\lim_{|\\Pi|\\rightarrow0} S_n=\\lim_{|\\Pi|\\rightarrow0} \\mathbb{E}[S_n]=T \\] <p>\u8fd9\u6837\u5c31\u5f97\u5230\u4e86 \\((\\mathrm{d}B)^2=\\mathrm{d}t\\)\u3002</p> <p>\u9898\u5916\u8bdd\uff1a\u7531\u4e8e\u5e03\u6717\u8fd0\u52a8\u662f\u5904\u5904\u8fde\u7eed\u5904\u5904\u4e0d\u53ef\u5bfc\u7684\uff0c\u8fd9\u624d\u5bfc\u81f4\u4e86\u5176\u4e8c\u6b21\u53d8\u5206\u7684\u503c\u4e0d\u4e3a\u96f6\u3002\u8003\u8651\u4e00\u4e2a\u8fde\u7eed\u51fd\u6570 \\(f\\)\uff0c\u6211\u4eec\u6765\u8003\u8651\u5176\u4e8c\u6b21\u53d8\u5206\uff0c\u5229\u7528\u4e2d\u503c\u5b9a\u7406\uff1a</p> \\[ \\begin{align*}     \\lim_{|\\Pi|\\rightarrow0}\\sum_{i}[f(t_{i+1})-f(t_i)]^2&amp;=\\lim_{|\\Pi|\\rightarrow0}\\sum_{i}[\\Delta t_i f'(s_i)]^2\\\\     &amp;\\le \\lim_{|\\Pi|\\rightarrow0}|\\Pi|\\sup_{x\\in[0,T]} f(x) \\sum_i\\Delta t_i\\\\     &amp;=\\lim_{|\\Pi|\\rightarrow0}|\\Pi|\\sup_{x\\in[0,T]} f(x) T\\\\     &amp;=\\lim_{|\\Pi|\\rightarrow0}O(|\\Pi|)\\\\     &amp;=0 \\end{align*} \\] <p>\u8fd9\u5176\u5b9e\u63ed\u793a\u4e86\u968f\u673a\u8fc7\u7a0b\u548c\u8fde\u7eed\u8fc7\u7a0b\u86ee\u672c\u672c\u8d28\u7684\u4e00\u4e2a\u533a\u522b\u70b9\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 9, 2025). \u6269\u6563\u6a21\u578b\u7406\u8bba\u7bc7: \u4ece\u591a\u9636\u6bb5\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5230\u6982\u7387\u6d41\u5e38\u5fae\u5206\u65b9\u7a0b\u91c7\u6837\u5668\u7cfb\u5217 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-expr/DDPM</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{DDPM,\n    title={\u6269\u6563\u6a21\u578b\u7406\u8bba\u7bc7: \u4ece\u591a\u9636\u6bb5\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5230\u6982\u7387\u6d41\u5e38\u5fae\u5206\u65b9\u7a0b\u91c7\u6837\u5668\u7cfb\u5217},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-expr/DDPM}},\n}\n</code></pre></p>"}, {"location": "DNN/model-expr/Image-models-replication/", "title": "\u56fe\u50cf\u5206\u7c7b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 128 \u5206\u949f\u3000|\u3000\u7ea6 13908 \u5b57\u3000\u26a0\ufe0f \u4e07\u5b57\u957f\u6587\uff0c\u8bf7\u6162\u6162\u9605\u8bfb\u3000|\u3000\u7ea6 223 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 3656 \u884c\u4ee3\u7801</p> <p>\u8fd9\u662f\u6a21\u578b\u590d\u73b0\u624b\u8bb0\u7684\u7b2c\u4e00\u7bc7\uff0c\u4e3b\u8981\u6311\u51e0\u4e2a\u7ecf\u5178\u6216\u8005\u90aa\u95e8\u7684\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u590d\u73b0\u3002\u76f8\u5173\u6a21\u578b\u7684\u67b6\u6784\u548c\u7406\u8bba\u5728\u7f51\u4e0a\u90fd\u6709\u8bf8\u591a\u7684\u8ba8\u8bba\u4e86\uff0c\u672c\u6587\u5c31\u4ec5\u505a\u7b80\u5355\u7684\u63a8\u5bfc\u800c\u5df2\u3002</p> <p>\u524d\u9762\u7684 MLP, CNN, ResNet, ViT \u90fd\u662f\u7ecf\u5178\u7684\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\uff0c\u540e\u9762\u51c6\u5907\u4ecb\u7ecd\u7684\u662f\u51e0\u4e2a\u90aa\u95e8\u7684\u6a21\u578b\uff0c\u5373\u53c2\u8003 ViT \u601d\u60f3\u7684 Patch based LSTM \u4ee5\u53ca\u4e24\u4e2a\u534a\u76d1\u7763\u7684\u751f\u6210\u6a21\u578b\uff0c\u5373 VAE \u548c AC-GAN\u3002\u90aa\u95e8\u6a21\u578b\u4e4b\u6240\u4ee5\u90aa\u95e8\uff0c\u4e3b\u8981\u5728\u4e8e\u5b83\u80fd\u7ed9\u6211\u4e00\u79cd\u521d\u770b\u89c9\u5f97 \u201c\u5367\u69fd\u8fd9\u4e5f\u80fd\u7f16\u7801\u56fe\u50cf\u6570\u636e\u505a\u5206\u7c7b\u201d \u800c\u7ec6\u770b\u53c8\u89c9\u5f97 \u201c\u600e\u4e48\u8fd9\u4e48\u5408\u7406\u554a\u201d \u7684\u611f\u89c9\u3002</p> <p>\u800c\u672c\u6587\u6b63\u662f\u57fa\u4e8e\u7b14\u8005\u5bf9\u6a21\u578b\u67b6\u6784\u7684\u8ba4\u77e5\uff0c\u9488\u5bf9\u590d\u73b0\u65f6\u9047\u5230\u7684\u8bb8\u591a\u73b0\u8c61\u63d0\u51fa\u81ea\u5df1\u7684\u7406\u89e3\u3002\u56e0\u6b64\u5fc5\u7136\u4f1a\u6709\u503c\u5f97\u5546\u69b7\u4e4b\u5904\u3002\u4e5f\u6b22\u8fce\u5927\u5bb6\u5728\u8bc4\u8bba\u533a\u8ba8\u8bba\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#_2", "title": "\u590d\u73b0\u4f7f\u7528\u7684\u4ee3\u7801\u6846\u67b6", "text": "<p>\u9664\u4e86\u540e\u9762\u7684\u751f\u6210\u5f0f\u6a21\u578b\uff0c\u672c\u6587\u7684\u4e00\u7cfb\u5217\u590d\u73b0\u57fa\u4e8e\u4e0b\u9762\u7684\u4ee3\u7801\uff0c\u4ee3\u7801\u8fd0\u884c\u5728 Kaggle \u7684 Jupyter Notebook \u4e0a\u9762\u3002\u6240\u4ee5\u6211\u6839\u636e Notebook \u7684\u6bcf\u4e00\u4e2a Cell \u6765\u7ed9\u51fa\u4ee3\u7801\u3002</p> <p>\u8fd9\u4e2a\u4ee3\u7801\u6846\u67b6\u7684\u5927\u81f4\u4ecb\u7ecd\u662f\uff1a\u901a\u8fc7\u6a21\u578b\u66b4\u9732\u7684\u4e00\u4e2a\u63a5\u53e3\u51fd\u6570 <code>get_model_on_device()</code> \u83b7\u53d6\u6a21\u578b\u5b9e\u4f8b\uff0c\u7136\u540e\u4f7f\u7528 hyperopt \u6846\u67b6\uff0c\u5728 CIFAR-10 \u6570\u636e\u96c6\u4e0a\u5206\u5272 20% \u6570\u636e\u7528\u4ee5\u5bf9\u6a21\u578b\u8fdb\u884c\u5168\u5c40\u5b66\u4e60\u7387\u548c\u8bad\u7ec3\u8f6e\u6b21\u7684\u65e9\u505c\u6cd5\u8c03\u53c2\uff1b\u83b7\u53d6\u6700\u4f18\u53c2\u6570\u540e\uff0c\u5728\u5168\u91cf\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u6536\u96c6\u8bad\u7ec3\u4fe1\u606f\u5f97\u5230\u7ed3\u679c\u548c\u90e8\u5206\u6570\u636e\u53d8\u5316\u7684\u53ef\u89c6\u5316\u56fe\u50cf\u3002</p> <p>\u7531\u4e8e\u6bcf\u4e00\u6b21\u90fd\u8981\u82b1\u5927\u91cf\u65f6\u95f4\u5bfb\u627e\u5408\u9002\u7684\u5b66\u4e60\u7387\uff0c\u7b14\u8005\u82b1\u4e86\u4e00\u5929\u65f6\u95f4\u7814\u7a76\u4e86\u4e00\u4e0b muP\uff08Paper link here\uff09 \u7684\u539f\u7406\u4ee5\u53ca\u600e\u6837\u8fc1\u79fb\u5b66\u4e60\u7387\uff0c\u7ed3\u8bba\uff1a\u5728\u5df2\u6709\u6570\u636e\u4e0a\uff08MLP, CNN, ResNet-18\uff09\u8fdb\u884c\u7684\u5b9e\u9a8c\u548c\u76f8\u5173\u7406\u8bba\u8ba1\u7b97\u8bc1\u660e\uff0c\u6a21\u578b\u67b6\u6784\uff08\u6b8b\u5dee\u8fde\u63a5\uff0cBN \u7b49\uff09\u4f1a\u5f71\u54cd\u635f\u5931\u5730\u5f62\uff08Paper link here\uff09\uff0c\u5bfc\u81f4\u8de8\u67b6\u6784\u7684\u5b66\u4e60\u7387\u8fc1\u79fb\u5931\u6548\u3002\u5176\u5b9e\u5f88\u660e\u663e\uff0c\u6bd4\u5982\u5fae\u8c03 ResNet \u5c31\u6bd4\u4ece\u96f6\u8bad\u7ec3 ResNet \u7684 best LR\u66f4\u4f4e\uff0c\u56e0\u4e3a\u9884\u8bad\u7ec3\u6743\u91cd\u5df2\u7ecf\u5728\u4e00\u4e2a\u6700\u5c0f\u503c\u9644\u8fd1\u4e86\uff0c\u635f\u5931\u5730\u5f62\u6bd4\u8d77\u968f\u673a\u70b9\u4f4d\u66f4\u5e73\u5766\u3002\u6240\u4ee5\u8be5\u82b1\u65f6\u95f4\u8c03\u53c2\u8fd8\u5f97\u82b1\u65f6\u95f4\u8c03\u53c2\u3002\u4e0d\u8fc7\uff0c\u53ef\u4ee5\u8003\u8651\u5728\u5c0f\u5bbd\u5ea6\u6a21\u578b\u4e0a\u518d scale up\uff0c\u8fd9\u6837\u5c31\u7b26\u5408 muP \u7684\u521d\u5fc3\u4e86\u3002\u5177\u4f53\u7684\u5b9e\u9a8c\u8fc7\u7a0b\uff0c\u8fd8\u8bf7\u5927\u5bb6\u53c2\u9605\u540e\u6587\u3002\u4e0d\u8fc7\u7b14\u8005\u5728\u8fd9\u4e0a\u9762\u63a2\u7d22\u4e0d\u591a\uff0c\u6bd5\u7adf\u4e3b\u8981\u505a\u7684\u662f\u8de8\u67b6\u6784\u7684\u590d\u73b0\u5de5\u4f5c\u3002\u540e\u9762\u7684\u8bad\u7ec3\u786e\u5b9e\u5f97\u82b1\u6bd4\u8f83\u591a\u7684\u65f6\u95f4\u7c97\u8c03\u5b66\u4e60\u7387\u3002</p> <p>\u5f53\u7136\uff0c\u8fd9\u4e2a\u6846\u67b6\u4e5f\u6709\u7f3a\u9677\uff0c\u4e3b\u8981\u662f\u5b83\u53ea\u80fd\u5bf9\u7aef\u5230\u7aef\u7684\u7f51\u7edc\u8fdb\u884c\u4e00\u952e\u5f0f\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u50cf VAE \u548c AC-GAN \u8fd9\u79cd\u6807\u7b7e\u8f85\u52a9\u7684\u751f\u6210\u7f51\u7edc\uff0c\u5c31\u9700\u8981\u81ea\u884c\u4fee\u6539\u4e86\u3002</p> <p>\u4e0b\u9762\u662f\u6bcf\u4e00\u4e2a Cell \u7684\u4ee3\u7801\uff1a</p>  Cell 1: \u5f15\u5165\u5fc5\u8981\u7684\u5e93\u4ee5\u53ca\u8bbe\u7f6e\u8bbe\u5907  <pre><code>import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, random_split, Subset\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\n\n# \u5bfc\u5165 hyperopt \u7528\u4e8e\u8d85\u53c2\u6570\u8c03\u4f18\nfrom hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n\n# \u5bfc\u5165 tqdm\uff0c\u5728 jupyter \u4e2d\u4f7f\u7528 notebook \u7248\u672c\nfrom tqdm.notebook import tqdm\n\n# torch.manual_seed(3407) is all you need!\n# \u4e3a\u4e86\u5b9e\u9a8c\u590d\u73b0\u6027\u4f7f\u7528\u7684\u624b\u52a8\u79cd\u5b50\u3002\ntorch.manual_seed(3407)\n\n# \u8bbe\u7f6e\u8bbe\u5907\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"using device: {device}\")\n</code></pre>  Cell 2: \u8c03\u4f18\u548c\u8bad\u7ec3\u4f7f\u7528\u7684\u53c2\u6570  <pre><code># --- Hyperopt \u8c03\u4f18\u53c2\u6570 ---\nTUNE_DATA_PERCENT = 0.2     # \u4f7f\u7528 20% \u7684\u6570\u636e\u8fdb\u884c\u5feb\u901f\u8c03\u4f18\nTUNE_MAX_EPOCHS = 50        # \u8c03\u4f18\u65f6\uff0c\u6bcf\u4e2a\u8bd5\u9a8c\u6700\u591a\u8bad\u7ec3\u7684 epoch \u6570\nPATIENCE = 5                # \u65e9\u505c\u6cd5\uff1a\u9a8c\u8bc1\u635f\u5931\u8fde\u7eed 5 \u4e2a epoch \u6ca1\u6709\u6539\u5584\u5c31\u505c\u6b62\nMAX_EVALS = 20              # \u8c03\u4f18\u603b\u5171\u5c1d\u8bd5\u7684\u6b21\u6570\nLR_SEARCH_RANGE = (-10, -4) # \u5b66\u4e60\u7387\u5bf9\u6570\u641c\u7d22\u8303\u56f4\uff0c\u4e5f\u5c31\u662f exp(-4)~exp(-10) \u5927\u6982 2e-2 \u52304e-5 \u4e4b\u95f4\n\n# --- \u6700\u7ec8\u8bad\u7ec3\u53c2\u6570\uff0c\u8fd9\u91cc\u53ea\u662f\u58f0\u660e\uff0c\u5177\u4f53\u503c\u7531\u8c03\u4f18\u8fc7\u7a0b\u51b3\u5b9a ---\nBEST_LEARNING_RATE = None\nBEST_EPOCHS = None\nBATCH_SIZE = 128\n</code></pre>  Cell 3: \u7ed8\u56fe\u548c\u8bc4\u4f30\u76f8\u5173\u51fd\u6570  <pre><code>def evaluate_model(model, data_loader, criterion, device):\n    \"\"\"\u8bc4\u4f30\u6a21\u578b\uff0c\u8fd4\u56de\u5e73\u5747\u635f\u5931\u548c\u51c6\u786e\u7387\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in data_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * images.size(0)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    avg_loss = total_loss / total\n    accuracy = 100 * correct / total\n    return avg_loss, accuracy\n\ndef count_parameters(model):\n    \"\"\"\u8ba1\u7b97\u6a21\u578b\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\"\"\"\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef plot_and_save_history(history, filename=\"training_curves.png\"):\n    \"\"\"\u7ed8\u5236\u5e76\u4fdd\u5b58\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u635f\u5931\u548c\u51c6\u786e\u7387\u66f2\u7ebf\"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n\n    # \u7ed8\u5236\u635f\u5931\u66f2\u7ebf (\u8bad\u7ec3 vs \u9a8c\u8bc1/\u6d4b\u8bd5)\n    ax1.plot(history['train_loss'], label='Training Loss', color='blue')\n    if 'val_loss' in history:\n        ax1.plot(history['val_loss'], label='Validation Loss', color='green')\n    ax1.set_title('Loss over Epochs', fontsize=16)\n    ax1.set_xlabel('Epoch', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.grid(True)\n    ax1.legend()\n\n    # \u7ed8\u5236\u51c6\u786e\u7387\u66f2\u7ebf\n    if 'val_accuracy' in history:\n        ax2.plot(history['val_accuracy'], label='Validation Accuracy', color='orange')\n    ax2.set_title('Accuracy over Epochs', fontsize=16)\n    ax2.set_xlabel('Epoch', fontsize=12)\n    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n    ax2.grid(True)\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.savefig(filename, bbox_inches='tight')\n    print(f\"Traing curve saved at {filename}\")\n    plt.show()\n</code></pre>  Cell 4: \u5b9a\u4e49\u6a21\u578b  <pre><code>\"\"\"\n\u8fd9\u91cc\u4f7f\u7528 MLP \u4f5c\u4e3a\u793a\u4f8b\u3002\u4e3a\u4e86\u4fdd\u8bc1\u6846\u67b6\u548c\u6a21\u578b\u89e3\u8026\uff0c\u7edf\u4e00\u53ea\u66b4\u9732\u4e00\u4e2a get_model_on_device \u7684\u65e0\u53c2\u6570\u51fd\u6570\u7528\u4ee5\u8fd4\u56de\u65b0\u7684\u6a21\u578b\u5b9e\u4f8b\u3002\n\"\"\"\n\n# \u6a21\u578b\u7ed3\u6784\u53c2\u6570\nINPUT_SIZE = 32 * 32 * 3\nHIDDEN_SIZE_1 = 512\nHIDDEN_SIZE_2 = 256\n\nclass MLP(nn.Module):\n    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_classes):\n        super(MLP, self).__init__()\n        self.network = nn.Sequential(\n            nn.Flatten(), # \u5c06 3x32x32 \u7684\u56fe\u50cf\u5c55\u5e73\u6210\u4e00\u7ef4\u5411\u91cf\n            nn.Linear(input_size, hidden_size_1),\n            nn.ReLU(),\n            nn.Linear(hidden_size_1, hidden_size_2),\n            nn.ReLU(),\n            nn.Linear(hidden_size_2, num_classes)\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\n# \u5bf9\u5916\u63a5\u53e3\uff0c\u65b9\u4fbf\u540e\u7eed\u5b9e\u9a8c\u6539\u6a21\u578b\u7ed3\u6784\ndef get_model_on_device():\n    return MLP(INPUT_SIZE, HIDDEN_SIZE_1, HIDDEN_SIZE_2, NUM_CLASSES).to(device)\n</code></pre>  Cell 5: \u52a0\u8f7d\u5e76\u5212\u5206\u6570\u636e\u96c6  <pre><code># \u6570\u636e\u96c6\u53c2\u6570\nNUM_CLASSES = 10\n\n# \u5b9a\u4e49\u6570\u636e\u9884\u5904\u7406\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        (0.4914, 0.4822, 0.4465), \n        (0.2023, 0.1994, 0.2010)\n    )\n])\n\n# \u52a0\u8f7d\u5b8c\u6574\u7684 CIFAR-10 \u8bad\u7ec3\u96c6\nfull_train_dataset = torchvision.datasets.CIFAR10(\n    root='./data', \n    train=True, \n    transform=transform, \n    download=True\n)\n\n# --- \u4e3a\u8c03\u4f18\u521b\u5efa\u5c0f\u89c4\u6a21\u6570\u636e\u96c6 ---\nnum_total_train = len(full_train_dataset)\ntune_subset_size = int(num_total_train * TUNE_DATA_PERCENT)\n\n# \u968f\u673a\u62bd\u53d6 20% \u7684\u6570\u636e\u7d22\u5f15\nindices = torch.randperm(num_total_train).tolist()\ntune_indices = indices[:tune_subset_size]\n\n# \u521b\u5efa\u4e00\u4e2a\u53ea\u5305\u542b\u8fd9 20% \u6570\u636e\u7684\u6570\u636e\u96c6\u5b50\u96c6\ntune_dataset = Subset(full_train_dataset, tune_indices)\n\n# \u5c06\u8fd9\u4e2a\u5b50\u96c6\u518d\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 (80% train, 20% val)\nnum_tune = len(tune_dataset)\nval_size_tune = int(num_tune * 0.2)\ntrain_size_tune = num_tune - val_size_tune\ntrain_subset_tune, val_subset_tune = random_split(tune_dataset, [train_size_tune, val_size_tune])\n\n# \u521b\u5efa\u7528\u4e8e\u8c03\u4f18\u7684\u6570\u636e\u52a0\u8f7d\u5668\ntrain_loader_tune = DataLoader(dataset=train_subset_tune, batch_size=BATCH_SIZE, shuffle=True)\nval_loader_tune = DataLoader(dataset=val_subset_tune, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(f\"total samples being used for hyperopt: {len(tune_dataset)}\")\nprint(f\"Train set size: {len(train_subset_tune)}\")\nprint(f\"Validation set size: {len(val_subset_tune)}\")\n</code></pre>  Cell 6: \u4f7f\u7528 hyperopt \u5bf9\u6a21\u578b\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22  <pre><code>def objective(params):\n    \"\"\"Hyperopt \u4f18\u5316\u7684\u76ee\u6807\u51fd\u6570\"\"\"\n    lr = params['lr']\n\n    model = get_model_on_device()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_val_loss = float('inf')\n    epochs_no_improve = 0\n    best_epoch = 0\n\n    # \u4f7f\u7528 tqdm \u53ef\u89c6\u5316\u6bcf\u4e2a trial \u7684 epoch \u8fdb\u5ea6\n    epoch_iterator = tqdm(range(TUNE_MAX_EPOCHS), desc=f\"LR {lr:.6f}\", leave=False)\n    for epoch in epoch_iterator:\n        model.train()\n        for images, labels in train_loader_tune:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        val_loss, val_accuracy = evaluate_model(model, val_loader_tune, criterion, device)\n\n        # \u66f4\u65b0\u8fdb\u5ea6\u6761\u663e\u793a\u5f53\u524d\u9a8c\u8bc1\u635f\u5931\n        epoch_iterator.set_postfix({'val_loss': f'{val_loss:.4f}'})\n\n        if val_loss &lt; best_val_loss:\n            best_val_loss = val_loss\n            epochs_no_improve = 0\n            best_epoch = epoch + 1\n        else:\n            epochs_no_improve += 1\n\n        if epochs_no_improve == PATIENCE:\n            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n            break\n\n    return {'loss': best_val_loss, 'status': STATUS_OK, 'best_epoch': best_epoch}\n\n# \u5b9a\u4e49\u5b66\u4e60\u7387\u7684\u641c\u7d22\u7a7a\u95f4\nspace = {'lr': hp.loguniform('lr', *LR_SEARCH_RANGE)}\n\nprint(\"--- Start finding best hyper parameters ---\")\ntrials = Trials()\nbest_params = fmin(\n    fn=objective,\n    space=space,\n    algo=tpe.suggest,\n    max_evals=MAX_EVALS,\n    trials=trials,\n)\n\n# \u4ece trials \u5bf9\u8c61\u4e2d\u627e\u5230\u6700\u4f73\u8bd5\u9a8c\u7684\u7ed3\u679c\nbest_trial = trials.best_trial\nBEST_LEARNING_RATE = best_params['lr']\nBEST_EPOCHS = best_trial['result']['best_epoch']\n\nprint(\"\\n--- Best hyper parameters found ---\")\nprint(f\"Best LR: {BEST_LEARNING_RATE:.6f}\")\nprint(f\"Best epochs: {BEST_EPOCHS}\")\n</code></pre>  Cell 7: \u5728\u5b8c\u6574\u8bad\u7ec3\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u5e76\u76d1\u63a7\u6027\u80fd  <pre><code>print(\"\\n--- Start training on full training set ---\")\n\n# \u4f7f\u7528\u5b8c\u6574\u7684\u8bad\u7ec3\u6570\u636e\u96c6 (50000\u5f20\u56fe\u7247)\nfull_train_loader = DataLoader(dataset=full_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# \u6d4b\u8bd5\u96c6\u52a0\u8f7d\u5668\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# \u91cd\u65b0\u5b9e\u4f8b\u5316\u6a21\u578b\u548c\u4f18\u5316\u5668\nfinal_model = get_model_on_device()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(final_model.parameters(), lr=BEST_LEARNING_RATE)\n\nhistory = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n\nstart_time = time.time()\n\nfor epoch in range(BEST_EPOCHS):\n    # --- \u8bad\u7ec3 ---\n    final_model.train()\n    running_loss = 0.0\n\n    train_iterator = tqdm(full_train_loader, desc=f\"Epoch {epoch+1}/{BEST_EPOCHS}\", leave=False)\n    for images, labels in train_iterator:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = final_model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n\n    epoch_train_loss = running_loss / len(full_train_loader.dataset)\n    history['train_loss'].append(epoch_train_loss)\n\n    # --- \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u4ee5\u76d1\u63a7\u6027\u80fd ---\n    epoch_val_loss, epoch_val_accuracy = evaluate_model(final_model, test_loader, criterion, device)\n    history['val_loss'].append(epoch_val_loss)\n    history['val_accuracy'].append(epoch_val_accuracy)\n\n    print(f\"Epoch [{epoch+1}/{BEST_EPOCHS}], Train Loss: {epoch_train_loss:.4f}, Test Loss: {epoch_val_loss:.4f}, Test Accuracy: {epoch_val_accuracy:.2f}%\")\n\nend_time = time.time()\ntraining_duration = end_time - start_time\n\nprint(\"--- Over ---\")\n</code></pre>  Cell 8: \u751f\u6210\u5b9e\u9a8c\u7684\u7ed3\u679c\u62a5\u544a  <pre><code># \u8ba1\u7b97\u6700\u7ec8\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\nfinal_test_loss, final_test_accuracy = evaluate_model(final_model, test_loader, criterion, device)\n\n# \u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u91cf\ntotal_params = count_parameters(final_model)\n\n# \u683c\u5f0f\u5316\u8bad\u7ec3\u65f6\u957f\nmins, secs = divmod(training_duration, 60)\nformatted_duration = f\"{int(mins)}m {int(secs)}s\"\n\n# \u7ed8\u5236\u5e76\u4fdd\u5b58\u6027\u80fd\u66f2\u7ebf\nreport_history = {\n    'train_loss': history['train_loss'],\n    'val_loss': history['val_loss'],\n    'val_accuracy': history['val_accuracy']\n}\nplot_and_save_history(report_history)\n\n# \u6253\u5370\u62a5\u544a\nprint(\"\\n\" + \"=\"*50)\nprint(\" \" * 15 + \"Results\")\nprint(\"=\"*50)\n\nprint(\"\\n[Hyper parameters]\")\nprint(f\"  - Best LR: {BEST_LEARNING_RATE:.6f}\")\nprint(f\"  - Best epochs: {BEST_EPOCHS} epochs\")\nprint(f\"  - Batch size: {BATCH_SIZE}\")\n\nprint(\"\\n[Model structure]\")\nprint(f\"  - Model type: MLP\")\nprint(f\"  - Model structure:\")\nprint(final_model)\nprint(f\"  - Total params: {total_params:,}\")\n\nprint(\"\\n[Training infomation]\")\nprint(f\"  - Training duration on full training set: {formatted_duration}\")\nplatform = \"Kaggle's free P100, Thank you Google!\" if torch.cuda.is_available() else \"some poor guy's broken Intel core\"\nprint(f\"  - Training device: {device} on {platform}\")\n\nprint(\"\\n[Benchmarks on test set]\")\nprint(f\"  - Test loss: {final_test_loss:.4f}\")\nprint(f\"  - Test accuracy: {final_test_accuracy:.2f}%\")\n\nprint(\"\\n\" + \"=\"*50)\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#mlp", "title": "MLP", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#mlp_1", "title": "MLP \u6a21\u578b\u7684\u8bad\u7ec3\u7ed3\u679c\u5c55\u793a", "text": "MLP \u7684\u8bad\u7ec3\u7ed3\u679c  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000056\n  - Best epochs: 13 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: MLP\n  - Model structure:\nMLP(\n  (network): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=3072, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=256, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n  - Total params: 1,707,274\n\n[Training infomation]\n  - Training duration on full training set: 2m 51s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 1.3208\n  - Test accuracy: 54.44%\n\n==================================================\n</code></pre> <p>\u8bad\u7ec3\u4ee3\u7801\u5df2\u7ecf\u653e\u5728\u524d\u9762\u4e86\uff0c\u8fd9\u91cc\u5c31\u4e0d\u7ed9\u51fa\u4e86\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#mlp_2", "title": "\u5bf9 MLP \u6a21\u578b\u7684\u89e3\u8bfb\u548c\u8bc4\u8ff0", "text": "<p>\u6a21\u578b\u7ed3\u6784\u56fe\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Graph direction and styling\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input Layer\"]\n        A[(\"RGB Image&lt;br&gt;3x32x32\")]\n    end\n    class Input input;\n\n    %% Flatten Layer\n    subgraph Flatten[\"Flatten Layer\"]\n        B[(\"Flatten\")]\n    end\n    A --&gt; |3 @ 32x32| B\n    class Flatten box;\n\n    %% Hidden Layer 1\n    subgraph Hidden1[\"Hidden Layer 1\"]\n        C[\"Linear&lt;br&gt;3072x512\"]\n        D[\"ReLU\"]\n    end\n    B --&gt;|3072| C --&gt; D\n    class Hidden1 box;\n\n    %% Hidden Layer 2\n    subgraph Hidden2[\"Hidden Layer 2\"]\n        E[\"Linear&lt;br&gt;512x256\"] \n        F[\"ReLU\"]\n    end\n    D --&gt;|512| E --&gt; F\n    class Hidden2 box;\n\n    %% Output Layer\n    subgraph Output[\"Output Layer\"]\n        G[\"Linear&lt;br&gt;256x10\"]\n    end\n    F --&gt;|256| G\n    class Output output;\n\n    %% Classification Result\n    subgraph Result[\"Classification Result\"]\n        H[(\"10 output logits\")]\n    end\n    G --&gt;|10| H\n    class Result result;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style H stroke:#a6e3a1,stroke-width:3px</code></pre> <p>MLP \u662f\u5229\u7528 \\(\\mathbb{R}^n\\rightarrow\\mathbb{R}^m\\) \u7684\u591a\u91cd\u7ebf\u6027\u6620\u5c04\u5b9e\u73b0\u6570\u636e\u7684\u964d\u7ef4\uff0c\u4f46\u662f\u5355\u7eaf\u7684\u7ebf\u6027\u6620\u5c04\u5d4c\u5957\u4ecd\u662f \\(\\mathbb{R}^{d_{in}}\\rightarrow\\mathbb{R}^{d_{out}}\\) \u7684\u7ebf\u6027\u6620\u5c04\uff0c\u56e0\u6b64\u9700\u8981\u5728\u5c42\u4e0e\u5c42\u4e4b\u95f4\u6dfb\u52a0\u975e\u7ebf\u6027\u7684\u6fc0\u6d3b\u51fd\u6570\u5f15\u5165\u975e\u7ebf\u6027\u3002\u8fd9\u6837\u4e00\u4e2a\u8db3\u591f\u5bbd\u7684\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u5373\u53ef\u62df\u5408\u4efb\u610f\u51fd\u6570\u3002</p> <p>\u5728\u8fd9\u4e2a\u4efb\u52a1\u91cc\u9762\uff0c\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u4e09\u5c42\u7684 MLP\uff0c\u5e76\u91c7\u7528 ReLU \u4f5c\u4e3a\u5c42\u95f4\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u7531\u4e8e\u6211\u4eec\u5bf9 one-hot \u5411\u91cf\u8fdb\u884c\u5206\u7c7b\uff0c\u56e0\u6b64\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5982\u679c\u7528 MSE \u7684\u8bdd\uff0c\u6c42\u5bfc\u4e4b\u540e\u4f1a\u53d1\u73b0\u5b83\u662f\u4ea4\u53c9\u71b5\u7684\u5bfc\u6570\u4e58\u4ee5\u6743\u91cd\uff0c\u8fd9\u5c31\u4e0d\u9002\u5408\u68af\u5ea6\u7a33\u5b9a\u66f4\u65b0\u3002</p> <p>\u8f93\u5165\u4e0a\u662f\u5c06 3@32x32 \u7684\u56fe\u50cf\u5c55\u5e73\u6210 3072 \u7ef4\u7684\u5411\u91cf\u3002\u5f53\u7136\u6211\u89c9\u5f97\u8fd9\u5f88\u6ca1\u9053\u7406\uff0c\u56fe\u50cf\u672c\u8eab\u5c31\u6709\u4e24\u4e2a\u7ef4\u5ea6\u4e09\u4e2a\u901a\u9053\uff0c\u8fd9\u79cd\u201c\u5e73\u9762\u5316\u201d\u7684\u4fe1\u606f\uff0c\u611f\u89c9\u5c31\u88ab\u4e00\u4e2a <code>nn.Flatten</code> \u7ed9\u4e22\u5f03\u4e86\u3002\u867d\u7136\u8bf4\u7406\u8bba\u4e0a\u7ecf\u8fc7\u8db3\u591f\u6570\u636e\u8bad\u7ec3\u4e4b\u540e\uff0c\u4e00\u4e2a fc layer \u8db3\u591f\u6709\u80fd\u529b\u63d0\u53d6\u5404\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u76f8\u5173\u6027\uff08\u4e07\u80fd\u62df\u5408\u5b9a\u7406\uff09\uff0c\u4f46\u662f\u7f51\u7edc\u8981\u8db3\u591f\u5bbd\uff0c\u6570\u636e\u8981\u8db3\u591f\u591a\uff0c\u6b63\u5219\u5316\u8981\u8db3\u591f\u5145\u5206\uff0c\u800c\u5982\u679c\u4e0d\u5f15\u5165\u66f4\u591a\u5148\u9a8c\u77e5\u8bc6\u6765\u6355\u6349\u56fe\u50cf\u4fe1\u606f\u7684\u7279\u5f81\uff0c\u8bad\u7ec3\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u90fd\u662f\u6781\u5176\u4f4e\u4e0b\u7684\u3002</p> <p>\u8fd9\u662f\u4e00\u4e2a\u4e09\u5c42\u7684\u591a\u5c42\u611f\u77e5\u673a\uff0c\u53c2\u6570\u91cf 1.7M\u3002\u7b2c\u4e00\u6b21\u8bad\u7ec3\u4e0b\u6765\u53d1\u73b0\u8fd9\u70b9\u53c2\u6570\u91cf\u53cd\u6620\u4e0b\u6765\u5c31\u662f\u5373\u4f7f\u662f P100 \u8fd9\u79cd\u8001 GPU \u90fd\u6839\u672c\u6ca1\u4f7f\u52b2\uff0c\u5012\u662f CPU \u4e00\u76f4\u5728\u6ee1\u8d1f\u8377\u53d1\u529b\uff0c\u642c\u8fd0\u6570\u636e\u3002\u540e\u6765\u610f\u8bc6\u5230\uff0cdataloader \u91cc\u9762\u53ef\u4ee5\u5199\u4e0a <code>num_workers=6</code> \u4ee5\u53ca <code>pin_memory=True</code> \u6765\u63d0\u5347\u8bbf\u5b58\u6548\u7387\uff0c\u5e76\u4e14\u628a batch_size \u8c03\u5927\uff08\u53cd\u6b63\u5c31 2 M\u4e0d\u5230\u7684\u6a21\u578b\u7206\u4e0d\u4e86\u663e\u5b58\uff09\uff0c\u8bad\u7ec3\u6548\u7387\u9ad8\u4e86\u5f88\u591a\u554a\u3002</p> <p>\u7ecf\u8fc7 13 \u4e2a Epoch \u7684\u8bad\u7ec3\u4e4b\u540e\uff0c\u6a21\u578b\u5728 CIFAR-10 \u4e0a\u53ea\u53d6\u5f97\u4e86 54.44% \u7684\u51c6\u786e\u7387\u3002\u589e\u5927\u6a21\u578b\u7684\u5bbd\u5ea6\u548c\u6df1\u5ea6\u7406\u8bba\u4e0a\u53ef\u4ee5\u6539\u5584\uff0c\u4f46\u662f\u6548\u7387\u592a\u4f4e\u4e86\uff08\u5173\u4e8e\u5bbd\u5ea6\u548c\u6df1\u5ea6\u7684\u601d\u8003\uff0c\u53ef\u4ee5\u53c2\u8003 EfficientNet \u7684\u8bba\u6587\uff09\u3002\u56e0\u6b64\u9700\u8981\u53d1\u6398\u56fe\u50cf\u4fe1\u606f\u7684\u7279\u6027\uff0c\u5728\u6a21\u578b\u7ed3\u6784\u4e0a\u9762\u5f15\u5165\u66f4\u591a\u5148\u9a8c\u4fe1\u606f\uff0c\u5bfb\u627e\u80fd\u591f\u66f4\u9ad8\u6548\u63d0\u53d6\u4fe1\u606f\u7684\u67b6\u6784\u3002\u6240\u4ee5\u53ef\u4ee5\u770b\u5230\u73b0\u5728\u7684\u7f51\u7edc\u67b6\u6784\u4e2d\uff0cMLP \u4ec5\u4ec5\u662f\u4f5c\u4e3a\u5206\u7c7b\u5934\u51fa\u73b0\u7684\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#cnn", "title": "CNN", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#cnn_1", "title": "CNN \u6a21\u578b\u7684\u8bad\u7ec3\u7ed3\u679c\u5c55\u793a", "text": "CNN \u7684\u4ee3\u7801\u5b9e\u73b0  <pre><code>class CNN(nn.Module):\n    def __init__(self, \n                 input_channels=3,\n                 num_classes=10,\n                 channels=[32, 64, 128],   # \u6bcf\u4e2a\u5377\u79ef\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\n                 kernel_sizes=[3, 3, 3],   # \u6bcf\u4e2a\u5377\u79ef\u5c42\u7684 kernel \u5927\u5c0f\n                 dropout_rate=0.5,         # dropout \u6982\u7387\n                 use_batchnorm=True):      # \u662f\u5426\u4f7f\u7528\u6279\u5f52\u4e00\u5316\n        super(CNN, self).__init__()\n\n        # \u5b58\u50a8\u914d\u7f6e\u53c2\u6570\n        self.config = {\n            'input_channels': input_channels,\n            'num_classes': num_classes,\n            'channels': channels,\n            'kernel_sizes': kernel_sizes,\n            'dropout_rate': dropout_rate,\n            'use_batchnorm': use_batchnorm\n        }\n\n        # \u786e\u4fdd\u5377\u79ef\u5c42\u6570\u91cf\u4e0e kernel \u5927\u5c0f\u6570\u91cf\u4e00\u81f4\n        assert len(channels) == len(kernel_sizes), \\\n            \"\u901a\u9053\u6570\u5217\u8868\u4e0ekernel\u5927\u5c0f\u5217\u8868\u957f\u5ea6\u5fc5\u987b\u4e00\u81f4\"\n\n        # \u6784\u5efa\u5377\u79ef\u5c42\n        self.features = nn.Sequential()\n        in_channels = input_channels\n\n        for i, (out_channels, kernel_size) in enumerate(zip(channels, kernel_sizes)):\n            # \u5377\u79ef\u5c42\n            self.features.add_module(\n                f'conv{i+1}',\n                nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n            )\n\n            # \u6279\u5f52\u4e00\u5316\u5c42\uff08\u53ef\u9009\uff09\n            if use_batchnorm:\n                self.features.add_module(\n                    f'bn{i+1}',\n                    nn.BatchNorm2d(out_channels)\n                )\n\n            # \u6fc0\u6d3b\u51fd\u6570\n            self.features.add_module(f'relu{i+1}', nn.ReLU(inplace=True))\n\n            # \u6c60\u5316\u5c42\n            self.features.add_module(f'pool{i+1}', nn.MaxPool2d(2, 2))\n\n            in_channels = out_channels\n\n        # \u8ba1\u7b97\u5377\u79ef\u5c42\u8f93\u51fa\u540e\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\n        # CIFAR-10\u8f93\u5165\u4e3a32x32\uff0c\u7ecf\u8fc7n\u6b21\u6c60\u5316\u540e\u5c3a\u5bf8\u4e3a32/(2^n)\n        self.feature_size = in_channels * (32 // (2 ** len(channels))) ** 2\n\n        # \u6784\u5efa\u5168\u8fde\u63a5\u5c42\n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_size, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)  # \u5c55\u5e73\u7279\u5f81\u56fe\n        x = self.classifier(x)\n        return x\n\ndef get_model_on_device():\n    return CNN().to(device)\n</code></pre>  CNN \u7684\u8bad\u7ec3\u7ed3\u679c  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000199\n  - Best epochs: 16 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: CNN\n  - Model structure:\nCNN(\n  (features): Sequential(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu1): ReLU(inplace=True)\n    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu3): ReLU(inplace=True)\n    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=2048, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n  - Total params: 1,147,914\n\n[Training infomation]\n  - Training duration on full training set: 4m 7s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 0.7026\n  - Test accuracy: 77.33%\n\n==================================================\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#cnn_2", "title": "\u5bf9 CNN \u6a21\u578b\u7684\u89e3\u8bfb\u548c\u8bc4\u8ff0", "text": "<p>\u7ed3\u6784\u56fe\uff08\u8bf7\u653e\u5927\u89c2\u770b\uff09\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3@32\u00d732\")]\n    end\n    class Input input;\n\n    %% Feature Extractor\n    %% -- Conv Block 1 --\n    subgraph Block1[\"Conv Block 1\"]\n        B[\"Conv2d&lt;br&gt; 3x32 x 3\u00d73 kernel\"] \n        C[\"BatchNorm2d&lt;br&gt; 32 channels\"]\n        D[\"ReLU\"]\n        E[\"MaxPool2d&lt;br&gt; 2\u00d72/2\"]\n    end\n    A --&gt; B\n    B --&gt;|32 @ 32x32| C --&gt; D --&gt; E\n    class Block1 conv;\n\n    %% -- Conv Block 2 --\n    subgraph Block2[\"Conv Block 2\"]\n        F[\"Conv2d&lt;br&gt; 32x64 x 3\u00d73 kernel\"] \n        G[\"BatchNorm2d&lt;br&gt; 64 channels\"]\n        H[\"ReLU\"]\n        I[\"MaxPool2d&lt;br&gt; 2\u00d72/2\"]\n    end\n    E --&gt; |32 @ 16\u00d716| F\n    F --&gt; |64 @ 16\u00d716| G --&gt; H --&gt; I\n    class Block2 conv;\n\n    %% -- Conv Block 3 --\n    subgraph Block3[\"Conv Block 3\"]\n        J[\"Conv2d&lt;br&gt; 64x128 x 3\u00d73 kernel\"]\n        K[\"BatchNorm2d&lt;br&gt; 128 channels\"]\n        L[\"ReLU\"]\n        M[\"MaxPool2d&lt;br&gt; 2\u00d72/2\"]\n    end\n    I --&gt; |64 @ 8\u00d78| J\n    J --&gt; |128 @ 8\u00d78| K --&gt; L --&gt; M\n    class Block3 conv;\n\n    %% Feature Flattening\n    subgraph Flatten[\"Flatten\"]\n        N[(\"2048\")]\n    end\n    M --&gt; |128 @ 4\u00d74| N\n    class Flatten box;\n\n    %% Classifier\n    subgraph Classifier[\"Classifier\"]\n        O[\"Linear&lt;br&gt; 2048x512\"]\n        P[\"ReLU\"]\n        Q[\"Dropout&lt;br&gt; p = 0.5\"]\n        R[\"Linear&lt;br&gt; 512x10\"]\n    end\n    N --&gt; O\n    O --&gt; P --&gt; Q --&gt; R\n    class Classifier box;\n\n    %% Output Layer\n    subgraph Output[\"Classification Result\"]\n        S[(\"10 output logits\")]\n    end\n    R --&gt; S\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style S stroke:#a6e3a1,stroke-width:3px</code></pre> <p><code>conv2d</code> \u5c31\u662f\u5377\u79ef\u64cd\u4f5c\uff0c\u672c\u8d28\u4e0a\u662f\u4ece\u8f93\u5165\u5f20\u91cf <code>(batch_size, in_channel, H, W)</code> \u5230\u8f93\u51fa\u5f20\u91cf <code>(batch_size, out_channel, H, W)</code> \u7684\u4e00\u4e2a\u5229\u7528\u56db\u7ef4\u5f20\u91cf <code>(in_channel, out_channel, H', W')</code> \u7684\u5377\u79ef\u6838\u8fdb\u884c\u7684\u5377\u79ef\u64cd\u4f5c\uff0c\u5177\u4f53\u662f\u5bf9\u4e8e\u5355\u5f20\u56fe\u50cf\u7684\u5404\u4e2a\u901a\u9053\u8fdb\u884c\u586b\u5145\u540e\uff0c\u5c06\u81ea\u5b9a\u4e49\u7684 <code>in_channel@H'xW'</code> \u7684\u77e9\u9635\u5728\u5176\u4e0a\u4e00\u4e00\u5bf9\u5e94\u8fdb\u884c\u6ed1\u52a8\u8986\u76d6\uff0c\u5e76\u5bf9\u8986\u76d6\u5230\u7684\u533a\u57df\u8fdb\u884c\u9010\u5143\u7d20\u6c42\u79ef\u5e76\u6c42\u548c\uff0c\u5f97\u5230\u4e86\u5355\u4e2a\u65b0\u77e9\u9635\uff0c\u5982\u6b64\u5171\u9009\u53d6 <code>out_channel</code> \u6b21\u81ea\u5b9a\u4e49\u77e9\u9635\uff0c\u5c31\u5f97\u5230\u4e86\u8f93\u51fa\u5f20\u91cf <code>(batch_size, out_channel, H, W)</code> \u8fd9\u662f\u4efb\u610f\u4e00\u672c\u6df1\u5ea6\u5b66\u4e60\u6559\u6750\u90fd\u4f1a\u8bb2\u89e3\u7684\u5185\u5bb9\u3002</p> <p>CNN \u901a\u8fc7\u5148\u9a8c\u5f15\u5165\u7a00\u758f\u8fde\u63a5\uff08\u4e5f\u5c31\u662f <code>conv2d</code> \uff09\u4e0d\u4ec5\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u66f4\u5927\u89c4\u6a21\u7f51\u7edc\u7684\u7a00\u758f\u8fd1\u4f3c\uff0c\u6ee1\u8db3\u56fe\u50cf\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u8fd8\u5177\u6709\u5f88\u597d\u7684\u53ef\u89e3\u91ca\u6027\uff08\u5377\u79ef\u6838\u5bf9\u5e94\u4e00\u4e2a\u5c0f\u9762\u79ef\u7684\u611f\u53d7\u91ce\uff0c\u89e3\u51b3\u4e4b\u524d\u63d0\u5230 MLP \u7684\u5c55\u5e73\u64cd\u4f5c\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u4e0d\u540c\u7684\u5377\u79ef\u6838\u63d0\u53d6\u4e0d\u540c\u7684\u7279\u5f81\uff09\u3002\u56e0\u6b64\u76f8\u5f53\u9002\u5408\u56fe\u50cf\u5904\u7406\u3002\u5f53\u7136\u6700\u540e\u8fd8\u662f\u5f97\u4f9d\u9760\u4e00\u4e2a MLP \u4f5c\u4e3a\u5206\u7c7b\u5934\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7684\u5c55\u5e73\u64cd\u4f5c\u5c31\u5408\u7406\u591a\u4e86\uff0c\u56e0\u4e3a\u7ecf\u8fc7\u591a\u6b21 <code>conv2d</code> \u4e4b\u540e\uff0c\u6a21\u578b\u63d0\u53d6\u5230\u7684\u90fd\u662f\u7a7a\u95f4\u4e0a\u5f31\u76f8\u5173\u7684\u6df1\u5c42\u6b21\uff08\u62bd\u8c61\uff09\u7279\u5f81\u4e86\u3002\u5728\u8fd9\u4e9b\u7279\u5f81\u4e4b\u95f4\u8fdb\u884c\u7ec4\u5408\u5c31\u975e\u5e38\u5408\u7406\u4e14\u76f4\u89c2\u4e86\u3002\u5728\u5f88\u957f\u7684\u4e00\u6bb5\u65f6\u95f4\u5185\uff0cCNN \u4f5c\u4e3a\u9ad8\u6548\u7684\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4e00\u76f4\u90fd\u662f\u5404\u79cd CV \u7f51\u7edc\u7684\u7816\u77f3\u3002</p> <p>\u8fd9\u4e2a\u7f51\u7edc\u867d\u7136\u53c2\u6570\u91cf\u4e0d\u5982\u5148\u524d\u7684 MLP\uff0c\u4f46\u662f\u5bbd\u5ea6\u8981\u5bbd\u4e00\u4e9b\uff08\u6211\u7406\u89e3\u7684\u7f51\u7edc\u5bbd\u5ea6\u5373\u901a\u9053\u6570\uff0c\u56e0\u4e3a\u8fd9\u51b3\u5b9a\u4e86\u6a21\u578b\u6355\u83b7\u7684\u7279\u5f81\u6570\u91cf\uff09\uff0c\u6839\u636e muP \u7684\u7406\u8bba\uff0c\u5b66\u4e60\u7387\u53ef\u4ee5\u7ffb 4 \u500d\uff08MLP\u9690\u85cf\u5c42\u7ef4\u5ea6 512\uff0c CNN \u6700\u5927\u901a\u9053\u6570 128\uff09\uff0c\u7ed3\u8bba\u5927\u81f4\u7b26\u5408\u9884\u671f\u3002CNN \u7684\u9ad8\u6548\u6027\u6b63\u5728\u4e8e\u5176\u4e2d\uff0c\u4ee5\u66f4\u4f4e\u7684\u53c2\u6570\u91cf\u83b7\u5f97\u66f4\u4f18\u7684\u6548\u679c\u3002</p> <p>\u540e\u9762\u7684 NiN, VGG, GoogLeNet \u7b49\u90fd\u662f\u57fa\u4e8e\u5377\u79ef\u6446\u653e\u4f4d\u7f6e\u548c\u591a\u5c11\u4ee5\u53ca\u5e76\u884c\u5ea6\u7684\u5dee\u5f02\uff0c\u8be6\u7ec6\u7684\u590d\u73b0\u656c\u8bf7\u671f\u5f85\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#resnet", "title": "ResNet", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#resnet-18", "title": "ResNet-18 \u6a21\u578b\u7684\u8bad\u7ec3\u7ed3\u679c\u5c55\u793a", "text": "\u4ee3\u7801  <pre><code>from torchvision.models import resnet18\nclass ResNet18(nn.Module):\n    def __init__(self, pretrained=False, num_classes=10):\n        super(ResNet18, self).__init__()\n        # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6216\u968f\u673a\u521d\u59cb\u5316\u7684ResNet-18\n        self.resnet = resnet18(pretrained=pretrained)\n\n        # \u8c03\u6574\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u4ee5\u9002\u5e9432x32\u8f93\u5165\n        # \u539f\u59cbResNet-18\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u662f7x7, stride=2, padding=3\n        # \u5bf9\u4e8e32x32\u56fe\u50cf\uff0c\u6211\u4eec\u6539\u4e3a3x3, stride=1, padding=1\n        self.resnet.conv1 = nn.Conv2d(\n            3, 64, kernel_size=3, stride=1, padding=1, bias=False\n        )\n\n        # \u8c03\u6574\u6700\u5927\u6c60\u5316\u5c42\uff0c\u4e0d\u9700\u8981\u4e0b\u91c7\u6837\u592a\u591a\n        self.resnet.maxpool = nn.Identity()  # \u79fb\u9664\u6700\u5927\u6c60\u5316\u5c42\n\n        # \u8c03\u6574\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u4ee5\u9002\u5e94CIFAR-10\u768410\u4e2a\u7c7b\u522b\n        in_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(in_features, num_classes)\n\n    def forward(self, x):\n        return self.resnet(x)\n\ndef get_model_on_device():\n    model = ResNet18()# pretrained=True \u4f7f\u7528\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u53cd\u4e4b\u4e0d\u4f7f\u7528\u3002\n    return model.to(device)\n</code></pre>  \u4ece\u96f6\u8bad\u7ec3\u7ed3\u679c  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.002787\n  - Best epochs: 8 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: ResNet18 from scrach\n  - Model structure:\nResNet18(\n  (resnet): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): Identity()\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n  - Total params: 11,173,962\n\n[Training infomation]\n  - Training duration on full training set: 5m 8s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 0.5767\n  - Test accuracy: 83.46%\n\n==================================================\n</code></pre>  \u5fae\u8c03\u7ed3\u679c  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000330\n  - Best epochs: 3 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: Pretrained ResNet18\n  - Model structure:\nResNet18(\n  (resnet): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): Identity()\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n  - Total params: 11,173,962\n\n[Training infomation]\n  - Training duration on full training set: 1m 55s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 0.3450\n  - Test accuracy: 89.06%\n\n==================================================\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#resnet-18_1", "title": "\u5bf9 ResNet-18 \u6a21\u578b\u7684\u89e3\u8bfb\u548c\u8bc4\u8ff0", "text": "<p>\u8003\u8651\u5230\u7b14\u8005\u4f7f\u7528\u7684 GPU \u6027\u80fd\u8f83\u5f31\uff0c\u672c\u6b21\u4f7f\u7528\u7684\u662f ResNet-18 \u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u4e2a\u76f8\u5bf9\u6d45\u7684 ResNet\uff0c\u76f8\u6bd4\u4e8e ResNet-50 \u7b49\u57fa\u4e8e BottleNeck \u5757\u7684\u7f51\u7edc\uff0cResNet-18 \u7531\u7a0d\u6709\u4e0d\u540c\u7684 BasicBlock \u7ec4\u6210\u3002</p> <p>ResNet-18 \u7684\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3 @ 32\u00d732\")]\n    end\n    class Input input;\n\n    %% Initial Convolution\n    subgraph InitConv[\"Initial Convolution\"]\n        B[\"Conv2d &lt;br&gt; 3x64 x 3\u00d73\"] \n        C[\"BatchNorm2d &lt;br&gt; 64 channels\"]\n        D[\"ReLU\"]\n    end\n    A --&gt; B\n    B --&gt; C --&gt; D\n    class InitConv conv;\n\n    %% Layer 1 (2\u00d7 BasicBlock without downsample)\n    subgraph Layer1[\"Layer1 (2\u00d7BasicBlock)\"]\n        F[\"BasicBlock 1\"]\n        G[\"BasicBlock 1\"]\n    end\n    D --&gt; |64 @ 32\u00d732| F\n    F --&gt; |64 @ 32\u00d732| G\n    class Layer1 box;\n\n    %% Layer 2 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer2[\"Layer2 (2\u00d7BasicBlock)\"]\n        H[\"BasicBlock 2\"]\n        I[\"BasicBlock 1\"]\n    end\n    G --&gt; |64 @ 32\u00d732| H\n    H --&gt; |128 @ 16\u00d716| I\n    class Layer2 box;\n\n    %% Layer 3 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer3[\"Layer3 (2\u00d7BasicBlock)\"]\n        J[\"BasicBlock 2\"]\n        K[\"BasicBlock 1\"]\n    end\n    I --&gt; |128 @ 16\u00d716| J\n    J --&gt; |256 @ 8\u00d78| K\n    class Layer3 box;\n\n    %% Layer 4 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer4[\"Layer4 (2\u00d7BasicBlock)\"]\n        L[\"BasicBlock 2\"]\n        M[\"BasicBlock 1\"]\n    end\n    K --&gt; |256 @ 8\u00d78| L\n    L --&gt; |512 @ 4\u00d74| M\n    class Layer4 box;\n\n    %% Global Pooling and FC\n    subgraph PoolFC[\"GAP &amp; Classfiaction\"]\n        N[\"AdaptiveAvgPool2d &lt;br&gt; 1\u00d71\"]\n        O[\"Flatten &lt;br&gt; 512-dim vec\"]\n        P[\"Linear &lt;br&gt; 512x10\"]\n    end\n    M --&gt; |512 @ 4\u00d74| N --&gt; |512 @ 1\u00d71| O --&gt; |512| P\n    class PoolFC box;\n\n    %% Output Layer\n    subgraph Output[\"output\"]\n        Q[(\"10\")]\n    end\n    P --&gt; Q\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style Q stroke:#a6e3a1,stroke-width:3px</code></pre> <p>\u5176\u4e2d\uff0cBasic block 1 \u662f\u4e0d\u5e26\u964d\u91c7\u6837\u7684\u6b8b\u5dee\u8fde\u63a5\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef residual fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n\n    %% BasicBlock Structure (No Downsample)\n    subgraph BasicBlockNoDS[\"BasicBlock 1\"]\n        A[\"Conv2d &lt;br&gt; 64x64 x 3\u00d73\"] \n        B[\"BatchNorm2d &lt;br&gt; 64 channels\"]\n        C[\"ReLU\"]\n        D[\"Conv2d &lt;br&gt; 64x64 x 3\u00d73\"] \n        E[\"BatchNorm2d &lt;br&gt; 64 channels\"]\n        F((\"+\"))\n        G[\"ReLU\"]\n    end\n\n    %% Input\n    Input[(\"64 @ H\u00d7W\")] --&gt; A\n    Input --&gt; F\n\n    %% Connections\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n    F --&gt; G\n\n    %% Output\n    G --&gt; Output[(\"64 @ H\u00d7W\")]\n\n    class BasicBlockNoDS residual;</code></pre> <p>Basic block 2 \u662f\u5e26\u964d\u91c7\u6837\u7684\u6b8b\u5dee\u8fde\u63a5\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef residual fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef downsample fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n\n    %% BasicBlock Structure (With Downsample)\n    subgraph BasicBlockWithDS[\"BasicBlock 2\"]\n        A[\"Conv2d &lt;br&gt; 64x128 x 3\u00d73 /2\"] \n        B[\"BatchNorm2d &lt;br&gt; 128 channels\"]\n        C[\"ReLU\"]\n        D[\"Conv2d: 128x128 x 3\u00d73\"] \n        E[\"BatchNorm2d &lt;br&gt; 128 channels\"]\n        F((\"+\"))\n        G[\"ReLU\"]\n\n        subgraph Downsample[\"Downsampling\"]\n            H[\"Conv2d: 64x128 x 1\u00d71 /2\"]\n            I[\"BatchNorm2d &lt;br&gt; 128 channels\"]\n        end\n    end\n\n    %% Input\n    Input[(\"64 @ H\u00d7W\")] --&gt; A\n    Input --&gt; H\n\n    %% Connections\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n    H --&gt; I --&gt; F\n    F --&gt; G\n\n    %% Output\n    G --&gt; Output[(\"128 @ H/2\u00d7W/2\")]\n\n    class BasicBlockWithDS residual;\n    class Downsample downsample;</code></pre> <p>ResNet-18 \u7684\u7ed3\u6784\uff08\u5728\u957f\u5bbd\u7ef4\u5ea6\uff09\u6b63\u5982\u4e00\u4e2a\u6f0f\u6597\u4e00\u6837\uff0c\u9664\u4e86\u521d\u59cb\u5316\u5c42\u548c Layer 1 \u4ee5\u5916\uff0c\u5176\u4f59\u7684 Layer \u90fd\u662f Basic block 2 -&gt; Basic block 1 \u7684\u7ed3\u6784\uff0c\u4e5f\u5c31\u662f\u5f52\u7eb3\u7279\u5f81\u5230\u63d0\u53d6\u7279\u5f81\u7684\u4e00\u4e2a\u987a\u5e8f\u3002\u6700\u540e\u4f7f\u7528\u81ea\u9002\u5e94\u6027\u6c60\u5316\u6765\u5e94\u5bf9\u4e0d\u540c\u7684\u8f93\u5165\u3002\u56e0\u4e3a torch \u63d0\u4f9b\u7684 ResNet-18 \u662f\u57fa\u4e8e ImageNet \u8bbe\u8ba1\u7684\uff0c\u8f93\u5165\u662f 3@224x224\uff0c\u5229\u7528\u81ea\u9002\u5e94\u6027\u6c60\u5316\uff0c\u5c31\u53ef\u4ee5\u53ea\u7528\u4fee\u6539\u5bf9\u8f93\u5165\u7684\u5904\u7406\u4e86\u3002</p> <p>\u9664\u6b64\u4e4b\u5916\uff0cResNet \u4f7f\u7528\u4e86\u591a\u79cd\u6280\u672f\u624d\u4f7f\u5982\u6b64\u6df1\u5c42\u7684\u7f51\u7edc\u6210\u4e3a\u53ef\u80fd\u3002</p> <p>\u4e00\u662f\u4f7f\u7528 ReLU \u6fc0\u6d3b\u3002\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\u5982 sigmoid\uff0c\u5176\u5bfc\u6570\u5728 \\([-1,1]\\) \u4e4b\u95f4\uff0c\u8fd9\u5c31\u5bfc\u81f4\u68af\u5ea6\u5411\u6df1\u5c42\u6d41\u52a8\u7684\u65f6\u5019\u4e0d\u65ad\u88ab\u4e00\u4e2a\u7edd\u5bf9\u503c\u5c0f\u4e8e \\(1\\) \u7684\u6570\u4e58\u8d77\u6765\uff0c\u9010\u6e10\u6d88\u5931\u3002ReLU \u6c42\u5bfc\u8981\u4e48 \\(0\\) \u8981\u4e48 \\(1\\)\uff0c\u4e5f\u5c31\u662f\u68af\u5ea6\u8981\u4e48\u5728\u8d1f\u6570\u8f93\u51fa\u5904\u505c\u6b62\u6d41\u52a8\u8981\u4e48\u5c31\u76f4\u63a5\u539f\u5c01\u4e0d\u52a8\u4f20\u4e0b\u53bb\u3002</p> <p>\u4e8c\u662f\u4f7f\u7528 BatchNorm2d\u3002\u6279\u5f52\u4e00\u5316\u8bd5\u56fe\u5c06\u6570\u636e\u62c9\u56de\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff0c\u8fd9\u89e3\u8026\u4e86\u5c42\u4e0e\u5c42\u4e4b\u95f4\u7684\u8f93\u5165\u4f9d\u8d56\uff0c\u76f8\u5f53\u4e8e\u6bcf\u4e00\u5c42\u90fd\u53ea\u7528\u5c06\u4e00\u6279\u6807\u51c6\u6b63\u6001\u6570\u636e\u6620\u5c04\u5230\u6807\u51c6\u6b63\u6001\u6570\u636e\uff0c\u72ec\u7acb\u6027\u5927\u5927\u589e\u5f3a\uff0c\u53cd\u6620\u5230\u635f\u5931\u5730\u5f62\u4e0a\uff0c\u5c31\u662f\u5bf9\u6a21\u578b\u7684\u5fae\u6270\uff08\u4e5f\u5c31\u662f\u4f18\u5316\u5668\u5e26\u6765\u7684\u53c2\u6570\u66f4\u65b0\uff09\u5e26\u6765\u7684\uff08\u53ef\u80fd\u7684\uff09\u5de8\u5927\u6270\u52a8\uff08\u5373\u5d0e\u5c96\u7684\u635f\u5931\u5730\u5f62\uff09\u7ed9\u5e73\u5766\u5316\u4e86\u3002</p> <p>\u5f53\u7136\u4e0a\u9762\u7684\u4e24\u70b9\u5728\u4e00\u822c\u7684 CNN \u4e2d\u90fd\u6709\u4f7f\u7528\uff0c\u50cf GoogLeNet \u8fd9\u79cd\u57fa\u4e8e Inception \u7684\u7f51\u7edc\u4e5f\u53ea\u6709 22 \u5c42\uff0c\u4f46\u662f\u57fa\u4e8e ResNet \u7684\u7f51\u7edc\u53ef\u4ee5\u8f7b\u677e\u8fbe\u5230\u6210\u767e\u4e0a\u5343\u5c42\uff0c\u5173\u952e\u5728\u4e8e\u2014\u2014</p> <p>\u4e09\u662f\u6b8b\u5dee\u8fde\u63a5\u3002Kaiming \u610f\u8bc6\u5230\u4ee5\u4e0b\u5bf9\u6bd4\uff1a\u8003\u8651\u4e00\u822c\u7684\u795e\u7ecf\u7f51\u7edc\u5355\u5c42</p> \\[ y=\\phi (\\mathrm{Layer}(x)) \\] <p>\u5176\u4e2d \\(y\\) \u4e3a\u8f93\u51fa\uff0c\\(\\phi\\) \u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\\(\\mathrm{Layer}\\) \u4e3a\u5bf9\u8f93\u5165 \\(x\\) \u505a\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u77e9\u9635\u4e58\u6cd5\u6216\u8005\u5377\u79ef\u7b49\u3002</p> <p>\u90a3\u4e48\u5411\u524d\u4f20\u9012\u7684\u68af\u5ea6\u4e3a</p> \\[ \\dfrac{\\partial y}{\\partial x}=\\dfrac{\\partial \\mathrm{Layer}}{\\partial x}\\phi' (\\mathrm{Layer}(x)) \\] <p>\u4e5f\u5c31\u662f\u4e00\u4e2a\u6570\u4e58\u4ee5\u5c0f\u4e8e\u7b49\u4e8e \\(1\\) \u7684\u6570\u3002\u4f46\u662f\uff0c\u5982\u679c\u6211\u4eec\u8003\u8651\u8fd9\u6837\u7684\u5355\u5c42\uff1a</p> \\[ y=\\phi (x+\\mathrm{Layer}(x)) \\] <p>\u90a3\u4e48\u5411\u524d\u4f20\u9012\u7684\u68af\u5ea6\u4e3a</p> \\[ \\dfrac{\\partial y}{\\partial x}=(1+\\dfrac{\\partial \\mathrm{Layer}}{\\partial x})\\phi' (\\mathrm{Layer}(x)) \\] <p>\u55ef\uff0c\u8fd9\u6837\u4f20\u9012\u5230\u7684\u68af\u5ea6\u786e\u5b9e\u53d8\u591a\u4e86\uff0c\u4f46\u662f\u8fd8\u662f\u53d7\u5236\u4e8e\u6fc0\u6d3b\u51fd\u6570\u7684\u5bfc\u6570\u554a\uff0c\u611f\u89c9\u2026\u2026\u7528\u5904\u4e0d\u5927\uff1f</p> <p>\u5475\u5475\uff0c\u4e8b\u60c5\u6ca1\u6709\u90a3\u4e48\u7b80\u5355\u3002\u8981\u4e0d\u56de\u5934\u770b\u770b\u7f51\u7edc\u7ed3\u6784\u91cc\u9762ReLU\u7684\u4f4d\u7f6e\u5230\u5e95\u5728\u54ea\u91cc\u5462\uff1f</p> <p>\u662f\u5728\u4e24\u4e2a conv2d \u7684\u4e2d\u95f4\uff01\u4e5f\u5c31\u662f\u8bf4\uff0c\u4e8b\u5b9e\u4e0a\u987a\u5e8f\u5e94\u8be5\u662f</p> \\[ y=x+\\phi (\\mathrm{Layer}(x)) \\] <p>\u90a3\u4e48\u5411\u524d\u4f20\u9012\u7684\u68af\u5ea6\u4e3a</p> \\[ \\dfrac{\\partial y}{\\partial x}=1+\\dfrac{\\partial \\mathrm{Layer}}{\\partial x}\\phi' (\\mathrm{Layer}(x)) \\] <p>\u8fd9\u6837\uff0c\u4e0d\u7ba1\u81ea\u5df1\u68af\u5ea6\u591a\u5c11\uff0c\u6df1\u5c42\u7684\u68af\u5ea6\u5c31\u90fd\u80fd\u987a\u7545\u6d41\u52a8\u5230\u6d45\u5c42\u4e86\u3002</p> <p>\u5f53\u7136 Kaiming \u5728\u8bba\u6587\u91cc\u9762\u7684\u89c2\u70b9\u662f\u6052\u7b49\u53d8\u6362\u4e0d\u6613\u5b66\u4e60\u6240\u4ee5\u8f6c\u800c\u5b66\u4e60\u6b8b\u5dee\uff0c\u8fd9\u6837\u5373\u4f7f\u4ec0\u4e48\u90fd\u6ca1\u6709\u5b66\u5230\uff0c\u81f3\u5c11\u8fd8\u80fd\u4fdd\u7559\u6052\u7b49\u6620\u5c04\u7684\u80fd\u529b\u3002\u4e0d\u8fc7\u6211\u66f4\u559c\u6b22\u4ece\u6570\u5b66\u89d2\u5ea6\u63a8\u5bfc\u54af~</p> <p>\u6700\u540e\u53ef\u4ee5\u770b\u5230 ResNet-18 \u867d\u7136\u5bbd\u5ea6\u6bd4 CNN \u5927\u4e00\u500d\uff0c\u4f46\u662f\u5c45\u7136\u53ef\u4ee5\u627f\u53d7\u6bd4 CNN \u5927\u597d\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u5b66\u4e60\u7387\uff0c\u539f\u56e0\u5c31\u5728\u4e8e\u8fd9\u51e0\u4e2a\u65b9\u6848\u4f7f\u5f97\u635f\u5931\u5730\u5f62\u6781\u5ea6\u5e73\u6ed1\uff0c\u53c2\u6570\u66f4\u65b0\u91cf\u5373\u4f7f\u6bd4\u8f83\u5927\uff0c\u4e5f\u4e0d\u4f1a\u6709\u7279\u522b\u5927\u7684\u9707\u8361\u3002\u7136\u540e muP \u7684\u7406\u8bba\u5728\u8fd9\u91cc\u5c31\u5b8c\u5168\u5931\u6548\u4e86\uff0c\u6bd5\u7adf muP \u7814\u7a76\u7684\u662f\u540c\u4e00\u6a21\u578b\u4e0d\u540c\u5c3a\u5ea6\u7684\u53c2\u6570\u8c03\u6574\u89c4\u5f8b\u3002</p> <p>\u540e\u9762\u6211\u4f7f\u7528 torch \u5b98\u65b9\u63d0\u4f9b\u7684\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u91cd\uff0c\u4f7f\u7528\u66f4\u5c0f\u7684\u5b66\u4e60\u7387\u5c31\u53ef\u4ee5\u5f97\u5230\u66f4\u52a0\u7684\u6548\u679c\uff0c\u679c\u7136\u9884\u8bad\u7ec3\u5c31\u662f\u6700\u4f73\u7684\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u554a\u3002</p> <p>\u53ef\u4ee5\u770b\u5230 ResNet \u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u6709\u4e0a\u4e86\u4e00\u4e2a\u53f0\u9636\u3002\u7f51\u4e0a\u4e5f\u662f\u5230\u5904\u90fd\u6709 ResNet \u7206\u6539 YOLOv8 \u9aa8\u5e72\u7f51\u7edc\u7684\u535a\u5ba2\uff0c\u770b\u6765\u5927\u5bb6\u90fd\u5f88\u559c\u6b22\u6b8b\u5dee\u8fde\u63a5\u554a\u3002</p> <p>ResNet-50, ResNeXt, DenseNet, EfficientNet \u7b49\u67b6\u6784\u4e2d\u4e5f\u662f\u5c06\u6b8b\u5dee\u8fde\u63a5\u4f5c\u4e3a\u57fa\u7840\uff08DenseNet \u66f4\u662f\u6269\u5c55\u4e86\u8fd9\u4e00\u601d\u8def\uff09\u3002\u8fd9\u4e9b\u7f51\u7edc\u7684\u590d\u73b0\u548c\u8bb2\u89e3\u656c\u8bf7\u671f\u5f85\u3002</p> <p>\u4e0b\u9762\u7684 Transformer \u6a21\u578b\u4e5f\u5229\u7528\u4e86\u6b8b\u5dee\u8fde\u63a5\u3002\u751a\u81f3 FCN \u548c U-Net \u7b49\u4e5f\u6c72\u53d6\u4e86\u7c7b\u4f3c\u7684\u601d\u8def\u5f15\u5165\u4e86\u8df3\u8dc3\u8fde\u63a5\u3002\u8fd9\u4e00\u90e8\u5206\u7684\u590d\u73b0\u8bf7\u53c2\u8003\u672c\u7cfb\u5217\u535a\u5ba2\u7684 \u7b2c\u4e8c\u7bc7\u3002</p> <p>\u6bd5\u7adf\u53c2\u6570\u91cf\u591f\u5927\uff0cScaling law \u6301\u7eed\u53d1\u529b\u4e2d......\u4e0d\u8fc7\u63d0\u5230 Scaling law\uff0c\u600e\u4e48\u80fd\u4e0d\u8bf7\u51fa\u6211\u4eec\u7684 Transformer \u6a21\u578b\u5462\uff1f</p>"}, {"location": "DNN/model-expr/Image-models-replication/#vit", "title": "ViT", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#vit_1", "title": "ViT \u6a21\u578b\u7684\u8bad\u7ec3\u7ed3\u679c\u5c55\u793a", "text": "nanoViT \u7684\u8bad\u7ec3\u4ee3\u7801 <pre><code>from torch import Tensor\nclass PatchEmbedding(nn.Module):\n    \"\"\"\u5c06\u56fe\u50cf\u5206\u5272\u4e3a\u8865\u4e01\u5e76\u8fdb\u884c\u5d4c\u5165\"\"\"\n    def __init__(self, img_size=32, patch_size=2, in_channels=3, embed_dim=128):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n\n        # \u8ba1\u7b97\u8865\u4e01\u6570\u91cf\n        self.num_patches = (img_size // patch_size) ** 2\n\n        # \u4f7f\u7528\u5377\u79ef\u5c42\u5b9e\u73b0\u8865\u4e01\u5d4c\u5165 (\u7b49\u4ef7\u4e8e\u6bcf\u4e2a\u8865\u4e01\u5e94\u7528\u4e00\u4e2a\u5377\u79ef\u6838)\n        self.proj = nn.Conv2d(\n            in_channels, \n            embed_dim, \n            kernel_size=patch_size, \n            stride=patch_size\n        )\n\n    def forward(self, x: Tensor) -&gt; Tensor:\n        # x\u5f62\u72b6: (batch_size, in_channels, img_size, img_size)\n        x = self.proj(x)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, embed_dim, num_patches^(1/2), num_patches^(1/2))\n        x = x.flatten(2)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, embed_dim, num_patches)\n        x = x.transpose(1, 2)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, num_patches, embed_dim)\n        return x\n\nclass TransformerClassifier(nn.Module):\n    \"\"\"\u7528\u4e8eCIFAR-10\u5206\u7c7b\u7684Transformer\u6a21\u578b\"\"\"\n    def __init__(\n        self,\n        img_size=32,\n        patch_size=2,\n        in_channels=3,\n        num_classes=10,\n        embed_dim=128,\n        depth=4,          # Transformer\u7f16\u7801\u5668\u5c42\u6570\n        num_heads=4,      # \u6ce8\u610f\u529b\u5934\u6570\n        mlp_ratio=2.0,    # MLP\u9690\u85cf\u5c42\u7ef4\u5ea6\u6bd4\u4f8b\n        dropout=0.1,      # Dropout\u6982\u7387\n    ):\n        super().__init__()\n\n        # \u8865\u4e01\u5d4c\u5165\n        self.patch_embed = PatchEmbedding(\n            img_size=img_size,\n            patch_size=patch_size,\n            in_channels=in_channels,\n            embed_dim=embed_dim\n        )\n        num_patches = self.patch_embed.num_patches\n\n        # \u7c7b\u522b\u4ee4\u724c (\u7528\u4e8e\u6700\u7ec8\u5206\u7c7b)\n        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n\n        # \u4f4d\u7f6e\u5d4c\u5165 (\u53ef\u5b66\u4e60)\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n\n        # Dropout\u5c42\n        self.pos_drop = nn.Dropout(p=dropout)\n\n        # Transformer\u7f16\u7801\u5668\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=int(embed_dim * mlp_ratio),\n            dropout=dropout,\n            batch_first=True,  # \u6279\u5904\u7406\u7ef4\u5ea6\u5728\u524d\n        )\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n\n        # \u5206\u7c7b\u5934\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            nn.Linear(embed_dim, num_classes)\n        )\n\n    def forward(self, x: Tensor) -&gt; Tensor:\n        # x\u5f62\u72b6: (batch_size, 3, 32, 32)\n        batch_size = x.shape[0]\n\n        # \u8865\u4e01\u5d4c\u5165\n        x = self.patch_embed(x)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, num_patches, embed_dim)\n\n        # \u6269\u5c55\u7c7b\u522b\u4ee4\u724c\u5230\u6279\u6b21\u5927\u5c0f\n        class_tokens = self.class_token.expand(batch_size, -1, -1)  # \u5f62\u72b6: (batch_size, 1, embed_dim)\n\n        # \u5c06\u7c7b\u522b\u4ee4\u724c\u4e0e\u8865\u4e01\u5d4c\u5165\u62fc\u63a5\n        x = torch.cat((class_tokens, x), dim=1)  # \u5f62\u72b6: (batch_size, num_patches + 1, embed_dim)\n\n        # \u6dfb\u52a0\u4f4d\u7f6e\u5d4c\u5165\u5e76\u5e94\u7528dropout\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        # Transformer\u7f16\u7801\n        x = self.transformer_encoder(x)  # \u5f62\u72b6: (batch_size, num_patches + 1, embed_dim)\n\n        # \u4f7f\u7528\u7c7b\u522b\u4ee4\u724c\u7684\u8f93\u51fa\u8fdb\u884c\u5206\u7c7b\n        x = x[:, 0]  # \u53d6\u7c7b\u522b\u4ee4\u724c\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u5f62\u72b6: (batch_size, embed_dim)\n        x = self.classifier(x)  # \u5f62\u72b6: (batch_size, num_classes)\n\n        return x\n\ndef get_model_on_device():\n    model = TransformerClassifier(\n        img_size=32,\n        patch_size=2,\n        in_channels=3,\n        num_classes=10,\n        embed_dim=192,\n        depth=4,\n        num_heads=8,\n        mlp_ratio=2.0,\n        dropout=0.1\n    )\n    return model.to(device)\n</code></pre>  ViT-B-16 \u7684\u5fae\u8c03\u4ee3\u7801\uff08\u539f\u7406\uff09 <pre><code>import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom torchvision.models import ViT_B_16_Weights\n\nclass ViT_Cifar10(nn.Module):\n    \"\"\"\n    \u4e00\u4e2a\u771f\u6b63\u201c\u5373\u63d2\u5373\u7528\u201d\u7684ViT-B/16\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8eCIFAR-10\u3002\n\n    \u8fd9\u4e2a\u7c7b\u4f1a\u81ea\u52a8\u5904\u7406\u8f93\u5165\u5c3a\u5bf8\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff1a\n    1. \u5185\u7f6e\u4e00\u4e2a\u4e0a\u91c7\u6837\u5c42\uff0c\u5728\u524d\u5411\u4f20\u64ad\u65f6\u81ea\u52a8\u5c06\u8f93\u5165\u768432x32\u56fe\u50cf\u653e\u5927\u5230224x224\u3002\n    2. \u52a0\u8f7d\u5728ImageNet\u4e0a\u9884\u8bad\u7ec3\u7684ViT-B/16\u6743\u91cd\u3002\n    3. \u5c06\u5206\u7c7b\u5934\u66ff\u6362\u4e3a\u9002\u7528\u4e8eCIFAR-10\u768410\u4e2a\u7c7b\u522b\u3002\n    \"\"\"\n    def __init__(self, num_classes: int = 10):\n        super().__init__()\n\n        # \u6b65\u9aa41: \u5b9a\u4e49\u4e00\u4e2a\u4e0a\u91c7\u6837/\u8c03\u6574\u5927\u5c0f\u7684\u5c42\n        # T.Resize \u662f torchvision.transforms \u4e2d\u7684\u4e00\u4e2a\u7c7b\uff0c\u5b83\u53ef\u4ee5\u4f5c\u4e3a nn.Module \u4f7f\u7528\n        self.upsampler = T.Resize((224, 224), antialias=True)\n\n        # \u6b65\u9aa42: \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684ViT\u6a21\u578b\n        self.vit = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n\n        # \u6b65\u9aa43: \u51bb\u7ed3\u4e3b\u5e72\u7f51\u7edc\u7684\u6240\u6709\u53c2\u6570\n        for param in self.vit.parameters():\n            param.requires_grad = False\n\n        # \u6b65\u9aa44: \u66ff\u6362\u5206\u7c7b\u5934\n        in_features = self.vit.heads.head.in_features\n        self.vit.heads.head = nn.Linear(in_features=in_features, out_features=num_classes)\n\n        # \u786e\u4fdd\u65b0\u5206\u7c7b\u5934\u7684\u53c2\u6570\u662f\u53ef\u8bad\u7ec3\u7684\n        for param in self.vit.heads.parameters():\n            param.requires_grad = True\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        \u5b9a\u4e49\u6a21\u578b\u7684\u524d\u5411\u4f20\u64ad\u3002\n\n        Args:\n            x (torch.Tensor): \u8f93\u5165\u7684\u56fe\u50cf\u5f20\u91cf\uff0c\u53ef\u4ee5\u662f (B, 3, 32, 32)\n\n        Returns:\n            torch.Tensor: \u6a21\u578b\u8f93\u51fa\u7684logits\uff0c\u5f62\u72b6\u4e3a (B, num_classes)\n        \"\"\"\n        # --- \u5173\u952e\u6539\u52a8 ---\n        # \u5728\u9001\u5165ViT\u4e4b\u524d\uff0c\u9996\u5148\u5c06\u8f93\u5165\u56fe\u50cf\u4e0a\u91c7\u6837\u5230224x224\n        x = self.upsampler(x)\n\n        # \u73b0\u5728\uff0c\u5c3a\u5bf8\u5339\u914d\u4e86\uff0c\u53ef\u4ee5\u5b89\u5168\u5730\u8c03\u7528ViT\n        return self.vit(x)\ndef get_model_on_device():\n    \"\"\"\n    \u5b9e\u4f8b\u5316ViTForCifar10\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u79fb\u52a8\u5230\u5728\u4e3b\u4f5c\u7528\u57df\u4e2d\u5b9a\u4e49\u7684\u8bbe\u5907\u4e0a\u3002\n\n    Returns:\n        ViTForCifar10: \u914d\u7f6e\u597d\u5e76\u79fb\u52a8\u5230\u8bbe\u5907\u4e0a\u7684\u6a21\u578b\u5b9e\u4f8b\u3002\n    \"\"\"\n    model = ViT_Cifar10(num_classes=10)\n    return model.to(device)\n</code></pre>  nanoViT \u7684\u8bad\u7ec3\u7ed3\u679c <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000232\n  - Best epochs: 16 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: ViT\n  - Model structure:\nTransformerClassifier(\n  (patch_embed): PatchEmbedding(\n    (proj): Conv2d(3, 192, kernel_size=(2, 2), stride=(2, 2))\n  )\n  (pos_drop): Dropout(p=0.1, inplace=False)\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-3): 4 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n        )\n        (linear1): Linear(in_features=192, out_features=384, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=384, out_features=192, bias=True)\n        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (classifier): Sequential(\n    (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=192, out_features=10, bias=True)\n  )\n)\n  - Total params: 1,242,442\n\n[Training infomation]\n  - Training duration on full training set: 19m 55s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 0.7802\n  - Test accuracy: 73.24%\n\n==================================================\n</code></pre>  ViT-B-16 \u7684\u5fae\u8c03\u7ed3\u679c  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000308\n  - Best epochs: 45 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: ViT\n  - Model structure:\nViT_Cifar10(\n  (upsampler): Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n  (vit): VisionTransformer(\n    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    (encoder): Encoder(\n      (dropout): Dropout(p=0.0, inplace=False)\n      (layers): Sequential(\n        (encoder_layer_0): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_1): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_2): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_3): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_4): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_5): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_6): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_7): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_8): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_9): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_10): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (encoder_layer_11): EncoderBlock(\n          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (self_attention): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (0): Linear(in_features=768, out_features=3072, bias=True)\n            (1): GELU(approximate='none')\n            (2): Dropout(p=0.0, inplace=False)\n            (3): Linear(in_features=3072, out_features=768, bias=True)\n            (4): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n    )\n    (heads): Sequential(\n      (head): Linear(in_features=768, out_features=10, bias=True)\n    )\n  )\n)\n  - Total params: 7,690\n\n[Training infomation]\n  - Training duration on full training set: 265m 15s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 0.1402\n  - Test accuracy: 95.42%\n\n==================================================\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#vit_2", "title": "\u5bf9 ViT \u6a21\u578b\u7684\u89e3\u8bfb\u548c\u8bc4\u8ff0", "text": "<p>\u672c\u6b21\u5b9e\u9a8c\u4ecd\u7136\u662f\u4ece\u96f6\u8bad\u7ec3+\u5fae\u8c03\u3002\u4ece\u96f6\u8bad\u7ec3\u4f7f\u7528\u5c55\u793a\u7684\u4e00\u4e2a nanoViT\uff0c\u5fae\u8c03\u4f7f\u7528\u7684\u662f torchvision \u63d0\u4f9b\u7684\u9884\u8bad\u7ec3\u6743\u91cd <code>ViT_B_16_Weights.IMAGENET1K_V1</code>\uff0c\u901a\u8fc7\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\u66ff\u6362\u5206\u7c7b\u5934\u7684\u65b9\u5f0f\u8fdb\u884c\u5fae\u8c03\u3002</p> <p>\u53eb nanoViT \u662f\u4e3a\u4e86\u5411 Karpathy \u7684 nanoGPT \u81f4\u656c\uff0c\u5176\u4ed6\u7f51\u7edc\u90fd\u5728\u5377\u82b1\u6d3b\u7684\u65f6\u5019\uff0cTransformer \u771f\u7684\u662f\u5927\u529b\u51fa\u5947\u8ff9\u3002</p> <p>\u4e0b\u9762\u662f nanoViT \u7684\u7ed3\u6784\u793a\u610f\uff0c\u6211\u4eec\u4ece\u5b8f\u89c2\u5230\u5fae\u89c2\u6765\u62c6\u89e3\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n    classDef transformer fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3@32\u00d732\")]\n    end\n    class Input input;\n\n    %% Patch Embedding\n    subgraph PatchEmbed[\"Patch Embedding\"]\n        B[\"Conv2d&lt;br&gt; 3x192 x 2\u00d72 / 2\"]\n        C[\"Dropout&lt;br&gt; p=0.1\"]\n        U[\"CLS token&lt;br&gt;192 dim vector\"]\n        V[(\"contact\")]\n    end\n    U --&gt; V\n    A --&gt; B --&gt; V\n    V --&gt; C\n    class PatchEmbed conv;\n\n    %% Positional Encoding\n    subgraph PosEnc[\"Postional Encoding\"]\n        S[\"Parameter Matrix&lt;br&gt;(256+1) x 192&lt;br&gt;1 for CLS token\"]\n    end\n    class PosEnc conv;\n\n    T[\"Dropout&lt;br&gt;p=0.1\"]\n    D[(\"+\")]\n    S --&gt; D --&gt; T\n    C --&gt;|257 tokens or patches&lt;br&gt;embedded into 192 dim per patch| D\n    %% Transformer Encoder\n    subgraph TransformerEncoder[\"Transformer Encoder\"]\n        E[\"Encoder Layer 1\"]\n        F[\"Encoder Layer 2\"]\n        G[\"Encoder Layer 3\"]\n        H[\"Encoder Layer 4\"]\n    end\n    T --&gt;|257x192| E --&gt; F --&gt; G --&gt; H\n    class TransformerEncoder transformer;\n\n    %% Extract [CLS] Token\n    I[\"Extract CLS token\"]\n    H --&gt;|257x192| I\n\n    %% Classification Head\n    subgraph Classifier[\"MLP Head\"]\n        J[\"LayerNorm&lt;br&gt;192 dim\"]\n        K[\"Linear&lt;br&gt;192x10\"]\n    end\n    I --&gt;|192 dim vector| J --&gt; K\n    class Classifier box;\n\n    %% Output Layer\n    subgraph Output[\"Output\"]\n        L[(\"10\")]\n    end\n    K --&gt; L\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style L stroke:#a6e3a1,stroke-width:3px</code></pre> <p>\u8fd9\u91cc\u5229\u7528\u5377\u79ef\u64cd\u4f5c\uff0c\u5c06 3@32x32 \u7684\u56fe\u50cf\u53d8\u6210 192@16x16 \u7684\u56fe\u50cf\u8865\u4e01\uff0c\u5e76\u5c06\u540e\u4e24\u4e2a\u7ef4\u5ea6\u5c55\u5e73\uff0c\u5c31\u5f97\u5230 192x256 \u7684\u77e9\u9635\uff0c\u5176\u4e2d 256 \u662f\u8865\u4e01\u7684\u4e2a\u6570\uff0c192 \u662f\u901a\u9053\u6570\uff08\u63d0\u53d6\u7684\u7279\u5f81\u6570\u91cf\uff09\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u8865\u4e01\u53ef\u4ee5\u6620\u5c04\u5230 192 \u7ef4\u7684\u5d4c\u5165\u7a7a\u95f4\u91cc\u9762\u3002\u9009 192 \u662f\u4e3a\u4e86\u63a7\u5236\u53c2\u6570\u91cf\u5728 1M \u7684\u6570\u91cf\u7ea7\uff0c\u5176\u5b9e\u5e94\u8be5\u66f4\u5927\u7684\uff0c\u5177\u4f53\u53ef\u89c1\u4e0b\u9762\u7684\u8ba8\u8bba\u3002\u56e0\u6b64\u6211\u4eec\u5c06\u77e9\u9635\u8f6c\u7f6e\u4e3a 256x192\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u4e58\u4ee5\u5d4c\u5165\u7ef4\u6570\uff0c\u8fd9\u5c31\u548c TrasformerEncoder \u7684\u8981\u6c42\u5339\u914d\u4e86\u3002\u9009\u62e9 2x2 \u7684\u8865\u4e01\u4e00\u65b9\u9762\u6709\u53d7\u5230 ViT \u8bba\u6587\u6807\u9898 An image is worth 16x16 words \u7684\u5f71\u54cd\uff0c\u6bd5\u7adf 32 / 2 = 16\uff0c\u53e6\u4e00\u65b9\u9762\u5c31\u662f\u7c7b\u6bd4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684 3x3 \u5377\u79ef\u6838\uff0c\u6240\u4ee5\u8003\u8651\u5728 2x2 \u548c 4x4 \u4e2d\u95f4\u9009\uff0c\u56e0\u4e3a\u5148\u524d\u6d4b\u8bd5\u8fc7 4x4 \u7684 patch_size \u6548\u679c\u4e0d\u5982 2x2 \u597d\uff0c\u4e8e\u662f\u5c31\u5b9a\u4e0b\u6765\u662f 2x2 \u4e86\u3002</p> <p>\u6211\u4eec\u77e5\u9053\u6ce8\u610f\u529b\u77e9\u9635\u4e0d\u5305\u542b\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6240\u4ee5\u9700\u8981\u4f4d\u7f6e\u7f16\u7801\u6765\u5bf9\u4e0d\u540c\u4f4d\u7f6e\u7684\u540c\u4e00\u4e2a token \u8fdb\u884c\u533a\u5206\u3002ViT \u7684\u4f5c\u8005\u5c1d\u8bd5\u4e86 1-D, 2-D \u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\u4ee5\u53ca\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u6548\u679c\u90fd\u5dee\u4e0d\u591a\uff0c\u56e0\u6b64\u5728\u8fd9\u91cc\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\u3002</p> <p>\u4f46\u662f\u7531\u4e8e\u6211\u4eec\u9700\u8981\u5bf9\u56fe\u50cf\u8fdb\u884c\u6709\u76d1\u7763\u5206\u7c7b\uff0c\u5355\u7eaf\u5bf9\u56fe\u50cf\u8fdb\u884c\u6ce8\u610f\u529b\u64cd\u4f5c\u662f\u4e0d\u4f1a\u5229\u7528\u5230\u4efb\u4f55\u6807\u7b7e\u4fe1\u606f\u7684\uff0c\u6240\u4ee5\u8fd8\u9700\u8981\u589e\u52a0\u4e00\u4e2a\u5355\u72ec\u7684 token\uff0c\u8fd9\u4e2a token \u7528\u6765\u6355\u83b7\u5206\u7c7b\u7684\u7ed3\u679c\u3002\u7531\u4e8e TrasformerEncoder \u4e0d\u4f1a\u6539\u53d8\u8f93\u5165\u7684\u5f62\u72b6\u548c\u4f4d\u7f6e\u5173\u7cfb\uff0c\u6240\u4ee5\u53ea\u9700\u8981\u5728\u6700\u540e\u63d0\u53d6\u8fd9\u4e2a\u5206\u7c7b token\uff0c\u5e76\u5c06\u5176\u6295\u5f71\u5230 10 \u4e2a\u7c7b\u522b\u4e0a\u9762\u5373\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u5b66\u4e60\u3002</p> <p>\u4e0b\u9762\u662f\u6bcf\u4e00\u4e2a TrasformerEncoder \u5c42\u7684\u7ec6\u8282\u5b9e\u73b0\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\u4e24\u4e2a\u6b8b\u5dee\u8fde\u63a5\uff0c\u5206\u522b\u8de8\u8d8a\u4e86\u591a\u5934\u6ce8\u610f\u529b\u6a21\u5757\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u3002\u6b8b\u5dee\u8fde\u63a5\u7684\u4f5c\u7528\u4e4b\u524d\u5df2\u7ecf\u8be6\u7ec6\u9610\u8ff0\uff0c\u6b64\u5904\u4e0d\u5fc5\u591a\u8bf4\u3002</p> <p>\u8fd9\u91cc\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u548c\u4e00\u822c\u7684 MLP head \u4e0d\u5927\u4e00\u6837\u3002\u4e4b\u524d\u6211\u4eec\u770b\u5230\u7684 MLP head \u90fd\u662f\u6f0f\u6597\u578b\u7684\uff0c\u8fd9\u91cc\u7684 FFN \u5374\u662f\u5148\u5347\u7ef4\u518d\u964d\u7ef4\u3002\u56e0\u4e3a\u6b64\u5904 FFN \u53ea\u662f\u5bf9\u62fc\u63a5\u7684\u591a\u5934\u6ce8\u610f\u529b\u8fdb\u884c\u6df7\u5408\uff0c\u4e0d\u662f\u538b\u7f29\u800c\u662f\u6df7\u5408\u7279\u5f81\uff0c\u56e0\u6b64\u9700\u8981\u5728\u9ad8\u7ef4\u5ea6\u533a\u5206\u7279\u5f81\uff0c\u53e6\u4e00\u65b9\u9762\u662f\uff0c\u52a0\u5165\u6fc0\u6d3b\u51fd\u6570\u7684 FFN \u5728\u5347\u7ef4\u7684\u65f6\u5019\u57fa\u672c\u4e0a\u4e0d\u4f1a\u56e0\u4e3a ReLU \u6216\u8005 GELU \u7b49\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\u7684\u6b7b\u8fde\u63a5\u800c\u5bfc\u81f4\u4fe1\u606f\u7684\u635f\u5931\uff08\u4e5f\u5c31\u662f\u964d\u79e9\uff09\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef attention fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef ffn fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n\n    %% Input\n    Input[(\"T\u00d7192\")] --&gt; Norm1[\"LayerNorm&lt;br&gt;192 dim\"]\n\n    %% Multi-head Attention (8 heads)\n    subgraph SelfAttn[\"Multi-Head Attention\"]\n        subgraph SA[\"Multi-Head Self Attention\"]\n            Z1[\"Attention Head 0&lt;br&gt;Tx192-&gt;Tx24\"]\n            Z2[\"......\"]\n            Z3[\"Attention Head 7&lt;br&gt;Tx192-&gt;Tx24\"]\n        end\n        Conc[\"Contact\"]\n        Proj[\"Linear&lt;br&gt; 192x192\"]\n    end\n    Norm1 --&gt; Z1\n    Norm1 --&gt; Z2\n    Norm1 --&gt; Z3\n    Z1 --&gt; Conc\n    Z2 --&gt; Conc\n    Z3 --&gt; Conc\n    Conc --&gt;|Tx192| Proj\n    class SelfAttn attention;\n\n    %% Residual Connection 1\n    Proj --&gt; Dropout1[\"Dropout: p=0.1\"]\n    Dropout1 --&gt; Add1((\"+\"))\n    Input --&gt; Add1\n\n    %% Feed Forward Network\n    Add1 --&gt; Norm2[\"LayerNorm&lt;br&gt;192 dims\"]\n\n    subgraph FFN[\"Feed Forward Network\"]\n        Linear1[\"Linear&lt;br&gt; 192x384\"]\n        Dropout2[\"Dropout&lt;br&gt; p=0.1\"]\n        Linear2[\"Linear&lt;br&gt; 384x192\"]\n    end\n    Norm2 --&gt; Linear1 --&gt; Dropout2 --&gt; Linear2\n    class FFN ffn;\n\n    %% Residual Connection 2\n    Linear2 --&gt; Dropout3[\"Dropout&lt;br&gt;p=0.1\"]\n    Dropout3 --&gt; Add2((\"+\"))\n    Add1 --&gt; Add2\n\n    %% Output\n    Add2 --&gt; Output[(\"T\u00d7192\")]</code></pre> <p>\u4e0b\u9762\u662f\u591a\u5934\u81ea\u6ce8\u610f\u529b\u6bcf\u4e00\u4e2a\u5934\u7684\u8ba1\u7b97\u8fc7\u7a0b\u3002\u5176\u5b9e\u6211\u8ba4\u4e3a\u8fd9\u91cc\u7684\u5934\u6570\u7c7b\u4f3c\u4e8e conv2d \u7684\u901a\u9053\u6570\uff0c\u8861\u91cf\u83b7\u53d6\u7279\u5f81\u7684\u591a\u5c11\uff1b\u4f46\u662f\u53e6\u4e00\u65b9\u9762\u53c8\u88ab\u5d4c\u5165\u7ef4\u5ea6\u6240\u9650\u5236\uff0c\u56e0\u4e3a\u5934\u6570\u4e00\u591a\uff0c\u5206\u7ed9\u6bcf\u4e2a\u5934\u7684\u6295\u5f71\u7ef4\u5ea6\u5c31\u5c11\u4e86\uff0c\u4fe1\u606f\u4e5f\u53d8\u5c11\u4e86\u3002\u56fe\u4e0a\u9762\u7684\u5934\u6570\u4e3a 8 \u662f\u6211\u968f\u610f\u8bbe\u7f6e\u7684\uff0c\u4e0d\u8fc7\u82cf\u5251\u6797\u6709\u4e00\u4e2a\u7ef4\u5ea6\u516c\u5f0f n &gt; 8.33 log N \u5bf9\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u800c\u8a00\uff0cN \u5c31\u662f\u9884\u8bad\u7ec3\u7684\u5e8f\u5217\u957f\u5ea6 T \u4e5f\u5c31\u662f 256\uff0cn \u5c31\u662f\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u7ef4\u5ea6\uff0c\u7b97\u51fa\u6765\u8981\u5927\u4e8e \\(8.33 \\times \\log_2 256\\approx 66.64\\) \u624d\u80fd\u591f\u5728\u6bcf\u4e2a\u5934\u91cc\u9762\u6709\u6548\u5b9a\u4f4d token\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684 num_heads \u8bbe\u7f6e\u6210 3 \u7406\u8bba\u4e0a\u770b\u4f3c\u4f1a\u597d\u4e00\u70b9\u3002\u5b9e\u9645\u4e0a\u56de\u5230\u4e4b\u524d\u7684\u8ba8\u8bba\uff0c\u867d\u7136\u7ef4\u5ea6\u591f\u4e86\uff0c\u4f46\u662f\u63d0\u53d6\u7684\u7279\u5f81\u4e0d\u591f\uff0c\u6240\u4ee5\u8fd8\u662f\u5dee\u4e00\u70b9\uff0c\u8bad\u7ec3\u51fa\u6765 loss = 0.9111 \u800c acc \u5f88\u9057\u61be\u5730\u53ea\u6709 69.17%\u3002\u6240\u4ee5\u56de\u8fc7\u5934\u6765\uff0c\u5982\u679c\u6211\u4eec\u7efc\u5408\u521a\u521a\u7684\u8ba8\u8bba\u628a num_heads \u8bbe\u7f6e\u5230 8 \u800c\u6bcf\u4e2a\u5934\u7684\u7ef4\u5ea6\u8bbe\u7f6e\u6210 64\u2026\u2026\u8bf6\uff0c\u8fd9\u4e0d\u5c31\u63a5\u8fd1 ViT-B-16 \u4f7f\u7528\u7684\u5d4c\u5165\u7ef4\u5ea6 768 \u561b\uff01</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef transform fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n    classDef attention fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n\n    %% Input\n    subgraph Input[\"Input sequence\"]\n        A[(\"T\u00d7embed_dim&lt;br&gt;T = 257&lt;br&gt;embed_dim = 192\")]\n    end\n    class Input input;\n\n    %% Linear Transformations\n    subgraph Transformations[\"Linear proj for head_i\"]\n        B[\"Projection matrix W_q_i&lt;br&gt; embed_dim\u00d7d_q = 192 x 24\"]\n        C[\"Projection matrix W_k_i&lt;br&gt; embed_dim\u00d7d_k = 192 x 24\"]\n        D[\"Projection matrix W_v_i&lt;br&gt; embed_dim\u00d7d_v = 192 x 24\"]\n    end\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n    class Transformations transform;\n\n    %% Transformed Representations\n    E[\"Q_i = XW_q_i&lt;br&gt;T\u00d7d_q\"]\n    F[\"K_i = XW_k_i&lt;br&gt;T\u00d7d_k\"]\n    G[\"V_i = XW_v_i&lt;br&gt;T\u00d7d_v\"]\n\n    B --&gt; E\n    C --&gt; F\n    D --&gt; G\n\n    %% Attention Score Calculation\n    subgraph ScoreCalc[\"Attention Score\"]\n        H[\"Q_i K_i\u1d40 &lt;br&gt;-------&lt;br&gt; \u221a(d_k)\"]\n        I[\"Softmax&lt;br&gt;Row-wise Norm\"]\n    end\n    E --&gt; H\n    F --&gt; H\n    H --&gt;|T x T| I\n\n    %% Output Calculation\n    subgraph OutputCalc[\"Attention Result\"]\n        J[\"Attention_i = O_i V_i\"]\n    end\n    I --&gt;|Attention Score O_i&lt;br&gt;T x T| J\n    G --&gt; J\n\n    %% Output\n    subgraph Output[\"Output for head_i\"]\n        K[(\"T\u00d7d_v\")]\n    end\n    J --&gt; K\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5</code></pre> <p>\u6ce8\u610f\u529b\u8fd9\u4e2a\u8bcd\u5176\u5b9e\u5f88\u5f62\u8c61\uff0c\u5b83\u901a\u8fc7\u8ba1\u7b97\u5f97\u77e5\u201c\u56fe\u50cf\u7684\u54ea\u4e00\u90e8\u5206\u662f\u91cd\u8981\u7684\u201d\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7531\u4e8e\u6211\u4eec\u9700\u8981\u7684\u662f\u81ea\u5df1\u6dfb\u52a0\u7684\u5206\u7c7b token\uff0c\u6240\u4ee5\u8ba9\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e0b\u8fd9\u4e2a token \u76f8\u5bf9\u6574\u5f20\u56fe\u7247\u7684\u6ce8\u610f\u529b\uff0c\u4e5f\u5c31\u80fd\u591f\u5f97\u77e5\u201c\u6a21\u578b\u9760\u4ec0\u4e48\u8fa8\u8ba4\u51fa\u8be5\u6807\u7b7e\u201d\uff1a</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u5e95\u5c42\u7684\u6ce8\u610f\u529b\u63d0\u53d6\u7684\u4fe1\u606f\u504f\u5411\u4e8e\u660e\u5ea6\u4fe1\u606f\uff0c\u5bf9\u8f83\u6697\u7684\u5982\u8349\u576a\u9634\u5f71\u548c\u72d7\u5934\u7b49\u5177\u6709\u8f83\u591a\u5173\u6ce8\u5ea6\uff0c\u540e\u9762\u7684\u5c42\u5173\u6ce8\u70b9\u9010\u6e10\u62bd\u8c61\uff0c\u5f00\u59cb\u805a\u7126\u8eab\u4f53\u3001\u56db\u80a2\u548c\u5c3e\u5df4\u7b49\u7684\u7279\u5f81\u3002\u4e3a\u4f55\u6a21\u578b\u4e0d\u518d\u5173\u6ce8\u80cc\u666f\u7684\u8349\u576a\u5462\uff1f\u8003\u8651\u540c\u65f6\u6709\u4e24\u5f20\u56fe\u7247\uff0c\u4e00\u5f20\u662f\u732b\u5728\u8349\u576a\u4e0a\u53e6\u4e00\u5f20\u662f\u72d7\u5728\u8349\u576a\u4e0a\uff0c\u5982\u679c\u6a21\u578b\u672a\u80fd\u5206\u5272\u51fa\u8349\u576a\uff0c\u5219\u5176\u5c31\u4f1a\u5c06\u4e24\u8005\u6df7\u4e3a\u4e00\u8c08\uff0c\u635f\u5931\u53d8\u5927\uff0c\u82e5\u60f3\u964d\u4f4e\u635f\u5931\uff0c\u6a21\u578b\u5fc5\u987b\u8981\u6355\u83b7\u5230\u4e24\u8005\u7684\u5dee\u522b\uff0c\u5373\u732b\u548c\u72d7\u8eab\u5f62\u6216\u56db\u80a2\u7b49\u7684\u5dee\u5f02\uff0c\u624d\u80fd\u6b63\u786e\u63d0\u53d6\u62bd\u8c61\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u3002</p> <p>\u603b\u7684 TransformerEncoder \u8ba1\u7b97\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(T^2d+kd^2)\\)\u3002\u5176\u4e2d \\(T\\) \u662f\u5e8f\u5217\u957f\u5ea6\uff0c\\(d\\) \u662f\u5d4c\u5165\u7ef4\u5ea6\u800c \\(k\\) \u662f\u6ce8\u610f\u529b\u524d\u7684\u6295\u5f71\uff0c\u6ce8\u610f\u529b\u540e\u7684 FFN \u7b49\u591a\u4e2a\u7ebf\u6027\u64cd\u4f5c\u5e26\u6765\u7684\u500d\u7387\u56e0\u5b50\u3002\u5728\u8fd9\u4e2a\u573a\u666f\u4e0b\u5e8f\u5217\u957f\u5ea6\u4e0d\u957f\uff0c\u8ba1\u7b97\u65f6\u95f4\u590d\u6742\u5ea6\u53ef\u4ee5\u63a5\u53d7\uff0c\u9ad8\u5206\u8fa8\u7387\u56fe\u7247\u6216\u8005 LLM \u91cc\u9762\u7684\u957f\u4e0a\u4e0b\u6587\u5c31\u96be\u641e\u54af\u3002</p> <p>\u6700\u540e\u8bad\u7ec3\u51fa\u6765\u7684 nanoViT \u5728 CIFAR-10 \u4e0a\u83b7\u5f97\u4e86 73.24% \u7684\u51c6\u786e\u7387\uff0c\u548c\u6734\u7d20 CNN \u7684\u51c6\u786e\u7387\u5728\u4e00\u4e2a\u6c34\u5e73\u3002\u56e0\u4e3a Transformer \u8981\u5927\u91cf\u6570\u636e\u6295\u5582\uff0c\u6240\u4ee5\u4e0d Scale \u600e\u4e48\u80fd\u884c\u5462\uff1f</p> <p>\u4e8e\u662f\u6211\u9009\u62e9\u4e00\u4e2a\u5927\u4e00\u70b9\u7684\uff0c\u5728 ImageNet \u4e0a\u5df2\u7ecf\u9884\u8bad\u7ec3\u8fc7\u7684\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4e5f\u5c31\u662f <code>ViT_B_16_Weights.IMAGENET1K_V1</code> \u8fd9\u4e2a\u6a21\u578b\u6743\u91cd\uff0c\u6587\u6863\u5728\u6b64\u3002\u8fd9\u4e2a\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u4e0a\u548c\u521a\u521a\u7684 nanoViT \u5b8c\u5168\u4e00\u6837\uff0c\u53ea\u4e0d\u8fc7\u6269\u5927\u4e86\u5bf9\u5e94\u7684\u53c2\u6570\u91cf\uff0c\u5c06\u7f16\u7801\u5668\u589e\u52a0\u5230\u4e86 12 \u4e2a\uff0c\u800c FFN \u5c42\u95f4\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\u4e86 GELU \u800c\u5df2\u3002</p> <p>\u5fae\u8c03\u7684\u65b9\u6cd5\u5c31\u662f\u5148\u628a 32x32 \u7684\u56fe\u50cf\u4e0a\u91c7\u6837\u5230 224x224\uff0c\u5c31\u80fd\u548c\u4e3a ImageNet \u9884\u8bad\u7ec3\u7684\u8f93\u5165\u5339\u914d\u4e86\uff0c\u7136\u540e\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\uff0c\u53ea\u9700\u8981\u66ff\u6362\u5206\u7c7b\u5934\uff0c\u8bad\u7ec3\u597d\u8fd9\u4e2a MLP \u5206\u7c7b\u5206\u7c7b\u5934\u5373\u53ef\u3002\u7531\u4e8e\u8fd9\u4e2a\u6a21\u578b\u7684\u5d4c\u5165\u7ef4\u5ea6\u662f 768\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u9700\u8981\u5bf9\u4e00\u4e2a 7690 \u4e2a\u53c2\u6570\u8fdb\u884c\u5fae\u8c03\u5c31\u884c\u4e86\uff0c\u6309\u7406\u8bf4\u5f88\u5feb\uff0c\u4e0d\u8fc7\u2026\u2026</p> <p>\u7531\u4e8e\u7b14\u8005\u91c7\u7528\u7684\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u7aef\u5230\u7aef\u7f51\u7edc\u8bad\u7ec3\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u6240\u4ee5\u6211\u60f3\uff0c\u5b9a\u4e49\u6a21\u578b\u7684\u65f6\u5019\uff0c<code>__init__</code>\u91cc\u9762\u58f0\u660e\u4e00\u4e0b\u51bb\u7ed3\u9aa8\u5e72\u7f51\uff0c\u66ff\u6362\u4e00\u4e0b\u5206\u7c7b\u5934\uff0c\u7136\u540e\u5728<code>forward</code>\u91cc\u9762\u4e0a\u91c7\u6837\u4e00\u4e0b\u5c31\u884c\u4e86\u3002\u7ed3\u679c\u5c31\u662f\uff0c\u5bf9\u8fd9 7690 \u4e2a\u53c2\u6570\u7684\u5fae\u8c03\uff0c\u7b97\u4e0a 5 \u6b21\u5728\u8bad\u7ec3\u5b50\u96c6\u4e0a\u8c03\u53c2\u548c\u4e00\u6b21\u5168\u91cf\u6570\u636e\u7684\u5fae\u8c03\uff0c\u4e00\u5171\u82b1\uff08\u6d6a\u8d39\u4e86\uff0910 \u5c0f\u65f6\u3002\u6240\u4ee5\u5927\u5bb6\u4e0d\u8981\u76f4\u63a5\u590d\u5236\u4e0a\u9762\u7684\u90a3\u4e2a\u5fae\u8c03\u539f\u7406\u4ee3\u7801\uff0c\u4f1a\u5f88\u6d6a\u8d39\u65f6\u95f4\uff08\u548c\u7535\uff0c\u5982\u679c\u4f60\u4f7f\u7528\u4e91\u7aef\u6536\u8d39 GPU \u7684\u8bdd\u8fd8\u5f88\u6d6a\u8d39\u94b1\uff09\u3002</p> <p>\u8fd9\u662f\u600e\u4e48\u56de\u4e8b\u5462\uff1f\u6d88\u8017\u65f6\u95f4\u7684\u5927\u5934\u7adf\u662f\u524d\u5411\u4f20\u64ad\u4e5f\u5c31\u662f\u63a8\u7406\uff01\u5b9e\u9645\u4e0a\u56e0\u4e3a\u6bcf\u4e00\u4e2a epoch \u90fd\u9700\u8981\u5bf9\u5168\u90e8\u8bad\u7ec3\u6837\u672c\u90fd\u5b8c\u6574\u8d70\u4e00\u904d\u524d\u5411\u8fc7\u7a0b\uff0c\u6240\u4ee5\u5728\u627e\u8d85\u53c2\u6570\u7684\u65f6\u5019\u6211\u91cd\u590d\u8fdb\u884c\u4e86 \\(\\dfrac{1}{5}(52+34+31+91+65)=54.6\\) \u6b21\u5168\u91cf\u6570\u636e\u7684\u524d\u5411\u4f20\u64ad\uff0c\u4f46\u5b9e\u9645\u4e0a\u6211\u4eec\u5df2\u7ecf\u51bb\u7ed3\u4e86\u9aa8\u5e72\u7f51\u7edc\uff0c\u6240\u4ee5\u53ea\u9700\u8981\u8d70\u4e00\u6b21\u5168\u91cf\u6570\u636e\u524d\u5411\u4f20\u64ad\uff0c\u5f97\u5230\u5b83\u4eec\u6700\u540e\u8f93\u51fa\u7684 784 \u7ef4\u7f16\u7801\u5411\u91cf\u5373\u53ef\uff01\u4e5f\u5c31\u662f\u8bf4\u6574\u4e2a\u8bad\u7ec3\u6d41\u7a0b\u5176\u5b9e\u53ea\u9700\u8981\u5341\u6765\u5206\u949f\u5c31\u53ef\u4ee5\u5b8c\u6210\u7684\u2026\u2026</p> <p>\u65e0\u8bba\u5982\u4f55\u5fae\u8c03\u7ed3\u679c\u662f\u76f8\u5f53\u68d2\u7684\uff0c\u51c6\u786e\u7387\u8fbe\u5230\u4e86 95% \u4ee5\u4e0a\uff0c\u53ef\u4ee5 \u5728 osu! \u91cc\u9762\u62ff\u5230 S \u8bc4\u7ea7\u4e86 \u548c\u90a3\u4e9b SOTA \u6a21\u578b\u5750\u4e00\u684c\u4e86\u3002</p> <p>\u5c06\u56fe\u50cf\u5229\u7528 Patch \u6765\u8f6c\u6362\u6210\u5d4c\u5165\u5e8f\u5217\u7684\u65b9\u5f0f\u5f88\u6709\u610f\u601d\uff01\u65e2\u7136 Transformer \u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u662f \\(O(T^2d)\\) \u7684\uff0c\u4e3a\u4f55\u4e0d\u8bf7\u51fa\u5e8f\u5217\u6570\u636e\u5904\u7406\uff08\u548c\u7ebf\u6027\u6ce8\u610f\u529b\uff09\u7684\u5143\u7956\uff0c\u5b9d\u5200\u672a\u8001\u7684 RNN \u7cfb\u5217\u6a21\u578b\u5462\uff1f\uff08\u597d\u5427 RNN \u56e0\u4e3a\u4e25\u91cd\u7684\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\u95ee\u9898\u5c1a\u80fd\u996d\u5426\u8fd8\u5f97\u6253\u4e2a\u95ee\u53f7\uff0c\u6211\u4eec\u5b9e\u9645\u4e0a\u4f7f\u7528 LSTM\uff09</p>"}, {"location": "DNN/model-expr/Image-models-replication/#patch-based-lstm", "title": "Patch based LSTM", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#patch-based-lstm_1", "title": "Patch based LSTM \u8bad\u7ec3\u7ed3\u679c\u5c55\u793a", "text": "\u8bad\u7ec3\u4f7f\u7528\u7684\u4ee3\u7801  <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\n\nclass PatchEmbedding(nn.Module):\n    \"\"\"\u5c06\u56fe\u50cf\u5206\u5272\u4e3a\u8865\u4e01\u5e76\u8fdb\u884c\u5d4c\u5165\"\"\"\n    def __init__(self, img_size=32, patch_size=2, in_channels=3, embed_dim=128):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n\n        # \u8ba1\u7b97\u8865\u4e01\u6570\u91cf\n        self.num_patches = (img_size // patch_size) ** 2\n\n        # \u4f7f\u7528\u5377\u79ef\u5c42\u5b9e\u73b0\u8865\u4e01\u5d4c\u5165 (\u7b49\u4ef7\u4e8e\u6bcf\u4e2a\u8865\u4e01\u5e94\u7528\u4e00\u4e2a\u5377\u79ef\u6838)\n        self.proj = nn.Conv2d(\n            in_channels, \n            embed_dim, \n            kernel_size=patch_size, \n            stride=patch_size\n        )\n\n    def forward(self, x: Tensor) -&gt; Tensor:\n        # x\u5f62\u72b6: (batch_size, in_channels, img_size, img_size)\n        x = self.proj(x)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, embed_dim, num_patches^(1/2), num_patches^(1/2))\n        x = x.flatten(2)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, embed_dim, num_patches)\n        x = x.transpose(1, 2)  # \u8f93\u51fa\u5f62\u72b6: (batch_size, num_patches, embed_dim)\n        return x\n\nclass PatchLSTM(nn.Module):\n    def __init__(self, num_classes=10, img_size=32, patch_size=2, \n                 embed_dim=128, hidden_size=256, num_layers=2, \n                 bidirectional=True, dropout=0.1):\n        super(PatchLSTM, self).__init__()\n\n        # \u4f7f\u7528\u5377\u79efPatch\u5d4c\u5165\u5c42\n        self.patch_embed = PatchEmbedding(\n            img_size=img_size,\n            patch_size=patch_size,\n            in_channels=3,\n            embed_dim=embed_dim\n        )\n\n        # \u8ba1\u7b97patch\u6570\u91cf\n        self.num_patches = (img_size // patch_size) ** 2\n\n        # \u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\n        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n\n        # Dropout\u5c42\n        self.dropout = nn.Dropout(dropout)\n\n        # RNN\u4e3b\u5e72\u7f51\u7edc (\u4f7f\u7528LSTM)\n        self.rnn = nn.LSTM(\n            input_size=embed_dim,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=bidirectional,\n            dropout=dropout if num_layers &gt; 1 else 0\n        )\n\n        # \u5206\u7c7b\u5934\n        rnn_output_size = hidden_size * 2 if bidirectional else hidden_size\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(rnn_output_size),\n            nn.Linear(rnn_output_size, hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, num_classes)\n        )\n\n    def forward(self, x):\n        # x\u5f62\u72b6: [B, 3, 32, 32]\n\n        # 1. \u4f7f\u7528\u5377\u79ef\u5c42\u8fdb\u884cpatch\u5d4c\u5165\n        patch_embeddings = self.patch_embed(x)  # [B, num_patches, embed_dim]\n\n        # 2. \u6dfb\u52a0\u4f4d\u7f6e\u7f16\u7801\n        patch_embeddings = patch_embeddings + self.pos_embed\n\n        # 3. \u5e94\u7528dropout\n        patch_embeddings = self.dropout(patch_embeddings)\n\n        # 4. \u901a\u8fc7RNN\u5904\u7406\u5e8f\u5217\n        rnn_output, _ = self.rnn(patch_embeddings)  # [B, num_patches, hidden_size * num_directions]\n\n        # 5. \u53d6\u5e8f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u8f93\u51fa\uff08\u8003\u8651\u4e86\u53cc\u5411\u4fe1\u606f\uff09\n        sequence_representation = rnn_output[:, -1, :]  # [B, hidden_size * num_directions]\n\n        # 6. \u5206\u7c7b\n        logits = self.classifier(sequence_representation)\n        return logits\n\ndef get_model_on_device():\n    # \u521b\u5efa\u6a21\u578b\u5b9e\u4f8b\n    model = PatchLSTM(\n        num_classes=10,        # CIFAR-10\u670910\u4e2a\u7c7b\u522b\n        img_size=32,           # CIFAR-10\u56fe\u50cf\u5c3a\u5bf8\n        patch_size=2,          # 2x2\u7684patch\n        embed_dim=128,         # \u5d4c\u5165\u7ef4\u5ea6\n        hidden_size=256,       # RNN\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\n        num_layers=2,          # RNN\u5c42\u6570\n        bidirectional=True,    # \u4f7f\u7528\u53cc\u5411RNN\n        dropout=0.1            # Dropout\u7387\n    )\n\n    # \u5c06\u6a21\u578b\u79fb\u52a8\u5230\u6307\u5b9a\u8bbe\u5907\n    return model.to(device)\n</code></pre>  Patch based LSTM \u7684\u8bad\u7ec3\u7ed3\u679c   ![plstm_result](./image.png)  <pre><code>==================================================\n               Results\n==================================================\n\n[Hyper parameters]\n  - Best LR: 0.000425\n  - Best epochs: 20 epochs\n  - Batch size: 128\n\n[Model structure]\n  - Model type: Patch based LSTM\n  - Model structure:\nPatchRNN(\n  (patch_embed): PatchEmbedding(\n    (proj): Conv2d(3, 128, kernel_size=(2, 2), stride=(2, 2))\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (rnn): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n  (classifier): Sequential(\n    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=512, out_features=256, bias=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n  - Total params: 2,536,842\n\n[Training infomation]\n  - Training duration on full training set: 20m 27s\n  - Training device: cuda on Kaggle's free P100, Thank you Google!\n\n[Benchmarks on test set]\n  - Test loss: 1.1816\n  - Test accuracy: 68.11%\n\n==================================================\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#patch-based-lstm_2", "title": "\u5bf9 Patch based LSTM \u7684\u89e3\u8bfb\u548c\u8bc4\u8ff0", "text": "<p>\u4e0b\u9762\u662f\u603b\u7684\u6a21\u578b\u7ed3\u6784\u56fe\uff0c\u4f7f\u7528\u4e86\u53cc\u5c42\u7684\u53cc\u5411 LSTM \u4f5c\u4e3a\u7f16\u7801\u5668\u3002\u5176\u5b9e\u53cc\u5411\u4ecd\u7136\u5728\u63d0\u53d6\u4f4d\u7f6e\u5173\u7cfb\u4e0a\u8fd8\u662f\u4e0d\u591f\u5145\u5206\u7684\uff0c\u56e0\u4e3a\u5c3d\u7ba1\u56fe\u50cf Patch \u5316\u4e86\uff0c\u5176\u5173\u8054\u4ecd\u7136\u4e0d\u662f\u7eaf\u7ebf\u6027\u5e8f\u5217\u7684\uff0c\u6240\u4ee5\u8fd8\u662f\u52a0\u4e0a\u4e86\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\u3002\u8fd9\u91cc\u7684\u7ed3\u6784\u5176\u5b9e\u5c31\u662f\u7c7b\u4f3c\u4e8e\u628a nanoViT \u7684\u56db\u4e2a TransformerEncoder \u6362\u6210\u4e86\u57fa\u4e8e LSTM \u7684 RNN Encoder\u3002\u81f3\u4e8e\u4e3a\u4ec0\u4e48\u8f93\u5165\u5e8f\u5217\u7ef4\u5ea6 128 \u8fc7\u4e86\u8fd9\u4e2a\u7f16\u7801\u5668\u4e4b\u540e\u5c31\u53d8\u6210 512 \u4e86\u5462\uff1f\u4e14\u770b\u540e\u9762\u5bf9\u8fd9\u4e2a\u7f16\u7801\u5668\u7684\u62c6\u89e3\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n    classDef rnn fill:#313244,stroke:#f9e2af,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3@32\u00d732\")]\n    end\n    class Input input;\n\n    %% Patch Embedding\n    subgraph PatchEmbed[\"Patch Embedding\"]\n        B[\"Conv2d&lt;br&gt; 3x128 x 2\u00d72 / 2\"]\n    end\n    A --&gt;|Image| B\n    class PatchEmbed conv;\n\n    %% Positional Encoding\n    subgraph PosEnc[\"Positional Encoding\"]\n        S[\"Parameter Matrix&lt;br&gt;256 x 128\"]\n    end\n    class PosEnc conv;\n\n    D[(\"+\")]\n    S --&gt; D\n    B --&gt;|256 patches&lt;br&gt;128 dim per patch| D\n\n    %% Dropout\n    T[\"Dropout&lt;br&gt;p=0.1\"]\n    D --&gt; T\n\n    %% RNN Encoder\n    subgraph RnnEncoder[\"RNN Encoder\"]\n        E[\"2-Layer Bi-LSTM&lt;br&gt;hidden=256\"]\n    end\n    T --&gt;|256x128| E\n    class RnnEncoder rnn;\n\n    %% Extract Last Output\n    I[\"Extract Last&lt;br&gt;Time Step's Output\"]\n    E --&gt;|Sequence Output&lt;br&gt;256x512| I\n\n    %% Classification Head\n    subgraph Classifier[\"MLP Head\"]\n        J[\"LayerNorm&lt;br&gt;512 dim\"]\n        K[\"Linear&lt;br&gt;512x256\"]\n        L[\"GELU\"]\n        M[\"Dropout&lt;br&gt;p=0.1\"]\n        N[\"Linear&lt;br&gt;256x10\"]\n    end\n    I --&gt;|Vector&lt;br&gt;512 dim| J --&gt; K --&gt; L --&gt; M --&gt; N\n    class Classifier box;\n\n    %% Output Layer\n    subgraph OutputLayer[\"Output\"]\n        O[(\"10\")]\n    end\n    N --&gt; O\n    class OutputLayer output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style O stroke:#a6e3a1,stroke-width:3px</code></pre> <p>\u4e0b\u9762\u662f\u5177\u4f53\u7684\u7f16\u7801\u5668\u67b6\u6784\u3002\u8f93\u5165\u5e8f\u5217\u662f\u4e00\u4e2a\u957f\u5ea6 256\uff0c\u5d4c\u5165\u7ef4\u5ea6 128 \u7684\u5e8f\u5217\uff0c\u5206\u522b\u8f93\u5165\u5230\u6b63\u5411\u548c\u53cd\u5411\u7684 LSTM \u91cc\u9762\uff0c\u53d6\u8f93\u51fa\u4e5f\u5c31\u662f\u9690\u85cf\u5c42\u72b6\u6001 \\(h\\)\uff0c\u5728\u5d4c\u5165\u7ef4\u5ea6\u4e0a\u62fc\u5230\u4e00\u8d77\uff0c\u5f97\u5230\u65b0\u7684\u5e8f\u5217\uff0c\u4e5f\u5c31\u662f\u9690\u85cf\u5c42\u7684\u7ef4\u5ea6 256\uff0c\u7136\u540e\u518d\u8fc7\u4e00\u904d\u6b63\u53cd\u5411 LSTM\uff0c\u7ef4\u5ea6\u518d\u7ffb\u4e00\u500d\uff0c\u5f97\u5230\u8f93\u51fa\u7684\u7ef4\u5ea6 512\u3002\u6240\u4ee5\u53cc\u5411 LSTM \u8f93\u51fa\u7ef4\u5ea6\u662f\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u7684\u4e24\u500d\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef rnn fill:#313244,stroke:#f9e2af,stroke-width:2px,color:#cdd6f4;\n\n    %% Input\n    Input[(\"Input Sequence&lt;br&gt;256 \u00d7 128\")]\n    class Input input\n\n    %% Layer 1\n    subgraph LSTM_Layer_1 [\"LSTM Layer 1\"]\n        direction LR\n        Fwd1[\"Forward LSTM&lt;br&gt;h=256\"]\n        Bwd1[\"Backward LSTM&lt;br&gt;h=256\"]\n    end\n\n    Concat1[\"Concatenate&lt;br&gt;Outputs\"]\n\n    Input --&gt; Fwd1\n    Input --&gt; Bwd1\n    Fwd1 --&gt; |256x256| Concat1\n    Bwd1 --&gt; |256x256| Concat1\n\n    %% Dropout between layers\n    Drop[\"Dropout&lt;br&gt;p=0.1\"]\n    Concat1 --&gt; |256x512| Drop\n\n    %% Layer 2\n    subgraph LSTM_Layer_2 [\"LSTM Layer 2\"]\n        direction LR\n        Fwd2[\"Forward LSTM&lt;br&gt;h=256\"]\n        Bwd2[\"Backward LSTM&lt;br&gt;h=256\"]\n    end\n\n    Concat2[\"Concatenate&lt;br&gt;Outputs\"]\n\n    Drop --&gt; Fwd2\n    Drop --&gt; Bwd2\n    Fwd2 --&gt; |256x256| Concat2\n    Bwd2 --&gt; |256x256| Concat2\n\n    %% Output\n    Output[(\"Output Sequence&lt;br&gt;256 \u00d7 512\")]\n    class Output output\n\n    Concat2 --&gt; |256x512| Output\n\n    %% Styling\n    class LSTM_Layer_1,LSTM_Layer_2 rnn</code></pre> <p>\u4e0b\u9762\u662f LSTM \u7684\u5177\u4f53\u7ed3\u6784\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef gate fill:#313244,stroke:#89dceb,stroke-width:2px,color:#cdd6f4;\n    classDef cell fill:#313244,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef op fill:#45475a,stroke:#cdd6f4,stroke-width:1px,shape:circle;\n    classDef transform fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef title fill:#1e1e2e,stroke:#cba6f7,stroke-width:1px,color:#cba6f7;\n\n    %% Inputs\n    subgraph Inputs\n        direction LR\n        Xt[\"Input x_t&lt;br&gt;dim: 128\"]\n        Ht_1[\"Hidden h_t-1&lt;br&gt;dim: 256\"]\n    end\n    Ct_1[\"Cell c_t-1&lt;br&gt;dim: 256\"]\n\n    %% Concatenation\n    Concat[\"Concatenate [h_t-1, x_t]&lt;br&gt;dim: 256 + 128 = 384\"]\n    Ht_1 --&gt; Concat\n    Xt --&gt; Concat\n\n    %% Linear Transformation\n    subgraph LinearProj [\"Gate &amp; Cell Candidate Projections\"]\n        W[\"Linear &lt;br&gt;input: 384&lt;br&gt;output: 4 * 256 = 1024&lt;br&gt;(Effectively 4 parallel Linear(384, 256) layers)\"]\n    end\n    Concat --&gt; W\n    class LinearProj transform;\n\n    %% Gate Activations\n    subgraph GateActivations [\"Gate Activations\"]\n        direction LR\n        subgraph ForgetGate[\"Forget Gate\"]\n            S_f[\"Sigmoid\"]\n        end\n        subgraph InputGate[\"Input Gate\"]\n            S_i[\"Sigmoid\"]\n        end\n        subgraph CellCandidate[\"Cell Candidate\"]\n            T_g[\"tanh\"]\n        end\n        subgraph OutputGate[\"Output Gate\"]\n            S_o[\"Sigmoid\"]\n        end\n    end\n    W --&gt; |Linear proj for f_t| S_f\n    W --&gt; |Linear proj for i_t| S_i\n    W --&gt; |Linear proj for g_t| T_g\n    W --&gt; |Linear proj for o_t| S_o\n\n    %% Cell State Update\n    subgraph CellState[\"Cell State Update\"]\n        Mul1(\"\u2299\")\n        Mul2(\"\u2299\")\n        Add(\"+\")\n    end\n\n    subgraph state[\"States of this time step\"]\n        Ct_1\n        Concat\n    end\n\n    S_f --&gt; |f_t&lt;br&gt;dim: 256| Mul1\n    Ct_1 --&gt; Mul1\n\n    S_i --&gt; |i_t&lt;br&gt;dim: 256| Mul2\n    T_g --&gt; |g_t&lt;br&gt;dim: 256| Mul2\n\n    Mul1 --&gt; Add\n    Mul2 --&gt; Add\n\n    Ct[\"New Cell c_t&lt;br&gt;dim: 256\"]\n    Add --&gt; Ct\n\n    %% Hidden State Update\n    subgraph HiddenState[\"Hidden State Update\"]\n        T_c[\"tanh\"]\n        Mul3(\"\u2299\")\n    end\n\n    Ct --&gt; T_c\n    S_o --&gt; |o_t&lt;br&gt;dim: 256| Mul3\n    T_c --&gt; Mul3\n\n    Ht[\"New Hidden h_t&lt;br&gt;dim: 256\"]\n    Mul3 --&gt; Ht\n\n    %% Recurrent Connections to next time step\n    Ct ---&gt; nCt_1\n    Ht  ---&gt; nHt_1\n    nXt_1 --&gt; nHt_1\n\n    subgraph nip[\"Input of the next time step\"]\n        nXt_1[\"Input x_t+1&lt;br&gt;dim: 256\"]\n        Ht\n    end\n\n    subgraph nst[\"States of the next time step\"]\n        nCt_1[\"Cell c_t&lt;br&gt;dim: 256\"]\n        nHt_1[\"Concatenated vector&lt;br&gt;dim: 384\"]\n    end\n\n    %% Styling\n    class Title title;\n    class Inputs,nip input;\n    class Ht,Ct output;\n    class GateActivations gate;\n    class CellState,HiddenState cell;\n    class Mul1,Mul2,Mul3,Add op;</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u4e0b\uff0c\u5148\u5c06\u8f93\u5165\u548c\u9690\u85cf\u72b6\u6001\u62fc\u63a5\uff0c\u7531\u8fd9\u4e2a 384 \u7ef4\u7684\u62fc\u63a5\u5411\u91cf\u7ecf\u8fc7\u4e00\u4e2a 4 \u500d\u9690\u85cf\u7ef4\u5ea6\u7684\u6295\u5f71\u5c42\uff0c\u5f88\u81ea\u7136\u7684\u5c31\u53ef\u4ee5\u628a\u6295\u5f71\u5411\u91cf\u5206\u6210\u56db\u4efd\u3002\u6bcf\u4e00\u4efd\u662f\u90fd\u5bf9\u5f53\u524d\u72b6\u6001\u548c\u5f53\u524d\u9690\u85cf\u72b6\u6001\u7684\u7279\u5f81\u8fdb\u884c\u6620\u5c04\u7684\u5411\u91cf\u3002\u8fd9\u4e9b\u5411\u91cf\u8981\u8d1f\u8d23\u7ed3\u5408\u7ec6\u80de\u72b6\u6001\u6765\u63a7\u5236\u72b6\u6001\u7684\u66f4\u65b0\u548c\u8f93\u51fa\u3002\u5176\u5b9e\u8fd9\u4e00\u6b65\u5f88\u50cf\u4f18\u5316\u5668\u7684\u6d41\u7a0b\uff0c\u4e8b\u5b9e\u4e0a\u5df2\u7ecf\u6709\u5173\u4e8e RNN \u548c\u4f18\u5316\u5668\u7684\u4e00\u4e9b\u5bf9\u6bd4\u8ba8\u8bba\u4e86\u3002</p> <p>\u9996\u5148\u6765\u770b\u7b2c\u4e00\u4e2a\u6295\u5f71\u5411\u91cf \\(f_t\\)\uff0c\u7ecf\u8fc7 Sigmoid \u6fc0\u6d3b\u540e\uff0c\u5c06\u5176\u4e0e\u7ec6\u80de\u72b6\u6001 \\(c_{t-1}\\) \u76f8\u4e58\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7 \\(f_t\\) \u6765\u63a7\u5236\u54ea\u4e9b\u5206\u91cf\u5e94\u8be5\u5fd8\u6389\uff0c\u4e5f\u5c31\u662f\u6fc0\u6d3b\u540e\u5f97\u5230 0 \u7684\u4f4d\u7f6e\u3002</p> <p>\u65e2\u7136\u6709\u9057\u5fd8\uff0c\u90a3\u4e5f\u9700\u8981\u8bb0\u5fc6\u3002\u8fd9\u5c31\u4ea4\u7ed9 \\(i_t\\) \u548c \\(g_t\\)\u3002\u7531\u4e8e \\(i_t\\) \u662f\u7279\u5f81\u7ecf\u8fc7 Sigmoid \u6fc0\u6d3b\u7684\u7ed3\u679c\uff0c\u6052\u4e3a\u6b63\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f5c\u4e3a\u7eaf\u8f93\u5165\u7684\u4fe1\u606f\u3002\u800c \\(g_t\\) \u7ecf\u8fc7\u7684\u662f tanh \u6fc0\u6d3b\uff0c\u6709\u6b63\u6709\u8d1f\uff0c\u548c \\(i_t\\) \u76f8\u4e58\u4e4b\u540e\uff0c\u4e00\u65b9\u9762\u53ef\u4ee5\u8bf4\u662f\u589e\u52a0\u7f51\u7edc\u7684\u5bbd\u5ea6\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u5bf9\u8f93\u5165\u4fe1\u606f\u63d0\u4f9b\u5408\u7406\u7684\u6291\u5236\uff0c\u9632\u6b62\u5176\u5355\u8c03\u9012\u589e\u3002\u6700\u540e\u548c\u9057\u5fd8\u95e8\u7684\u7ed3\u679c\u52a0\u8d77\u6765\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u65b0\u7684\u7ec6\u80de\u72b6\u6001 \\(c_t\\) \u4e86\u3002\u8fd9\u91cc\u7684\u7ec6\u80de\u72b6\u6001\u901a\u8fc7\u95e8\u63a7\u51b3\u5b9a\u81ea\u5df1\u5e94\u8be5\u4fdd\u7559\u591a\u5c11\u3001\u66f4\u65b0\u591a\u5c11\uff0c\u4f5c\u7528\u5c31\u548c\u6734\u7d20 RNN \u7684\u9690\u85cf\u72b6\u6001\u662f\u4e00\u81f4\u7684\u3002</p> <p>\u4f46\u662f LSTM \u91cc\u9762\u4e5f\u51fa\u73b0\u4e86\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\uff0c\u6309\u6211\u7684\u7406\u89e3\uff0c\u5176\u5b9e LSTM \u533a\u5206\u7ec6\u80de\u72b6\u6001\u548c\u9690\u85cf\u72b6\u6001\u662f\u4e00\u79cd\u5bf9 RNN \u9690\u85cf\u72b6\u6001\u7684\u529f\u80fd\u89e3\u8026\u3002\u56e0\u4e3a\u4e00\u65b9\u9762\uff0c\u9690\u85cf\u72b6\u6001\u8981\u8d1f\u8d23\u8bb0\u5fc6\u5148\u524d\u7684\u5e8f\u5217\u4fe1\u606f\uff0c\u53e6\u4e00\u65b9\u9762\uff0c\u9690\u85cf\u72b6\u6001\u8fd8\u8981\u80a9\u8d1f\u8d77\u63d0\u53d6\u5e8f\u5217\u7279\u5f81\u8f93\u51fa\u7684\u4f5c\u7528\uff0c\u6240\u4ee5 LSTM \u91c7\u7528\u4e86\u7ec6\u80de\u72b6\u6001\u8bb0\u5fc6\u5e8f\u5217\u4fe1\u606f\uff0c\u800c\u548c\u8f93\u5165\u4e00\u8d77\u4e22\u8fdb\u6765\u7684\u90a3\u4e2a\u6240\u8c13\u7684\u9690\u85cf\u72b6\u6001\uff0c\u8d77\u5230\u7684\u5c31\u662f\u63d0\u53d6\u7279\u5f81\u7684\u4f5c\u7528\u3002\u4f55\u4ee5\u89c1\u5f97\uff1f\u8ba9\u6211\u4eec\u770b\u770b\u8f93\u51fa\u7684\u8ba1\u7b97\u3002</p> <p>\u8fd9\u91cc\u4ecd\u7136\u662f\u7279\u5f81\u7ecf\u8fc7 Sigmoid \u6fc0\u6d3b\u540e\u5f97\u5230\u5411\u91cf \\(o_t\\)\uff0c\u7136\u540e\u9700\u8981\u548c tanh \u6fc0\u6d3b\u540e\u7684\u65b0\u7ec6\u80de\u72b6\u6001\u76f8\u4e58\u2014\u2014\u4e5f\u5c31\u662f\u8bf4\uff0c\u4e3a\u4e86\u5f97\u5230\u65b0\u7684\u9690\u85cf\u72b6\u6001\uff0c\u9700\u8981\u53c2\u8003\u76ee\u524d\u7684\u8bb0\u5fc6\uff0c\u6765\u9009\u62e9\u6027\u63d0\u53d6\u5f53\u524d\u8f93\u5165\u5e26\u6765\u7684\u7279\u5f81\u3002</p> <p>\u56e0\u6b64 LSTM \u4e5f\u53ef\u4ee5\u89e3\u51b3 RNN \u7684\u68af\u5ea6\u7206\u70b8/\u6d88\u5931\u7684\u95ee\u9898\u3002RNN \u56e0\u4e3a\u662f\u5bf9\u8bb0\u5fc6\u7684\u5168\u91cf\u66f4\u65b0\uff0c\u5f88\u5bb9\u6613\u9057\u5fd8\u65e9\u671f\u4fe1\u606f\uff0c\u540c\u65f6\u4e5f\u5728\u8fd9\u79cd\u5168\u91cf\u66f4\u65b0\u4e0a\u7d2f\u79ef\u68af\u5ea6\uff0c\u6210\u4e86\u7b49\u6bd4\u6570\u5217\uff1b\u800c LSTM \u53ea\u4e0d\u8fc7\u5f15\u5165\u95e8\u63a7\u6765\u9650\u5236\u66f4\u65b0\uff0c\u5c31\u53ef\u4ee5\u589e\u5f3a\u8bb0\u5fc6\u529b\u800c\u7f13\u89e3\u68af\u5ea6\u95ee\u9898\u3002</p> <p>\u5f53\u7136\u6700\u540e\u8bad\u7ec3\u51fa\u6765\u4e00\u4e2a\u53c2\u6570\u91cf 2M \u7684 LSTM\uff0c\u8fd8\u662f\u6ca1\u80fd\u6253\u8d25 nanoViT\u3002\u6bd5\u7adf\u4e8c\u7ef4\u7684\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u5bf9\u957f\u8ddd\u79bb/\u7a7a\u95f4\u4e0a\u7684\u7279\u5f81\u4f9d\u8d56\u6548\u679c\u5fc5\u7136\u597d\u4e8e\u4ec5\u9760\u4e00\u4e24\u4e2a\u9690\u85cf\u72b6\u6001\u5efa\u6a21\u8bb0\u5fc6\u529b\u7684 LSTM \u597d\u3002\u4e0d\u8fc7\uff0c\u6211\u4eec\u4e5f\u6ca1\u6709\u5fc5\u8981\u52c9\u5f3a\u5b83\uff0c\u6bd5\u7adf\uff0c\u56fe\u50cf\u4efb\u52a1\u4ece\u6765\u90fd\u4e0d\u662f\u64c5\u957f\u5e8f\u5217\u5efa\u6a21\u7684 RNN \u7684\u5f3a\u9879\u3002\u81f3\u5c11\u6211\u4eec\u8bc1\u660e\u4e86\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f7f\u7528 RNN \u662f\u53ef\u884c\u7684\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#vae", "title": "VAE", "text": "<p>\u8fd9\u91cc\u7b14\u8005\u4f7f\u7528\u4e86\u4e09\u79cd\u5229\u7528 VAE \uff08\u51c6\u786e\u8bf4\u662f \u03b2-VAE\uff09\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c \u8ba9\u6211\u4eec\u6309\u7167\u4ece\u592f\u5230\u62c9\u7684\u987a\u5e8f\u8bc4\u9274\u4e00\u4e0b \u601d\u8def\u5404\u5f02\uff1a</p> <ul> <li>\u5728\u9690\u7a7a\u95f4\u8fdb\u884c K-means \u805a\u7c7b\uff0c\u6309\u6807\u7b7e\u6295\u7968\u6210\u4e3a\u8be5\u805a\u7c7b\u7684\u6807\u7b7e\u3002</li> <li>CVAE\uff0c\u5373\u62fc\u63a5\u56fe\u50cf\u548c\u6807\u7b7e\uff0c\u518d\u7ed9\u9690\u7a7a\u95f4\u52a0\u4e2a\u6807\u7b7e\u7ef4\u5ea6\uff0c\u8fd9\u6837\u751a\u81f3\u53ef\u4ee5\u5e26\u6807\u7b7e\u751f\u6210\u3002</li> <li>\u8fd8\u662f CVAE \u7684\u601d\u8def\uff0c\u4f46\u662f\u501f\u7528\u7f16\u7801\u5668\u7684\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5934\uff0c\u5c06\u5206\u7c7b\u635f\u5931\u7f29\u653e\u4e00\u4e2a\u6bd4\u4f8b\u63ba\u5230\u603b\u635f\u5931\u91cc\u9762\uff08\u6216\u8bb8\u53ef\u4ee5\u53eb \u03b3-C-\u03b2-VAE\uff1f\uff09\uff0c\u5176\u5b9e\u6709\u70b9\u7c7b\u4f3c\u7528 VAE \u7ed9\u7f16\u7801\u5668\u505a\u6b63\u5219\u5316\u3002</li> </ul> <p>\u7531\u4e8e CIFAR-10 \u7684\u8bad\u7ec3\u96c6\u98ce\u683c\u5dee\u5f02\u5f88\u5927\u4e14\u6570\u636e\u91cf\u4e5f\u4e0d\u591f\uff0c\u6240\u4ee5\u5728\u4ecb\u7ecd\u5c06 VAE \u63a5\u5165\u5206\u7c7b\u4efb\u52a1\u4e4b\u524d\uff0c\u5148\u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e0b VAE \u7684\u672c\u95e8\u529f\u592b\u2014\u2014\u56fe\u50cf\u751f\u6210\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#aka", "title": "\u52a8\u6f2b\u98ce\u683c\u5934\u50cf\u751f\u6210 a.k.a. \u753b\u8001\u5a46", "text": "<p>\u672c\u6b21\u4f7f\u7528\u7684\u6570\u636e\u96c6\u662f Kaggle \u4e0a\u9762\u7684 Anime Face Dataset\uff0c\u662f\u57fa\u4e8e Danbooru \u7684\u4e00\u4e2a 63k \u5f20\u56fe\u50cf\u7684\u5b50\u96c6\uff0c\u4f46\u662f GitHub \u4e0a\u7684\u6570\u636e\u8c8c\u4f3c\u56e0\u4e3a\u7248\u6743\u539f\u56e0\u88ab\u62ff\u4e0b\u4e86\u3002\u4e0d\u8fc7\u6211\u672c\u6765\u4e00\u76f4\u90fd\u5728 Kaggle \u7684 GPU \u4e0a\u9762\u8bad\u7ec3\u6240\u4ee5\u4e5f\u6ca1\u591a\u5927\u5f71\u54cd\u3002</p> <p>\u6570\u636e\u96c6\u662f\u4e0d\u5e26\u6807\u7b7e\u7684 3@64x64 \u56fe\u50cf\uff0c\u4e0b\u9762\u662f\u4e00\u4e9b\u6837\u672c\uff1a</p> <p></p> <p>\uff08\u7b2c\u4e94\u6392\u4ece\u5de6\u5f80\u53f3\u7b2c\u4e09\u4e2a\u662f galgame \"Island\" \u7684\u5973\u4e3b\u5fa1\u539f\u51db\u97f3\u7684\u7acb\u7ed8\uff0c\u5927\u5bb6\u90fd\u6765\u73a9\u554a~ \u73b0\u5728\u77e5\u9053\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u6570\u636e\u96c6\u5728GitHub\u4e0a\u56e0\u4e3a\u7248\u6743\u95ee\u9898\u88ab\u62ff\u4e0b\u4e86\u5427 \uff09</p> <p>\u6211\u4eec\u73b0\u5728\u7684\u4efb\u52a1\u5c31\u662f\u6839\u636e\u5df2\u7ecf\u6709\u7684\u5934\u50cf\uff0c\u753b\u51fa\u65b0\u7684\u5934\u50cf\u3002\u4e5f\u5c31\u662f \\(y=f(x)\\) \u5176\u4e2d \\(y\\) \u662f\u6211\u4eec\u7684\u751f\u6210\u56fe\u7247\uff0c \\(x\\) \u662f\u539f\u59cb\u56fe\u7247\u3002\u4e3a\u4e86\u907f\u514d\u4e71\u751f\u6210\uff0c\u5176\u5b9e\u9700\u8981\u6700\u5c0f\u5316 \\(y\\) \u548c \\(x\\) \u7684\u504f\u5dee\u3002\u2014\u2014\u8fd9\u4e0d\u662f ResNet \u5e72\u7684\u6d3b\u5417\uff1f\u56e0\u6b64\u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u6f84\u6e05\u4e00\u70b9\uff1a</p> <p>\u6211\u4eec\u5e76\u4e0d\u662f\u53d6\u5b66\u4e60\u67d0\u4e00\u5f20\u56fe\u7247\uff0c\u800c\u662f\u6240\u6709\u8bad\u7ec3\u56fe\u7247\u6784\u6210\u7684\u6982\u7387\u5206\u5e03\uff01\u4e86\u89e3\u4e86\u8fd9\u4e2a\u6982\u7387\u5206\u5e03\u7684\u5f62\u72b6\u4e4b\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u91cc\u9762\u91c7\u6837\uff0c\u5f97\u5230\u751f\u6210\u7684\u56fe\u7247\u4e86\u3002\u800c ResNet \u53ea\u4f1a\u628a\u8f93\u5165\u6570\u636e\u539f\u6837\u8fd4\u56de\u3002</p> <p>\u6211\u4eec\u5047\u8bbe\u8f93\u5165\u7684\u6570\u636e\u4e3a \\(x\\) \u800c\u6982\u7387\u5206\u5e03\u4e3a \\(p(x)\\)\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u4e2a\u65b9\u5f0f\u53bb\uff08\u8fd1\u4f3c\uff09\u63cf\u8ff0 \\(p(x)\\)\u3002\u7531\u4e8e\u6570\u636e\u7ef4\u5ea6\u5f88\u9ad8\uff0c\u4e14\u7ef4\u5ea6\u4e4b\u95f4\u6709\u590d\u6742\u7684\u76f8\u4e92\u5173\u8054\uff0c\u56e0\u6b64\u76f4\u63a5\u5bfb\u627e\u662f\u76f8\u5f53\u590d\u6742\u7684\uff0c\u90a3\u600e\u4e48\u529e\u5462\uff1f</p> <p>\u8bf6\uff0c\u5f53\u6211\u4eec\u9700\u8981\u5728\u590d\u6742\u4efb\u52a1\u91cc\u9762\u627e\u89c4\u5f8b\u7684\u65f6\u5019\uff0c\u7b2c\u4e00\u65f6\u95f4\u60f3\u5230\u7684\u662f\u4ec0\u4e48\uff1f\u964d\u7ef4\uff01\u5177\u4f53\u800c\u8a00\uff0c\u5c31\u662f\u8003\u8651\u8fd9\u4e2a\u76ee\u6807\u5206\u5e03\u662f\u8f93\u5165\u901a\u8fc7\u7f16\u7801\u518d\u89e3\u7801\u7684\u7ed3\u679c\uff0c\u800c\u7f16\u7801\u7684\u8fc7\u7a0b\uff0c\u5c31\u662f\u5bf9\u7279\u5f81\u548c\u89c4\u5f8b\u8fdb\u884c\u964d\u7ef4\u3001\u538b\u7f29\u3001\u63d0\u53d6\u7684\u8fc7\u7a0b\uff1a</p> \\[ p(x)\\approx q(x)=\\int q(x|z)q(z)\\mathrm d z \\] <p>\u8fd9\u91cc\uff0c\\(x\\) \u662f\u8f93\u5165\uff0c\\(q(x)\\) \u662f\u6211\u4eec\u5bf9\u76ee\u6807\u51fd\u6570 \\(p(x)\\) \u7684\u62df\u5408\u5c1d\u8bd5\uff0c\\(z\\) \u662f\u964d\u7ef4\u540e\u7684\u9690\u53d8\u91cf\uff0c\\(q(z)\\) \u5c31\u662f\u9690\u53d8\u91cf\u7684\u5206\u5e03\uff0c\u800c \\(q(x|z)\\)  \u5c31\u662f\u4ece\u9690\u53d8\u91cf\u751f\u6210\u56fe\u7247\u7684\u89e3\u7801\u5668\u3002\u8fd9\u4e2a\u5f0f\u5b50\u5f88\u597d\u7406\u89e3\uff0c\u91cc\u9762\u7684\u7b49\u5f0f\u5c31\u662f\u5168\u6982\u7387\u516c\u5f0f\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u8981\u89e3\u51b3\u8fd9\u6837\u51e0\u4e2a\u95ee\u9898\uff1a</p> <ul> <li>\u600e\u4e48\u83b7\u53d6\u7f16\u7801\u5668\uff0c\u4e5f\u5c31\u662f\u4ece\u539f\u59cb\u7684\u56fe\u50cf\u5f97\u5230\u9690\u53d8\u91cf\u7684\u5206\u5e03\uff1f</li> <li>\u600e\u4e48\u8861\u91cf\u4e24\u4e2a\u5206\u5e03\u7684\u8fd1\u4f3c\u7a0b\u5ea6\u6765\u5f97\u5230\u635f\u5931\u51fd\u6570\uff1f</li> </ul> <p>\u7b2c\u4e00\u4e2a\u95ee\u9898\u6bd4\u8f83\u6838\u5fc3\uff0c\u4e5f\u6d89\u53ca\u5230 VAE \u7684\u751f\u56fe\u98ce\u683c\uff0c\u6211\u4eec\u7b49\u4f1a\u518d\u804a\u3002\u7b2c\u4e8c\u4e2a\u95ee\u9898\uff0c\u5927\u5bb6\u57fa\u672c\u4e0a\u90fd\u80fd\u8131\u53e3\u800c\u51fa\u2014\u2014\u4f7f\u7528 KL \u6563\u5ea6\u4e0d\u5c31\u884c\u4e86\u5417\u3002</p> <p>\u4f46\u662f\u8fd9\u91cc\u5982\u679c\u8ba1\u7b97 \\(p(x)\\) \u548c \\(q(x)\\) \u7684 KL \u6563\u5ea6\uff0c\u5176\u5b9e\u5f88\u4e0d\u65b9\u4fbf\uff0c\u56e0\u4e3a\u4e00\u662f\u8fd9\u4e9b\u5f0f\u5b50\u90fd\u6bd4\u8f83\u539f\u5b50\u5316\u62c6\u4e0d\u5f00\u5c31\u4e0d\u597d\u5316\u7b80\uff08\u66f4\u4f55\u51b5 \\(p(x)\\) \u90fd\u4e0d\u77e5\u9053\uff0c\u6ca1\u529e\u6cd5\u7b97\uff09\uff0c\u4e8c\u662f\u521a\u521a\u8d39\u529b\u5f15\u5165\u7684 \\(z\\) \u6ca1\u7528\u4e0a\u3002</p> <p>\u56e0\u6b64\u6211\u4eec\u8003\u8651\u5bf9\u8054\u5408\u5206\u5e03 \\(p(x,z)\\) \u548c \\(q(x,z)\\) \u8ba1\u7b97 KL \u6563\u5ea6\uff0c\u4e5f\u5c31\u662f\u8bf4\u5229\u7528\u9690\u53d8\u91cf\u76f8\u5bf9 \\(p\\) \u4e0e \\(q\\) \u7684\u5173\u7cfb\uff1a\uff08\u63a8\u5bfc\u7565\u957f\u4f46\u662f\u4e0d\u96be\uff0c\u4e0b\u9762\u6709 Hint\uff09</p> \\[ \\begin{align*}   KL\\left(p(x,z)||q(x,z)\\right)&amp;=\\int\\int p(x,z) \\log \\dfrac{p(x,z)}{q(x,z)} \\mathrm d x \\mathrm d z\\\\   &amp;= \\int\\int p(x)p(z|x) \\log\\dfrac{p(x)p(z|x)}{q(x,z)} \\mathrm d z \\mathrm d x\\\\   &amp;=\\int p(x)[\\int p(z|x)\\log\\dfrac{p(x)p(z|x)}{q(x,z)} \\mathrm d z]\\mathrm d x\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\int p(z|x)[\\log p(x) + \\log p(z|x)- \\log q(x,z)] \\mathrm d z]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\log p(x)+\\int p(z|x)\\log\\dfrac{p(z|x)}{q(z)q(x|z)}\\mathrm d z]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\log p(x)-\\int p(z|x)\\log q(x|z)\\mathrm d z+\\int p(z|x)\\log\\dfrac{p(z|x)}{q(z)}\\mathrm d z]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\log p(x)-\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]+\\int p(z|x)\\log\\dfrac{p(z|x)}{q(z)}\\mathrm d z]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\log p(x)-\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]+KL(p(z|x) || q(z))]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\log p(x)]+\\mathbb E_{x\\sim p(x)}[-\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]+KL(p(z|x) || q(z))]\\\\   &amp;=\\mathrm{Constant.}+\\mathbb E_{x\\sim p(x)}[-ELBO] \\end{align*} \\] <p>\u8fd9\u5c31\u662f\u6211\u4eec\u5f97\u5230\u7684\u635f\u5931\u51fd\u6570\u3002\u63a8\u5bfc\u65f6\u5e94\u7528\u4e86\u671f\u671b\u7684\u6027\u8d28\u548c\u6761\u4ef6\u6982\u7387\u516c\u5f0f\u4ee5\u53ca KL \u6563\u5ea6\u7684\u5b9a\u4e49\uff0c\u7b2c\u4e94\u884c\u6d88\u6389\u7b2c\u4e00\u9879\u7684 \\(p(z|x)\\) \u662f\u7528\u7684\u6982\u7387\u7684\u5f52\u4e00\u5316\u6027\u8d28\u3002\u91cc\u9762\u7684 \\(ELBO\\) \u8fd9\u4e2a\u9a6c\u7532\u7684\u610f\u601d\u53eb Evidence Lower Bound\uff0c\u5373\u8bc1\u636e\u4e0b\u754c\uff0c\u56e0\u4e3a\u8fd9\u4e00\u8054\u5408\u5206\u5e03\u7684 KL \u6563\u5ea6\u6052\u5927\u4e8e\u4e4b\u524d\u63d0\u5230\u7684\u8fb9\u9645\u5206\u5e03\u7684 KL \u6563\u5ea6\uff0c\u6240\u4ee5\u53eb\u505a\u4e0b\u754c\uff0c\u5176\u5b9e\u8bc1\u636e\u4e0b\u754c\u5c31\u662f\u5bf9\u8fd1\u4f3c\u7a0b\u5ea6\u7684\u8861\u91cf\uff0c\u7b80\u5355\u8bf4\u5c31\u662f\u8981\u6700\u5927\u5316\u7684\u91cf\u3002\u6574\u4e2a\u63a8\u5bfc\u7684\u76ee\u6807\u5f88\u660e\u786e\uff0c\u5c3d\u91cf\u4e0d\u8981\u8ba9\u542b\u6709 \\(p\\) \u7684\u51fd\u6570\u53c2\u4e0e\u5230\u6700\u540e\u7684\u5f0f\u5b50\u91cc\u9762\uff0c\u5229\u7528\u597d\u5df2\u6709\u7684 \\(q\\) \u76f8\u5173\u7684\u51fd\u6570\u3002\u800c\u4e14\u8981\u8ba9\u7ed3\u679c\u9760\u8fd1\u5bf9\u201c\u7f16\u7801\u5668\u201d\u548c\u201c\u89e3\u7801\u5668\u201d\u7684\u635f\u5931\u8ba1\u7b97\u3002\u4e8e\u662f\u4e4e\uff0c\u6211\u4eec\u53ea\u9700\u8981\u6700\u5927\u5316 \\(ELBO\\) \u5373\u53ef\u3002\u5173\u4e8e \\(ELBO\\)\uff0c\u53ef\u4ee5\u62c6\u5f00\uff1a</p> \\[ \\begin{align*}   ELBO&amp;=\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]-KL(p(z|x) || q(z)) \\end{align*} \\] <p>\u7b2c\u4e00\u9879\u7684\u610f\u601d\u662f\u662f\u91cd\u6784\u8bef\u5dee\uff0c\u8861\u91cf\u89e3\u7801\u5668 \\(q(x|z)\\) \u7684\u7ed3\u679c\u5bf9\u539f\u56fe \\(x\\) \u7684\u5dee\u5f02\u7a0b\u5ea6\uff1b\u7b2c\u4e8c\u9879\u7684\u610f\u601d\u662f\u8861\u91cf\u7f16\u7801\u5668\u5bf9\u9690\u53d8\u91cf\u5206\u5e03\u7684\u8fd1\u4f3c\u7a0b\u5ea6\u3002</p> <p>\u5b9e\u9645\u4e0a\u6211\u4eec\u53ef\u4ee5\u5c06\u4e24\u9879\u89e3\u8026\uff0c\u6765\u5206\u914d\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u4e5f\u5c31\u662f\u53ef\u4ee5\u5199\u6210</p> \\[ \\begin{align*}   ELBO&amp;=\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]-\\beta KL(p(z|x) || q(z)) \\end{align*} \\] <p>\u8fd9\u53eb\u505a \u03b2-VAE\uff0c\u540e\u9762\u6211\u4eec\u4f1a\u770b\u5230\u8fd9\u6837\u505a\u7684\u7406\u7531\u548c\u610f\u4e49\u3002</p> <p>\u4e3a\u4e86\u8ba1\u7b97 \\(ELBO\\)\uff0c\\(q(x|z)\\) \u81ea\u7136\u662f\u5bf9\u9690\u53d8\u91cf \\(z\\) \u89e3\u7801\u5230 \\(x\\) \u4e0a\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u800c VAE \u7684\u4f5c\u8005\u5bf9\u9690\u53d8\u91cf\u5206\u5e03 \\(q(z)\\) \u548c\u7f16\u7801\u5668 \\(p(z|x)\\) \u7ed9\u4e86\u4e2a\u5f88\u6fc0\u8fdb\u7684\u65b9\u6848\uff1a\u9ed8\u8ba4\u5b83\u4eec\u662f\u6b63\u6001\u5206\u5e03\uff01\u8fd9\u4f3c\u4e4e\u542c\u8d77\u6765\u6709\u70b9\u7406\u7531\u4f46\u53c8\u6709\u70b9\u6b66\u65ad\uff0c\u5176\u5b9e\u540e\u9762\u6211\u4eec\u5c06\u4f1a\u770b\u5230\uff0c\u5bf9 VAE \u800c\u8a00\uff0c\u6210\u4e5f\u6b63\u6001\u5206\u5e03\uff0c\u8d25\u4e5f\u6b63\u6001\u5206\u5e03\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u5bf9 \\(q(z)\\) \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5047\u5b9a\u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(N(0,I)\\)\uff0c\u4f46\u662f \\(p(z|x)\\) \u662f\u4e2a\u6761\u4ef6\u5206\u5e03\uff0c\u600e\u4e48\u641e\u5462\uff1f\u4e8b\u5b9e\u4e0a\u56de\u5fc6\u4e00\u4e0b\u591a\u5143\u6b63\u6001\u51fd\u6570\u7684\u5b9a\u4e49\uff1a</p> \\[ p(z|x)=\\dfrac{\\exp{\\left(-0.5\\left |\\dfrac{z-\\mu}{\\sigma}\\right |^2\\right)}}{\\prod \\sqrt{2\\pi\\sigma_i^2}} \\] <p>\u8fd9\u91cc\u7684 \\(\\mu\\) \u548c \\(\\sigma\\) \u90fd\u662f\u548c\u9690\u53d8\u91cf \\(z\\) \u7ef4\u5ea6\u4e00\u81f4\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u8bf4\u53ef\u4ee5\u7528\u795e\u7ecf\u7f51\u7edc\u6765\u538b\u7f29\uff01</p> <p>\u90a3\u4e48 KL \u6563\u5ea6\u9879\u5c31\u53ef\u4ee5\u5f88\u8f7b\u677e\u89e3\u51b3\u4e86\uff1a</p> \\[ \\begin{align*}   KL &amp;= \\int p(z|x)\\log\\dfrac{p(z|x)}{q(z)}\\mathrm d z\\\\   &amp;=\\mathbb{E}_{z\\sim p(z|x)}[\\log \\dfrac{p(z|x)}{q(z)}]\\\\   &amp;=\\mathbb{E}_{z\\sim p(z|x)}[\\log\\dfrac{\\exp{\\left(-0.5\\left |\\dfrac{z-\\mu}{\\sigma}\\right |^2\\right)}}{\\prod \\sqrt{2\\pi\\sigma_i^2}}\\times \\dfrac{\\prod \\sqrt{2\\pi}}{\\exp{(-0.5 |z|^2)}}]\\\\   &amp;=\\mathbb{E}_{z\\sim p(z|x)}[0.5|z|^2-0.5\\left |\\dfrac{z-\\mu}{\\sigma}\\right |^2-\\sum \\log \\sigma_i]\\\\   &amp;=\\dfrac 12 \\sum \\sigma_i^2 +\\mu_i^2-1-\\log \\sigma_i \\end{align*} \\] <p>\u6700\u540e\u4e00\u6b65\u4f7f\u7528\u4e86\u6b63\u6001\u5206\u5e03\u4e8c\u9636\u77e9\u7684\u6027\u8d28\uff1a\\(\\mathbb{E}[x^2]=\\mu^2+\\sigma^2\\)\u3002</p> <p>\u5bf9\u4e8e\u91cd\u6784\u8bef\u5dee\u9879\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u60f3\u5230\u5229\u7528 MSE \u6765\u8861\u91cf\u91cd\u6784\u8bef\u5dee\uff0c\u4f46\u662f\u8fd9\u6837\u505a\u662f\u5426\u6709\u7406\u8bba\u4f9d\u636e\u5462\uff1f\u4e8b\u5b9e\u4e0a\u5982\u679c\u8003\u8651\u89e3\u7801\u5668 \\(q(x|z)\\) \u548c\u7f16\u7801\u5668\u4e00\u6837\u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\uff1a</p> \\[ \\begin{align*}   \\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]&amp;=\\mathbb E_{z\\sim p(z|x)}[\\log \\dfrac{\\exp{\\left(-0.5\\left |\\dfrac{x-\\mu'}{\\sigma'}\\right |^2\\right)}}{\\prod \\sqrt{2\\pi{\\sigma'}_i^2}}]\\\\   &amp;=-\\dfrac{1}{2|\\sigma'|^2}|x-\\mu'|^2-\\sum\\log \\sqrt{2\\pi{\\sigma'}_i^2} \\end{align*} \\] <p>\u8fd9\u91cc\u7684 \\(\\mu'\\) \u5373\u89e3\u7801\u7684\u5747\u503c\u5176\u5b9e\u5c31\u662f\u8f93\u51fa\u7684\u56fe\u50cf\u7684\u5747\u503c\u3002\u5982\u679c\u53d6 \\(\\sigma'\\) \u662f\u56fa\u5b9a\u7684\u5411\u91cf\uff0c\u90a3\u5c31\u5f97\u5230 MSE \u4e86\u3002\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u91cc \\(\\sigma'\\) \u7684\u5927\u5c0f\u4f30\u8ba1\u5c31\u548c \u03b2-VAE \u7684\u601d\u60f3\u7b49\u4ef7\uff0c\u90fd\u662f\u6765\u8c03\u63a7\u4e24\u79cd\u635f\u5931\u7684\u6bd4\u4f8b\u7684\u3002\u56e0\u6b64\u6211\u4eec\u5c31\u4f30\u8ba1\u51fa\u4e86\u6700\u7ec8\u7684\u635f\u5931\u51fd\u6570\uff1a</p> \\[ \\begin{align*}   \\mathcal{L}&amp;=-\\mathbb E_{x\\sim p(x)}[ELBO]\\\\   &amp;=-\\mathbb E_{x\\sim p(x)}[\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z)]-\\beta KL(p(z|x) || q(z))]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[\\dfrac{1}{2}|x-\\mu'|^2-\\beta\\dfrac 12 \\sum \\sigma_i^2 +\\mu_i^2-1-\\log \\sigma_i]\\\\   &amp;=\\mathbb E_{x\\sim p(x)}[MSE -\\beta KLD]\\\\   &amp;=\\dfrac 1n \\sum_i^n (MSE_{x_i}-\\beta KLD_{x_i}) \\end{align*} \\] <p>\u6700\u540e\u4e00\u6b65\uff0c\u5c31\u662f\u901a\u8fc7\u91c7\u6837\u8fd1\u4f3c\u671f\u671b\u3002\u5b9e\u9645\u4e0a\u6211\u4eec\u8fdb\u884c\u7684\u662f\u6279\u91cf\u8bad\u7ec3\uff0c\u56e0\u6b64\uff0c\u6bcf\u6b21\u53ea\u9700\u8981\u5bf9\u8f93\u5165\u91c7\u6837\u4e00\u4e2a\u9690\u53d8\u91cf \\(z\\) \u5373\u53ef\u3002\u4e5f\u5c31\u662f\u8bf4\u6700\u7ec8\u6211\u4eec\u5f97\u5230\u4e86\u53ef\u4ee5\u8ba1\u7b97\u7684\u635f\u5931\u51fd\u6570\uff01</p> \\[ \\mathcal{L(x)}=MSE_{x}-\\beta KLD_{x} \\] <p>\u4f46\u662f\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\uff1a\u867d\u7136\u8fd9\u662f\u53ef\u4ee5\u8ba1\u7b97\u7684\uff0c\u4f46 \\(\\mu\\) \u548c \\(\\sigma\\) \u7684\u503c\u4f1a\u968f\u7740\u53c2\u6570\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u8fdb\u800c\u5f71\u54cd\u5230\u5206\u5e03 \\(q(z)\\)\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e26\u53c2\u6570\u7684\u6b63\u6001\u5206\u5e03\u662f\u65e0\u6cd5\u76f4\u63a5\u8fdb\u884c\u5fae\u5206\u6765\u53cd\u5411\u4f20\u64ad\u7684\u3002\u8fd9\u4e00\u95ee\u9898\u6709\u4e00\u4e2a\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff1a\u91cd\u53c2\u6570\u5316\u3002</p> <p>\u4e5f\u5c31\u662f\u4ece\u5206\u5e03 \\(N(\\mu,\\sigma^2)\\) \u91c7\u6837\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5e73\u79fb\u52a0\u7f29\u653e\uff0c\u53ea\u9700\u8981\u5728\u6807\u51c6\u5206\u5e03 \\(N(0,1)\\) \u91cc\u9762\u91c7\u6837 \\(y\\)\uff0c\u7136\u540e\u8ba1\u7b97 \\(y'=\\mu+\\sigma y\\) \u5c31\u53ef\u4ee5\u5f97\u5230\u4ece\u5206\u5e03 \\(N(\\mu,\\sigma^2)\\) \u91c7\u6837\u7684\u7ed3\u679c\u4e86\u3002\u7531\u4e8e\u7ebf\u6027\u53d8\u6362\u53ef\u5fae\uff0c\u5c31\u53ef\u4ee5\u4ea4\u7ed9\u4f18\u5316\u5668\u505a\u66f4\u65b0\u4e86\u3002</p> <p>\u73b0\u5728\u56de\u987e\u4e00\u4e0b\u6574\u4e2a VAE \u7684\u8bad\u7ec3\u6d41\u7a0b\uff1a</p> <ul> <li>\u8f93\u5165 \\(x\\) \u901a\u8fc7\u7f16\u7801\u5668\u5f97\u5230\u4e24\u4e2a\u548c \\(z\\) \u7ef4\u5ea6\u4e00\u81f4\u7684\u5411\u91cf \\(\\mu\\) \u548c \\(\\sigma\\)\u3002</li> <li>\u5728\u6807\u51c6\u6b63\u6001\u5206\u5e03\u4e0b\u91c7\u6837\u5411\u91cf \\(\\epsilon\\) \u7136\u540e\u8ba1\u7b97 \\(z=\\mu + \\epsilon\\odot\\sigma\\)\u3002</li> <li>\u5c06 \\(z\\) \u8f93\u5165\u5230\u89e3\u7801\u5668\u5f97\u5230\u91cd\u6784\u56fe\u50cf \\(x'\\)\u3002</li> <li>\u6839\u636e \\(\\mu\\)\u3001\\(\\sigma\\) \u548c \\(x\\) \u4ee5\u53ca \\(x'\\)\uff0c\u4f7f\u7528\u635f\u5931\u51fd\u6570 \\(\\mathcal{L(x)}=MSE_{x}-\\beta KLD_{x}\\) \u8ba1\u7b97\u68af\u5ea6\u5e76\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\u3002</li> </ul> <p>\u5982\u6b64\uff0c\u901a\u5f80 VAE \u7684\u9053\u8def\u5df2\u7ecf\u94fa\u597d\uff0c\u8ba9\u6211\u4eec\u7f16\u5199\u4ee3\u7801\u5427\u3002</p>  \u52a0\u8f7d\u6570\u636e\u96c6\u4f7f\u7528\u7684\u4ee3\u7801  <pre><code>import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.utils as vutils\nimport numpy as np\n\n# \u6570\u636e\u96c6\u6240\u5728\u7684\u8def\u5f84\nDATA_DIR = '/kaggle/input/animefacedataset/images/'\n\n# \u5b9a\u4e49\u8d85\u53c2\u6570\nIMAGE_SIZE = 64    # \u56fe\u50cf\u5c06\u88ab\u8c03\u6574\u5230\u7684\u5927\u5c0f\nBATCH_SIZE = 256   # \u6bcf\u4e2a\u6279\u6b21\u52a0\u8f7d\u7684\u56fe\u50cf\u6570\u91cf\uff0c\u6700\u597d\u548c\u4e0b\u9762\u8bad\u7ec3\u7684 bs \u4e00\u81f4\nNUM_WORKERS = 6    # \u52a0\u8f7d\u6570\u636e\u7684\u5de5\u4f5c\u8fdb\u7a0b\u6570\uff0c\u867d\u7136 Kaggle \u4f1a\u62a5 warning \u4f46\u662f\u5b9e\u6d4b 6 \u6bd4 4 \u597d\u3002\n\n# \u5b9a\u4e49\u56fe\u50cf\u9884\u5904\u7406/\u53d8\u6362\n# 1. Resize: \u7f29\u653e\u5230 IMAGE_SIZE\n# 2. ToTensor: \u8f6c\u6362\u4e3a PyTorch Tensor\uff0c\u5e76\u5c06\u50cf\u7d20\u503c\u4ece [0, 255] \u5f52\u4e00\u5316\u5230 [0.0, 1.0]\n# 3. Normalize: \u5c06 [0.0, 1.0] \u7684\u6570\u636e\u6807\u51c6\u5316\u5230 [-1.0, 1.0]\uff0c\u8fd9\u662f\u8bad\u7ec3 GAN \u7684\u6807\u51c6\u505a\u6cd5\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.CenterCrop(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n\nclass AnimeFaceDataset(Dataset):\n    \"\"\"\u81ea\u5b9a\u4e49\u52a8\u6f2b\u4eba\u8138\u6570\u636e\u96c6\"\"\"\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_files = [f for f in os.listdir(root_dir)]\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image\n\nprint(\"loading dataset\")\n# \u5b9e\u4f8b\u5316\u6570\u636e\u96c6\nanime_dataset = AnimeFaceDataset(root_dir=DATA_DIR, transform=transform)\nprint(f\"Dataset size: {len(anime_dataset)} pictures.\")\n\n# \u5b9e\u4f8b\u5316 DataLoader\ndataloader = DataLoader(\n    dataset=anime_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\nreal_batch = next(iter(dataloader))\n\n# \u8bbe\u7f6e\u7ed8\u56fe\nplt.figure(figsize=(8, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n\ngrid = vutils.make_grid(real_batch[:64], padding=2, normalize=True)\nplt.imshow(np.transpose(grid.cpu(), (1, 2, 0))) # \u4ece (C, H, W) \u8f6c\u4e3a (H, W, C)\nplt.show()\n</code></pre> <p>\u9ed8\u8ba4\u4e00\u53d1 64 \u62bd\uff0c\u53ef\u4ee5\u770b\u770b\u62bd\u51fa\u6765\u7684\u6709\u6ca1\u6709\u8ba4\u8bc6\u7684\uff08\uff09</p> <p>\u4e0b\u9762\u5c31\u53ef\u4ee5\u6109\u5feb\u8bad\u7ec3\u4e86\u3002</p>  \u8bad\u7ec3\u4f7f\u7528\u7684\u4ee3\u7801 <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\n\nconfig = {\n\"METHOD_NAME\": \"VAE\",\n\"LATENT_DIM\": 128,\n\"BATCH_SIZE\": 256,\n\"EPOCHS\": 30,\n\"LR\": 1e-4,\n\"BETA\": 1.5,\n\"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n\"DATA_PATH\": \"./data\",\n\"OUTPUT_PATH\": \"./output\"\n}\noutput_dir = os.path.join(config[\"OUTPUT_PATH\"], config[\"METHOD_NAME\"])\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Using device: {config['DEVICE']}\")\nprint(f\"Running with Beta = {config['BETA']}\")\n\ntrain_loader = dataloader\n\n# --- 2. \u6a21\u578b\u5b9a\u4e49 ---\nclass VAE(nn.Module):\n    def __init__(self, latent_dim):\n        super(VAE, self).__init__()\n        self.latent_dim = latent_dim\n\n        # Encoder (64x64 -&gt; 8x8)\n        self.encoder_features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d(2, 2)\n        )\n        self.fc_mu = nn.Linear(256 * 8 * 8, latent_dim)\n        self.fc_log_var = nn.Linear(256 * 8 * 8, latent_dim)\n\n        # Decoder (latent_dim -&gt; 64x64)\n        self.decoder_fc = nn.Linear(latent_dim, 256 * 8 * 8)\n        self.decoder_conv = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n            nn.Tanh() # \u8f93\u51fa\u8303\u56f4 [-1, 1]\uff0c\u5339\u914d\u6570\u636e\u5f52\u4e00\u5316\n        )\n\n    def encode(self, x):\n        h = self.encoder_features(x)\n        h = h.view(h.size(0), -1)\n        return self.fc_mu(h), self.fc_log_var(h)\n\n    def reparameterize(self, mu, log_var):\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h = self.decoder_fc(z)\n        h = h.view(h.size(0), 256, 8, 8)\n        return self.decoder_conv(h)\n\n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        return self.decode(z), mu, log_var\n\n# --- 3. \u635f\u5931\u51fd\u6570 ---\ndef vae_loss_function(recon_x, x, mu, log_var):\n    MSE = F.mse_loss(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    return MSE, KLD\n\n# \u7528\u4e8e\u5b58\u50a8\u6307\u6807\u7684\u5b57\u5178\nmetrics = {\n    'MSE loss': [],\n    'KLD loss': [],\n    'Total loss': [],\n}\n\n# --- 4. \u8bad\u7ec3\u5faa\u73af ---\ndef train(model, train_loader, optimizer, epoch):\n    model.train()\n    total_loss, tot_mse, tot_kld = 0, 0, 0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['EPOCHS']}\")\n    for data in pbar:\n        data = data.to(config[\"DEVICE\"])\n        optimizer.zero_grad()\n        recon_batch, mu, log_var = model(data)\n        mse_loss, kld_loss = vae_loss_function(recon_batch, data, mu, log_var)\n        loss = mse_loss + config[\"BETA\"] * kld_loss\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        tot_mse += mse_loss.item()\n        tot_kld += kld_loss.item()\n        pbar.set_postfix(loss=loss.item() / len(data))\n    avg_loss = total_loss / len(train_loader.dataset)\n    avg_mse = tot_mse / len(train_loader.dataset)\n    avg_kld = tot_kld / len(train_loader.dataset)\n    metrics[\"Total loss\"].append(avg_loss)\n    metrics[\"MSE loss\"].append(avg_mse)\n    metrics[\"KLD loss\"].append(avg_kld)\n    print(f'====&gt; Epoch: {epoch+1} Average MSE loss:{avg_mse:.4f}, KLD loss:{avg_kld:.4f}, total loss: {avg_loss:.4f}')\n\n# --- 5. \u751f\u6210\u51fd\u6570  ---\ndef generate_and_save_images(model, save_path, n_samples=64):\n    model.eval()\n    with torch.no_grad():\n        noise = torch.randn(n_samples, config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n        generated_images = model.decode(noise).cpu()\n        grid = make_grid(generated_images, nrow=8, padding=2, normalize=True)\n        plt.figure(figsize=(8, 8))\n        plt.imshow(grid.permute(1, 2, 0))\n        plt.axis(\"off\")\n        plt.title(\"Generated Images from VAE\")\n        plt.savefig(save_path)\n        plt.show()\n\n# --- 6. \u8bad\u7ec3\u6307\u6807\u7ed8\u56fe ---\ndef loss_visualization():\n    # \u8bad\u7ec3\u5b8c\u6210\u540e\u7ed8\u5236\u6307\u6807\u56fe\u8868\n    plt.figure(figsize=(10, 6))\n\n    plt.plot(metrics['MSE loss'], label='MSE Loss', color='blue')\n    plt.plot(metrics['KLD loss'], label='KL Divergence Loss', color='red')\n    plt.plot(metrics['Total loss'], label='Total Loss', color='green')\n\n    plt.title(f'MSE, KLD and total Loss, beta = {config[\"BETA\"]}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n\n    plt.legend()\n    plt.show()\n\n# --- \u4e3b\u7a0b\u5e8f ---\nif __name__ == \"__main__\":\n    model = VAE(latent_dim=config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n    optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n\n    print(\"--- Training VAE Model ---\")\n    for epoch in range(config[\"EPOCHS\"]):\n        train(model, train_loader, optimizer, epoch)\n\n    print(\"\\n--- Generating Images from Trained VAE ---\")\n    gen_save_path = os.path.join(output_dir, \"generated_images.png\")\n    generate_and_save_images(model, gen_save_path)\n    loss_visualization()\n</code></pre> <p>\u8fd9\u662f VAE \u7684\u603b\u7684\u67b6\u6784\uff0c\u8fd9\u91cc\u628a KL \u53d6\u4e86\u4e2a\u8d1f\u53f7\u6240\u4ee5\u6700\u540e\u662f\u52a0\u6cd5\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n    classDef latent fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef loss fill:#313244,stroke:#f2cdcd,stroke-width:2px,color:#cdd6f4;\n\n    %% Input\n    subgraph InputGraph[\"Input\"]\n        A[(\"Image&lt;br&gt;3@64x64\")]\n    end\n    class InputGraph input;\n\n    %% Encoder\n    subgraph Encoder[\"Encoder\"]\n        B[\"Feature Extractor&lt;br&gt;map: 3@64x64\u2192latent dim\"]\n    end\n    A --&gt; B\n    class Encoder conv;\n\n    %% Latent Space Distribution\n    subgraph LatentDistribution[\"Latent Distribution\"]\n        mu[\"\u03bc &lt;br&gt;latent dim\"]\n        logvar[\"log(\u03c3\u00b2)&lt;br&gt;latent dim\"]\n    end\n    B --&gt;|latent dim vector| mu\n    B --&gt;|latent dim vector| logvar\n    class LatentDistribution latent;\n\n    %% Reparameterization Trick\n    subgraph ReparamTrick[\"Reparameterization\"]\n        C[\"z = \u03bc + \u03b5 * \u03c3&lt;br&gt;\u03b5~N(0,I)\"]\n    end\n    mu --&gt; C\n    logvar --&gt; C\n    class ReparamTrick latent;\n\n    %% Decoder\n    subgraph Decoder[\"Decoder\"]\n        D[\"Latent vector decoder\"]\n    end\n    C --&gt; |sample vector z&lt;br&gt;latent dim| D\n    class Decoder conv;\n\n    %% Output\n    subgraph OutputGraph[\"Output\"]\n        E[(\"Reconstructed Image&lt;br&gt;3@64x64\")]\n    end\n    D --&gt; E\n    class OutputGraph output;\n\n    %% Loss Calculation\n    subgraph LossCalc[\"Loss Calculation\"]\n        L[\"Loss = MSE + \u03b2 * KLD\"]\n        M[\"MSE\"]\n        N[\"KLD\"]\n    end\n    E --&gt; |Reconstruction| M\n    A --&gt; |Original| M\n    mu --&gt; |Distribution| N\n    logvar --&gt; |Distribution| N\n    M --&gt; L\n    N --&gt; L\n    class LossCalc loss;</code></pre> <p>\u5176\u4e2d\uff0c\u7f16\u7801\u5668\u4f7f\u7528\u4e09\u5c42\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u4f7f\u7528\u4e86\u6c60\u5316\u6765\u7f29\u5c0f\u7279\u5f81\u56fe\uff0c\u8fd9\u4e5f\u662f\u201c\u7cca\u201d\u7684\u4e00\u90e8\u5206\u539f\u56e0\uff0c\u5728\u540e\u9762\u7684 GAN \u590d\u73b0\u4e2d\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u5168\u5377\u79ef\u7684\u67b6\u6784\uff0c\u56e0\u4e3a\u7f29\u5c0f\u7279\u5f81\u56fe\u5fc5\u4e0d\u4e00\u5b9a\u975e\u8981\u6c60\u5316\uff0c\u8fd8\u53ef\u4ee5\u6539\u53d8\u6b65\u957f\u3002\u4e0b\u9762\u662f\u7f16\u7801\u5668\u7684\u5177\u4f53\u67b6\u6784\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef latent fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef fc fill:#313244,stroke:#cba6f7,stroke-width:2px,color:#cdd6f4;\n    classDef convBlock fill:#1e1e2e,stroke:#89dceb,stroke-width:1px,color:#89dceb;\n\n    %% Input\n    Input[(\"Input Image&lt;br&gt;3@64x64\")]\n    class Input input;\n\n    %% Encoder Block 1\n    subgraph EncoderBlock1 [\"Encoder Block 1\"]\n        direction LR\n        Conv1[\"Conv2d &lt;br&gt; 3x64 x 3x3 /1\"]\n        BN1[\"BatchNorm2d&lt;br&gt;64\"]\n        ReLU1[\"ReLU\"]\n        Pool1[\"MaxPool2d&lt;br&gt;2x2 /2\"]\n        Conv1 --&gt; BN1 --&gt; ReLU1 --&gt; Pool1\n    end\n\n    %% Encoder Block 2\n    subgraph EncoderBlock2 [\"Encoder Block 2\"]\n        direction LR\n        Conv2[\"Conv2d &lt;br&gt; 64x128 x 3x3 /1\"]\n        BN2[\"BatchNorm2d&lt;br&gt;128\"]\n        ReLU2[\"ReLU\"]\n        Pool2[\"MaxPool2d&lt;br&gt;2x2 /2\"]\n        Conv2 --&gt; BN2 --&gt; ReLU2 --&gt; Pool2\n    end\n\n    %% Encoder Block 3\n    subgraph EncoderBlock3 [\"Encoder Block 3\"]\n        direction LR\n        Conv3[\"Conv2d &lt;br&gt; 128x256 x 3x3 /1\"]\n        BN3[\"BatchNorm2d&lt;br&gt;256\"]\n        ReLU3[\"ReLU\"]\n        Pool3[\"MaxPool2d&lt;br&gt;2x2 /2\"]\n        Conv3 --&gt; BN3 --&gt; ReLU3 --&gt; Pool3\n    end\n\n    %% Flatten and FC layers\n    Flatten[\"Flatten\"]\n    FC_mu[\"Linear&lt;br&gt;16384 x latent dim\"]\n    FC_logvar[\"Linear&lt;br&gt;16384 x latent dim\"]\n\n    %% Outputs\n    mu[\"\u03bc&lt;br&gt;latent dim\"]\n    logvar[\"log(\u03c3\u00b2)&lt;br&gt;latent dim\"]\n\n    %% Connections\n    Input --&gt; EncoderBlock1\n    EncoderBlock1 --&gt; |64 @ 32x32| EncoderBlock2\n    EncoderBlock2 --&gt; |128 @ 16x16| EncoderBlock3\n    EncoderBlock3 --&gt; |256 @ 8x8| Flatten\n    Flatten --&gt; |16384| FC_mu --&gt; mu\n    Flatten --&gt; |16384| FC_logvar --&gt; logvar\n\n    %% Styling\n    class EncoderBlock1,EncoderBlock2,EncoderBlock3 convBlock;\n    class FC_mu,FC_logvar fc;\n    class mu,logvar latent;</code></pre> <p>\u89e3\u7801\u5668\u548c\u7f16\u7801\u5668\u7684\u914d\u7f6e\u57fa\u672c\u4e0a\u4e00\u81f4\uff0c\u53ea\u4e0d\u8fc7\u4f7f\u7528\u4e86\u53cd\u5377\u79ef\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef fc fill:#313244,stroke:#cba6f7,stroke-width:2px,color:#cdd6f4;\n    classDef deconvBlock fill:#1e1e2e,stroke:#a6e3a1,stroke-width:1px,color:#a6e3a1;\n\n    %% Input\n    Input[(\"Sample z&lt;br&gt;latent dim\")]\n    class Input input;\n\n    %% FC and Reshape\n    FC_dec[\"Linear&lt;br&gt;latent_dim x 16384\"]\n    Reshape[\"Reshape\"]\n\n    %% Decoder Block 1\n    subgraph DecoderBlock1 [\"Decoder Block 1\"]\n        direction LR\n        ConvT1[\"ConvTranspose2d&lt;br&gt;256x128 x 4x4 x 2\"]\n        BN1[\"BatchNorm2d\"]\n        ReLU1[\"ReLU\"]\n        ConvT1 --&gt; BN1 --&gt; ReLU1\n    end\n\n    %% Decoder Block 2\n    subgraph DecoderBlock2 [\"Decoder Block 2\"]\n        direction LR\n        ConvT2[\"ConvTranspose2d&lt;br&gt;128x64 x 4x4 x 2\"]\n        BN2[\"BatchNorm2d\"]\n        ReLU2[\"ReLU\"]\n        ConvT2 --&gt; BN2 --&gt; ReLU2\n    end\n\n    %% Final Conv and Activation\n    ConvT3[\"ConvTranspose2d&lt;br&gt;64x3 x 4x4 x 2\"]\n    Tanh[\"Tanh\"]\n\n    %% Output\n    Output[(\"Reconstructed Image&lt;br&gt;3@64x64\")]\n\n    %% Connections\n    Input --&gt; FC_dec\n    FC_dec --&gt; |16384| Reshape\n    Reshape --&gt; |256 @ 8x8| DecoderBlock1\n    DecoderBlock1 --&gt; |128 @ 16x16| DecoderBlock2\n    DecoderBlock2 --&gt; |64 @ 32x32| ConvT3\n    ConvT3 --&gt; Tanh --&gt; Output\n\n    %% Styling\n    class FC_dec fc;\n    class DecoderBlock1,DecoderBlock2 deconvBlock;\n    class Output output;</code></pre> <p>\u7ecf\u8fc7\u4e00\u6bb5\u65f6\u95f4\u7684\u7b49\u5f85\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u770b\u5230\u751f\u6210\u7684\u56fe\u50cf\u4e86\uff0c\u6709\u7684\u8fd8\u662f\u633a\u50cf\u6a21\u50cf\u6837\u7684\u3002\u8ba9\u6211\u4eec\u8c03\u6574 \u03b2 \u591a\u8bd5\u51e0\u6b21\uff1a</p> \u03b2 = 1.5 \u03b2 = 1 \u03b2 = 0.5 \u751f\u6210\u56fe\u50cf \u635f\u5931\u53d8\u5316 <p>\u53ef\u4ee5\u770b\u5230\u5176\u5b9e MSE \u548c KLD \u662f\u6309\u4e0b\u846b\u82a6\u6d6e\u8d77\u74e2\u7684\u5173\u7cfb\uff0c\u56e0\u4e3a MSE \u5bf9\u5e94\u89e3\u7801\u5668\u7684\u91cd\u6784\u8bef\u5dee\uff0cKLD \u5bf9\u5e94\u7f16\u7801\u5668\u7684\u5efa\u6a21\u8bef\u5dee\uff0c\u56e0\u6b64\u4e24\u8fb9\u90fd\u80fd\u5f97\u5230\u6709\u6548\u7684\u8bad\u7ec3\u3002</p> <p>\u5bf9\u6bd4 \u03b2 = 1.5 \u7684\u60c5\u51b5\uff0c\u03b2 = 1 \u65f6\u786e\u5b9e\u6709\u4e00\u70b9\u70b9\u66f4\u6e05\u6670\u4e86\uff0c\u4f46\u662f\u56fe\u7247\u66f4\u810f\u4e86\u3002\u7f51\u4e0a\u5f88\u591a\u8ba8\u8bba\u8bf4\u964d\u4f4e \u03b2 \u53ef\u4ee5\u63d0\u5347\u6e05\u6670\u5ea6\uff0c\u5176\u5b9e\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u5bf9\u3002\u4e8b\u5b9e\u4e0a\u6211\u964d\u4f4e\u4e86 \u03b2 \u8c8c\u4f3c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6539\u5584 MSE \u635f\u5931\u63d0\u5347\u91cd\u5efa\u76f8\u4f3c\u5ea6\uff0c\u4f46\u5176\u5b9e\u5728\u8fd9\u4e2a\u8bad\u7ec3\u6570\u636e\u4e0b MSE \u635f\u5931\u76f8\u6bd4\u4e8e KLD \u635f\u5931\u66f4\u5bb9\u6613\u4e0b\u964d\uff0c\u6240\u4ee5\u53ef\u4ee5\u770b\u5230 \u03b2 = 1 \u76f8\u6bd4 \u03b2 = 1.5\uff0cMSE \u867d\u7136\u7565\u6709\u4e0b\u964d\u4f46\u662f KLD \u6da8\u4e86\u4e00\u5927\u622a\u3002\u800c \u03b2 = 0.5 \u7684\u65f6\u5019\uff0cKLD \u76f4\u63a5\u5c31\u7ffb\u500d\u4e86\u3002</p> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u5f53 \u03b2 \u6bd4\u8f83\u5927\u7684\u65f6\u5019\uff0c\u56fe\u50cf\u5012\u662f\u6709\u9f3b\u5b50\u6709\u773c\uff0c\u5c31\u662f\u5f88\u7cca\uff1b\u03b2 \u6bd4\u8f83\u5c0f\uff0c\u56fe\u50cf\u53c8\u5f00\u59cb\u810f\u8d77\u6765\u4e86\uff0c\u53d8\u5f97\u4e0d\u53ef\u540d\u72b6\u3002</p> <p>\u6211\u4eec\u601d\u8003 \u03b2 \u7684\u4f5c\u7528\uff1a\u03b2 \u53ef\u4ee5\u8861\u91cf\u8f93\u51fa\u56fe\u50cf\u7684\u65b9\u5dee\uff0c\u03b2 \u8d8a\u5927\u5219 KL \u6563\u5ea6\u9879\u5360\u6bd4\u8d8a\u5927\uff0c\u8fd9\u5c31\u5bf9\u5e94\u589e\u5927\u91cd\u6784\u8bef\u5dee\u7684\u65b9\u5dee\u4f30\u8ba1\uff0c\u4e5f\u5c31\u662f\u8bf4\u5927 \u03b2 \u4f1a\u8ba9\u7f16\u7801\u5668\u7684\u8f93\u51fa\u5c3d\u53ef\u80fd\u5e73\u6ed1\uff0c\u4ece\u800c\u5bfc\u81f4\u56fe\u50cf\u80fd\u591f\u627e\u5230\u6240\u6709\u4eba\u8138\u7684\u5171\u540c\u7279\u5f81\uff0c\u4f46\u662f\u6ca1\u6cd5\u751f\u6210\u5177\u4f53\u7684\u7cbe\u7ec6\u7279\u5f81\uff0c\u7b80\u5355\u8bf4\u5c31\u662f\u7cca\uff1b\u800c\u5c0f \u03b2 \u5bf9\u5e94\u7684\u5c31\u662f\u4e0d\u90a3\u4e48\u7cca\u7684\u56fe\u7247\uff0c\u4f46\u662f\u4e00\u76f4\u88ab\u91cd\u6784\u8bef\u5dee\u7275\u7740\u8d70\uff0c\u867d\u7136\u91cd\u6784\u8bef\u5dee\u5c0f\u80fd\u591f\u8ba9\u56fe\u50cf\u66f4\u6e05\u6670\uff0c\u4f46\u5374\u4e5f\u6ca1\u6cd5\u5bf9\u8f93\u5165\u8fdb\u884c\u7279\u522b\u6709\u6548\u7684\u7f16\u7801\uff0c\u4ece\u800c\u5bfc\u81f4\u7279\u5f81\u6df7\u8d77\u6765\u4e86\uff0c\u8f93\u51fa\u5c31\u4f1a\u6bd4\u8f83\u810f\u3002</p> <p>\u6240\u4ee5\u8bf4\u6734\u7d20\u7684 VAE \u7cca\uff0c\u4e3b\u8981\u8fd8\u662f\u56e0\u4e3a\u8fd9\u4e9b\u539f\u56e0\uff1a</p> <ul> <li>\u5bf9\u9690\u53d8\u91cf\u3001\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u5efa\u6a21\u592a\u6b66\u65ad\uff0c\u65e2\u7136\u4e3a\u4e86\u63a8\u5bfc\u4f7f\u7528\u4e86\u6b63\u6001\u5206\u5e03\uff0c\u5c31\u8981\u5403\u8fd9\u4e2a\u5e26\u6765\u7684\u540e\u679c\u3002</li> <li>\u538b\u7f29\u592a\u4e25\u91cd\u3002\u5efa\u6a21\u65f6\u6781\u5176\u5bb9\u6613\u5e73\u6ed1\u6389\u56fe\u50cf\u7684\u9ad8\u9891\u4fe1\u606f\u3002</li> </ul> <p>\u4ecb\u7ecd\u4e86 VAE \u7684\u672c\u95e8\u529f\u592b\u2014\u2014\u56fe\u50cf\u751f\u6210\u4e4b\u540e\uff0c\u6211\u4eec\u6765\u770b\u770b\u600e\u4e48\u62ff VAE \u8fdb\u884c\u90aa\u4fee\uff0c\u4e5f\u5c31\u662f\u505a\u56fe\u50cf\u5206\u7c7b\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#_3", "title": "\u65e0\u76d1\u7763\u805a\u7c7b", "text": "<p>\u7b2c\u4e00\u4e2a\u60f3\u6cd5\u76f8\u5f53\u81ea\u7136\uff0c\u65e2\u7136\u6211\u4eec\u4f7f\u7528\u9690\u53d8\u91cf\u5206\u5e03 \\(q(z)\\) \u6765\u5bf9\u539f\u6709\u56fe\u50cf\u505a\u538b\u7f29\u4e4b\u540e\u7684\u8868\u5f81\uff0c\u90a3\u4e48\u6211\u4eec\u53ea\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2a\u8f93\u5165 \\(x\\)\uff0c\u8ba1\u7b97\u5176\u5bf9\u5e94\u7684\u9690\u53d8\u91cf\u5206\u5e03 \\(q(z)\\) \u7684\u5747\u503c \\(\\mu\\)\uff0c\u5c31\u53ef\u4ee5\u5c06\u8f93\u5165\u538b\u7f29\u5230\u9690\u7a7a\u95f4\u5185\u3002\u6309\u7406\u8bf4\uff0c\u8fd9\u4e2a\u7a7a\u95f4\u662f\u63d0\u53d6\u4e86 \\(x\\) \u7684\u7279\u5f81\u4fe1\u606f\u7684\uff0c\u56e0\u6b64\u5728\u8fd9\u4e2a\u7a7a\u95f4\u91cc\u9762\u505a\u65e0\u76d1\u7763\u7684\u805a\u7c7b\uff0c\u5c31\u53ef\u4ee5\u8fdb\u884c\u5206\u7c7b\u4e86\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u4f7f\u7528 K-means \u4f5c\u4e3a\u805a\u7c7b\u624b\u6bb5\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u8fdb\u884c\u6295\u7968\uff0c\u5f97\u7968\u6700\u9ad8\u7684\u6807\u7b7e\u4ee3\u8868\u672c\u7c7b\u522b\u7684\u6807\u7b7e\u3002\u6700\u540e\uff0c\u5bf9\u5f97\u5230\u7684\u9690\u7a7a\u95f4\u505a t-SNE \u53ef\u89c6\u5316\u3002\u4e0b\u9762\u662f\u7ed3\u679c\uff1a</p> \u03b2 = 0.1 \u03b2 = 1 \u03b2 = 10 \u51c6\u786e\u7387 23.59% 24.64% 24.01% t-SNE\u53ef\u89c6\u5316 \u751f\u6210\u56fe\u50cf <p>\u51c6\u786e\u7387\u5927\u6982\u662f 24% \u5de6\u53f3\uff0c\u8fd8\u662f\u5f88\u5408\u7406\u7684\uff0c\u56e0\u4e3a\u6807\u7b7e\u4fe1\u606f\u53ea\u5360\u4e86\u56fe\u50cf\u8bed\u4e49\u4fe1\u606f\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u56e0\u6b64\u805a\u7c7b\u5f97\u5230\u7684\u8fb9\u754c\u57fa\u672c\u4e0a\u662f\u591a\u79cd\u8bed\u4e49\u7279\u5f81\u7684\u6df7\u5408\uff08\u4e3e\u4f8b\uff1a\u6211\u4e0d\u4ec5\u53ef\u4ee5\u6309\u7269\u4f53\u7c7b\u522b\u805a\u7c7b\uff0c\u8fd8\u53ef\u4ee5\u6309\u7167\u80cc\u666f\u8272\u8c03\u805a\u7c7b\uff0c\u65e2\u7136\u6ca1\u6709\u6807\u7b7e\u5e26\u6765\u7684\u5206\u7c7b\u60e9\u7f5a\uff0c\u6211\u5c31\u53ef\u4ee5\u968f\u5fc3\u6240\u6b32\uff09\uff0c\u81ea\u7136\u4e0d\u80fd\u548c\u6807\u7b7e\u4fe1\u606f\u5b8c\u5168\u5bf9\u5e94\u3002\u6bd4\u5982\u8bf4\uff0c\u622a\u81f3\u672c\u6587\u5199\u4f5c\u65f6\u95f4\uff0c\u76ee\u524d\u6700\u5f3a\u5927\u7684\u5f00\u6e90\u81ea\u76d1\u7763\u89c6\u89c9\u6a21\u578b DINOv3 \u5728 ImageNet \u4e0a\u81ea\u76d1\u7763\u805a\u7c7b\u7684\u51c6\u786e\u7387\u4e5f\u53ea\u6709 75% \u5de6\u53f3\u3002\u4f46\u662f\u52a0\u4e0a\u6807\u7b7e\u4fe1\u606f\u4e4b\u540e\uff0c\u51c6\u786e\u7387\u5c31\u53ef\u4ee5\u7a81\u98de\u731b\u8fdb\u4e86\u3002</p> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u03b2 \u57fa\u672c\u4e0a\u5bf9\u51c6\u786e\u7387\u6ca1\u6709\u5f71\u54cd\uff0c\u56e0\u4e3a\u6211\u4eec\u662f\u4e0d\u5e26\u6807\u7b7e\u4fe1\u606f\u5b8c\u5168\u65e0\u76d1\u7763\u5730\u8fdb\u884c\u8bad\u7ec3\u7684\uff0c\u4f46\u662f\u8d8a\u5927\u7684 \u03b2 \u53ef\u89c6\u5316\u51fa\u6765\u7684\u7c07\u8d8a\u96c6\u4e2d\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u589e\u5927 KL \u6563\u5ea6\u9879\u7684\u6743\u91cd\uff0c\u76f8\u5f53\u6709\u5229\u4e8e\u6570\u636e\u964d\u7ef4\u538b\u7f29\uff0c\u4f46\u662f\u5bf9\u5e94\u56fe\u50cf\u4e5f\u8d8a\u7cca\uff0c\u56e0\u4e3a\u8fd9\u4e00\u538b\u7f29\u8fc7\u7a0b\u662f\u4e0d\u53ef\u9006\u7684\uff0c\u8f93\u51fa\u4e5f\u88ab\u8fc7\u5ea6\u5e73\u6ed1\u4e86\u3002</p>  \u65e0\u76d1\u7763\u805a\u7c7b VAE \u4f7f\u7528\u7684\u4ee3\u7801  <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom tqdm import tqdm\nimport os\nfrom scipy.stats import mode\n\n# --- 1. \u914d\u7f6e\u53c2\u6570 ---\nconfig = {\n    \"METHOD_NAME\": \"VAE\",\n    \"LATENT_DIM\": 128,\n    \"NUM_CLUSTERS\": 10,\n    \"BATCH_SIZE\": 128,\n    \"EPOCHS\": 30,\n    \"LR\": 1e-3,\n    \"BETA\": 0.1,\n    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"DATA_PATH\": \"./data\",\n    \"OUTPUT_PATH\": \"./output\"\n}\n\noutput_dir = os.path.join(config[\"OUTPUT_PATH\"], config[\"METHOD_NAME\"])\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Using device: {config['DEVICE']}\")\nprint(f\"Running with Beta = {config['BETA']}\")\n\n# --- 2. \u6570\u636e\u52a0\u8f7d ---\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=True, transform=transform, download=True)\ntest_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=False, transform=transform, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=True, pin_memory=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# --- 3. \u6a21\u578b\u5b9a\u4e49: VAE ---\nclass VAE(nn.Module):\n    def __init__(self, latent_dim):\n        super(VAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.encoder_features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d(2, 2)\n        )\n        self.fc_mu = nn.Linear(256 * 4 * 4, latent_dim)\n        self.fc_log_var = nn.Linear(256 * 4 * 4, latent_dim)\n        self.decoder_fc = nn.Linear(latent_dim, 256 * 4 * 4)\n        self.decoder_conv = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Sigmoid()\n        )\n\n    def encode(self, x):\n        h = self.encoder_features(x)\n        h = h.view(h.size(0), -1)\n        return self.fc_mu(h), self.fc_log_var(h)\n\n    def reparameterize(self, mu, log_var):\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h = self.decoder_fc(z)\n        h = h.view(h.size(0), 256, 4, 4)\n        return self.decoder_conv(h)\n\n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        return self.decode(z), x, mu, log_var\n\n# --- 4. \u635f\u5931\u51fd\u6570 ---\ndef vae_loss_function(recon_x, x, mu, log_var):\n    MSE = F.mse_loss(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    return MSE + config[\"BETA\"] * KLD \n\n# --- 5. \u8bad\u7ec3\u5faa\u73af ---\ndef train(model, train_loader, optimizer, epoch):\n    model.train()\n    total_loss = 0\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['EPOCHS']}\")\n    for data, _ in pbar:\n        data = data.to(config[\"DEVICE\"])\n        optimizer.zero_grad()\n        recon_batch, _, mu, log_var = model(data)\n        loss = vae_loss_function(recon_batch, data, mu, log_var)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        pbar.set_postfix(loss=loss.item() / len(data))\n    avg_loss = total_loss / len(train_loader.dataset)\n    print(f'====&gt; Epoch: {epoch+1} Average loss: {avg_loss:.4f}')\n\ndef calculate_and_show_accuracy(cluster_labels, true_labels):\n    cluster_map = {}\n    for i in range(config[\"NUM_CLUSTERS\"]):\n        labels_in_cluster = true_labels[cluster_labels == i]\n        if len(labels_in_cluster) == 0:\n            cluster_map[i] = 0 \n            continue\n        most_common_label = mode(labels_in_cluster, keepdims=False)[0]\n        cluster_map[i] = most_common_label\n    predicted_labels = np.array([cluster_map[c] for c in cluster_labels])\n    accuracy = np.mean(predicted_labels == true_labels)\n    print(f\"Clustering Accuracy: {accuracy * 100:.2f}%\")\n    print(\"\\nCluster to Label Mapping:\")\n    for i in range(config[\"NUM_CLUSTERS\"]):\n        print(f\"  Cluster {i} -&gt; '{classes[cluster_map[i]]}'\")\n    return cluster_map\n\ndef cluster_and_visualize_kmeans(model, data_loader):\n    model.eval()\n    all_latents, all_true_labels = [], []\n    with torch.no_grad():\n        for data, labels in tqdm(data_loader, desc=\"Encoding data for clustering\"):\n            data = data.to(config[\"DEVICE\"])\n            mu, _ = model.encode(data)\n            all_latents.append(mu.cpu().numpy())\n            all_true_labels.append(labels.numpy())\n    all_latents = np.concatenate(all_latents, axis=0)\n    all_true_labels = np.concatenate(all_true_labels, axis=0)\n\n    print(\"Performing K-Means clustering...\")\n    kmeans = KMeans(n_clusters=config[\"NUM_CLUSTERS\"], random_state=42, n_init='auto')\n    cluster_labels = kmeans.fit_predict(all_latents)\n    cluster_map = calculate_and_show_accuracy(cluster_labels, all_true_labels)\n\n    print(\"Performing t-SNE...\")\n    tsne = TSNE(n_components=2, random_state=42)\n    latents_2d = tsne.fit_transform(all_latents)\n    plt.figure(figsize=(8, 7))\n    plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=cluster_labels, cmap='tab10', s=10)\n    plt.title('VAE + K-Means Clustering Visualization')\n    plt.savefig(os.path.join(output_dir, \"cluster_visualization.png\"))\n    plt.show()\n    return kmeans, cluster_map\n\ndef generate_labeled_images_kmeans(model, kmeans, cluster_map, save_path, n_samples=5):\n    model.eval()\n    centers = torch.from_numpy(kmeans.cluster_centers_).float().to(config[\"DEVICE\"])\n    fig, axes = plt.subplots(n_samples, config[\"NUM_CLUSTERS\"], figsize=(12, 6))\n    fig.suptitle(\"Generated Samples per Cluster\", fontsize=16)\n    with torch.no_grad():\n        for i in range(config[\"NUM_CLUSTERS\"]):\n            center_i = centers[i].unsqueeze(0).repeat(n_samples, 1)\n            noise = torch.randn_like(center_i) * 0.5\n            samples = center_i + noise\n            generated_images = model.decode(samples).cpu()\n            label_name = classes[cluster_map[i]]\n            axes[0, i].set_title(f\"Cluster {i}\\n -&gt; '{label_name}'\")\n            for j in range(n_samples):\n                img = generated_images[j].permute(1, 2, 0).numpy()\n                axes[j, i].imshow(img)\n                axes[j, i].axis(\"off\")\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(save_path)\n    plt.show()\n\nif __name__ == \"__main__\":\n    model = VAE(latent_dim=config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n    optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n\n    print(\"--- Training VAE Model ---\")\n    for epoch in range(config[\"EPOCHS\"]):\n        train(model, train_loader, optimizer, epoch)\n\n    print(\"\\n--- Clustering, Visualization, and Accuracy ---\")\n    kmeans_model, cluster_to_label_map = cluster_and_visualize_kmeans(model, test_loader)\n\n    print(\"\\n--- Generating Labeled Images ---\")\n    gen_save_path = os.path.join(output_dir, \"generated_labeled_images.png\")\n    generate_labeled_images_kmeans(model, kmeans_model, cluster_to_label_map, gen_save_path)\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#cvae", "title": "CVAE", "text": "<p>CVAE \u5373\u6761\u4ef6 VAE\u3002CVAE \u7684\u76ee\u6807\u672c\u4e0d\u662f\u89e3\u51b3\u5206\u7c7b\u4efb\u52a1\uff0c\u800c\u662f\u5229\u7528\u6807\u7b7e\u6765\u9650\u5b9a\u751f\u6210\u3002\u8fd9\u662f\u672c\u7cfb\u5217\u535a\u5ba2\u4e2d\uff0c\u6211\u4eec\u63a5\u89e6\u5230\u7684\u7b2c\u4e00\u4e2a\u6587\u751f\u56fe\uff08T2I\uff09\u6a21\u578b\u3002\u4e3a\u6b64\uff0c\u9996\u5148\u9700\u8981\u8f93\u5165\u5e26\u6807\u7b7e\u7684\u8bad\u7ec3\u6570\u636e\u2014\u2014\u8fd9\u4e2a\u7b80\u5355\uff0c\u53ea\u9700\u8981\u63d0\u53d6\u8f93\u5165\u7279\u5f81\u4e4b\u540e\uff0c\u62fc\u63a5\u4e0a\u6807\u7b7e\u5411\u91cf\u5373\u53ef\uff0c\u7136\u540e\u538b\u7f29\u5230 \\(\\mu\\) \u548c \\(\\sigma\\) \u7684\u5206\u5e03\u4e0a\u3002\u7136\u540e\u89e3\u7801\u5668\u90e8\u5206\uff0c\u5bf9\u9690\u53d8\u91cf \\(z\\) \u4e5f\u62fc\u63a5\u4e0a\u6807\u7b7e\u5411\u91cf\u3002\u5c31\u5b8c\u4e86\u3002</p> <p>\u4e3a\u4f55\uff1f\u6211\u4eec\u6700\u5f00\u59cb\u662f\u5bf9\u9690\u53d8\u91cf \\(z\\) \u8fdb\u884c\u968f\u673a\u91c7\u6837\u7684\uff0c\u8fd9\u5c31\u610f\u5473\u7740 \\(z\\) \u4e0d\u5e26\u6709\u4efb\u4f55\u6807\u7b7e\u4fe1\u606f\uff0c\u5982\u679c\u6211\u4eec\u7ed9\u5b83\u52a0\u4e0a\u6807\u7b7e\u4fe1\u606f\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u7ed9\u5b9a\u6807\u7b7e \\(y\\)\uff0c\u8981\u91cd\u5efa\u7684\u662f\u57fa\u4e8e\u8fd9\u4e2a\u6807\u7b7e\u7684\u6761\u4ef6\u5206\u5e03 \\(q(z|y)\\)\u3002\u5bf9\u4e8e\u7f16\u7801\u5668\u800c\u8a00\uff0c\u56e0\u4e3a\u6807\u7b7e \\(y\\) \u5df2\u77e5\uff0c\u6240\u4ee5\u76f4\u63a5\u5229\u7528\u8054\u5408\u6761\u4ef6\u5206\u5e03 \\(p(z|x,y)\\) \u6765\u538b\u7f29\u5230 \\(z\\) \u4e0a\uff0c\u800c\u5bf9\u89e3\u7801\u5668\u800c\u8a00\uff0c\u4e5f\u662f\u4e00\u4e2a\u8054\u5408\u7684\u6761\u4ef6\u5206\u5e03 \\(q(x|z,y)\\) \u6765\u4ece\u9690\u53d8\u91cf\u7684\u6761\u4ef6\u5206\u5e03\u6765\u8f93\u51fa\u670d\u4ece\u6807\u7b7e\u7684\u6761\u4ef6\u5206\u5e03\u3002\u4e5f\u5c31\u662f\u4e0b\u9762\u7684 \\(ELBO\\)\u3002</p> \\[ \\begin{align*}   ELBO&amp;=\\mathbb E_{z\\sim p(z|x)}[\\log q(x|z,y)]-\\beta KL(p(z|x,y) || q(z|y)) \\end{align*} \\] <p>\u800c\u5206\u7c7b\u65b9\u6848\u5c31\u662f\u5bf9\u5355\u4e2a\u6837\u672c\u53d6\u6240\u6709\u6807\u7b7e\uff0c\u8ba1\u7b97\u635f\u5931\u6700\u5c0f\u7684\u90a3\u4e00\u4e2a\u3002</p> <p>CVAE \u5229\u7528\u6807\u7b7e\u7684\u6548\u7387\u597d\u4e0d\u597d\u5462\uff1f\u8ba9\u6211\u4eec\u770b\u770b\u4e0b\u9762\u7684\u7ed3\u679c\u3002</p> \u03b2 = 0.1 \u03b2 = 1 \u03b2 = 10 \u51c6\u786e\u7387\u53d8\u5316 \u751f\u6210\u56fe\u50cf <p>\u53ef\u4ee5\u770b\u5230\u4e0d\u7ba1 \u03b2 \u8c03\u591a\u5c11\uff0c\u57fa\u672c\u4e0a\u53ea\u80fd\u6bd4\u968f\u673a\u57fa\u7ebf\u7684 10% \u9ad8\u4e00\u4e22\u4e22\uff0c\u8bf4\u660e\u6807\u7b7e\u5728\u5176\u4e2d\u7684\u8d21\u732e\u76f8\u5f53\u5c0f\uff01\u8fd9\u8bf4\u660e\u6a21\u578b\u57fa\u672c\u4e0a\u5ffd\u7565\u4e86\u6761\u4ef6\u4fe1\u606f\uff0c\u57fa\u672c\u4e0a\u6ca1\u6709\u5c06\u5176\u53c2\u4e0e\u8fdb\u56fe\u50cf\u91cd\u6784\u4e2d\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5c31\u662f\u539f\u6765\u7684 VAE \u63d0\u4f9b\u7684\u4fe1\u606f\u548c\u635f\u5931\u5df2\u7ecf\u8db3\u591f\u4e30\u5bcc\uff0c\u4f7f\u5f97\u6a21\u578b\u53ef\u4ee5\u57fa\u672c\u4e0a\u76f4\u63a5\u65e0\u89c6\u5206\u7c7b\u7684\u6761\u4ef6\u3002\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5c31\u662f VAE \u7684\u4e00\u4e2a\u7f3a\u9677\u2014\u2014\u5f53\u89e3\u7801\u5668\u8fc7\u4e8e\u5f3a\u5927\uff0c\u5b83\u4f1a\u76f4\u63a5\u65e0\u89c6\u9690\u53d8\u91cf\u63d0\u4f9b\u7684\u4fe1\u606f\u6765\u751f\u6210\uff08\u7c7b\u4f3c\u4e8e\u7f16\u7801\u5668\u9000\u5316\u6389\uff0c\u89e3\u7801\u5668\u53d8\u6210 GAN \u7684\u751f\u6210\u5668\u800c\u91cd\u6784\u8bef\u5dee\u9879\u5c31\u662f\u5224\u522b\u5668\uff09\uff0c\u8fd9\u88ab\u79f0\u4f5c\u540e\u9a8c\u5d29\u584c\u3002</p> <p>VQ-VAE \u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002\u7531\u4e8e\u8fd9\u4e0d\u662f\u672c\u6587\u7684\u4e3b\u9898\uff0c\u4ec5\u5728\u6b64\u7b80\u5355\u4ecb\u7ecd\uff1aVQ-VAE \u629b\u5f03\u4e86\u5bf9\u9690\u7a7a\u95f4 \\(q(z)\\) \u7684\u8fc7\u5f3a\u7684\u6b63\u6001\u5206\u5e03\u5047\u8bbe\uff0c\u5b83\u8fc7\u5ea6\u5e73\u6ed1\uff0c\u56e0\u6b64\u8003\u8651\u4f7f\u7528\u4e00\u4e2a <code>d @ m x m</code> \u7684\u5f20\u91cf\uff08\u88ab\u79f0\u4f5c\u7801\u8868\uff09\uff0c\u6216\u8005\u8bf4\u662f \\(m \\times m\\) \u4e2a\u6392\u6210\u77e9\u9635\u7684 \\(d\\) \u7ef4\u5411\u91cf\uff0c\u6765\u5bf9\u9690\u7a7a\u95f4\u505a\u79bb\u6563\u7684\u5efa\u6a21\uff0c\u8fd9\u6837\uff0cCNN \u8f93\u51fa\u7684\u7279\u5f81\u56fe \\(z\\) \u5c31\u53ef\u4ee5\u548c\u8fd9\u4e2a\u5f20\u91cf\u505a\u6620\u5c04\uff0c\u5177\u4f53\u800c\u8a00\u662f\u62bd\u53d6\u67d0\u4e2a\u50cf\u7d20\u4f4d\u7f6e\u7684\u6240\u6709\u901a\u9053\u7279\u5f81\u5f97\u5230\u4e00\u4e2a \\(d\\) \u7ef4\u5411\u91cf\uff0c\u7136\u540e\u627e\u5230\u4e4b\u524d\u90a3\u4e2a\u5f20\u91cf\u91cc\u9762\u548c\u8fd9\u4e2a \\(d\\) \u7ef4\u5411\u91cf\u6700\u63a5\u8fd1\u7684\u90a3\u4e2a \\(d\\) \u7ef4\u5411\u91cf\uff0c\u8fdb\u884c\u66ff\u6362\uff0c\u4e5f\u5c31\u662f\u7528\u7801\u8868\u53bb\u8fd1\u4f3c\u7279\u5f81\u3002\u7136\u540e\u66ff\u6362\u540e\u5f97\u5230\u7684\u7279\u5f81\u56fe \\(z_q\\) \u5c31\u53ef\u4ee5\u4f7f\u7528\u53cd\u5377\u79ef\u8fdb\u884c\u89e3\u7801\u4e86\u3002VQ-VAE \u53e6\u4e00\u4e2a\u521b\u65b0\u5c31\u662f\u5728\u7801\u8868\u66ff\u6362\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u8fd9\u4e00\u8fc7\u7a0b\u65e0\u6cd5\u6c42\u68af\u5ea6\uff0c\u4e8e\u662f\u4f5c\u8005\u8bbe\u8ba1\u4e86\u8fd9\u6837\u7684\u635f\u5931\u9879</p> \\[ \\mathcal L=|x-D(z+\\mathrm{sg}[z_q-z])|^2 + \\gamma |z-\\mathrm{sg}[z_q]|^2+\\beta |z_q-\\mathrm{sg}[z]|^2 \\] <p>\u8fd9\u91cc \\(\\mathrm{sg}[z]\\) \u7684\u610f\u601d\u662f\uff0c\u524d\u5411\u4f20\u64ad\u7167\u5e38\u8ba1\u7b97\uff0c\u53cd\u5411\u4f20\u64ad\u4e22\u5f03\u68af\u5ea6\uff08stop gradient\uff09\uff0c\u8fd9\u6837\u524d\u5411\u4f20\u64ad\u7684\u65f6\u5019\uff0c\u5c31\u901a\u8fc7 \\(z_q\\) \u8fdb\u884c\u751f\u6210\uff0c\u800c\u53cd\u5411\u4f20\u64ad\u7684\u65f6\u5019\uff0c\u91cd\u6784\u8bef\u5dee\u4f9d\u9760 \\(z\\) \u8ba1\u7b97\u68af\u5ea6\uff0c\u800c\u4e3a\u4e86\u8ba9\u68af\u5ea6\u6b63\u5e38\u66f4\u65b0\uff0c\u53c8\u9700\u8981 \\(z_q\\) \u5c3d\u91cf\u63a5\u8fd1 \\(z\\)\uff0c\u5c31\u6709\u4e86\u540e\u9762\u4e24\u9879\uff0c\u901a\u8fc7\u53c2\u6570\u5927\u5c0f\u6765\u5206\u914d\u7801\u8868\u548c\u7f16\u7801\u5668\u7684\u53c2\u6570\u66f4\u65b0\uff0c\u8fd9\u5c31\u5bf9\u5e94 VAE \u91cc\u9762\u7684 KLD\uff0c\u53ea\u4e0d\u8fc7\u8fd9\u6b21\u6211\u4eec\u6ca1\u6709\u5f3a\u5236\u5bf9\u9f50\u5230\u6b63\u6001\u5206\u5e03\u4e86\u3002</p> <p>\u8fd9\u91cc\u8dd1\u9898\u633a\u8fdc\uff0c\u626f\u56de\u6b63\u9898\uff0c\u4e0b\u9762\u662f\u4ee3\u7801\uff1a</p>  CVAE \u7684\u4ee3\u7801  <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom tqdm import tqdm\nimport os\n\n# --- 1. \u914d\u7f6e\u53c2\u6570 ---\nconfig = {\n    \"METHOD_NAME\": \"CVAE\",\n    \"LATENT_DIM\": 128,\n    \"NUM_CLASSES\": 10,\n    \"BATCH_SIZE\": 128,\n    \"EPOCHS\": 30,\n    \"LR\": 1e-3,\n    \"BETA\": 0.1,\n    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"DATA_PATH\": \"./data\",\n    \"OUTPUT_PATH\": \"./output\"\n}\n\noutput_dir = os.path.join(config[\"OUTPUT_PATH\"], config[\"METHOD_NAME\"])\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Using device: {config['DEVICE']}\")\nprint(f\"Running with Beta = {config['BETA']}\")\n\n# --- 2. \u6570\u636e\u52a0\u8f7d ---\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=True, transform=transform, download=True)\ntest_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=False, transform=transform, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=True, pin_memory=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# --- 3. \u6a21\u578b\u5b9a\u4e49: CVAE ---\nclass CVAE(nn.Module):\n    def __init__(self, latent_dim, num_classes):\n        super(CVAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.num_classes = num_classes\n\n        self.encoder_features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d(2, 2)\n        )\n\n        self.fc_mu = nn.Linear(256 * 4 * 4 + num_classes, latent_dim)\n        self.fc_log_var = nn.Linear(256 * 4 * 4 + num_classes, latent_dim)\n\n        self.decoder_fc = nn.Linear(latent_dim + num_classes, 256 * 4 * 4)\n        self.decoder_conv = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Sigmoid()\n        )\n\n    def encode(self, x, y_onehot):\n        h = self.encoder_features(x)\n        h_flat = h.view(h.size(0), -1)\n        h_combined = torch.cat([h_flat, y_onehot], dim=1)\n        return self.fc_mu(h_combined), self.fc_log_var(h_combined)\n\n    def reparameterize(self, mu, log_var):\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z, y_onehot):\n        z_combined = torch.cat([z, y_onehot], dim=1)\n        h = self.decoder_fc(z_combined)\n        h = h.view(h.size(0), 256, 4, 4)\n        return self.decoder_conv(h)\n\n    def forward(self, x, y_onehot):\n        mu, log_var = self.encode(x, y_onehot)\n        z = self.reparameterize(mu, log_var)\n        recon_x = self.decode(z, y_onehot)\n        return recon_x, x, mu, log_var\n\n# --- 4. \u635f\u5931\u51fd\u6570 ---\ndef cvae_loss_function(recon_x, x, mu, log_var):\n    MSE = F.mse_loss(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    return MSE + config[\"BETA\"] * KLD\n\n# --- 5. \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u5faa\u73af ---\ndef train(model, train_loader, optimizer, epoch):\n    model.train()\n    total_loss = 0\n    pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{config['EPOCHS']}\")\n    for data, labels in pbar:\n        data = data.to(config[\"DEVICE\"])\n        labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float().to(config[\"DEVICE\"])\n\n        optimizer.zero_grad()\n        recon_batch, _, mu, log_var = model(data, labels_onehot)\n        loss = cvae_loss_function(recon_batch, data, mu, log_var)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        pbar.set_postfix(loss=loss.item() / len(data))\n\n    avg_loss = total_loss / len(train_loader.dataset)\n    print(f'====&gt; Train Epoch: {epoch+1} | Avg Loss: {avg_loss:.4f}')\n    return avg_loss\n\ndef test(model, test_loader, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    pbar = tqdm(test_loader, desc=f\"Test Epoch {epoch+1}/{config['EPOCHS']}\")\n    with torch.no_grad():\n        for data, labels in pbar:\n            data, labels = data.to(config[\"DEVICE\"]), labels.to(config[\"DEVICE\"])\n            batch_size = data.size(0)\n\n            # \u5b58\u50a8\u6bcf\u4e2a\u6837\u672c\u5728\u6bcf\u4e2a\u5019\u9009\u7c7b\u522b\u4e0b\u7684\u635f\u5931\n            losses_per_class = torch.zeros(batch_size, config[\"NUM_CLASSES\"]).to(config[\"DEVICE\"])\n\n            # \u904d\u5386\u6240\u6709\u53ef\u80fd\u7684\u7c7b\u522b\n            for c in range(config[\"NUM_CLASSES\"]):\n                # \u4e3a\u6574\u4e2abatch\u521b\u5efa\u540c\u4e00\u4e2a\u7c7b\u522b\u7684one-hot\u6807\u7b7e\n                class_labels = torch.full_like(labels, c)\n                class_onehot = F.one_hot(class_labels, num_classes=config[\"NUM_CLASSES\"]).float()\n\n                # \u8ba1\u7b97\u635f\u5931\n                recon_batch, _, mu, log_var = model(data, class_onehot)\n                loss = cvae_loss_function(recon_batch, data, mu, log_var)\n\n                # VAE\u635f\u5931\u662f\u6574\u4e2abatch\u7684\u603b\u548c\uff0c\u6211\u4eec\u9700\u8981\u6bcf\u4e2a\u6837\u672c\u7684\u635f\u5931\n                # \u8fd9\u91cc\u7528\u5e73\u5747\u635f\u5931\u8fdb\u884c\u8fd1\u4f3c\n                losses_per_class[:, c] = loss / batch_size\n\n            # \u627e\u5230\u6bcf\u4e2a\u6837\u672c\u635f\u5931\u6700\u5c0f\u7684\u7c7b\u522b\u4f5c\u4e3a\u9884\u6d4b\u7ed3\u679c\n            pred = losses_per_class.argmin(dim=1)\n            correct += pred.eq(labels).sum().item()\n\n            # \u8ba1\u7b97\u6d4b\u8bd5\u635f\u5931\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u771f\u5b9e\u6807\u7b7e\n            true_labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float()\n            recon_true, _, mu_true, log_var_true = model(data, true_labels_onehot)\n            test_loss += cvae_loss_function(recon_true, data, mu_true, log_var_true).item()\n\n            pbar.set_postfix(acc=f\"{100. * correct / len(test_loader.dataset):.2f}%\")\n\n    avg_loss = test_loss / len(test_loader.dataset)\n    accuracy = 100. * correct / len(test_loader.dataset)\n\n    print(f'====&gt; Test set | Avg Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%')\n    return avg_loss, accuracy\n\n\n# --- 6. \u53ef\u89c6\u5316\u51fd\u6570 ---\ndef visualize_latent_space(model, data_loader):\n    model.eval()\n    all_latents, all_labels = [], []\n    with torch.no_grad():\n        for data, labels in tqdm(data_loader, desc=\"Encoding data for visualization\"):\n            data = data.to(config[\"DEVICE\"])\n            labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float().to(config[\"DEVICE\"])\n            mu, _ = model.encode(data, labels_onehot)\n            all_latents.append(mu.cpu().numpy())\n            all_labels.append(labels.numpy())\n\n    all_latents = np.concatenate(all_latents, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n\n    print(\"Performing t-SNE...\")\n    tsne = TSNE(n_components=2, random_state=42, n_iter=300, n_jobs=-1)\n    latents_2d = tsne.fit_transform(all_latents)\n\n    plt.figure(figsize=(12, 10))\n    scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=all_labels, cmap='tab10', s=10)\n    plt.colorbar(scatter, ticks=range(10))\n    plt.title('t-SNE of Latent Space (Colored by True Class)')\n    plt.savefig(os.path.join(output_dir, \"latent_space_true_labels.png\"))\n    plt.show()\n\ndef generate_images_by_class(model, n_samples=5):\n    model.eval()\n    fig, axes = plt.subplots(n_samples, config[\"NUM_CLASSES\"], figsize=(15, 8))\n    fig.suptitle(\"Generated Samples by Class\", fontsize=16)\n\n    with torch.no_grad():\n        for class_idx in range(config[\"NUM_CLASSES\"]):\n            class_onehot = F.one_hot(torch.tensor([class_idx]), num_classes=config[\"NUM_CLASSES\"]).float()\n            class_onehot = class_onehot.repeat(n_samples, 1).to(config[\"DEVICE\"])\n            z = torch.randn(n_samples, config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n            generated_images = model.decode(z, class_onehot).cpu()\n            axes[0, class_idx].set_title(f\"'{classes[class_idx]}'\")\n            for sample_idx in range(n_samples):\n                img = generated_images[sample_idx].permute(1, 2, 0).numpy()\n                axes[sample_idx, class_idx].imshow(img)\n                axes[sample_idx, class_idx].axis(\"off\")\n\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(os.path.join(output_dir, \"generated_images_by_class.png\"))\n    plt.show()\n\ndef plot_curves(train_losses, test_losses, test_accuracies):\n    epochs = range(1, len(train_losses) + 1)\n\n    plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n    plt.plot(epochs, test_losses, 'ro-', label='Test Loss')\n    plt.title('Training and Test Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, test_accuracies, 'go-', label='Test Accuracy')\n    plt.title('Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n\n    plt.suptitle('Training Metrics', fontsize=16)\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.savefig(os.path.join(output_dir, \"training_curves.png\"))\n    plt.show()\n\n\n# --- \u4e3b\u7a0b\u5e8f ---\nif __name__ == \"__main__\":\n    model = CVAE(latent_dim=config[\"LATENT_DIM\"], num_classes=config[\"NUM_CLASSES\"]).to(config[\"DEVICE\"])\n    optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n\n    train_losses, test_losses, test_accuracies = [], [], []\n\n    print(\"--- Training Pure CVAE Model for Classification ---\")\n    for epoch in range(config[\"EPOCHS\"]):\n        train_loss = train(model, train_loader, optimizer, epoch)\n        test_loss, test_acc = test(model, test_loader, epoch)\n\n        train_losses.append(train_loss)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_acc)\n        print(\"-\" * 50)\n\n    print(\"\\n--- Plotting Training Curves ---\")\n\n    plot_curves(train_losses, test_losses, test_accuracies)\n\n    print(\"\\n--- Visualizing Latent Space ---\")\n    visualize_latent_space(model, test_loader)\n\n    print(\"\\n--- Generating Images by Class ---\")\n    generate_images_by_class(model)\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#cvae_1", "title": "CVAE \u63a5\u5206\u7c7b\u5934", "text": "<p>\u6700\u540e\u4e00\u4e2a\u65b9\u6848\u6bd4\u8f83\u5de5\u7a0b\uff0c\u65e2\u7136\u6211\u4eec\u7684\u7f16\u7801\u5668\u5df2\u7ecf\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u5728\u8fd9\u4e2a\u7279\u5f81\u63d0\u53d6\u5668\u4e0a\u9762\u8bad\u7ec3\u5206\u7c7b\u5934\uff0c\u6700\u540e\u5c06\u5206\u7c7b\u635f\u5931\u548c VAE \u7684\u635f\u5931\u6c47\u603b\u5462\uff1f\u4e5f\u5c31\u662f</p> \\[ \\mathcal L= \\gamma CE-ELBO \\] <p>\u4f46\u662f\u6211\u4eec\u4e5f\u53ef\u4ee5\u6362\u4e2a\u89c6\u89d2\uff0c\u6211\u4eec\u4e0d\u5c06\u5176\u770b\u4f5c\u662f CVAE \u7684\u9b54\u6539\uff0c\u800c\u662f\u4e00\u4e2a CNN \u7684\u9b54\u6539\uff1a\u5bf9\u4e00\u4e2a CNN \u63a5\u4e86\u4e2a CVAE \u7684\u652f\u7ebf\uff0c\u8fd9\u6837 \\(-ELBO\\) \u5c31\u662f\u5bf9 CNN \u539f\u6709\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7684\u6b63\u5219\u5316\u9879\uff01\u800c\u8fd9\u6837\u7684\u6b63\u5219\u5316\u6781\u5176\u6709\u9053\u7406\u2014\u2014\u6211\u4eec\u5e76\u4e0d\u662f\u50cf \\(L_2\\) \u6b63\u5219\u5316\u4e00\u6837\u7ea6\u675f\u53c2\u6570\u5927\u5c0f\uff0c\u800c\u662f\u57fa\u4e8e\u5176\u56fe\u50cf\u672c\u8eab\u548c\u9884\u6d4b\u7c7b\u522b\uff0c\u6765\u8fdb\u4e00\u6b65\u7ea6\u675f\u7279\u5f81\u63d0\u53d6\u5668\u3002\u5f53\u7136\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282 \\(\\beta\\) \u548c \\(\\gamma\\) \u6765\u63a7\u5236\u6b63\u5219\u5316\u60e9\u7f5a\u7684\u5f3a\u5ea6\u3002</p> <p>\u8fd9\u662f\u76ee\u524d\u4e09\u79cd\u5c1d\u8bd5\u91cc\u9762\u6700\u597d\u7684\u6548\u679c\uff0c\u80fd\u591f\u8fbe\u5230\u5206\u7c7b\u51c6\u786e\u7387 82% \u4ee5\u4e0a\uff0c\u8fd9\u8fd8\u53ea\u662f\u4e00\u4e2a\u7b80\u5355\u7684 3 \u5c42 CNN\uff0c\u6548\u679c\u5c31\u5df2\u7ecf\u63a5\u8fd1\u4e4b\u524d\u4ece\u96f6\u8bad\u7ec3\u7684 ResNet-18 \u4e86\u3002</p> \u03b2 = 0.1 \u03b2 = 1 \u03b2 = 10 \u8bad\u7ec3\u6307\u6807\u66f2\u7ebf \u751f\u6210\u56fe\u50cf  \u5e26\u5206\u7c7b\u5934\u7684 CVAE \u7684\u8bad\u7ec3\u4ee3\u7801  <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom tqdm import tqdm\nimport os\n\n# --- 1. \u914d\u7f6e\u53c2\u6570 ---\nconfig = {\n    \"METHOD_NAME\": \"CVAE_Classifier\",\n    \"LATENT_DIM\": 128,\n    \"NUM_CLASSES\": 10,\n    \"BATCH_SIZE\": 128,\n    \"EPOCHS\": 30,\n    \"LR\": 1e-3,\n    \"BETA\": 0.1,\n    \"GAMMA\": 50,\n    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"DATA_PATH\": \"./data\",\n    \"OUTPUT_PATH\": \"./output\"\n}\n\noutput_dir = os.path.join(config[\"OUTPUT_PATH\"], config[\"METHOD_NAME\"])\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Using device: {config['DEVICE']}\")\nprint(f\"Running with Beta = {config['BETA']}, Gamma = {config['GAMMA']}\")\n\n# --- 2. \u6570\u636e\u52a0\u8f7d ---\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=True, transform=transform, download=True)\ntest_dataset = datasets.CIFAR10(root=config[\"DATA_PATH\"], train=False, transform=transform, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=True, pin_memory=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# --- 3. \u6a21\u578b\u5b9a\u4e49: CVAE + \u5206\u7c7b\u5668 ---\nclass CVAE(nn.Module):\n    def __init__(self, latent_dim, num_classes):\n        super(CVAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.num_classes = num_classes\n\n        # \u7f16\u7801\u5668\n        self.encoder_features = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d(2, 2)\n        )\n\n        # \u5206\u7c7b\u5934\u4ece\u56fe\u50cf\u7279\u5f81\u76f4\u63a5\u8fdb\u884c\u5206\u7c7b\n        self.classifier = nn.Linear(256 * 4 * 4, num_classes)\n\n        # VAE\u90e8\u5206\n        self.fc_mu = nn.Linear(256 * 4 * 4 + num_classes, latent_dim)\n        self.fc_log_var = nn.Linear(256 * 4 * 4 + num_classes, latent_dim)\n\n        # \u89e3\u7801\u5668\n        self.decoder_fc = nn.Linear(latent_dim + num_classes, 256 * 4 * 4)\n        self.decoder_conv = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Sigmoid()\n        )\n\n    def encode(self, x, y_onehot):\n        # \u63d0\u53d6\u56fe\u50cf\u7279\u5f81\n        h = self.encoder_features(x)\n        h_flat = h.view(h.size(0), -1)\n\n        # --- \u5206\u7c7b\u9884\u6d4b ---\n        logits = self.classifier(h_flat)\n\n        # \u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u6807\u7b7e\u4fe1\u606f\u62fc\u63a5\u7528\u4e8eVAE\n        h_combined = torch.cat([h_flat, y_onehot], dim=1)\n        mu, log_var = self.fc_mu(h_combined), self.fc_log_var(h_combined)\n        return mu, log_var, logits\n\n    def reparameterize(self, mu, log_var):\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z, y_onehot):\n        # \u5c06\u6f5c\u5728\u53d8\u91cf\u4e0e\u6807\u7b7e\u4fe1\u606f\u62fc\u63a5\n        z_combined = torch.cat([z, y_onehot], dim=1)\n        h = self.decoder_fc(z_combined)\n        h = h.view(h.size(0), 256, 4, 4)\n        return self.decoder_conv(h)\n\n    def forward(self, x, y_onehot):\n        mu, log_var, logits = self.encode(x, y_onehot)\n        z = self.reparameterize(mu, log_var)\n        recon_x = self.decode(z, y_onehot)\n        return recon_x, x, mu, log_var, logits\n\n# --- 4. \u635f\u5931\u51fd\u6570 ---\ndef loss_function(recon_x, x, mu, log_var, logits, labels):\n    # VAE\u635f\u5931\n    MSE = F.mse_loss(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    vae_loss = MSE + config[\"BETA\"] * KLD\n\n    # \u5206\u7c7b\u635f\u5931\n    class_loss = F.cross_entropy(logits, labels, reduction='sum')\n\n    # \u603b\u635f\u5931\n    total_loss = vae_loss + config[\"GAMMA\"] * class_loss\n\n    return total_loss, vae_loss, class_loss\n\n# --- 5. \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u5faa\u73af ---\ndef train(model, train_loader, optimizer, epoch):\n    model.train()\n    total_loss, total_vae_loss, total_class_loss = 0, 0, 0\n    correct = 0\n    total_samples = 0\n\n    pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{config['EPOCHS']}\")\n    for data, labels in pbar:\n        data, labels = data.to(config[\"DEVICE\"]), labels.to(config[\"DEVICE\"])\n\n        # \u521b\u5efaone-hot\u6807\u7b7e\n        labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float()\n\n        optimizer.zero_grad()\n        recon_batch, _, mu, log_var, logits = model(data, labels_onehot)\n\n        # \u8ba1\u7b97\u635f\u5931\n        t_loss, v_loss, c_loss = loss_function(recon_batch, data, mu, log_var, logits, labels)\n\n        t_loss.backward()\n        optimizer.step()\n\n        # \u7d2f\u52a0\u635f\u5931\u548c\u6b63\u786e\u5206\u7c7b\u6570\n        total_loss += t_loss.item()\n        total_vae_loss += v_loss.item()\n        total_class_loss += c_loss.item()\n\n        pred = logits.argmax(dim=1, keepdim=True)\n        correct += pred.eq(labels.view_as(pred)).sum().item()\n        total_samples += len(data)\n\n        pbar.set_postfix(\n            loss=t_loss.item() / len(data), \n            acc=f\"{100. * correct / total_samples:.2f}%\"\n        )\n\n    avg_loss = total_loss / len(train_loader.dataset)\n    avg_vae_loss = total_vae_loss / len(train_loader.dataset)\n    avg_class_loss = total_class_loss / len(train_loader.dataset)\n    accuracy = 100. * correct / len(train_loader.dataset)\n\n    print(f'====&gt; Train Epoch: {epoch+1} | Avg Loss: {avg_loss:.4f} | VAE Loss: {avg_vae_loss:.4f} | Class Loss: {avg_class_loss:.4f} | Accuracy: {accuracy:.2f}%')\n    return avg_loss, accuracy\n\ndef test(model, test_loader, epoch):\n    model.eval()\n    total_loss, total_vae_loss, total_class_loss = 0, 0, 0\n    correct = 0\n\n    with torch.no_grad():\n        for data, labels in test_loader:\n            data, labels = data.to(config[\"DEVICE\"]), labels.to(config[\"DEVICE\"])\n            labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float()\n\n            recon_batch, _, mu, log_var, logits = model(data, labels_onehot)\n            t_loss, v_loss, c_loss = loss_function(recon_batch, data, mu, log_var, logits, labels)\n\n            total_loss += t_loss.item()\n            total_vae_loss += v_loss.item()\n            total_class_loss += c_loss.item()\n\n            pred = logits.argmax(dim=1, keepdim=True)\n            correct += pred.eq(labels.view_as(pred)).sum().item()\n\n    avg_loss = total_loss / len(test_loader.dataset)\n    avg_vae_loss = total_vae_loss / len(test_loader.dataset)\n    avg_class_loss = total_class_loss / len(test_loader.dataset)\n    accuracy = 100. * correct / len(test_loader.dataset)\n\n    print(f'====&gt; Test set | Avg Loss: {avg_loss:.4f} | VAE Loss: {avg_vae_loss:.4f} | Class Loss: {avg_class_loss:.4f} | Accuracy: {accuracy:.2f}%')\n    return avg_loss, accuracy\n\n# --- 6. \u53ef\u89c6\u5316\u51fd\u6570 ---\ndef visualize_latent_space(model, data_loader):\n    model.eval()\n    all_latents, all_labels, all_preds = [], [], []\n    with torch.no_grad():\n        for data, labels in tqdm(data_loader, desc=\"Encoding data for visualization\"):\n            data = data.to(config[\"DEVICE\"])\n            labels_onehot = F.one_hot(labels, num_classes=config[\"NUM_CLASSES\"]).float().to(config[\"DEVICE\"])\n\n            mu, _, logits = model.encode(data, labels_onehot)\n\n            all_latents.append(mu.cpu().numpy())\n            all_labels.append(labels.numpy())\n            all_preds.append(logits.argmax(dim=1).cpu().numpy())\n\n    all_latents = np.concatenate(all_latents, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n    all_preds = np.concatenate(all_preds, axis=0)\n\n    print(\"Performing t-SNE...\")\n    tsne = TSNE(n_components=2, random_state=42, n_iter=300, n_jobs=-1)\n    latents_2d = tsne.fit_transform(all_latents)\n\n    # \u6309\u771f\u5b9e\u6807\u7b7e\u53ef\u89c6\u5316\n    plt.figure(figsize=(12, 10))\n    scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=all_labels, cmap='tab10', s=10)\n    plt.colorbar(scatter, ticks=range(10))\n    plt.title('t-SNE of Latent Space (Colored by True Class)')\n    plt.savefig(os.path.join(output_dir, \"latent_space_true_labels.png\"))\n    plt.show()\n\n    # \u6309\u9884\u6d4b\u6807\u7b7e\u53ef\u89c6\u5316\n    plt.figure(figsize=(12, 10))\n    scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=all_preds, cmap='tab10', s=10)\n    plt.colorbar(scatter, ticks=range(10))\n    plt.title('t-SNE of Latent Space (Colored by Predicted Class)')\n    plt.savefig(os.path.join(output_dir, \"latent_space_predicted_labels.png\"))\n    plt.show()\n\ndef generate_images_by_class(model, n_samples=5):\n    model.eval()\n    fig, axes = plt.subplots(n_samples, config[\"NUM_CLASSES\"], figsize=(15, 8))\n    fig.suptitle(\"Generated Samples by Class\", fontsize=16)\n\n    with torch.no_grad():\n        for class_idx in range(config[\"NUM_CLASSES\"]):\n            class_onehot = F.one_hot(torch.tensor([class_idx]), num_classes=config[\"NUM_CLASSES\"]).float()\n            class_onehot = class_onehot.repeat(n_samples, 1).to(config[\"DEVICE\"])\n\n            z = torch.randn(n_samples, config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n            generated_images = model.decode(z, class_onehot).cpu()\n\n            axes[0, class_idx].set_title(f\"'{classes[class_idx]}'\")\n\n            for sample_idx in range(n_samples):\n                img = generated_images[sample_idx].permute(1, 2, 0).numpy()\n                axes[sample_idx, class_idx].imshow(img)\n                axes[sample_idx, class_idx].axis(\"off\")\n\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(os.path.join(output_dir, \"generated_images_by_class.png\"))\n    plt.show()\n\n# --- \u7ed8\u5236\u8bad\u7ec3\u66f2\u7ebf\u7684\u51fd\u6570 ---\ndef plot_curves(train_losses, test_losses, train_accuracies, test_accuracies):\n    epochs = range(1, len(train_losses) + 1)\n\n    # \u521b\u5efa\u4e00\u4e2afigure\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u56fe\n    plt.figure(figsize=(14, 6))\n\n    # \u5b50\u56fe1: \u635f\u5931\u66f2\u7ebf\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n    plt.plot(epochs, test_losses, 'ro-', label='Test Loss')\n    plt.title('Training and Test Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # \u5b50\u56fe2: \u51c6\u786e\u7387\u66f2\u7ebf\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, 'bo-', label='Training Accuracy')\n    plt.plot(epochs, test_accuracies, 'ro-', label='Test Accuracy')\n    plt.title('Training and Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n\n    plt.suptitle('Training Metrics', fontsize=16)\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.savefig(os.path.join(output_dir, \"training_curves.png\"))\n    plt.show()\n\nif __name__ == \"__main__\":\n    model = CVAE(latent_dim=config[\"LATENT_DIM\"], num_classes=config[\"NUM_CLASSES\"]).to(config[\"DEVICE\"])\n    optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n\n    # \u7528\u4e8e\u8bb0\u5f55\u5386\u53f2\u6570\u636e\n    train_losses, test_losses = [], []\n    train_accuracies, test_accuracies = [], []\n\n    print(\"--- Training CVAE with Classifier ---\")\n    for epoch in range(config[\"EPOCHS\"]):\n        train_loss, train_acc = train(model, train_loader, optimizer, epoch)\n        test_loss, test_acc = test(model, test_loader, epoch)\n\n        # \u8bb0\u5f55\u6570\u636e\n        train_losses.append(train_loss)\n        train_accuracies.append(train_acc)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_acc)\n        print(\"-\" * 50)\n\n    print(\"\\n--- Plotting Training Curves ---\")\n    plot_curves(train_losses, test_losses, train_accuracies, test_accuracies)\n\n    print(\"\\n--- Visualizing Latent Space ---\")\n    visualize_latent_space(model, test_loader)\n\n    print(\"\\n--- Generating Images by Class ---\")\n    generate_images_by_class(model)\n</code></pre>"}, {"location": "DNN/model-expr/Image-models-replication/#gan", "title": "GAN", "text": ""}, {"location": "DNN/model-expr/Image-models-replication/#dc-gan", "title": "\u62ff DC-GAN \u753b\u8001\u5a46", "text": "<p>\u867d\u7136\u63a8\u51fa GAN \u6846\u67b6\u7684\u65b9\u6cd5\u6709\u5f88\u591a\uff0c\u6bd4\u5982\u535a\u5f08\u8bba\uff08\u5373\u4e00\u5f00\u59cb\u63d0\u51fa GAN \u7684\u8bba\u6587\u7684\u601d\u8def\uff09\u548c\u80fd\u91cf\u89c6\u89d2\u7b49\uff0c\u4e0d\u8fc7\uff0c\u6211\u4e2a\u4eba\u66f4\u503e\u5411\u4e8e\u63a5\u7740 VAE \u7684\u601d\u8def\uff0c\u7528\u53d8\u5206\u63a8\u65ad\u7684\u6846\u67b6\u53bb\u63a8\u5bfc GAN\u3002</p> <p>\u4e66\u63a5\u4e0a\u56de\uff0c\u6211\u4eec\u77e5\u9053 VAE \u5047\u5b9a\u76ee\u6807\u5206\u5e03 \\(p(x)\\) \u53ef\u4ee5\u88ab\u4e24\u6b65\u62df\u5408\u800c\u6210\uff0c\u4e5f\u5c31\u662f\u9884\u671f \\(p(x)\\approx\\int q(x|z)q(z)\\mathrm dz\\)\u3002\\(q(z)\\) \u5373\u4e3a\u9690\u53d8\u91cf\u5206\u5e03\uff0c\u800c \\(q(x|z)\\) \u662f\u4ece\u91c7\u6837\u751f\u6210\u56fe\u7247\u7684\u89e3\u7801\u5668\u2014\u2014\u6216\u8005\u6211\u4eec\u53ef\u4ee5\u6362\u4e2a\u540d\u5b57\uff0c\u53eb\u505a\u751f\u6210\u5668\uff0c\u4e5f\u5c31\u662f \\(G(z)\\)\u3002</p> <p>\u4f46\u662f\u7531\u4e8e VAE \u5f15\u5165\u7684\u6b63\u6001\u5206\u5e03\u5148\u9a8c\u8fc7\u591a\uff0c\u5bfc\u81f4\u6734\u7d20 VAE \u51fa\u56fe\u5f88\u7cca\uff0c\u4e8e\u662f\u6211\u4eec\u8003\u8651\uff0c\u81f3\u5c11\u548c\u51fa\u56fe\u76f4\u63a5\u76f8\u5173\u7684\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u6539\u6210\u975e\u6b63\u6001\u5206\u5e03\u3002\u600e\u4e48\u6539\u5462\uff1fGAN \u8ba4\u4e3a\uff0c\u53ef\u4ee5\u76f4\u63a5\u5efa\u7acb\u968f\u673a\u53d8\u91cf \\(z\\) \u5230 \\(x\\) \u7684\u4e00\u4e00\u5bf9\u5e94\uff01</p> \\[ q(x|z)=\\delta(x-G(z)) \\] <p>\u8fd9\u91cc\u7528\u5230\u4e86 Dirac's Delta \u51fd\u6570\uff0c\u5c31\u662f\u8981\u5efa\u7acb\u8fd9\u79cd\u4e00\u4e00\u5bf9\u5e94\u3002\u7531\u4e8e\u6211\u4eec\u6ca1\u6709\u5f3a\u5236\u5047\u8bbe\u6b63\u6001\u6027\uff0c\u6240\u4ee5\u73b0\u5728\u4e5f\u4e0d\u597d\u8bf4 \\(z\\) \u662f\u9690\u53d8\u91cf\uff0c\u540c\u65f6\u540e\u9a8c\u5206\u5e03 \\(p(z|x)\\) \u4e5f\u4e0d\u597d\u63a8\u77e5\u4e86\uff08\u5728 VAE \u91cc\u9762\uff0c\u662f\u4e00\u4e2a\u6b63\u6001\u5206\u5e03\uff09\u3002\u81f3\u5c11\u6211\u4eec\u6ca1\u6709\u5f3a\u5236\u7528\u5148\u9a8c\u7684\u6b63\u6001\u5206\u5e03\uff0c\u4e0d\u4f1a\u90a3\u4e48\u201c\u7cca\u201d\u4e86\u3002</p> <p>\u6211\u4eec\u77e5\u9053\u65e0\u8bba\u5982\u4f55\u53d8\u5206\u63a8\u65ad\u7684\u76ee\u7684\uff0c\u662f\u5c06\u4e0d\u597d\u63a8\u5bfc\u7684 \\(KL(q(x)||p(x))\\) \u901a\u8fc7\u5f15\u5165\u9690\u53d8\u91cf \\(y\\)\uff0c\u8f6c\u5316\u6210\u66f4\u5f3a\u4e5f\u66f4\u5bb9\u6613\u63a8\u5bfc\u7684 \\(KL(q(x,y)||p(x,y))\\)\u3002</p> <p>GAN \u8ba4\u4e3a\uff0c\u8fd9\u4e2a\u9690\u53d8\u91cf\u662f\u4e00\u4e2a\u4e8c\u5143\u7684\u6807\u7b7e\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u7528\u6765\u533a\u5206\u54ea\u4e9b\u662f\u4ece \\(q(x|z)q(z)\\) \u751f\u6210\u7684\uff0c\u54ea\u4e9b\u662f \\(p(x)\\) \u672c\u6765\u7684\u5206\u5e03\u3002\u4e5f\u5c31\u662f\u8bf4\uff1a</p> \\[ q(x,y)=\\left\\{   \\begin{align*}     &amp;\\dfrac 12\\ p(x),\\ y = 1\\\\     &amp;\\dfrac 12\\ q(x),\\ y = 0   \\end{align*} \\right. \\] <p>\u4ee5\u53ca</p> \\[ p(x,y)=p(y|x)p(x) \\] <p>\u8fd9\u91cc\u7684 \\(\\dfrac 12\\) \u4e3b\u8981\u662f\u8d77\u4e00\u4e2a\u5f52\u4e00\u5316\u7684\u4f5c\u7528\u3002\u4e0b\u9762\u7684\u5f0f\u5b50\u662f\u53d8\u5206\u63a8\u65ad\u6846\u67b6\u7684\u4e00\u90e8\u5206\uff0c\u6211\u4eec\u5728 VAE \u7684\u7406\u8bba\u63a8\u5bfc\u4e2d\u5c31\u89c1\u8fc7\u4e86\uff0c\u53ea\u4e0d\u8fc7\uff0c\u5728 VAE \u91cc\u9762\uff0c\u5b83\u7684\u610f\u601d\u662f\u7f16\u7801\u5668\uff0c\u8fd9\u91cc\u7f16\u7684\u662f\u4ec0\u4e48\u7801\u5462\uff1f\u662f\u5bf9\u56fe\u50cf\u6765\u6e90\u8fdb\u884c\u5224\u522b\u5f97\u5230\u7684\u6807\u7b7e\u7f16\u7801\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u628a \\(p(1|x)\\) \u770b\u4f5c\u4e00\u4e2a\u5206\u8fa8\u56fe\u50cf\u662f\u5426\u670d\u4ece\u539f\u5206\u5e03\u7684\u5224\u522b\u5668\uff0c\u8bb0\u4f5c \\(D(x)\\)</p> <p>\u7136\u540e\u5f88\u673a\u68b0\u5730\u6211\u4eec\u5e26\u5165 KL \u6563\u5ea6\u7684\u8ba1\u7b97\u5f0f\u91cc\u9762\uff1a</p> \\[ \\begin{align*}   KL(q(x,y)||p(x,y))&amp;=\\sum_y\\int q(x,y) \\log \\dfrac{q(x,y)}{p(x,y)} \\mathrm d x\\\\   &amp;=\\int q(x,1) \\log \\dfrac{q(x,1)}{p(x,1)} \\mathrm d x+\\int q(x,0) \\log \\dfrac{q(x,0)}{p(x,0)} \\mathrm d x\\\\   &amp;=\\int \\dfrac 12 p(x) \\log \\dfrac{\\frac 12 p(x)}{p(1|x)p(x)}\\mathrm dx+\\int \\dfrac 12 q(x) \\log \\dfrac{\\frac 12 q(x)}{p(0|x)p(x)}\\mathrm dx\\\\   &amp;=-\\log 2-\\dfrac 12 \\int p(x) \\log p(1|x)\\mathrm dx+\\dfrac 12 \\int q(x)\\log \\dfrac{q(x)}{p(0|x)p(x)}\\mathrm dx\\\\   &amp;=-\\log 2-\\dfrac 12 \\int p(x) \\log p(1|x)\\mathrm dx+\\dfrac 12 \\int q(x)\\log q(x)\\mathrm dx-\\dfrac 12 \\int q(x)\\log p(0|x)p(x)\\mathrm dx \\end{align*} \\] <p>\u4e22\u6389\u5e38\u6570\u548c\u7cfb\u6570\u3002\u7531\u4e8e\u91cc\u9762\u65e2\u6709\u751f\u6210\u5668 \\(G\\) \u53c8\u6709\u5224\u522b\u5668 \\(D\\)\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u6bcf\u4e00\u6b21\u4f18\u5316\u5206\u4e24\u6b65\u8fdb\u884c\uff0c\u4e5f\u5c31\u662f EM \u7b97\u6cd5\u3002</p> <p>\u9996\u5148\uff0c\u56fa\u5b9a\u751f\u6210\u5668 \\(G\\) \u4e5f\u5c31\u662f\u8bf4\u73b0\u5728\u751f\u6210\u7684\u5206\u5e03 \\(q(x)\\) \u4e0d\u53d8\uff0c\u540c\u65f6\u771f\u5b9e\u5206\u5e03 \\(p(x)\\) \u4e0d\u53ef\u80fd\u53d8\uff1b\u6211\u4eec\u4f18\u5316\u5224\u522b\u5668 \\(D\\)\uff0c\u5199\u6210\u671f\u671b\u5f62\u5f0f:</p> \\[ -\\mathbb E_{x\\sim p(x)}[\\log D(x)]+\\mathrm{Constant.}-\\mathbb E_{x\\sim q(x)}[\\log (1-D(x))]-\\int q(x) \\log p(x) \\mathrm dx \\] <p>\u7b2c\u4e8c\u9879\u548c\u7b2c\u56db\u9879\u90fd\u662f\u5e38\u6570\uff0c\u6211\u4eec\u7531\u6b64\u5f97\u5230\u4e86\u5224\u522b\u5668\u7684\u4f18\u5316\u76ee\u6807\uff0c\u4e5f\u5c31\u662f\u635f\u5931\u51fd\u6570\uff1a</p> \\[ \\begin{align*}   \\mathcal L_D&amp;= - \\mathbb E_{x\\sim p(x)}[\\log D(x)] - \\mathbb E_{x\\sim q(x)}[\\log (1-D(x))]\\\\   &amp;= - \\mathbb E_{x\\sim p(x)}[\\log D(x)] - \\mathbb E_{z\\sim q(z)}[\\log (1-D(G(z)))] \\end{align*} \\] <p>\u4e0b\u9762\u6211\u4eec\u56fa\u5b9a\u5224\u522b\u5668\uff0c\u4e5f\u5c31\u662f \\(p(1|x)\\) \u56fa\u5b9a\uff0c\u4e0a\u5f0f\u5c31\u5269\u4e0b\u4e0b\u9762\u4e24\u9879\u4e0d\u662f\u5e38\u6570\uff1a</p> \\[ \\int q(x)\\log q(x)\\mathrm dx-\\int q(x)\\log p(0|x)p(x)\\mathrm dx \\] <p>\u8fd9\u91cc \\(p(x)\\) \u4e0d\u77e5\u9053\uff0c\u600e\u4e48\u529e\uff1f\u4e8b\u5b9e\u4e0a\u8003\u8651\u4e00\u4e2a\u597d\u7684\u5224\u522b\u5668 \\(D=p(1|x)\\) \u5e94\u8be5\u80fd\u5b8c\u7f8e\u533a\u5206\u6765\u81ea \\(p(x)\\) \u7684\u539f\u59cb\u56fe\u50cf\u548c\u6765\u81ea \\(q(x)\\) \u7684\u4f2a\u9020\u56fe\u50cf\uff0c\u4e5f\u5c31\u662f\u8bf4\uff1a</p> \\[ D(x)=\\dfrac{p(x)}{p(x)+\\hat q(x)} \\] <p>\u5c31\u53ef\u4ee5\u8868\u5f81\u5728 \\(p(x)\\) \u548c \\(q(x)\\) \u7684\u6df7\u5408\u4e0b\u7cbe\u51c6\u8bc6\u522b\u51fa\u771f\u5b9e\u6837\u672c\u3002\u8fd9\u91cc\u4f7f\u7528 \\(\\hat q(x)\\) \u662f\u56e0\u4e3a\u6211\u4eec\u662f\u5206\u6b65\u8fdb\u884c\u7684\uff0c\u8fd9\u4e00\u6b65\u521a\u597d\u8981\u5bf9\u751f\u6210\u5668 \\(G(z)=q(x|z)\\) \u66f4\u65b0\uff0c\u6240\u4ee5\u51fa\u73b0\u7684 \\(q(x)\\) \u5fc5\u987b\u662f\u4e0a\u4e00\u6b65\u7684\u4f2a\u9020\u5206\u5e03\u3002\u89e3\u51fa \\(p(x)\\) \u53ef\u5f97\uff1a</p> \\[ p(x)=\\hat q(x)\\dfrac{D(x)}{1-D(x)} \\] <p>\u4ee3\u5165\u5373\u53ef\uff1a</p> \\[ \\begin{align*}   \\mathcal L_G&amp;=\\int q(x)\\log q(x)\\mathrm dx-\\int q(x)\\log p(0|x)p(x)\\mathrm dx\\\\   &amp;=\\int q(x)\\log q(x)\\mathrm dx-\\int q(x)\\log [(1-D(x))\\hat q(x)\\dfrac{D(x)}{1-D(x)}]\\mathrm dx\\\\   &amp;=\\int q(x)\\log q(x)\\mathrm dx-\\int q(x)\\log \\hat q(x)\\mathrm dx-\\int q(x)\\log D(x)\\mathrm dx\\\\   &amp;=-\\mathbb E_{x\\sim q(x)}[\\log D(x)]+\\int q(x)\\log \\dfrac{q(x)}{\\hat q(x)}\\mathrm dx\\\\   &amp;=-\\mathbb E_{z\\sim q(z)}[\\log D(G(z))]+KL(q(x)||\\hat q(x)) \\end{align*} \\] <p>\u4e8b\u5b9e\u4e0a\uff0c\\(KL(q(x)||\\hat q(x))\\) \u53ef\u4ee5\u8bf4\u662f\u5bf9\u53c2\u6570\u66f4\u65b0\u5e45\u5ea6\u7684\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u5b83\u8981\u6c42\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\\(q\\) \u7684\u53d8\u52a8\u5c3d\u53ef\u80fd\u5c0f\u3002\u8fd9\u5176\u5b9e\u5c31\u5f15\u51fa\u4e86\u5404\u79cd\u64cd\u4f5c\uff0c\u6bd4\u5982\u52a0\u4e0a BatchNorm\uff0c\u6216\u8005\u4f7f\u7528\u68af\u5ea6\u60e9\u7f5a\u7b49\u65b9\u6cd5\u3002\u5f53\u7136\u672c\u6587\u7684\u590d\u73b0\u4e0d\u6d89\u53ca WGAN\uff0c\u6240\u4ee5\u5c31\u4e0d\u6df1\u6316\uff0c\u53ea\u8bb2\u4e00\u4e0b\u540e\u9762\u4f1a\u7528\u5230\u7684\u8c31\u5f52\u4e00\u5316\u3002</p> <p>\u4e3a\u4e86\u4e0d\u8bad\u70b8\uff0c\u63a7\u5236\u53c2\u6570\u66f4\u65b0\u91cf\uff0c\u6211\u4eec\u5e94\u8be5\u5bf9\u7f51\u7edc\u7ed3\u6784\u505a\u51fa\u4e00\u5b9a\u7684\u5149\u6ed1\u6027\u7ea6\u675f\u3002\u8fd9\u6837\u5c31\u5f15\u5165\u4e86 Lipschitz \u8fde\u7eed\u6027\u7684\u6761\u4ef6\uff0c\u4e5f\u5c31\u662f\u5bf9\u4e8e \\(f(x)\\) \u800c\u8a00\u8981\u6c42\u5b58\u5728 \\(K\\) \u4f7f\u5f97</p> \\[ |f(x_1)-f(x_2)|\\leq K|x_1-x_2| \\] <p>\u5bf9\u4e8e\u5355\u4e2a\u7ebf\u6027\u5c42 \\(f(x)=Wx\\) \u800c\u8a00\uff0c\\(K\\) \u5176\u5b9e\u8861\u91cf\u7684\u662f \\(W\\) \u80fd\u628a \\(x\\) \u6620\u5c04\u591a\u201c\u8fdc\u201d\u7684\u80fd\u529b\uff0c\u663e\u7136\u4ece\u51e0\u4f55\u610f\u4e49\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9 \\(W\\) \u505a\u4e00\u4e2a SVD \u4e5f\u5c31\u662f \\(W=U\\Sigma V^\\top\\)\uff0c\u7531\u4e8e \\(U\\) \u548c \\(V\\) \u90fd\u662f\u6b63\u4ea4\u9635\uff0c\\(K\\) \u5176\u5b9e\u5c31\u662f\u5bf9\u5e94\u7f29\u653e\u77e9\u9635 \\(\\Sigma\\) \u91cc\u9762\u6700\u5927\u7684\u90a3\u4e2a\u5947\u5f02\u503c\uff08\u8fd9\u88ab\u79f0\u4f5c\u8be5\u77e9\u9635\u7684\u8c31\u8303\u6570\uff09\u3002\u90a3\u8fd9\u4e0d\u5c31\u597d\u529e\u4e86\uff1a\u5bf9\u4e8e\u6bcf\u4e00\u5c42\uff0c\u6211\u4eec\u90fd\u5f3a\u5236\u9650\u5236\u77e9\u9635\u53c2\u6570\u9664\u4ee5\u8c31\u8303\u6570\uff0c\u5c31\u53ef\u4ee5\u628a\u6bcf\u4e00\u5c42\u7684 Lipschitz \u6761\u4ef6\u63a7\u5236\u5230 \\(K=1\\) \u56e0\u6b64\u6574\u4e2a\u7f51\u7edc\u7684 \\(K\\) \u4e5f\u5c31\u9650\u5236\u5230 \\(1\\) \u4e86\u3002\u8fd9\u4e00\u64cd\u4f5c\u79f0\u4f5c\u8c31\u5f52\u4e00\u5316\u3002</p> <p>\u8fd9\u6837\u6211\u4eec\u5c31\u4ece\u53d8\u5206\u63a8\u65ad\u6846\u67b6\u548c EM \u7b97\u6cd5\u5f97\u5230\u4e86 GAN \u7684\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <ul> <li>\u52a0\u8f7d\u4e00\u6279\u771f\u5b9e\u6837\u672c\uff0c\u8ba1\u7b97 \\(\\mathbb E_{x\\sim p(x)}[\\log D(x)]\\)</li> <li>\u751f\u6210\u4e00\u6279\u968f\u673a\u79cd\u5b50\uff0c\u7136\u540e\u4ea4\u7ed9 \\(G\\) \u8fdb\u884c\u4f2a\u9020\u751f\u6210\u540e\u518d\u5224\u522b\uff0c\u8fdb\u800c\u8ba1\u7b97 \\(\\mathbb E_{z\\sim q(z)}[\\log (1-D(G(z)))]\\) \u548c \\(\\mathbb E_{z\\sim q(z)}[\\log D(G(z))]\\)</li> <li>\u8ba1\u7b97\u5224\u522b\u5668\u7684\u635f\u5931\u5e76\u8fdb\u884c\u4f18\u5316\uff1a\\(\\mathcal L_D= - \\mathbb E_{x\\sim p(x)}[\\log D(x)] - \\mathbb E_{z\\sim q(z)}[\\log (1-D(G(z)))]\\)</li> <li>\u8ba1\u7b97\u751f\u6210\u5668\u7684\u635f\u5931\u5e76\u8fdb\u884c\u4f18\u5316\uff1a\\(\\mathcal L_G=-\\mathbb E_{z\\sim q(z)}[\\log D(G(z))]\\)</li> </ul> <p>\u4e0b\u9762\u5c31\u662f\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\u4e86\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313444', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef gen fill:#313244,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef disc fill:#313244,stroke:#f9e2af,stroke-width:2px,color:#cdd6f4;\n    classDef loss fill:#313244,stroke:#f2cdcd,stroke-width:2px,color:#cdd6f4;\n    classDef op fill:#313244,stroke:#89dceb,stroke-width:2px,color:#cdd6f4;\n    classDef step fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4,radius:16px;\n    classDef addOp fill:#45475a,stroke:#cdd6f4,stroke-width:1px,shape:circle;\n\n    %% --- Data Generation ---\n    subgraph DataGen [Data Generation]\n        direction LR\n        Noise[(\"Latent Noise&lt;br&gt;z\")] --&gt; |latent_dim| G[(\"Generator&lt;br&gt;G\")] --&gt; |3 @ 64x64| FakeImg[(\"Fake Image&lt;br&gt;G(z)\")]\n        RealImg[(\"Real Image&lt;br&gt;x\")]\n    end\n\n    %% --- Discriminator Update Phase ---\n    subgraph Phase1 [Update Discriminator]\n        direction LR\n        D1[(\"Discriminator&lt;br&gt;D\")]\n\n        subgraph LossCalcD [Loss Calculation]\n            Loss_D_Fake[\"Fake loss =&lt;br&gt;-E[log(1-D(G(z)))]\"]\n            Loss_D_Real[\"Real loss =&lt;br&gt;-E[log D(x)]\"]\n            Add_D_Loss[(+)]\n            Loss_D_Real --&gt; Add_D_Loss\n            Loss_D_Fake --&gt; Add_D_Loss\n        end\n        Add_D_Loss --&gt; L_D[\"D loss =&lt;br&gt; Real loss + Fake loss\"]\n    end\n\n    %% --- Generator Update Phase ---\n    subgraph Phase2 [Update Generator]\n        direction LR\n        D2[(\"Discriminator&lt;br&gt;D\")]\n        Loss_G[\"G loss =-E[log D(G(z))]\"]\n    end\n\n    %% --- Connecting the Phases ---\n    %% Connections for Discriminator training\n    Detach[\"Detach&lt;br&gt;Gradient\"]\n    FakeImg --&gt; Detach --&gt; |3 @ 64x64| D1 -- \"Score D(G(z))\" --&gt; Loss_D_Fake\n\n    FakeImg --&gt; |3 @ 64x64| D2 -- \"Score D(G(z))\" --&gt; Loss_G\n    RealImg --&gt; |3 @ 64x64| D1 -- \"Score D(x)\" --&gt; Loss_D_Real\n\n    %% Connection for Generator training\n\n    %% Set flow from left to right\n\n\n    %% Styling\n    class G gen;\n    class D1,D2 disc;\n    class Detach op;\n    class Add_D_Loss addOp;\n    class Noise,RealImg input;\n    class Loss_D_Real, Loss_D_Fake;\n    class Step_D,Step_G,Backward_D,Backward_G step;</code></pre> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u5bf9\u5224\u522b\u5668\u8ba1\u7b97\u635f\u5931\u5e76\u66f4\u65b0\u7684\u65f6\u5019\uff0c\u6709\u4e00\u4e2a detach \u7684\u64cd\u4f5c\uff0c\u8fd9\u5c31\u662f\u9632\u6b62\u68af\u5ea6\u56de\u4f20\u5230\u751f\u6210\u5668\u3002\u751f\u6210\u5668\u6709\u81ea\u5df1\u7684\u635f\u5931\u51fd\u6570\u7528\u6765\u66f4\u65b0\u3002\u5176\u4ed6\u7684\u90e8\u5206\u548c\u521a\u521a\u63a8\u5bfc\u7684\u65e0\u5f02\u3002</p> <p>\u8fd9\u4e2a\u56fe\u8fd8\u6709\u4e00\u4e2a\u503c\u5f97\u4e00\u63d0\u7684\u70b9\uff1a\u751f\u6210\u5668\u7684\u68af\u5ea6\u5b8c\u5168\u7531\u5224\u522b\u5668\u56de\u4f20\u800c\u6765\uff0c\u4e5f\u5c31\u662f\u8bf4\u6709\u53ef\u80fd\u4f1a\u53d1\u751f\u4e4b\u524d\u5728 VAE \u91cc\u9762\u63d0\u5230\u7684\u540e\u9a8c\u5d29\u584c\u95ee\u9898\uff0c\u5373\u5224\u522b\u5668\u8fc7\u4e8e\u5f3a\u5927\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5411\u751f\u6210\u5668\u56de\u4f20\u68af\u5ea6\u3002\u6709\u4e00\u4e2a\u5de7\u5999\u7684\u8bad\u7ec3\u7b56\u7565\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff1aTTUR (Two Time-scale Update Rule)\uff0c\u4e5f\u5c31\u662f\u7ed9\u751f\u6210\u5668\u66f4\u9ad8\u7684\u5b66\u4e60\u7387\uff0c\u8ba9\u5b83\u5728\u5224\u522b\u5668\u5c1a\u672a\u5145\u5206\u5f3a\u5927\u7684\u65f6\u5019\u5148\u53d8\u5f3a\u3002\u53ef\u4ee5\u770b\u5230\u65e0\u8bba\u662f TTUR \u8fd8\u662f\u8c31\u5f52\u4e00\u5316\uff0c\u6291\u6216\u662f\u7406\u8bba\u91cc\u9762\u63a8\u5bfc\u5230\u7684 KL \u6563\u5ea6\u9879\uff0c\u90fd\u662f\u5728\u9632\u6b62\u5224\u522b\u5668\u592a\u5feb\u5730\u53d8\u5f97\u8fc7\u5f3a\u3002</p> <p>\u4e0b\u9762\u662f\u751f\u6210\u5668\u6a21\u5757\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef deconvBlock fill:#1e1e2e,stroke:#a6e3a1,stroke-width:1px,color:#a6e3a1;\n\n    %% Input\n    Input[(\"Latent Vector z&lt;br&gt;latent_dim\")]\n    Reshape[\"Reshape to&lt;br&gt;latent_dim@1x1\"]\n\n    %% Upsample Block 1\n    subgraph UpsampleBlock1 [\"Upsample Block 1\"]\n        direction LR\n        ConvTranspose2d1[\"ConvTranspose2d&lt;br&gt; latent_dim x 512 x 4x4 / 1\"]\n        BN1[\"BatchNorm2d\"]\n        ReLU1[\"ReLU\"]\n        ConvTranspose2d1 --&gt; BN1 --&gt; ReLU1\n    end\n\n    %% Upsample Block 2\n    subgraph UpsampleBlock2 [\"Upsample Block 2\"]\n        direction LR\n        ConvTranspose2d2[\"ConvTranspose2d&lt;br&gt;512x256 x 4x4 / 2\"]\n        BN2[\"BatchNorm2d\"]\n        ReLU2[\"ReLU\"]\n        ConvTranspose2d2 --&gt; BN2 --&gt; ReLU2\n    end\n\n    %% Upsample Block 3\n    subgraph UpsampleBlock3 [\"Upsample Block 3\"]\n        direction LR\n        ConvTranspose2d3[\"ConvTranspose2d&lt;br&gt;256x128 x 4x4 / 2\"]\n        BN3[\"BatchNorm2d\"]\n        ReLU3[\"ReLU\"]\n        ConvTranspose2d3 --&gt; BN3 --&gt; ReLU3\n    end\n\n    %% Upsample Block 4\n    subgraph UpsampleBlock4 [\"Upsample Block 4\"]\n        direction LR\n        ConvTranspose2d4[\"ConvTranspose2d&lt;br&gt;128x64 x 4x4 / 2\"]\n        BN4[\"BatchNorm2d\"]\n        ReLU4[\"ReLU\"]\n        ConvTranspose2d4 --&gt; BN4 --&gt; ReLU4\n    end\n\n    %% Final Conv and Activation\n    ConvTranspose2d5[\"ConvTranspose2dranspose2d&lt;br&gt;64x3 x 4x4 / 2\"]\n    Tanh[\"Tanh\"]\n    Output[(\"Generated Image&lt;br&gt;3@64x64\")]\n\n    %% Connections\n    Input --&gt; Reshape\n    Reshape --&gt; UpsampleBlock1\n    UpsampleBlock1 --&gt; |512 @4x4| UpsampleBlock2\n    UpsampleBlock2 --&gt; |256 @8x8| UpsampleBlock3\n    UpsampleBlock3 --&gt; |128 @16x16| UpsampleBlock4\n    UpsampleBlock4 --&gt; |64 @32x32| ConvTranspose2d5\n    ConvTranspose2d5 --&gt; Tanh --&gt; Output\n\n    %% Styling\n    class Input input;\n    class Output output;\n    class UpsampleBlock1,UpsampleBlock2,UpsampleBlock3,UpsampleBlock4 deconvBlock;</code></pre> <p>\u4e0b\u9762\u662f\u5224\u522b\u5668\u6a21\u5757\u3002</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef convBlock fill:#1e1e2e,stroke:#f9e2af,stroke-width:1px,color:#f9e2af;\n\n    %% Input\n    Input[(\"Input Image&lt;br&gt;3@64x64\")]\n\n    %% Downsample Block 1\n    subgraph DownsampleBlock1 [\"Downsample Block 1\"]\n        direction LR\n        Conv1[\"Conv2d&lt;br&gt;3x64 x 4x4 / 2\"]\n        LReLU1[\"LeakyReLU(0.2)\"]\n        Conv1 --&gt; LReLU1\n    end\n\n    %% Downsample Block 2\n    subgraph DownsampleBlock2 [\"Downsample Block 2\"]\n        direction LR\n        Conv2[\"Conv2d&lt;br&gt;64x128 x 4x4 / 2\"]\n        BN2[\"BatchNorm2d\"]\n        LReLU2[\"LeakyReLU(0.2)\"]\n        Conv2 --&gt; BN2 --&gt; LReLU2\n    end\n\n    %% Downsample Block 3\n    subgraph DownsampleBlock3 [\"Downsample Block 3\"]\n        direction LR\n        Conv3[\"Conv2d&lt;br&gt;128x256 x 4x4 / 2\"]\n        BN3[\"BatchNorm2d\"]\n        LReLU3[\"LeakyReLU(0.2)\"]\n        Conv3 --&gt; BN3 --&gt; LReLU3\n    end\n\n    %% Downsample Block 4\n    subgraph DownsampleBlock4 [\"Downsample Block 4\"]\n        direction LR\n        Conv4[\"Conv2d&lt;br&gt;256x512 x 4x4 / 2\"]\n        BN4[\"BatchNorm2d\"]\n        LReLU4[\"LeakyReLU(0.2)\"]\n        Conv4 --&gt; BN4 --&gt; LReLU4\n    end\n\n    %% Final Conv and Activation\n    Conv5[\"Conv2d&lt;br&gt;512x1 x 4x4 / 4\"]\n    Sigmoid[\"Sigmoid\"]\n    Output[(\"Output Probability&lt;br&gt;Scalar\")]\n\n    %% Connections\n    Input --&gt; DownsampleBlock1\n    DownsampleBlock1 --&gt; |64 @32x32| DownsampleBlock2\n    DownsampleBlock2 --&gt; |128 @16x16| DownsampleBlock3\n    DownsampleBlock3 --&gt; |256 @8x8| DownsampleBlock4\n    DownsampleBlock4 --&gt; |512 @4x4| Conv5\n    Conv5 --&gt; |1 @1x1| Sigmoid --&gt; Output\n\n    %% Styling\n    class Input input;\n    class Output output;\n    class DownsampleBlock1,DownsampleBlock2,DownsampleBlock3,DownsampleBlock4 convBlock;</code></pre> <p>\u53ef\u89c1\uff0c\u8fd9\u91cc\u7684\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u90fd\u662f\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u5e76\u4e14\u90fd\u4f7f\u7528\u4e86 BatchNorm2d \u6765\u7a33\u5b9a\u68af\u5ea6\u3002\u5168\u5377\u79ef\u7684\u4f5c\u7528\u5728\u4e8e\u4e0d\u4f1a\u56e0\u4e3a\u6c60\u5316\u7684\u964d\u91c7\u6837\u800c\u635f\u5931\u7ec6\u8282\u3002</p> <p>\u4e0b\u9762\u653e\u51fa\u4ee3\u7801\uff1a</p>  \u8bad\u7ec3 DC-GAN \u4f7f\u7528\u7684\u4ee3\u7801  <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid, save_image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\n\ntorch.backends.cudnn.benchmark = True\n\nconfig = {\n    \"METHOD_NAME\": \"DC-GAN\",\n    \"LATENT_DIM\": 128,\n    \"BATCH_SIZE\": 256,\n    \"EPOCHS\": 50,\n    \"LR\": 2e-4,\n    \"BETA1\": 0.5,  # Adam\u4f18\u5316\u5668\u7684beta1\u53c2\u6570\n    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"DATA_PATH\": \"./data\",\n    \"OUTPUT_PATH\": \"./output\"\n}\noutput_dir = os.path.join(config[\"OUTPUT_PATH\"], config[\"METHOD_NAME\"])\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Using device: {config['DEVICE']}\")\n\ntrain_loader = dataloader\n\nclass Generator(nn.Module):\n    def __init__(self, latent_dim):\n        super(Generator, self).__init__()\n        self.latent_dim = latent_dim\n\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        input = input.view(-1, self.latent_dim, 1, 1)\n        return self.main(input)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input).view(-1, 1)\n\n# --- 3. \u521d\u59cb\u5316\u6a21\u578b\u548c\u4f18\u5316\u5668 ---\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\n# --- 4. \u8bad\u7ec3\u5faa\u73af ---\ndef train(generator, discriminator, train_loader, g_optimizer, d_optimizer, epoch):\n    generator.train()\n    discriminator.train()\n\n    real_label = 1.0\n    fake_label = 0.0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['EPOCHS']}\")\n\n    d_losses = []\n    g_losses = []\n\n    for i, data in enumerate(pbar):\n        # \u8bad\u7ec3\u5224\u522b\u5668\n        # \u4f7f\u7528\u771f\u5b9e\u56fe\u50cf\n        real_images = data.to(config[\"DEVICE\"])\n        batch_size = real_images.size(0)\n        label = torch.full((batch_size, 1), real_label, dtype=torch.float, device=config[\"DEVICE\"])\n\n        discriminator.zero_grad()\n        output = discriminator(real_images)\n        errD_real = F.binary_cross_entropy(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        # \u4f7f\u7528\u751f\u6210\u56fe\u50cf\n        noise = torch.randn(batch_size, config[\"LATENT_DIM\"], device=config[\"DEVICE\"])\n        fake_images = generator(noise)\n        label.fill_(fake_label)\n        output = discriminator(fake_images.detach())\n        errD_fake = F.binary_cross_entropy(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        d_optimizer.step()\n\n        # \u8bad\u7ec3\u751f\u6210\u5668\n        generator.zero_grad()\n        label.fill_(real_label)  # \u751f\u6210\u5668\u5e0c\u671b\u5224\u522b\u5668\u5c06\u5047\u56fe\u50cf\u5224\u65ad\u4e3a\u771f\n        output = discriminator(fake_images)\n        errG = F.binary_cross_entropy(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        g_optimizer.step()\n\n        # \u8bb0\u5f55\u635f\u5931\n        d_losses.append(errD.item())\n        g_losses.append(errG.item())\n\n        # \u66f4\u65b0\u8fdb\u5ea6\u6761\n        if i % 50 == 0:\n            pbar.set_postfix({\n                'D_loss': errD.item(), \n                'G_loss': errG.item(),\n                'D(x)': D_x,\n                'D(G(z))': f\"{D_G_z1:.4f}/{D_G_z2:.4f}\"\n            })\n\n    return np.mean(d_losses), np.mean(g_losses)\n\n# --- 5. \u751f\u6210\u51fd\u6570 ---\ndef generate_and_save_images(generator, save_path, n_samples=64):\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(n_samples, config[\"LATENT_DIM\"], device=config[\"DEVICE\"])\n        generated_images = generator(noise).cpu()\n        grid = make_grid(generated_images, nrow=8, padding=2, normalize=True)\n        plt.figure(figsize=(8, 8))\n        plt.imshow(grid.permute(1, 2, 0))\n        plt.axis(\"off\")\n        plt.title(\"Generated Images from DC-GAN\")\n        plt.savefig(save_path)\n        plt.close()\n\n        # \u540c\u65f6\u4fdd\u5b58\u56fe\u50cf\u6587\u4ef6\n        save_image(generated_images, os.path.join(output_dir, f\"generated_samples.png\"), nrow=8, normalize=True)\n\n# --- 6. \u8bad\u7ec3\u6307\u6807\u7ed8\u56fe ---\ndef loss_visualization(d_losses, g_losses):\n    plt.figure(figsize=(10, 6))\n    plt.plot(d_losses, label='Discriminator Loss', color='blue')\n    plt.plot(g_losses, label='Generator Loss', color='red')\n    plt.title('DC-GAN Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig(os.path.join(output_dir, \"training_loss.png\"))\n    plt.close()\n\n# --- \u4e3b\u7a0b\u5e8f ---\nif __name__ == \"__main__\":\n    # \u521d\u59cb\u5316\u6a21\u578b\n    generator = Generator(latent_dim=config[\"LATENT_DIM\"]).to(config[\"DEVICE\"])\n    discriminator = Discriminator().to(config[\"DEVICE\"])\n\n    # \u5e94\u7528\u6743\u91cd\u521d\u59cb\u5316\n    generator.apply(weights_init)\n    discriminator.apply(weights_init)\n\n    # \u521d\u59cb\u5316\u4f18\u5316\u5668\n    g_optimizer = optim.Adam(generator.parameters(), lr=config[\"LR\"], betas=(config[\"BETA1\"], 0.999))\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=config[\"LR\"], betas=(config[\"BETA1\"], 0.999))\n\n    # \u7528\u4e8e\u5b58\u50a8\u635f\u5931\n    d_losses = []\n    g_losses = []\n\n    print(\"--- Training DC-GAN Model ---\")\n    for epoch in range(config[\"EPOCHS\"]):\n        d_loss, g_loss = train(generator, discriminator, train_loader, g_optimizer, d_optimizer, epoch)\n        d_losses.append(d_loss)\n        g_losses.append(g_loss)\n\n        # \u6bcf5\u4e2aepoch\u4fdd\u5b58\u4e00\u6b21\u751f\u6210\u56fe\u50cf\n        if (epoch + 1) % 5 == 0:\n            gen_save_path = os.path.join(output_dir, f\"generated_images_epoch_{epoch+1}.png\")\n            generate_and_save_images(generator, gen_save_path)\n            torch.save(generator.state_dict(), os.path.join(output_dir, f\"generator_{epoch+1}.pth\"))\n\n    print(\"\\n--- Generating Images from Trained DC-GAN ---\")\n    gen_save_path = os.path.join(output_dir, \"final_generated_images.png\")\n    generate_and_save_images(generator, gen_save_path)\n\n    # \u4fdd\u5b58\u6a21\u578b\n    torch.save(generator.state_dict(), os.path.join(output_dir, \"generator.pth\"))\n    torch.save(discriminator.state_dict(), os.path.join(output_dir, \"discriminator.pth\"))\n\n    # \u7ed8\u5236\u635f\u5931\u66f2\u7ebf\n    loss_visualization(d_losses, g_losses)\n</code></pre> <p>\u8dd1\u4e86 50 \u4e2a Epoch\uff0c\u635f\u5931\u66f2\u7ebf\u5982\u4e0b\uff1a</p> <p></p> <p>\u751f\u6210\u7684\u56fe\u50cf\u968f\u7740 Epoch \u53d8\u5316\u5982\u4e0b\uff1a</p> Epoch 5 10 20 30 40 50 \u751f\u6210\u56fe\u50cf <p>50 \u4e2a Epoch \u540e\u7684\u56fe\u50cf\uff1a</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u635f\u5931\u4e0b\u964d\u7684\u540c\u65f6\uff0c\u56fe\u50cf\u4e5f\u8d8a\u6765\u8d8a\u6709\u6a21\u6709\u6837\uff0c\u540c\u65f6\u4e5f\u4e0d\u201c\u7cca\u201d\u4e86\u3002</p> <p>\u4e3a\u4e86\u6f14\u793a\u8fd9\u4e2a\u6a21\u578b\uff0c\u6211\u505a\u4e86\u4e00\u4e2a demo\uff0c\u5c31\u90e8\u7f72\u5728\u672c\u535a\u5ba2\u4e0a\u9762\uff1a\u8001\u5a46\u751f\u6210\u5668\u3002\u63a8\u7406\u4f7f\u7528\u7684\u662f TensorFlow.js\uff0c\u5b8c\u5168\u5728\u7f51\u9875\u7aef\u8fdb\u884c\u7684\u63a8\u7406\u3002\u52a0\u8f7d\u6a21\u578b\u9700\u8981\u4e00\u6bb5\u65f6\u95f4\uff0c\u56e0\u4e3a\u8bad\u7ec3\u7528\u56fe\u50cf\u90fd\u662f 64x64 \u7684\uff0c\u56e0\u6b64\u4e0d\u4f1a\u5403\u592a\u591a\u6027\u80fd\u3002</p> <p>\u4e0b\u9762\u8ba9\u6211\u4eec\u770b\u770b\u600e\u4e48\u7528 GAN \u505a\u5206\u7c7b\u5427\u3002</p>"}, {"location": "DNN/model-expr/Image-models-replication/#ac-gan", "title": "AC-GAN \u5206\u7c7b", "text": "<p>AC-GAN \u662f\u6211\u4eec\u9047\u5230\u7684\u7b2c\u4e8c\u4e2a T2I \u6a21\u578b\u3002\u5176\u6838\u5fc3\u601d\u60f3\u548c CVAE \u5dee\u4e0d\u591a\uff1a\u9996\u5148\u5728\u91c7\u6837\u751f\u6210\u7684\u65f6\u5019\uff0c\u540c\u65f6\u62fc\u63a5\u4e00\u4e2a\u6807\u7b7e\u4fe1\u606f\uff0c\u6700\u540e\u5728\u5224\u522b\u7684\u65f6\u5019\uff0c\u5728\u8f93\u51fa\u771f\u4f2a\u6982\u7387\u7684\u540c\u65f6\uff0c\u4e5f\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c\u3002\u8fd9\u6837\uff0c\u901a\u8fc7\u4eba\u4e3a\u63a7\u5236\u6807\u7b7e\uff0c\u5c31\u53ef\u4ee5\u5b9e\u73b0\u6761\u4ef6\u751f\u6210\u3002\u5bf9\u4e8e\u635f\u5931\u51fd\u6570\uff0c\u52a0\u4e0a\u5206\u7c7b\u635f\u5931\u5373\u53ef\u3002</p> <ul> <li>\u5224\u522b\u5668\u7684\u635f\u5931\uff1a</li> </ul> \\[ \\begin{align*} \\mathcal L_D=&amp; - \\mathbb E_{x\\sim p(x)}[\\log D_{\\mathrm{score}}(x)] + CE(D_{\\mathrm{tag}}(x)||\\mathrm{real\\ tag}) \\\\&amp;- \\mathbb E_{z\\sim q(z)}[\\log (1-D_{\\mathrm{score}}(G(z)))] + CE(D_{\\mathrm{tag}}(G(z))||\\mathrm{fake\\ tag}) \\end{align*} \\] <ul> <li>\u751f\u6210\u5668\u7684\u635f\u5931\uff1a</li> </ul> \\[ \\mathcal L_G=-\\mathbb E_{z\\sim q(z)}[\\log D_{\\mathrm{score}}(G(z))]+ CE(D_{\\mathrm{tag}}(G(z))||\\mathrm{fake\\ tag}) \\] <p>\u5176\u4e2d \\(D_{\\mathrm{score}}\\) \u662f\u8f93\u51fa\u771f\u4f2a\u6982\u7387\u7684\u5224\u522b\u5668\uff0c\\(D_{\\mathrm{tag}}\\) \u662f\u8f93\u51fa\u5206\u7c7b\u4fe1\u606f\u7684\u5206\u7c7b\u5224\u522b\u5668\uff0c\\(CE\\) \u662f\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5206\u7c7b\u4efb\u52a1\u7684\u6807\u914d\u3002\u5728\u5b9e\u73b0\u4e0a\uff0c\u53ef\u4ee5\u5171\u7528\u4e00\u4e2a\u7279\u5f81\u63d0\u53d6\u7684\u9aa8\u5e72\u7f51\u7edc\uff0c\u66ff\u6362\u4e0d\u540c\u7ef4\u5ea6\u7684\u6295\u5f71\u5934\u5373\u53ef\u3002</p> <p>\u4e0b\u9762\u770b\u770b\u4ee3\u7801\uff1a</p>  AC-GAN \u7684\u521d\u7248\u8bad\u7ec3\u4ee3\u7801  <pre><code>import random\nimport contextlib\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\n\n# -------------------\n# Configs &amp; utils\n# -------------------\nseed = 3407\nrandom.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# cuDNN \u52a0\u901f\ncudnn.enabled = True\ncudnn.benchmark = True\n\n# \u663e\u5f0f\u7981\u7528 TF32\uff08P100 \u4e0d\u652f\u6301\uff1b\u6b64\u8bbe\u7f6e\u5728 P100 \u4e0a\u4e3a no-op\uff09\ntry:\n    torch.backends.cuda.matmul.allow_tf32 = False\n    torch.backends.cudnn.allow_tf32 = False\nexcept Exception:\n    pass\n\n# Hyper-params\nnum_classes = 10\nimage_size = 32\nz_dim = 128\ng_embed_dim = 128\nbatch_size = 256\nlr = 2e-4\nbeta1, beta2 = 0.5, 0.999\nnum_epochs = 250\nuse_amp = (device.type == 'cuda')  # P100 \u652f\u6301 FP16\uff08\u65e0 TensorCores\uff09\nuse_channels_last = (device.type == 'cuda')\nreal_label_smooth = 0.9\n\n# Data transforms: \u65e0\u8bad\u7ec3\u589e\u5e7f\uff1b\u4ec5\u5f52\u4e00\u5316\u5230 [-1, 1]\nmean = (0.5, 0.5, 0.5)\nstd  = (0.5, 0.5, 0.5)\ntrain_tfms = T.Compose([\n    T.ToTensor(),\n    T.Normalize(mean, std),\n])\ntest_tfms = T.Compose([\n    T.ToTensor(),\n    T.Normalize(mean, std),\n])\n\n# Datasets &amp; Dataloaders\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\ntest_set  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tfms)\n\nloader_kwargs = dict(\n    batch_size=batch_size,\n    num_workers=6,\n    pin_memory=True,\n    persistent_workers=True,  # \u82e5\u5728 notebook \u53cd\u590d\u8fd0\u884c\u62a5\u9519\uff0c\u53ef\u6539\u4e3a False\n    prefetch_factor=4,\n)\ntrain_loader = DataLoader(train_set, shuffle=True, drop_last=True, **loader_kwargs)\ntest_loader  = DataLoader(test_set, shuffle=False, drop_last=False, **loader_kwargs)\n\nclasses = train_set.classes\n\n# AMP autocast context\namp_ctx = torch.autocast(device_type='cuda', dtype=torch.float16) if use_amp else contextlib.nullcontext()\n\ndef denorm(x):\n    # [-1, 1] -&gt; [0, 1]\n    return (x * 0.5 + 0.5).clamp(0, 1)\n\n# -------------------\n# Models\n# -------------------\nclass Generator(nn.Module):\n    def __init__(self, z_dim=128, num_classes=10, embed_dim=100, base_ch=256):\n        super().__init__()\n        self.embed = nn.Embedding(num_classes, embed_dim)\n        self.fc = nn.Linear(z_dim + embed_dim, 4 * 4 * base_ch)\n        self.net = nn.Sequential(\n            nn.BatchNorm2d(base_ch),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch, base_ch // 2, 4, 2, 1, bias=False),  # 8x8\n            nn.BatchNorm2d(base_ch // 2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch // 2, base_ch // 4, 4, 2, 1, bias=False),  # 16x16\n            nn.BatchNorm2d(base_ch // 4),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch // 4, base_ch // 8, 4, 2, 1, bias=False),  # 32x32\n            nn.BatchNorm2d(base_ch // 8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(base_ch // 8, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z, y):\n        e = self.embed(y)\n        h = torch.cat([z, e], dim=1)\n        h = self.fc(h)\n        # \u7528 reshape\uff08\u517c\u5bb9 channels_last / \u975e\u8fde\u7eed\u5185\u5b58\uff09\n        h = h.reshape(h.size(0), -1, 4, 4)\n        return self.net(h)\n\nclass Discriminator(nn.Module):\n    def __init__(self, num_classes=10, base_ch=64):\n        super().__init__()\n        sn = nn.utils.spectral_norm  # \u7a33\u5b9a\u8bad\u7ec3\n        self.features = nn.Sequential(\n            sn(nn.Conv2d(3, base_ch, 4, 2, 1, bias=False)),   # 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch, base_ch * 2, 4, 2, 1, bias=False)),  # 8x8\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch * 2, base_ch * 4, 4, 2, 1, bias=False)),  # 4x4\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch * 4, base_ch * 8, 4, 2, 1, bias=False)),  # 2x2\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n        self.flatten_dim = base_ch * 8 * 2 * 2\n        self.src_head = sn(nn.Linear(self.flatten_dim, 1))            # real/fake\n        self.cls_head = sn(nn.Linear(self.flatten_dim, num_classes))  # class logits\n\n    def forward(self, x):\n        h = self.features(x)\n        # \u7528 flatten\uff08\u517c\u5bb9 channels_last\uff09\n        h = torch.flatten(h, 1)\n        src = self.src_head(h)\n        cls = self.cls_head(h)\n        return src, cls\n\ndef weights_init(m):\n    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n        if getattr(m, 'weight', None) is not None:\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        if getattr(m, 'bias', None) is not None:\n            nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1.0, 0.02)\n        nn.init.zeros_(m.bias)\n\nG = Generator(z_dim, num_classes, g_embed_dim).to(device)\nD = Discriminator(num_classes).to(device)\n\nif use_channels_last:\n    G = G.to(memory_format=torch.channels_last)\n    D = D.to(memory_format=torch.channels_last)\n\nG.apply(weights_init)\nD.apply(weights_init)\n\n# -------------------\n# Optimizers &amp; Losses\n# -------------------\nopt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\nopt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n\nbce = nn.BCEWithLogitsLoss()\nce  = nn.CrossEntropyLoss()\n\nscaler_G = torch.cuda.amp.GradScaler(enabled=use_amp)\nscaler_D = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n# -------------------\n# Eval: classifier accuracy on test set\n# -------------------\n@torch.no_grad()\ndef eval_test_accuracy():\n    D.eval()\n    total, correct = 0, 0\n    for x, y in test_loader:\n        x = x.to(device, non_blocking=True)\n        if use_channels_last:\n            x = x.to(memory_format=torch.channels_last)\n        y = y.to(device, non_blocking=True)\n        with amp_ctx:\n            _, logits = D(x)\n        pred = logits.argmax(dim=1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\n    acc = 100.0 * correct / total\n    return acc\n\n# -------------------\n# Training loop\n# -------------------\ndef train():\n    G.train(); D.train()\n    hist_loss_D, hist_loss_G, hist_acc = [], [], []\n\n    for epoch in range(1, num_epochs + 1):\n        pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{num_epochs}', leave=True)\n        running_D, running_G = 0.0, 0.0\n\n        for i, (x_real, y_real) in enumerate(pbar):\n            x_real = x_real.to(device, non_blocking=True)\n            if use_channels_last:\n                x_real = x_real.to(memory_format=torch.channels_last)\n            y_real = y_real.to(device, non_blocking=True)\n\n            bsz = x_real.size(0)\n            valid = torch.full((bsz, 1), real_label_smooth, device=device)\n            fake  = torch.zeros(bsz, 1, device=device)\n\n            # -----------------\n            # Train Discriminator\n            # -----------------\n            z = torch.randn(bsz, z_dim, device=device)\n            y_fake = torch.randint(0, num_classes, (bsz,), device=device)\n\n            with amp_ctx:\n                x_fake = G(z, y_fake).detach()\n                d_src_real, d_cls_real = D(x_real)\n                d_src_fake, d_cls_fake = D(x_fake)\n                d_loss_real = bce(d_src_real, valid) + ce(d_cls_real, y_real)\n                d_loss_fake = bce(d_src_fake, fake)  + ce(d_cls_fake, y_fake)\n                d_loss = d_loss_real + d_loss_fake\n\n            opt_D.zero_grad(set_to_none=True)\n            scaler_D.scale(d_loss).backward()\n            scaler_D.step(opt_D)\n            scaler_D.update()\n\n            # -----------------\n            # Train Generator\n            # -----------------\n            z = torch.randn(bsz, z_dim, device=device)\n            y_fake = torch.randint(0, num_classes, (bsz,), device=device)\n            with amp_ctx:\n                gen = G(z, y_fake)\n                g_src, g_cls = D(gen)\n                g_loss = bce(g_src, valid) + ce(g_cls, y_fake)\n\n            opt_G.zero_grad(set_to_none=True)\n            scaler_G.scale(g_loss).backward()\n            scaler_G.step(opt_G)\n            scaler_G.update()\n\n            running_D += d_loss.item()\n            running_G += g_loss.item()\n\n            if (i + 1) % 10 == 0:\n                pbar.set_postfix({\n                    'loss_D': f'{running_D / (i + 1):.4f}',\n                    'loss_G': f'{running_G / (i + 1):.4f}'\n                })\n\n        # epoch \u5e73\u5747\u635f\u5931\n        epoch_loss_D = running_D / len(train_loader)\n        epoch_loss_G = running_G / len(train_loader)\n        hist_loss_D.append(epoch_loss_D)\n        hist_loss_G.append(epoch_loss_G)\n\n        # \u8bc4\u4f30\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\uff08\u5224\u522b\u5668\u7684\u8f85\u52a9\u5206\u7c7b\u5934\uff09\n        acc = eval_test_accuracy()\n        hist_acc.append(acc)\n\n        print(f'[Epoch {epoch}] loss_D={epoch_loss_D:.4f} loss_G={epoch_loss_G:.4f} | Test Acc={acc:.2f}%')\n\n        # \u7ee7\u7eed\u8bad\u7ec3\u6a21\u5f0f\n        D.train(); G.train()\n\n    return hist_loss_D, hist_loss_G, hist_acc\n\n# -------------------\n# Plot: \u635f\u5931\u66f2\u7ebf + \u51c6\u786e\u7387\u66f2\u7ebf\n# -------------------\ndef plot_history(loss_D, loss_G, acc):\n    epochs = range(1, len(loss_D) + 1)\n    plt.figure(figsize=(12, 4))\n    # \u635f\u5931\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss_D, label='D loss')\n    plt.plot(epochs, loss_G, label='G loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('AC-GAN Training Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    # \u51c6\u786e\u7387\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, acc, color='tab:green', label='Test Acc (%)')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Aux Classifier Test Accuracy')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\n# -------------------\n# Generate: 10 classes, 5 images each, grid 10x5\n# -------------------\n@torch.no_grad()\ndef generate_grid_horizontal_labeled(n_per=5):\n    G.eval()\n    imgs_by_class = []\n    for c in range(num_classes):\n        z = torch.randn(n_per, z_dim, device=device)\n        y = torch.full((n_per,), c, dtype=torch.long, device=device)\n        # \u5173\u95ed autocast \u6216\u663e\u793a\u524d\u8f6c float32\uff0c\u907f\u514d matplotlib \u4e0d\u652f\u6301 float16\n        with torch.autocast(device_type='cuda', enabled=False) if use_amp else contextlib.nullcontext():\n            x = G(z, y)\n        imgs_by_class.append(x.detach().cpu().float())  # [n_per, 3, 32, 32]\n\n    # \u753b\u6210 5 \u884c \u00d7 10 \u5217\n    fig, axes = plt.subplots(n_per, num_classes, figsize=(num_classes * 1.8, n_per * 1.8))\n    if n_per == 1:\n        axes = np.expand_dims(axes, 0)  # \u517c\u5bb9 n_per=1 \u7684\u7d22\u5f15\n\n    for col in range(num_classes):\n        # \u9876\u90e8\u5217\u6807\u9898\uff08\u7c7b\u522b\u540d\uff09\n        axes[0, col].set_title(classes[col], fontsize=10)\n        for row in range(n_per):\n            img = denorm(imgs_by_class[col][row]).permute(1, 2, 0).numpy()  # HWC float32\n            ax = axes[row, col]\n            ax.imshow(img)\n            ax.axis('off')\n\n    plt.tight_layout(w_pad=0.1, h_pad=0.1)\n    plt.show()\n\n# -------------------\n# Run\n# -------------------\nloss_D_hist, loss_G_hist, acc_hist = train()\nplot_history(loss_D_hist, loss_G_hist, acc_hist)\ngenerate_grid_horizontal_labeled()\n</code></pre> <p></p> <p></p> <p>\u867d\u7136\u51c6\u786e\u7387\u6700\u7ec8\u7a33\u5b9a\u5728\u4e86 66% \u5de6\u53f3\uff0c\u4f46\u662f\u53ef\u89c1\u51fa\u73b0\u4e86\u4e00\u4e2a\u5f88\u5927\u7684\u95ee\u9898\u3002\u867d\u7136 loss \u4e00\u76f4\u5f88\u7a33\u6ca1\u6709\u70b8\uff0c\u4f46\u662f\u540c\u4e00\u7c7b\u522b\u4e0b\uff0c\u4e0d\u540c\u79cd\u5b50\u751f\u6210\u7684\u56fe\u50cf\u5168\u90fd\u4e00\u4e2a\u6837\u3002</p> <p>\u8fd9\u610f\u5473\u7740\u51fa\u73b0\u4e86\u6a21\u5f0f\u5d29\u584c\uff0c\u5176\u5b9e\u95ee\u9898\u8fd8\u662f\u51fa\u5728\u7ed3\u6784\u4e0a\u9762\uff1a\u751f\u6210\u5668\u5f97\u5230\u7684\u68af\u5ea6\u5b8c\u5168\u662f\u4ece\u5224\u522b\u5668\u56de\u4f20\u5f97\u5230\u7684\uff0c\u8fd9\u5c31\u8bf4\u660e\u6211\u7684\u751f\u6210\u5668\u53ef\u4ee5\u5077\u4e2a\u61d2\uff0c\u53ea\u6253\u78e8\u90a3\u4e48\u4e00\u4e2a\u53ef\u4ee5\u9a97\u8fc7\u5224\u522b\u5668\u7684\u8f93\u51fa\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e13\u5fc3\u53bb\u5e94\u5bf9\u5206\u7c7b\u635f\u5931\u9879\u4e86\uff0c\u8fd9\u5176\u5b9e\u6709\u70b9 reward hacking \u7684\u5473\u9053\u4e86\uff0c\u56e0\u6b64\u6211\u4eec\u8fd8\u9700\u8981\u52a0\u5165\u4e00\u4e2a\u6539\u8fdb\uff0c\u5f3a\u8feb\u751f\u6210\u5668\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u6837\u672c\u3002</p> <p>\u5bf9\u6837\u672c\u7684\u591a\u6837\u5316\u7a0b\u5ea6\u8be5\u5982\u4f55\u8861\u91cf\uff1f\u4ece\u7edf\u8ba1\u5b66\u610f\u4e49\u4e0a\u8bb2\uff0c\u4f7f\u7528\u6807\u51c6\u5dee\u5373\u53ef\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u8fd9\u4e2a batch \u91cc\u9762\u7684\u6240\u6709\u6837\u672c\u8ba1\u7b97\u4e00\u4e2a\u6807\u51c6\u5dee\uff0c\u518d\u62fc\u63a5\u5230\u7279\u5f81\u56fe\u540e\u9762\u3002\u8fd9\u6837\uff0c\u5224\u522b\u5668\u5c31\u53ef\u4ee5\u6839\u636e\u8fd9\u4e00\u7ebf\u7d22\u6765\u5bf9\u751f\u6210\u5668\u7684\u5077\u61d2\u884c\u4e3a\u505a\u51fa\u53cd\u5e94\u3002\u8fd9\u4e2a\u53eb\u505a Mini-Batch StdDev \u7b56\u7565\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u8bad\u7ec3\u4e00\u5f00\u59cb\u5bf9\u6837\u672c\u52a0\u5165\u5c11\u91cf\u566a\u58f0\uff0c\u8fd9\u6837\u4e00\u5f00\u59cb\u5c31\u53ef\u4ee5\u5f3a\u8feb\u751f\u6210\u5668\u8f93\u51fa\u66f4\u591a\u6837\u7684\u5185\u5bb9\uff08\u71b5\u66f4\u9ad8\uff09\uff0c\u540e\u9762\u518d\u8870\u51cf\u3002</p> <p>\u7ed3\u5408\u4e0a\u4e4b\u524d\u7a33\u5b9a\u8bad\u7ec3\u7684 TTUR \u548c\u8c31\u5f52\u4e00\u5316\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5199\u51fa\u4e0b\u9762\u7684\u4ee3\u7801\u4e86\uff1a</p>  \u8bad\u7ec3 AC-GAN \u7684\u4ee3\u7801  <pre><code>import random\nimport contextlib\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\n\n# -------------------\n# Configs &amp; utils\n# -------------------\nseed = 3407\nrandom.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# cuDNN \u52a0\u901f\ncudnn.enabled = True\ncudnn.benchmark = True\n\n# \u663e\u5f0f\u7981\u7528 TF32\ntry:\n    torch.backends.cuda.matmul.allow_tf32 = False\n    torch.backends.cudnn.allow_tf32 = False\nexcept Exception:\n    pass\n\n# Hyper-params\nnum_classes = 10\nimage_size = 32\nz_dim = 128\ng_embed_dim = 128\nbatch_size = 256\nbeta1, beta2 = 0.5, 0.999\nnum_epochs = 250\nuse_amp = (device.type == 'cuda') \nuse_channels_last = (device.type == 'cuda')\n\n# \u6291\u5236\u6a21\u5f0f\u5d29\u584c\u7684\u5173\u952e\u8d85\u53c2\nreal_label_smooth = 0.9\nlambda_cls = 0.5                 # \u5206\u7c7b\u635f\u5931\u6743\u91cd\uff08AC-GAN \u7684 CE\uff09\nlr_G, lr_D = 1e-4, 2e-4          # TTUR\ninst_noise_start = 0.1           # instance noise \u521d\u59cb\u6807\u51c6\u5dee\ninst_noise_stop_frac = 0.5       # \u5728\u524d 50% epoch \u7ebf\u6027\u8870\u51cf\u5230 0\n\n# Data transforms: \u65e0\u8bad\u7ec3\u589e\u5e7f\uff1b\u4ec5\u5f52\u4e00\u5316\u5230 [-1, 1]\nmean = (0.5, 0.5, 0.5)\nstd  = (0.5, 0.5, 0.5)\ntrain_tfms = T.Compose([\n    T.ToTensor(),\n    T.Normalize(mean, std),\n])\ntest_tfms = T.Compose([\n    T.ToTensor(),\n    T.Normalize(mean, std),\n])\n\n# Datasets &amp; Dataloaders\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\ntest_set  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tfms)\n\nloader_kwargs = dict(\n    batch_size=batch_size,\n    num_workers=6,\n    pin_memory=True,\n    persistent_workers=True,  # \u82e5\u5728 notebook \u53cd\u590d\u8fd0\u884c\u62a5\u9519\uff0c\u53ef\u6539\u4e3a False\n    prefetch_factor=4,\n)\ntrain_loader = DataLoader(train_set, shuffle=True, drop_last=True, **loader_kwargs)\ntest_loader  = DataLoader(test_set, shuffle=False, drop_last=False, **loader_kwargs)\n\nclasses = train_set.classes\n\n# AMP autocast context\namp_ctx = torch.autocast(device_type='cuda', dtype=torch.float16) if use_amp else contextlib.nullcontext()\n\ndef denorm(x):\n    # [-1, 1] -&gt; [0, 1]\n    return (x * 0.5 + 0.5).clamp(0, 1)\n\n# \u8bad\u7ec3\u7528\uff1a\u5728 D \u8f93\u5165\u4fa7\u52a0\u5165 Instance Noise\ndef add_instance_noise(x, epoch, num_epochs, start_std=0.1, stop_frac=0.5):\n    stop_epoch = int(num_epochs * stop_frac)\n    if epoch &gt; stop_epoch or start_std &lt;= 0:\n        return x\n    # \u7ebf\u6027\u8870\u51cf\n    t = epoch / max(1, stop_epoch)\n    std = start_std * (1.0 - t)\n    noise = torch.randn_like(x) * std\n    return (x + noise).clamp(-1, 1)\n\n# -------------------\n# Models\n# -------------------\nclass Generator(nn.Module):\n    def __init__(self, z_dim=128, num_classes=10, embed_dim=128, base_ch=256):\n        super().__init__()\n        self.embed = nn.Embedding(num_classes, embed_dim)\n        self.fc = nn.Linear(z_dim + embed_dim, 4 * 4 * base_ch)\n        self.net = nn.Sequential(\n            nn.BatchNorm2d(base_ch),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch, base_ch // 2, 4, 2, 1, bias=False),  # 8x8\n            nn.BatchNorm2d(base_ch // 2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch // 2, base_ch // 4, 4, 2, 1, bias=False),  # 16x16\n            nn.BatchNorm2d(base_ch // 4),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(base_ch // 4, base_ch // 8, 4, 2, 1, bias=False),  # 32x32\n            nn.BatchNorm2d(base_ch // 8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(base_ch // 8, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z, y):\n        e = self.embed(y)\n        h = torch.cat([z, e], dim=1)\n        h = self.fc(h)\n        h = h.reshape(h.size(0), -1, 4, 4)  # \u517c\u5bb9 channels_last\n        return self.net(h)\n\nclass MinibatchStdDev(nn.Module):\n    def __init__(self, eps=1e-8):\n        super().__init__()\n        self.eps = eps\n    def forward(self, x):\n        # \u8ba1\u7b97\u6279\u5185\u6807\u51c6\u5dee\u7684\u5747\u503c\uff0c\u4f5c\u4e3a1\u4e2a\u989d\u5916\u901a\u9053\n        # x: [N, C, H, W]\n        std = torch.sqrt(x.var(dim=0, unbiased=False) + self.eps)  # [C, H, W]\n        mean_std = std.mean().view(1, 1, 1, 1).expand(x.size(0), 1, x.size(2), x.size(3))\n        return torch.cat([x, mean_std], dim=1)\n\nclass Discriminator(nn.Module):\n    def __init__(self, num_classes=10, base_ch=64):\n        super().__init__()\n        sn = nn.utils.spectral_norm  # \u7a33\u5b9a\u8bad\u7ec3\n        self.features = nn.Sequential(\n            sn(nn.Conv2d(3, base_ch, 4, 2, 1, bias=False)),                  # 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch, base_ch * 2, 4, 2, 1, bias=False)),        # 8x8\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch * 2, base_ch * 4, 4, 2, 1, bias=False)),    # 4x4\n            nn.LeakyReLU(0.2, inplace=True),\n            sn(nn.Conv2d(base_ch * 4, base_ch * 8, 4, 2, 1, bias=False)),    # 2x2\n            nn.LeakyReLU(0.2, inplace=True),\n            MinibatchStdDev(),                                               # +1 \u901a\u9053\n        )\n        self.flatten_dim = (base_ch * 8 + 1) * 2 * 2\n        self.src_head = sn(nn.Linear(self.flatten_dim, 1))            # real/fake\n        self.cls_head = sn(nn.Linear(self.flatten_dim, num_classes))  # class logits\n\n    def forward(self, x):\n        h = self.features(x)\n        h = torch.flatten(h, 1)  # \u517c\u5bb9 channels_last\n        src = self.src_head(h)\n        cls = self.cls_head(h)\n        return src, cls\n\ndef weights_init(m):\n    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n        if getattr(m, 'weight', None) is not None:\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        if getattr(m, 'bias', None) is not None:\n            nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1.0, 0.02)\n        nn.init.zeros_(m.bias)\n\nG = Generator(z_dim, num_classes, g_embed_dim).to(device)\nD = Discriminator(num_classes).to(device)\n\nif use_channels_last:\n    G = G.to(memory_format=torch.channels_last)\n    D = D.to(memory_format=torch.channels_last)\n\nG.apply(weights_init)\nD.apply(weights_init)\n\n# -------------------\n# Optimizers &amp; Losses\n# -------------------\nopt_G = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(beta1, beta2))  # TTUR\nopt_D = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(beta1, beta2))\n\nbce = nn.BCEWithLogitsLoss()\nce  = nn.CrossEntropyLoss()\n\nscaler_G = torch.cuda.amp.GradScaler(enabled=use_amp)\nscaler_D = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n# -------------------\n# Eval: classifier accuracy on test set\n# -------------------\n@torch.no_grad()\ndef eval_test_accuracy():\n    D.eval()\n    total, correct = 0, 0\n    for x, y in test_loader:\n        x = x.to(device, non_blocking=True)\n        if use_channels_last:\n            x = x.to(memory_format=torch.channels_last)\n        y = y.to(device, non_blocking=True)\n        with amp_ctx:\n            _, logits = D(x)  # \u8bc4\u4f30\u65f6\u4e0d\u52a0\u566a\u58f0\n        pred = logits.argmax(dim=1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\n    acc = 100.0 * correct / total\n    return acc\n\n# -------------------\n# Training loop\n# -------------------\ndef train():\n    G.train(); D.train()\n    hist_loss_D, hist_loss_G, hist_acc = [], [], []\n\n    for epoch in range(1, num_epochs + 1):\n        pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{num_epochs}', leave=True)\n        running_D, running_G = 0.0, 0.0\n\n        for i, (x_real, y_real) in enumerate(pbar):\n            x_real = x_real.to(device, non_blocking=True)\n            if use_channels_last:\n                x_real = x_real.to(memory_format=torch.channels_last)\n            y_real = y_real.to(device, non_blocking=True)\n\n            bsz = x_real.size(0)\n            valid = torch.full((bsz, 1), real_label_smooth, device=device)\n            fake  = torch.zeros(bsz, 1, device=device)\n\n            # -----------------\n            # Train Discriminator\n            # -----------------\n            z = torch.randn(bsz, z_dim, device=device)\n            y_fake = torch.randint(0, num_classes, (bsz,), device=device)\n\n            with amp_ctx:\n                x_fake = G(z, y_fake).detach()\n\n                # Instance noise\uff08\u4ec5\u8bad\u7ec3\u4f7f\u7528\uff09\n                x_real_in = add_instance_noise(x_real, epoch, num_epochs, inst_noise_start, inst_noise_stop_frac)\n                x_fake_in = add_instance_noise(x_fake, epoch, num_epochs, inst_noise_start, inst_noise_stop_frac)\n\n                d_src_real, d_cls_real = D(x_real_in)\n                d_src_fake, d_cls_fake = D(x_fake_in)\n\n                d_loss_real = bce(d_src_real, valid) + lambda_cls * ce(d_cls_real, y_real)\n                d_loss_fake = bce(d_src_fake, fake)  + lambda_cls * ce(d_cls_fake, y_fake)\n                d_loss = d_loss_real + d_loss_fake\n\n            opt_D.zero_grad(set_to_none=True)\n            scaler_D.scale(d_loss).backward()\n            scaler_D.step(opt_D)\n            scaler_D.update()\n\n            # -----------------\n            # Train Generator\n            # -----------------\n            z = torch.randn(bsz, z_dim, device=device)\n            y_fake = torch.randint(0, num_classes, (bsz,), device=device)\n            with amp_ctx:\n                gen = G(z, y_fake)\n                # G \u53cd\u4f20\u8def\u5f84\u4e5f\u52a0\u540c\u6837\u7684 instance noise\n                gen_in = add_instance_noise(gen, epoch, num_epochs, inst_noise_start, inst_noise_stop_frac)\n                g_src, g_cls = D(gen_in)\n                g_loss = bce(g_src, valid) + lambda_cls * ce(g_cls, y_fake)\n\n            opt_G.zero_grad(set_to_none=True)\n            scaler_G.scale(g_loss).backward()\n            scaler_G.step(opt_G)\n            scaler_G.update()\n\n            running_D += d_loss.item()\n            running_G += g_loss.item()\n\n            if (i + 1) % 10 == 0:\n                pbar.set_postfix({\n                    'loss_D': f'{running_D / (i + 1):.4f}',\n                    'loss_G': f'{running_G / (i + 1):.4f}'\n                })\n\n        # epoch \u5e73\u5747\u635f\u5931\n        epoch_loss_D = running_D / len(train_loader)\n        epoch_loss_G = running_G / len(train_loader)\n        hist_loss_D.append(epoch_loss_D)\n        hist_loss_G.append(epoch_loss_G)\n\n        # \u8bc4\u4f30\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\uff08\u5224\u522b\u5668\u7684\u8f85\u52a9\u5206\u7c7b\u5934\uff09\n        acc = eval_test_accuracy()\n        hist_acc.append(acc)\n\n        print(f'[Epoch {epoch}] loss_D={epoch_loss_D:.4f} loss_G={epoch_loss_G:.4f} | Test Acc={acc:.2f}%')\n\n        # \u7ee7\u7eed\u8bad\u7ec3\u6a21\u5f0f\n        D.train(); G.train()\n\n    return hist_loss_D, hist_loss_G, hist_acc\n\n# -------------------\n# Plot: \u635f\u5931\u66f2\u7ebf + \u51c6\u786e\u7387\u66f2\u7ebf\n# -------------------\ndef plot_history(loss_D, loss_G, acc):\n    epochs = range(1, len(loss_D) + 1)\n    plt.figure(figsize=(12, 4))\n    # \u635f\u5931\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss_D, label='D loss')\n    plt.plot(epochs, loss_G, label='G loss')\n    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('AC-GAN Training Loss')\n    plt.legend(); plt.grid(True, alpha=0.3)\n    # \u51c6\u786e\u7387\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, acc, color='tab:green', label='Test Acc (%)')\n    plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.title('Aux Classifier Test Accuracy')\n    plt.legend(); plt.grid(True, alpha=0.3)\n    plt.tight_layout(); plt.show()\n\n# -------------------\n# Generate: \u6a2a\u5411 10 \u7c7b \u00d7 \u6bcf\u7c7b 5 \u5f20\uff0c\u5217\u9876\u663e\u793a\u6807\u7b7e\n# -------------------\n@torch.no_grad()\ndef generate_grid_horizontal_labeled(n_per=5):\n    G.eval()\n    imgs_by_class = []\n    for c in range(num_classes):\n        z = torch.randn(n_per, z_dim, device=device)\n        y = torch.full((n_per,), c, dtype=torch.long, device=device)\n        # \u5173\u95ed autocast \u6216\u663e\u793a\u524d\u8f6c float32\uff0c\u907f\u514d matplotlib \u4e0d\u652f\u6301 float16\n        with torch.autocast(device_type='cuda', enabled=False) if use_amp else contextlib.nullcontext():\n            x = G(z, y)\n        imgs_by_class.append(x.detach().cpu().float())  # [n_per, 3, 32, 32]\n\n    fig, axes = plt.subplots(n_per, num_classes, figsize=(num_classes * 1.8, n_per * 1.8))\n    if n_per == 1:\n        axes = np.expand_dims(axes, 0)\n\n    for col in range(num_classes):\n        axes[0, col].set_title(classes[col], fontsize=10)\n        for row in range(n_per):\n            img = denorm(imgs_by_class[col][row]).permute(1, 2, 0).numpy()\n            ax = axes[row, col]\n            ax.imshow(img)\n            ax.axis('off')\n\n    plt.tight_layout(w_pad=0.1, h_pad=0.1)\n    plt.show()\n\n# -------------------\n# Run\n# -------------------\nloss_D_hist, loss_G_hist, acc_hist = train()\nplot_history(loss_D_hist, loss_G_hist, acc_hist)\ngenerate_grid_horizontal_labeled()\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u6a21\u578b\u8bad\u7ec3\u76f8\u5f53\u7a33\u5b9a\uff0c\u51c6\u786e\u7387\u4e5f\u6bd4\u4e4b\u524d\u9ad8\u4e86\u4e00\u4e9b\uff0c\u8fbe\u5230\u4e86 69% \u7684\u6c34\u51c6\u3002</p> <p></p> <p>\u751f\u6210\u7684\u56fe\u50cf\u91cc\u9762\uff0c\u4e5f\u6709\u5f88\u591a\u662f\u633a\u50cf\u6a21\u50cf\u6837\u7684\u3002</p> <p></p>"}, {"location": "DNN/model-expr/Image-models-replication/#_4", "title": "\u603b\u7ed3", "text": "<p>\u901a\u8fc7\u672c\u6b21\u5bf9\u591a\u4e2a\u7ecf\u5178\u53ca\u63a2\u7d22\u6027\u6a21\u578b\u7684\u590d\u73b0\u4e4b\u65c5\uff0c\u6211\u4eec\u4ece\u6700\u57fa\u7840\u7684 MLP \u4e00\u8def\u8d70\u5230\u590d\u6742\u7684\u751f\u6210\u5f0f\u7f51\u7edc\uff0c\u4e0d\u4ec5\u89c2\u5bdf\u4e86\u5b83\u4eec\u5728 CIFAR-10 \u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u66f4\u6df1\u5165\u4f53\u4f1a\u4e86\u5176\u8bbe\u8ba1\u54f2\u5b66\u80cc\u540e\u7684\u6f14\u53d8\u903b\u8f91\u3002\u8fd9\u4e9b\u5b9e\u9a8c\u544a\u8bc9\u6211\u4eec\uff0c\u6a21\u578b\u7684\u9009\u62e9\u7edd\u975e\u7b80\u5355\u7684\u6027\u80fd\u6392\u884c\u699c\uff0c\u800c\u662f\u4e00\u573a\u5728\u7cbe\u5ea6\u3001\u6548\u7387\u3001\u6570\u636e\u4f9d\u8d56\u6027\u548c\u67b6\u6784\u590d\u6742\u6027\u4e4b\u95f4\u7684\u591a\u7ef4\u6743\u8861\u3002</p> <p>\u6700\u521d\u7684 MLP \u50cf\u662f\u4e00\u628a\u4e07\u80fd\u94a5\u5319\uff0c\u8bd5\u56fe\u7528\u5de8\u91cf\u7684\u53c2\u6570\u5f3a\u884c\u62df\u5408\u6240\u6709\u95ee\u9898\uff0c\u4f46\u5b83\u5ffd\u7565\u4e86\u56fe\u50cf\u6700\u57fa\u672c\u7684\u7a7a\u95f4\u7ed3\u6784\u4fe1\u606f\uff0c\u6548\u7387\u4f4e\u4e0b\uff0c\u6700\u7ec8\u7ed3\u679c\u4e5f\u96be\u5c3d\u5982\u4eba\u610f\u3002CNN \u7684\u5f15\u5165\u662f\u4e00\u4e2a\u9769\u547d\u6027\u7684\u7a81\u7834\uff0c\u5b83\u901a\u8fc7\u5377\u79ef\u3001\u6c60\u5316\u7b49\u64cd\u4f5c\u5de7\u5999\u5730\u6ce8\u5165\u4e86\u201c\u5e73\u79fb\u4e0d\u53d8\u6027\u201d\u548c\u201c\u5c40\u90e8\u6027\u201d\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f7f\u5f97\u7f51\u7edc\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u6355\u6349\u56fe\u50cf\u7279\u5f81\u3002\u6211\u4eec\u7684\u590d\u73b0\u4e5f\u5370\u8bc1\u4e86\u8fd9\u4e00\u70b9\uff0c\u4e00\u4e2a\u53c2\u6570\u91cf\u66f4\u5c11\u7684\u7b80\u5355 CNN \u53d6\u5f97\u4e86\u8fdc\u4f18\u4e8e MLP \u7684\u6548\u679c\u3002\u800c ResNet \u53ca\u5176\u6b8b\u5dee\u8fde\u63a5\u5219\u8fdb\u4e00\u6b65\u89e3\u51b3\u4e86\u6df1\u5c42\u7f51\u7edc\u7684\u68af\u5ea6\u4f20\u9012\u96be\u9898\uff0c\u8ba9\u7f51\u7edc\u80fd\u591f\u5411\u66f4\u6df1\u3001\u66f4\u5f3a\u5927\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u6210\u4e3a\u6b64\u540e\u591a\u5e74\u6765\u7684\u4e2d\u6d41\u7825\u67f1\u3002</p> <p>Transformer \u7684\u51fa\u73b0\u6539\u53d8\u4e86\u6e38\u620f\u89c4\u5219\u3002ViT \u5c06\u56fe\u50cf\u62c6\u5206\u4e3a Patch\uff0c\u5e76\u5229\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u5168\u5c40\u5efa\u6a21\uff0c\u8fd9\u79cd\u201c\u65e0\u5148\u9a8c\u201d\u7684\u8bbe\u8ba1\u4f7f\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u5c55\u73b0\u4e86\u60ca\u4eba\u7684 Scaling Law\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u6e05\u6670\u5c55\u793a\u4e86\u8fd9\u4e00\u70b9\uff1a\u5728\u5c0f\u89c4\u6a21\u4ece\u5934\u8bad\u7ec3\u7684 nanoViT \u8868\u73b0\u5e73\u5e73\uff0c\u4f46\u5176\u5927\u578b\u9884\u8bad\u7ec3\u7248\u672c\uff08ViT-B\uff09\u901a\u8fc7\u5fae\u8c03\u4fbf\u80fd\u8fbe\u5230\u60ca\u4eba\u7684\u6027\u80fd\uff0c\u8fd9\u63ed\u793a\u4e86\u201c\u9884\u8bad\u7ec3+\u5fae\u8c03\u201d\u8303\u5f0f\u5728\u5f53\u4eca AI \u9886\u57df\u7684\u7edd\u5bf9\u7edf\u6cbb\u529b\u3002</p> <p>\u800c\u90a3\u4e9b\u201c\u90aa\u95e8\u201d\u7684\u63a2\u7d22\uff0c\u5982 PatchLSTM\u3001VAE \u548c AC-GAN\uff0c\u5219\u4ece\u53e6\u4e00\u4e2a\u7ef4\u5ea6\u62d3\u5c55\u4e86\u6211\u4eec\u7684\u89c6\u91ce\u3002\u5b83\u4eec\u8bc1\u660e\u4e86\u56fe\u50cf\u7684\u8868\u793a\u548c\u5b66\u4e60\u65b9\u5f0f\u53ef\u4ee5\u591a\u79cd\u591a\u6837\u2014\u2014\u65e0\u8bba\u662f\u7528\u5e8f\u5217\u6a21\u578b\u5904\u7406\uff0c\u8fd8\u662f\u901a\u8fc7\u5b66\u4e60\u6570\u636e\u5206\u5e03\u672c\u8eab\u6765\u83b7\u5f97\u5f3a\u5927\u7684\u7279\u5f81\u8868\u793a\u3002\u7279\u522b\u662f\u5c06 VAE \u4f5c\u4e3a\u6b63\u5219\u5316\u5668\u4e0e\u5206\u7c7b\u5668\u8054\u5408\u8bad\u7ec3\u7684\u601d\u8def\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u573a\u666f\u4e0b\u663e\u793a\u51fa\u72ec\u7279\u7684\u4ef7\u503c\u3002</p> <p>\u4e3a\u4e86\u66f4\u76f4\u89c2\u5730\u5bf9\u6bd4\uff0c\u6211\u4eec\u5c06\u672c\u6b21\u590d\u73b0\u7684\u6838\u5fc3\u7ed3\u679c\u5f52\u7eb3\u5982\u4e0b\u8868\uff1a</p> \u6a21\u578b \u53c2\u6570\u91cf \u6d4b\u8bd5\u51c6\u786e\u7387 \u7279\u70b9\u4e0e\u9002\u7528\u573a\u666f MLP ~1.7M 54.44% \u57fa\u7ebf\u6a21\u578b\uff0c\u5ffd\u7565\u7a7a\u95f4\u7ed3\u6784\uff0c\u6548\u7387\u4f4e\uff0c\u4ec5\u7528\u4e8e\u6559\u5b66\u548c\u7406\u89e3\u3002 CNN ~1.1M 77.33% \u67b6\u6784\u9ad8\u6548\uff0c\u5f15\u5165\u5c40\u90e8\u6027\u4e0e\u5e73\u79fb\u4e0d\u53d8\u6027\u5148\u9a8c\uff0c\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u7684\u826f\u597d\u5e73\u8861\u3002 ResNet-18 (\u4ece\u96f6\u8bad\u7ec3) ~11.2M 83.46% \u6df1\u5c42\u7f51\u7edc\u5178\u8303\uff0c\u6b8b\u5dee\u8fde\u63a5\u89e3\u51b3\u68af\u5ea6\u95ee\u9898\uff0c\u901a\u7528\u6027\u5f3a\u3002 ResNet-18 (\u5fae\u8c03) ~11.2M 89.06% \u9884\u8bad\u7ec3+\u5fae\u8c03\u8303\u5f0f\u7684\u4f53\u73b0\uff0c\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\u83b7\u5f97\u4f18\u5f02\u6027\u80fd\u3002 nanoViT (\u4ece\u96f6\u8bad\u7ec3) ~1.2M 73.24% \u6570\u636e\u4e0d\u8db3\u65f6\u6613\u8fc7\u62df\u5408\uff0c\u4f46\u5c55\u73b0\u4e86\u5168\u5c40\u5efa\u6a21\u7684\u6f5c\u529b\u3002 ViT-B/16 (\u5fae\u8c03) &gt;86M 95.42% \u5927\u6570\u636e\u9884\u8bad\u7ec3\u529b\u91cf\u7684\u8bc1\u660e\uff0c\u5f53\u524d SOTA \u7684\u4ee3\u8868\uff0c\u7cbe\u5ea6\u5929\u82b1\u677f\u9ad8\u3002 PatchLSTM ~2.5M 68.11% \u5c06\u56fe\u50cf\u89c6\u4e3a\u5e8f\u5217\u7684\u63a2\u7d22\u6027\u5c1d\u8bd5\uff0c\u6027\u80fd\u901a\u5e38\u4e0d\u5982CNN\uff0c\u6548\u7387\u8f83\u4f4e\u3002 VAE (\u65e0\u76d1\u7763\u805a\u7c7b) - ~24% \u9a8c\u8bc1\u4e86\u9690\u7a7a\u95f4\u7279\u5f81\u7684\u6709\u6548\u6027\uff0c\u4f46\u65e0\u76d1\u7763\u5206\u7c7b\u4e0e\u8bed\u4e49\u6807\u7b7e\u6709\u5929\u7136\u5dee\u8ddd\u3002 VAE + \u5206\u7c7b\u5934 - ~82% \u751f\u6210\u5f0f\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u9879\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u662f\u63d0\u5347\u6cdb\u5316\u7684\u6709\u6548\u624b\u6bb5\u3002 AC-GAN - ~69% \u517c\u5177\u751f\u6210\u4e0e\u5206\u7c7b\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u534a\u76d1\u7763\u5b66\u4e60\u548c\u9700\u8981\u751f\u6210\u80fd\u529b\u7684\u573a\u666f\u3002 <p>\u7eb5\u89c2\u4e0a\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u66f4\u8d34\u8fd1\u5b9e\u8df5\u7684\u7ed3\u8bba\uff1a</p> <ul> <li>\u82e5\u8ffd\u6c42\u6781\u81f4\u7cbe\u5ea6\u4e14\u8d44\u6e90\u5145\u8db3\uff1a\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982 ViT, ResNet\uff09\u5fae\u8c03\u662f\u6bcb\u5eb8\u7f6e\u7591\u7684\u9996\u9009\uff0c\u8fd9\u662f\u5f53\u524d\u5e94\u7528\u548c\u7814\u7a76\u7684\u4e3b\u6d41\u3002</li> <li>\u82e5\u9700\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\uff1aCNN \u53ca\u5b83\u7684\u73b0\u4ee3\u53d8\u4f53\uff08\u5982 ResNet \u7b49\uff09 \u4ecd\u7136\u662f\u7a33\u5065\u548c\u9ad8\u6548\u7684\u9009\u62e9\uff0c\u5728\u7cbe\u5ea6\u3001\u901f\u5ea6\u548c\u53ef\u9760\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002</li> <li>\u82e5\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff1a\u751f\u6210\u5f0f\u6a21\u578b\uff08\u5982 VAE \u548c GAN\uff09 \u63d0\u4f9b\u4e86\u4e00\u6761\u4e0d\u540c\u7684\u601d\u8def\u3002\u5c06\u5176\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u5668\u6216\u6b63\u5219\u5316\u5668\u4e0e\u5206\u7c7b\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\uff0c\u5f80\u5f80\u80fd\u901a\u8fc7\u5229\u7528\u6570\u636e\u672c\u8eab\u5206\u5e03\u6765\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002</li> <li>\u82e5\u8fdb\u884c\u6a21\u578b\u63a2\u7d22\u4e0e\u7814\u7a76\uff1aTransformer\u3001\u57fa\u4e8e\u5e8f\u5217\u7684\u6a21\u578b\u4e43\u81f3\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u4e3a\u6211\u4eec\u6253\u5f00\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u9700\u8981\u66f4\u591a\u7684\u6570\u636e\u3001\u8c03\u4f18\u6280\u5de7\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e5f\u9762\u4e34\u672a\u77e5\u7684\u6027\u80fd\u4e0a\u9650\u548c\u66f4\u5177\u6311\u6218\u6027\u7684\u8fc7\u7a0b\u3002</li> </ul> <p>\u672c\u6587\u662f\u590d\u73b0\u7b14\u8bb0\u7cfb\u5217\u7684\u7b2c\u4e00\u7bc7\u3002\u56fe\u50cf\u5206\u7c7b\u5f88\u7b80\u5355\u4e5f\u5f88\u7ecf\u5178\uff0c\u4f46\u4e5f\u50ac\u751f\u4e86\u8bf8\u591a\u9ad8\u6548\u7684\u6a21\u578b\u3002\u5e0c\u671b\u672c\u7bc7\u6587\u7ae0\u7684\u590d\u73b0\u7ecf\u5386\u4e0e\u5bf9\u6bd4\u5206\u6790\uff0c\u80fd\u4e3a\u5404\u4f4d\u770b\u5b98\u7684\u9009\u62e9\u63d0\u4f9b\u4e00\u4efd\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002\u4f5c\u8005\u529f\u529b\u5c1a\u964b\uff0c\u4e0d\u8db3\u4e4b\u5904\u8bf7\u5728\u4e0b\u65b9\u8bc4\u8bba\u533a\u6279\u8bc4\u6307\u6b63\uff0c\u5207\u78cb\u4ea4\u6d41\u3002\u611f\u8c22\u60a8\u7684\u9605\u8bfb\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 8, 2025). \u56fe\u50cf\u5206\u7c7b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-expr/Image-models-replication</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{Image-models-replication,\n    title={\u56fe\u50cf\u5206\u7c7b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-expr/Image-models-replication}},\n}\n</code></pre></p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/", "title": "\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u548c\u76ee\u6807\u68c0\u6d4b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 57 \u5206\u949f\u3000|\u3000\u7ea6 6436 \u5b57\u3000|\u3000\u7ea6 59 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 2069 \u884c\u4ee3\u7801</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_2", "title": "\u8bed\u4e49\u5206\u5272", "text": "<p>\u8bed\u4e49\u5206\u5272\u7684\u96be\u70b9\u5728\u4e8e\u8f93\u51fa\u5230\u548c\u539f\u56fe\u5206\u8fa8\u7387\u4e00\u81f4\u7684\u7279\u5f81\u56fe\u3002\u56e0\u6b64\u4e0d\u7ba1\u662f FCN, U-Net \u8fd8\u662f Deeplab \u7b49\u7f51\u7edc\uff0c\u5173\u952e\u70b9\u4e3b\u8981\u5728\u4e8e\u4e0b\u91c7\u6837\u548c\u4e0a\u91c7\u6837\u7684\u4fe1\u606f\u6d41\u52a8\u3002\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u9700\u8981\u5229\u7528\u4e0b\u91c7\u6837\u6765\u83b7\u53d6\u7279\u5f81\u56fe\u8fdb\u884c\u5206\u5272\u5206\u7c7b\uff0c\u8fd9\u8981\u6c42\u4e0b\u91c7\u6837\u8fc7\u7a0b\u80fd\u591f\u9ad8\u6548\u63d0\u53d6\u4fe1\u606f\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u5bf9\u4e0b\u91c7\u6837\u4e4b\u540e\u7684\u7ed3\u679c\u8fdb\u884c\u89e3\u7801\uff0c\u8fd9\u53c8\u8981\u6c42\u4e0b\u91c7\u6837\u4e0d\u80fd\u4e22\u5f03\u592a\u591a\u4fe1\u606f\uff0c\u540c\u65f6\u8fd8\u9700\u8981\u5f15\u5165\u7f16\u7801\u5668\u7684\u4e2d\u95f4\u7ed3\u679c\u6765\u63d0\u4f9b\u989d\u5916\u7684\u4fe1\u606f\u3002\u4e3a\u6b64\u4fbf\u6709\u4e86\u8df3\u8dc3\u8fde\u63a5\u3001\u7a7a\u6d1e\u5377\u79ef\u7b49\u6838\u5fc3\u64cd\u4f5c\u3002</p> <p>\u867d\u7136\u90fd\u662f\u67d0\u79cd\u610f\u4e49\u4e0a\u7684\u201c\u751f\u6210\u6a21\u578b\u201d\uff0c\u8fd9\u4e00\u90e8\u5206\u7684\u6a21\u578b\u5c31\u6ca1\u6709 VAE \u7b49\u6a21\u578b\u90a3\u6837\u5f3a\u7684\u6570\u5b66\uff0c\u800c\u662f\u504f\u91cd\u4e8e\u5de5\u7a0b\u5b9e\u73b0\u3002</p> <p>\u672c\u6587\u5bf9\u8bed\u4e49\u5206\u5272\u4e3b\u8981\u4ecb\u7ecd FCN\u3001U-Net \u7b49\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#fcn", "title": "FCN", "text": ""}, {"location": "DNN/model-expr/S-and-D-models-replication/#_3", "title": "\u67b6\u6784", "text": "<p>\uff08\u5176\u5b9e\u6211\u672c\u6765\u60f3\u76f4\u63a5\u4e0a U-Net \u7684\uff0c\u56e0\u4e3a\u6211\u4e00\u5f00\u59cb\u8bfb FCN \u6587\u7ae0\u7684\u65f6\u5019\u5c31\u5bf9\u8fd9\u4e2a\u67b6\u6784\u6709\u4e24\u4e2a\u7591\u70b9\uff0c\u7ed3\u679c\u53d1\u73b0 U-Net \u90fd\u80fd\u89e3\u51b3\u2026\u2026\uff09</p> <p>\u672c\u6587\u4e3b\u8981\u590d\u73b0\u7684\u662f FCN-8s\u3002\u5b83\u7684\u524d\u534a\u622a\u7f16\u7801\u5668\u90e8\u5206\u662f VGG-16\uff0c\u4e8e\u662f\u6211\u4eec\u53c8\u53ef\u4ee5\u5feb\u4e50\u5730\u4f7f\u7528 ImageNet \u9884\u8bad\u7ec3\u6743\u91cd\u4e86\u3002\u5148\u56de\u987e\u4e00\u4e0b VGG-16 \u7684\u7ed3\u6784\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3 @ 224\u00d7224\")]\n    end\n    class Input input;\n\n    %% Initial Convolution\n    subgraph InitConv[\"Convolution Block 1\"]\n        B[\"Conv2d &lt;br&gt; 3x64 x 3\u00d73\"] \n        C[\"Conv2d &lt;br&gt; 64x64 x 3\u00d73\"] \n        D[\"Maxpool 1&lt;br&gt;stride = 2\"]\n    end\n    A --&gt; B\n    B --&gt; C --&gt; D\n    class InitConv conv;\n\n    %% Layer 1 (2\u00d7 BasicBlock without downsample)\n    subgraph Layer1[\"Convolution Block 2\"]\n        F[\"Conv2d &lt;br&gt; 64x128 x 3\u00d73\"] \n        GG[\"Conv2d &lt;br&gt; 128x128 x 3\u00d73\"] \n        G[\"Maxpool 2&lt;br&gt;stride = 2\"]\n    end\n    D --&gt; |64 @ 112\u00d7112| F\n    F --&gt; GG --&gt; G\n    class Layer1 conv;\n\n    %% Layer 2 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer2[\"Convolution Block 3\"]\n        H[\"Conv2d &lt;br&gt; 128x256 x 3\u00d73\"]\n        I[\"Conv2d &lt;br&gt; 256x256 x 3\u00d73\"]\n        J[\"Maxpool 3&lt;br&gt;stride = 2\"]\n    end\n    G --&gt; |128 @ 56\u00d756| H\n    H --&gt; I --&gt; J\n    class Layer2 conv;\n\n    %% Layer 3 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer3[\"Convolution Block 4\"]\n        K[\"Conv2d &lt;br&gt; 256x512 x 3\u00d73\"]\n        L[\"Conv2d &lt;br&gt; 512x512 x 3\u00d73\"]\n        M[\"Maxpool 4&lt;br&gt;stride = 2\"]\n    end\n    J --&gt; |256 @ 28\u00d728| K\n    K --&gt; L --&gt; M\n    class Layer3 conv;\n\n    %% Layer 4 (2\u00d7 BasicBlock with downsample in first block)\n    subgraph Layer4[\"Convolution Block 5\"]\n        N[\"Conv2d &lt;br&gt; 512x512 x 3\u00d73\"]\n        O[\"Conv2d &lt;br&gt; 512x512 x 3\u00d73\"]\n        P[\"Maxpool 5&lt;br&gt;stride = 2\"]\n    end\n    M --&gt; |512 @ 14\u00d714| N\n    N --&gt; O --&gt; P\n    class Layer4 conv;\n\n    %% Global Pooling and FC\n    subgraph PoolFC[\"GAP &amp; Classfiaction\"]\n        Q[\"Flatten &lt;br&gt; or GAP\"]\n        S[\"Linear Layers\"]\n    end\n    P --&gt; |512 @ 7x7| Q --&gt; S\n    class PoolFC box;\n\n    %% Output Layer\n    subgraph Output[\"output\"]\n        T[(\"1000\")]\n    end\n    S --&gt; T\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style T stroke:#a6e3a1,stroke-width:3px</code></pre> <p>\u8fd9\u91cc\u6211\u4eec\u53d6\u5230 <code>Maxpool 5</code> \u4e4b\u524d\u7684\u5730\u65b9\u5c31\u591f\u4e86\uff0c\u8fd9\u6837 VGG-16 \u7684\u8f93\u51fa\u5c31\u662f\u4e00\u5f20 <code>512@7x7</code> \u7684\u4f4e\u5206\u8fa8\u7387\u7279\u5f81\u56fe\u3002\u7136\u540e FCN \u5728\u8fd9\u91cc\u5c31\u51fa\u73b0\u4e86\u51e0\u4e2a\u53d8\u4f53\uff08\u6216\u8005\u8bf4\u4e00\u4e2a\u6f14\u8fdb\u7684\u8fc7\u7a0b\uff09\uff1a</p> <p>\u9996\u5148\u8003\u8651\u628a\u8fd9\u4e2a\u7279\u5f81\u56fe\u76f4\u63a5\u4e0a\u91c7\u6837\u5230 224x224\uff0c\u6211\u4eec\u80af\u5b9a\u4e0d\u80fd\u76f4\u63a5\u7528\u4ec0\u4e48\u7ebf\u6027\u63d2\u503c\u3001\u7acb\u65b9\u63d2\u503c\u3001Lanczos \u63d2\u503c\u7b49\u7b97\u6cd5\uff0c\u56e0\u4e3a\u5b83\u53ea\u662f\u63d2\u503c\u800c\u4e0d\u5f15\u5165\u65b0\u4fe1\u606f\u3002\u8fd9\u5c31\u8981\u796d\u51fa\u6211\u4eec\u5728 DC-GAN \u4ee5\u53ca SRCNN \u7b49\u751f\u6210\u5f0f\u6a21\u578b\u91cc\u9762\u89c1\u5230\u7684 <code>ConvTranspose2d</code> \u4e86\u3002\u4e4b\u524d\u5728\u5206\u7c7b\u6a21\u578b\u4e0b\u9762\u6ca1\u6709\u7ec6\u8bb2\uff0c\u8fd9\u91cc\u7b80\u8981\u4ecb\u7ecd\u4e00\u4e0b\uff1a<code>ConvTranspose2d</code> \u7684\u539f\u7406\u662f\u5728\u539f\u6709\u50cf\u7d20\u7684\u56db\u5468\u5747\u5300\u63d2 0 \u5f97\u5230\u548c\u76ee\u6807\u5927\u5c0f\u4e00\u81f4\u7684\u5927\u56fe\uff0c\u7136\u540e\u518d\u5728\u8fd9\u4e2a\u5927\u56fe\u4e0a\u9762\u505a\u6b63\u5e38\u5377\u79ef\u3002</p> <p>\u4e8e\u662f\u6211\u4eec\u901a\u8fc7\u6b65\u957f\u4e3a 32 \u7684\u8f6c\u7f6e\u5377\u79ef\u4e00\u6b21\u6027\u5c06 <code>512@7x7</code> \u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5230 <code>n@224x224</code>\uff0c\u5f97\u5230\u6211\u4eec\u7684\u76ee\u6807\u56fe\u50cf\u3002\u8fd9\u4fbf\u662f FCN-32s\u3002\u8fd9\u91cc\u7684 32 \u5c31\u662f\u8f6c\u7f6e\u5377\u79ef\u7684\u6b65\u957f\uff0cs \u5c31\u662f stride \u7684\u610f\u601d\u3002</p> <p>\u5f88\u663e\u7136\uff0c\u8fd9\u4e2a <code>512@7x7</code> \u7684\u7279\u5f81\u56fe\u5269\u4e0b\u7684\u4fe1\u606f\u76f8\u6bd4\u4e8e\u539f\u56fe\u5df2\u7ecf\u5f88\u5c11\u4e86\uff0c\u800c\u6211\u4eec\u7684\u76ee\u6807\u662f\u8981\u5b9e\u73b0\u50cf\u7d20\u7ea7\u7684\u5206\u5272\uff0c\u4e3a\u6b64\uff0cFCN \u63d0\u51fa\u4e86\u8df3\u8dc3\u8fde\u63a5\u7684\u6982\u5ff5\uff1a\u65e2\u7136\u7f16\u7801\u5668\u50cf\u4e00\u4e2a\u201c\u6f0f\u6597\u201d\u4e00\u6837\u53bb\u538b\u69a8\u7279\u5f81\uff0c\u90a3\u4e48\u6211\u53d6\u538b\u69a8\u4e4b\u524d\u5177\u6709\u66f4\u4e30\u5bcc\u4fe1\u606f\u7684\u7279\u5f81\u56fe\uff0c\u548c\u6211\u540e\u9762\u8f6c\u7f6e\u5377\u79ef\u4e0a\u91c7\u6837\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e00\u878d\u5408\uff0c\u4e0d\u5c31\u884c\u4e86\u561b\u3002\u8fd9\u4fbf\u662f FCN \u63d0\u51fa\u7684\u8df3\u8dc3\u8fde\u63a5\u601d\u60f3\u3002\uff08\u5176\u5b9e\u548c ResNet \u7684\u6b8b\u5dee\u8fde\u63a5\u6709\u70b9\u50cf\uff09</p> <p>\u8fd9\u6837\uff0c\u6211\u4eec\u5c31\u4e0d\u4e00\u6b21\u6027\u66b4\u529b\u6062\u590d\uff0c\u800c\u662f\u5148\u5229\u7528\u6b65\u957f\u4e3a 2 \u7684\u8f6c\u7f6e\u5377\u79ef\u5c06 <code>512@7x7</code> \u7684\u7279\u5f81\u56fe\u4e0a\u91c7\u6837\u5230 <code>n@14x14</code>\uff0c\u5176\u4e2d n \u662f\u7c7b\u522b\u6570\uff0c\u4e5f\u5c31\u662f\u548c <code>Maxpool 4</code> \u7684\u8f93\u51fa\u5c3a\u5bf8\u4e00\u81f4\u3002\u8fd9\u6837\uff0c\u524d\u4e00\u4e2a\u9636\u6bb5\u7684\u4fe1\u606f\u7ecf\u8fc7\u4e00\u4e2a 1x1 \u5377\u79ef\u5408\u5e76\u901a\u9053\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u878d\u5408\u4e86\u3002\u800c\u8fd9\u5f15\u53d1\u4e86\u6211\u5bf9\u4e8e FCN \u67b6\u6784\u7684\u7b2c\u4e00\u4e2a\u7591\u70b9\u2014\u2014FCN \u7684\u8bba\u6587\u8bf4\u662f\u5c06\u4e24\u4e2a\u7279\u5f81\u56fe\u76f8\u52a0\u3002\u4f46\u662f\u6211\u8ba4\u4e3a\u5728\u901a\u9053\u7ef4\u76f4\u63a5\u62fc\u63a5\uff0c\u53ef\u80fd\u6548\u679c\u66f4\u597d\uff0c\u56e0\u4e3a\u5bf9\u4e8e\u7279\u5f81\u56fe\u76f8\u52a0\u4e4b\u540e\u8fdb\u884c\u7684\u5377\u79ef\u64cd\u4f5c C1 \u800c\u8a00\uff0c\u6211\u4eec\u603b\u80fd\u8bbe\u8ba1\u4e00\u4e2a\u5377\u79ef\u6838\u4f7f\u5f97\u62fc\u63a5\u7279\u5f81\u56fe\u518d\u8fdb\u884c\u5377\u79ef\u64cd\u4f5c C2 \u7684\u8f93\u51fa\u548c\u76f8\u52a0\u540e\u8fdb\u884c C1 \u7684\u8f93\u51fa\u5b8c\u5168\u4e00\u6837\uff0c\u8fd9\u610f\u5473\u7740\u62fc\u63a5\u518d\u5377\u79ef\u4f5c\u4e3a\u4e00\u4e2a\u5f20\u91cf\u5230\u5f20\u91cf\u7684\u6620\u5c04\u96c6\u5408\uff0c\u5176\u201c\u7ef4\u5ea6\u201d\u662f\u5927\u4e8e\u76f8\u52a0\u518d\u5377\u79ef\u7684\uff0c\u56e0\u800c\u6709\u80fd\u529b\u627f\u8f7d\u66f4\u591a\u7684\u7279\u5f81\u3002\u4e0d\u8fc7\uff0c\u6211\u4eec\u5148\u6309\u7167\u539f\u8bba\u6587\u6765\uff0c\u8fdb\u884c\u76f8\u52a0\u64cd\u4f5c\uff0c\u5f97\u5230 <code>n@14x14</code> \u7684\u7279\u5f81\u56fe\u3002\u6700\u540e\uff0c\u6211\u4eec\u5b9e\u65bd\u4e00\u6b21\u6b65\u957f\u4e3a 16 \u7684\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0a\u91c7\u6837\u5230 <code>n@224x224</code>\uff0c\u7531\u4e8e\u8fd9\u4e00\u6b65\u6b65\u957f\u4e3a 16\uff0c\u6240\u4ee5\u53eb FCN-16s\u3002</p> <p>\u8fd9\u6837\uff0cFCN-8s \u7684\u610f\u601d\u5c31\u5f88\u7b80\u5355\u4e86\u3002\u6211\u4eec\u5bf9 <code>n@14x14</code> \u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e00\u6b21\u6b65\u957f\u4e3a 2 \u7684\u8f6c\u7f6e\u5377\u79ef\uff0c\u518d\u540c <code>Maxpool 3</code> \u7684\u8f93\u51fa\u7279\u5f81\u56fe\u76f8\u52a0\u5f97\u5230 <code>n@28x28</code> \u7684\u7279\u5f81\u56fe\uff0c\u518d\u5b9e\u65bd\u4e00\u6b21\u6b65\u957f\u4e3a 8 \u7684\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0a\u91c7\u6837\u5230 <code>n@224x224</code> \u5373\u53ef\u3002</p> <p>FCN \u7684\u8bba\u6587\u53ea\u505a\u5230 8s\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u63a5\u7740\u5f80\u540e\u9762\u505a\u5462\uff1f\u8fd9\u5c31\u662f\u6211\u7684\u7b2c\u4e8c\u4e2a\u7591\u70b9\u3002\u5982\u679c\u9010\u5c42\u5e94\u7528\u8df3\u8dc3\u8fde\u63a5\uff0c\u4e5f\u5c31\u662f <code>n@28x28</code> \u5230 <code>n@56x56</code> \u5230 <code>n@112x112</code> \u518d\u5230 <code>n@224x224</code>\uff0c\u6bcf\u4e00\u6b65\u90fd\u4ee5\u62fc\u63a5\u7684\u65b9\u5f0f\u5b9e\u73b0\u8df3\u8dc3\u8fde\u63a5\uff0c\u90a3\u4e48\u6211\u4eec\u51e0\u4e4e\u5c31\u53d1\u660e\u4e86 U-Net\u3002</p> <p>\u4e0b\u9762\u662f FCN-8s \u7684\u67b6\u6784\uff1a</p> <pre><code>%%{init: {'theme': 'dark', 'themeVariables': { 'darkMode': true, 'primaryColor': '#1e1e2e', 'edgeLabelBackground':'#313244', 'tertiaryColor': '#181825'}}}%%\ngraph LR\n    %% Styling definitions\n    classDef box fill:#313244,stroke:#cdd6f4,stroke-width:2px,color:#cdd6f4,radius:8px;\n    classDef input fill:#585b70,stroke:#89b4fa,stroke-width:2px,color:#cdd6f4;\n    classDef output fill:#313244,stroke:#f38ba8,stroke-width:2px,color:#cdd6f4;\n    classDef result fill:#45475a,stroke:#a6e3a1,stroke-width:2px,color:#cdd6f4;\n    classDef conv fill:#313244,stroke:#74c7ec,stroke-width:2px,color:#cdd6f4;\n    classDef skip fill:#313244,stroke:#cba6f7,stroke-width:2px,color:#cdd6f4;\n    classDef upsample fill:#313244,stroke:#f5c2e7,stroke-width:2px,color:#cdd6f4;\n\n    %% Input Layer\n    subgraph Input[\"Input\"]\n        A[(\"3 @ 224\u00d7224\")]\n    end\n    class Input input;\n\n    %% VGG-16 Backbone (until pool5)\n    subgraph Backbone[\"VGG-16 Backbone\"]\n        %% Block 1\n        subgraph Block1[\"Block 1\"]\n            B[\"Conv 3x64&lt;br&gt;3\u00d73\"]\n            C[\"Conv 64x64&lt;br&gt;3\u00d73\"]\n            D[\"MaxPool&lt;br&gt;2\u00d72 stride=2\"]\n        end\n\n        %% Block 2\n        subgraph Block2[\"Block 2\"]\n            E[\"Conv 64x128&lt;br&gt;3\u00d73\"]\n            F[\"Conv 128x128&lt;br&gt;3\u00d73\"]\n            G[\"MaxPool&lt;br&gt;2\u00d72 stride=2\"]\n        end\n\n        %% Block 3\n        subgraph Block3[\"Block 3\"]\n            H[\"Conv 128x256&lt;br&gt;3\u00d73\"]\n            I[\"Conv 256x256&lt;br&gt;3\u00d73\"]\n            J[\"Conv 256x256&lt;br&gt;3\u00d73\"]\n            K[\"MaxPool&lt;br&gt;2\u00d72 stride=2&lt;br&gt;(pool3)\"]\n        end\n\n        %% Block 4\n        subgraph Block4[\"Block 4\"]\n            L[\"Conv 256x512&lt;br&gt;3\u00d73\"]\n            M[\"Conv 512x512&lt;br&gt;3\u00d73\"]\n            N[\"Conv 512x512&lt;br&gt;3\u00d73\"]\n            O[\"MaxPool&lt;br&gt;2\u00d72 stride=2&lt;br&gt;(pool4)\"]\n        end\n\n        %% Block 5\n        subgraph Block5[\"Block 5\"]\n            P[\"Conv 512x512&lt;br&gt;3\u00d73\"]\n            Q[\"Conv 512x512&lt;br&gt;3\u00d73\"]\n            R[\"Conv 512x512&lt;br&gt;3\u00d73\"]\n            S[\"MaxPool&lt;br&gt;2\u00d72 stride=2&lt;br&gt;(pool5)\"]\n        end\n    end\n\n    A --&gt; B\n    B --&gt; C --&gt; D\n    D --&gt; E\n    E --&gt; F --&gt; G\n    G --&gt; H\n    H --&gt; I --&gt; J --&gt; K\n    K --&gt; L\n    L --&gt; M --&gt; N --&gt; O\n    O --&gt; P\n    P --&gt; Q --&gt; R --&gt; S\n\n    class Backbone conv;\n    class Block1,Block2,Block3,Block4,Block5 box;\n\n    %% FCN-8s Specific Layers\n    subgraph FCN[\"FCN-8s Head\"]\n        %% 1x1 Convs to reduce channels to num_classes\n        T[\"1\u00d71 Conv&lt;br&gt;512\u2192n\"]\n        U[\"1\u00d71 Conv&lt;br&gt;512\u2192n\"]\n        V[\"1\u00d71 Conv&lt;br&gt;256\u2192n\"]\n\n        %% 2x Upsampling\n        W[\"2x Upsample&lt;br&gt;transposed conv\"]\n        X[\"2x Upsample&lt;br&gt;transposed conv\"]\n\n        %% Skip connections and addition\n        Y[\"Add&lt;br&gt;pool4 + 2x(pool5)\"]\n        Z[\"Add&lt;br&gt;pool3 + 2x(combined)\"]\n\n        %% Final 8x Upsampling\n        AA[\"8x Upsample&lt;br&gt;transposed conv\"]\n    end\n\n    S --&gt; T\n    O --&gt; U\n    K --&gt; V\n    T --&gt; W\n    W --&gt; Y\n    U --&gt; Y\n    Y --&gt; X\n    X --&gt; Z\n    V --&gt; Z\n    Z --&gt; AA\n\n    class FCN skip;\n    class T,U,V conv;\n    class W,X,AA upsample;\n    class Y,Z result;\n\n    %% Output Layer\n    subgraph Output[\"Output\"]\n        AB[(\"n @ 224\u00d7224&lt;br&gt;(Segmentation Mask)\")]\n    end\n    AA --&gt; AB\n    class Output output;\n\n    %% Styling\n    style A stroke-dasharray: 5 5\n    style AB stroke:#a6e3a1,stroke-width:3px\n\n    %% Skip connection annotations\n    linkStyle 15 stroke:#cba6f7,stroke-width:2px,stroke-dasharray: 5 5;\n    linkStyle 16 stroke:#cba6f7,stroke-width:2px,stroke-dasharray: 5 5;</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_4", "title": "\u6307\u6807", "text": "<p>\u5148\u524d\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u91cc\u9762\uff0c\u6211\u4eec\u57fa\u672c\u4e0a\u6ca1\u6709\u53bb\u8861\u91cf\u9664\u4e86\u51c6\u786e\u7387\u548c\u635f\u5931\u4e4b\u5916\u7684\u5176\u4ed6\u6307\u6807\uff0c\u4f46\u662f\u8bed\u4e49\u5206\u5272\u548c\u76ee\u6807\u68c0\u6d4b\u8fd9\u4e00\u5757\uff0c\u6211\u4eec\u5c31\u4e0d\u4ec5\u8981\u5173\u6ce8\u7c7b\u522b\u5bf9\u4e0d\u5bf9\uff0c\u66f4\u8981\u5173\u6ce8\u5206\u5272/\u68c0\u6d4b\u662f\u5426\u5230\u4f4d\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u56de\u987e\u4e00\u4e0b\u6982\u7387\u8bba\u8bfe\u7a0b\u4e2d\u7684\u53c2\u6570\u63a8\u65ad\uff0c\u91cc\u9762\u63d0\u5230\u4e24\u79cd\u9519\u8bef\uff1a\u62d2\u771f\u548c\u53d6\u4f2a\uff08\u6216\u8005\u53eb\u5047\u9633\u5047\u9634\u6216\u8005\u7b2c\u4e00\u7c7b\u9519\u8bef\u7b2c\u4e8c\u7c7b\u9519\u8bef\u4ec0\u4e48\u7684\uff09\uff0c\u5982\u679c\u6211\u4eec\u628a\u8fd9\u4e24\u79cd\u9519\u8bef\u7684\u9891\u6570\u548c\u4e24\u79cd\u6b63\u786e\u7684\u9891\u6570\u653e\u5230\u4e00\u8d77\uff0c\u5c31\u5f97\u5230\u4e86\u6df7\u6dc6\u77e9\u9635\uff1a</p> \u9884\u6d4b\u4e3a\u771f \u9884\u6d4b\u4e3a\u5047 \u603b\u548c \u5b9e\u9645\u4e3a\u771f \u771f\u9633\u6027 TP \u5047\u9634\u6027 FN \u771f\u6837\u672c\u6570 T \u5b9e\u9645\u4e3a\u5047 \u5047\u9633\u6027 FP \u771f\u9634\u6027 TN \u5047\u6837\u672c\u6570 F \u603b\u548c \u9633\u6027\u6570 P \u9634\u6027\u6570 N \u603b\u6570 S <p>\u90a3\u4e48\u6211\u4eec\u5c31\u53ef\u4ee5\u4ee5\u6b64\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u4e86\uff1a</p> \\[ \\begin{align*}     \\mathrm{Acc.}&amp;=\\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{S}}\\\\     \\mathrm{Prec.}&amp;=\\frac{\\mathrm{TP}}{\\mathrm{P}}=1-\\frac{\\mathrm{FP}}{\\mathrm{P}}\\\\     \\mathrm{Recall}&amp;=\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}} \\end{align*} \\] <p>\u7b2c\u4e00\u4e2a\u662f\u51c6\u786e\u7387\u5373\u9884\u6d4b\u6b63\u786e\u5360\u603b\u6570\u7684\u6bd4\u4f8b\u3002\u7b2c\u4e8c\u4e2a\u662f\u7cbe\u51c6\u7387\uff0c\u8d8a\u9ad8\u8bf4\u660e\u5047\u9634\u6027/\u5047\u9633\u6027\u7684\u5360\u6bd4\u8d8a\u4f4e\u3002\u6700\u540e\u4e00\u4e2a\u662f\u53ec\u56de\u7387\uff0c\u53ef\u4ee5\u7406\u89e3\u6210\u5728\u9884\u6d4b\u6b63\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u6709\u591a\u5927\u610f\u613f\u7ed9\u51fa\u9634\u6027/\u9633\u6027\u7ed3\u679c\u3002\u5728\u8bed\u4e49\u5206\u5272\u7684\u8bed\u5883\u4e0b\uff0c\u6211\u4eec\u5728\u5355\u5f20\u56fe\u7247\u7684\u50cf\u7d20\u610f\u4e49\u4e0a\u8ba1\u7b97\u8fd9\u4e9b\u6307\u6807\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u50cf\u7d20\u51c6\u786e\u7387 PA\u3002</p> <p></p> <p>\u5982\u56fe\uff0c\u5047\u8bbe\u9ed1\u5708\u662f ground truth \u800c\u767d\u5708\u662f prediction\uff0c\u90a3\u4e48\u4ee5\u4e0a\u4e09\u4e2a\u7387\u5c31\u80fd\u53ef\u89c6\u5316\u4e86\u3002</p> <p>\u5982\u679c\u505a\u7684\u662f\u50cf Pascal VOC \u8fd9\u6837\u7684\u591a\u7c7b\u522b\u8bed\u4e49\u5206\u5272\uff0c\u6211\u4eec\u7ed9\u6bcf\u4e2a\u7c7b\u522b\u90fd\u8ba1\u7b97 PA\uff0c\u7136\u540e\u6c42\u5e73\u5747\uff0c\u5c31\u5f97\u5230\u4e00\u4e2a\u603b\u7684\u8ba1\u7b97\u51c6\u786e\u7387\u7684\u6307\u6807\uff1a\u5e73\u5747\u7c7b\u522b\u50cf\u7d20\u51c6\u786e\u7387 mPA\u3002</p> <p>\u53e6\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u5176\u5b9e\u5e0c\u671b\u767d\u5708\u548c\u9ed1\u5708\u5c3d\u53ef\u80fd\u91cd\u5408\uff0c\u5176\u5b9e\u5c31\u662f\u76f8\u4ea4\u5f97\u66f4\u591a\uff0c\u4e0d\u5c5e\u4e8e\u76f8\u4ea4\u7684\u90e8\u5206\u66f4\u5c11\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f15\u5165\u4e00\u4e2a\u6307\u6807\u6765\u8861\u91cf\uff1a\u4ea4\u5e76\u6bd4 IoU\uff0c\u4e5f\u5c31\u662f II \u533a\u57df\u7684\u9762\u79ef\u9664\u4ee5 I\u3001II \u548c III \u533a\u57df\u7684\u9762\u79ef\u4e4b\u548c\u3002</p> \\[ \\mathrm{IoU}=\\dfrac{\\mathrm{TP}}{\\mathrm{T}+\\mathrm{P}-\\mathrm{TP}} \\] <p>\u540c\u6837\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u7c7b\u522b\u5e73\u5747\u4ea4\u5e76\u6bd4 mIoU\u3002</p> <p>\u4e0b\u9762\u7684\u4ee3\u7801\u5c31\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6df7\u6dc6\u77e9\u9635\u8ba1\u7b97 PA \u548c mIoU\u3002</p> <pre><code>def compute_metrics(hist):\n    pixel_accuracy = np.diag(hist).sum() / hist.sum() # \u5bf9\u89d2\u7ebf\u5143\u7d20\u90fd\u662f\u9884\u6d4b\u6b63\u786e\u7684\n    iou = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n    # \u5ffd\u7565NaN\u503c\uff08\u4f8b\u5982\u67d0\u4e2a\u7c7b\u522b\u5728\u9a8c\u8bc1\u96c6\u4e2d\u4ece\u672a\u51fa\u73b0\u8fc7\uff09\n    miou = np.nanmean(iou)\n    return pixel_accuracy, miou\n</code></pre> <p>FCN \u7684\u635f\u5931\u51fd\u6570\u5f53\u7b80\u5355\uff1a\u5176\u5b9e\u6211\u4eec\u7b49\u4e8e\u662f\u5bf9\u4e00\u4e2a\u548c\u539f\u56fe\u5c3a\u5bf8\u4e00\u81f4\u7684\u50cf\u7d20\u9635\u5217\u505a\u72ec\u7acb\u7684\u5206\u7c7b\uff0c\u90a3\u4e48\u548c\u5206\u7c7b\u4efb\u52a1\u4e00\u6837\uff0c\u76f4\u63a5\u6cbf\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u5373\u53ef\uff01</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_5", "title": "\u5b9e\u73b0\u7ec6\u8282", "text": "<p>\u8fd9\u91cc\u7684\u7ec6\u8282\u4e3b\u8981\u662f\u6765\u8bb2 FCN-8s \u8fd9\u4e2a\u7c7b\u7684\u5177\u4f53\u5b9e\u73b0\u3002</p> <pre><code>class FCN8s(nn.Module):\n    def __init__(self, num_classes):\n        super(FCN8s, self).__init__()\n        # \u9884\u8bad\u7ec3 VGG16\n        vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n        features = vgg.features\n\n        # \u63d0\u53d6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n        # \u5728 PyTorch \u7684\u5b9e\u73b0\u4e2d\uff0cVGG \u7684\u8fde\u7eed\u5377\u79ef-\u6c60\u5316\u64cd\u4f5c\u662f\u4fdd\u5b58\u5728 vgg.features \u8fd9\u4e2a list \u91cc\u9762\n        # [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'] \u5176\u4e2d M \u5c31\u662f Maxpool\n        # \u7531\u4e8e\u8fd9\u4e2a list \u88ab\u5c01\u5370\u8fdb nn.Sequnential \u91cc\u9762\uff0c\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\uff0c\u8f93\u51fa\u5c31\u662f\u7279\u5f81\u56fe\n        self.pool3_features = features[:17]   # \u5230 pool3\n        self.pool4_features = features[17:24] # \u5230 pool4\n        self.pool5_features = features[24:]   # \u5230 pool5\n\n        # \u5168\u8fde\u63a5\u5c42\u6539\u4e3a\u5377\u79ef\u5c42\uff08FCN\uff09\n        # VGG \u7684\u7b2c\u4e00\u4e2a Linear: 512@7x7 -&gt; 4096@7x7\n        # \u5f53\u7136\u8fd9\u91cc\u4e3a\u4e86\u9002\u5e94\u4efb\u610f\u5bbd\u5ea6\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u4f7f\u7528 GAP\n        # \u4e0d\u8fc7\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u4e0a VGG \u7684\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u6bd4\u8d77\u91cd\u65b0\u8bad\u6548\u679c\u80af\u5b9a\u66f4\u597d\n        self.fc6 = nn.Conv2d(512, 4096, kernel_size=7, padding=3)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.drop6 = nn.Dropout2d()\n\n        # VGG \u7684\u7b2c\u4e8c\u4e2a Linear: 4096@7x7 -&gt; 4096@7x7\n        # \u4ecd\u7136\u662f\u62f7\u8d1d\u6743\u91cd\u7136\u540e reshape \u5230\u5377\u79ef\u6838\n        self.fc7 = nn.Conv2d(4096, 4096, kernel_size=1)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.drop7 = nn.Dropout2d()\n\n        # \u4ecd\u7136\u662f\u9760 1x1 \u5377\u79ef\u8d1f\u8d23\u5f97\u5230\u4e00\u4e2a num_classes@7x7 \u7684\u5206\u7c7b\u5f97\u5206\n        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n\n        # \u901a\u8fc7 1x1 \u5377\u79ef\u5f97\u5230 num_classes@HxW \u7684\u7279\u5f81\u56fe\u7528\u4e8e\u8df3\u8dc3\u8fde\u63a5\n        self.score_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n        self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n\n        # \u4e0a\u91c7\u6837\u5c42\n        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n\n        # \u5c06 VGG classifier \u7684 fc6/fc7 \u9884\u8bad\u7ec3\u6743\u91cd\u62f7\u8d1d\u5230\u5377\u79ef\u5c42\n        with torch.no_grad():\n            # vgg.classifier: [Linear(25088,4096), ReLU, Dropout, Linear(4096,4096), ReLU, Dropout, Linear(4096,1000)]\n            # view(4096, 512, 7, 7) \u64cd\u4f5c\u5c31\u662f\u628a 25088x4096 \u7684\u7ebf\u6027\u5c42 reshape \u5230\u8fd9\u4e2a\u5f62\u72b6\u7684\u5f20\u91cf\n            fc6_w = vgg.classifier[0].weight.view(4096, 512, 7, 7)\n            fc6_b = vgg.classifier[0].bias\n            self.fc6.weight.copy_(fc6_w)\n            self.fc6.bias.copy_(fc6_b)\n\n            # \u8fd9\u91cc\u4e5f\u662f\u540c\u6837\u7684\u64cd\u4f5c\u8f6c\u6362\u6210\u5f20\u91cf\n            fc7_w = vgg.classifier[3].weight.view(4096, 4096, 1, 1)\n            fc7_b = vgg.classifier[3].bias\n            self.fc7.weight.copy_(fc7_w)\n            self.fc7.bias.copy_(fc7_b)\n\n        # \u53cd\u5377\u79ef\u5c42\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u8fdb\u884c\u521d\u59cb\u5316\n        # \u53cd\u5377\u79ef\u7684\u521d\u59cb\u5316\u7684\u7ec6\u8282\u5728\u540e\u9762\u8bf4\u660e\n        with torch.no_grad():\n            self.upscore2.weight.copy_(bilinear_kernel(num_classes, num_classes, 4))\n            self.upscore_pool4.weight.copy_(bilinear_kernel(num_classes, num_classes, 4))\n\n    def forward(self, x):\n        input_size = x.shape[2:] # (B, C, H, W) -&gt; (H, W)\n\n        # \u76f4\u63a5\u5f97\u5230 pool3, pool4, pool5 \u540e\u7684\u7279\u5f81\u56fe\n        pool3 = self.pool3_features(x)\n        pool4 = self.pool4_features(pool3)\n        pool5 = self.pool5_features(pool4)\n\n        # 1x1 \u5377\u79ef\u5f97\u5230\u6211\u4eec\u9700\u8981\u7684 num_classes@7x7 \u7684\u7279\u5f81\u56fe\n        h = self.relu6(self.fc6(pool5))\n        h = self.drop6(h)\n        h = self.relu7(self.fc7(h))\n        h = self.drop7(h)\n        h = self.score_fr(h)\n\n        # \u7b2c\u4e00\u6b21\u4e0a\u91c7\u6837\u901a\u8fc7\u8f6c\u7f6e\u5377\u79ef\u8f93\u51fa\u5bbd\u9ad8\u6269\u5f20\u4e00\u500d\u7684\u7279\u5f81\u56fe\n        upscore2 = self.upscore2(h)\n\n        # \u8df3\u8fde pool4\n        score_pool4 = self.score_pool4(pool4)\n        # \u8fd9\u91cc\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u9002\u5e94\u7279\u5f81\u56fe\u5927\u5c0f\n        upscore2 = F.interpolate(upscore2, size=score_pool4.size()[2:], mode='bilinear', align_corners=False)\n        fuse_pool4 = upscore2 + score_pool4\n\n        # \u7b2c\u4e8c\u6b21\u4e0a\u91c7\u6837\u901a\u8fc7\u8f6c\u7f6e\u5377\u79ef\u8f93\u51fa\u5bbd\u9ad8\u6269\u5f20\u4e00\u500d\u7684\u7279\u5f81\u56fe\n        upscore_pool4 = self.upscore_pool4(fuse_pool4)\n\n        # \u8df3\u8fde pool3\n        score_pool3 = self.score_pool3(pool3)\n        # \u540c\u6837\u4f7f\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u9002\u5e94\u5927\u5c0f\n        upscore_pool4 = F.interpolate(upscore_pool4, size=score_pool3.size()[2:], mode='bilinear', align_corners=False)\n        fuse_pool3 = upscore_pool4 + score_pool3\n\n        # \u6700\u7ec8\u4e0a\u91c7\u6837\u5230\u8f93\u5165\u5c3a\u5bf8\uff0c\u76f4\u63a5\u63d2\u503c\uff0c\u7701\u65f6\u9ad8\u6548\n        out = F.interpolate(fuse_pool3, size=input_size, mode='bilinear', align_corners=False)\n        return out\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u9664\u5f00\u4e4b\u524d\u63d0\u5230\u7684\u6574\u4f53\u67b6\u6784\u4ee5\u5916\uff0c\u4ee3\u7801\u8fd8\u6709\u4e00\u4e9b\u5c0f\u7ec6\u8282\u3002</p> <p>\u9996\u5148\u662f\u53cd\u5377\u79ef\u7684\u53cc\u7ebf\u6027\u63d2\u503c\u521d\u59cb\u5316\u3002\u8fd9\u4e00\u90e8\u5206\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>def bilinear_kernel(in_channels, out_channels, kernel_size):\n    \"\"\"\u751f\u6210\u53cc\u7ebf\u6027\u63d2\u503c\u7684\u53cd\u5377\u79ef\u521d\u59cb\u5316\u6743\u91cd\"\"\"\n    factor = (kernel_size + 1) // 2\n    if kernel_size % 2 == 1:\n        center = factor - 1\n    else:\n        center = factor - 0.5\n    og = np.ogrid[:kernel_size, :kernel_size] # \u751f\u6210\u4e24\u4e2a\u4e8c\u7ef4\u6570\u7ec4\uff0c\u5206\u522b\u8868\u793a\u884c\u548c\u5217\u7684\u7d22\u5f15\u7f51\u683c\u3002\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float32)\n    for i in range(min(in_channels, out_channels)):\n        weight[i, i, :, :] = filt\n    return torch.from_numpy(weight)\n</code></pre> <p>\u8fd9\u91cc\u5173\u952e\u662f <code>filt</code> \u7684\u8ba1\u7b97\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u5377\u79ef\u6838\u5185\u90e8\u8ba1\u7b97\u5bf9\u5e94\u7684\u884c\u5230\u8fb9\u754c\u7684\u5f52\u4e00\u5316\u66fc\u54c8\u987f\u8ddd\u79bb\u4e58\u4ee5\u5bf9\u5e94\u7684\u5217\u5230\u8fb9\u754c\u7684\u5f52\u4e00\u5316\u66fc\u54c8\u987f\u8ddd\u79bb\u3002\u5bf9\u4e8e\u4ece\u5c0f\u56fe\u5230\u5927\u56fe\u7684\u8f6c\u7f6e\u5377\u79ef\u800c\u8a00\uff0c\u5927\u56fe\u91cc\u9762\u4e24\u4e2a\u6e90\u4e8e\u5c0f\u56fe\u7684\u50cf\u7d20\u4e4b\u95f4\u7684\u50cf\u7d20\uff0c\u5c31\u53ef\u4ee5\u6839\u636e\u5230\u8fd9\u4e24\u4e2a\u50cf\u7d20\u7684\u66fc\u54c8\u987f\u8ddd\u79bb\u4f5c\u4e3a\u6bd4\u4f8b\u6765\u6df7\u5408\u5f97\u5230\u3002\u4e5f\u5c31\u662f\u8bf4\u5373\u4f7f\u6211\u4eec\u8fd8\u6ca1\u6709\u4ece\u7f51\u7edc\u91cc\u9762\u5b66\u5230\u4efb\u4f55\u77e5\u8bc6\uff0c\u8fd9\u4e2a\u5377\u79ef\u6838\u81f3\u5c11\u8fd8\u53ef\u4ee5\u4e0d\u7834\u574f\u539f\u6709\u4fe1\u606f\u800c\u76f4\u63a5\u63d2\u503c\u653e\u5927\u3002\u540c\u65f6\u672c\u6765 FCN \u7684\u5377\u79ef\u6838\u5c31\u9700\u8981\u5bf9\u7279\u5f81\u56fe\u8fdb\u884c\u653e\u5927\uff0c\u8fd9\u65e0\u7591\u662f\u76f8\u6bd4\u968f\u673a\u521d\u59cb\u5316\u66f4\u9ad8\u6548\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u3002</p> <p>\u4e0b\u9762\u662f\u5b8c\u6574\u7684\u8bad\u7ec3\u4ee3\u7801\uff0c\u5173\u4e8e\u6570\u636e\u52a0\u8f7d\u548c\u589e\u5f3a\u7684\u5927\u91cf\u5de5\u7a0b\u6027\u4ee3\u7801\u5c31\u4e0d\u7ec6\u8bb2\u4e86\u3002\u4e0d\u8fc7\uff0c\u4ee3\u7801\u91cc\u7684\u6570\u636e\u589e\u5f3a\u8fd8\u662f\u6bd4\u8f83\u6709\u6548\u3002</p>  FCN-8s \u5b8c\u6574\u8bad\u7ec3\u4ee3\u7801  <pre><code>import os\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision.transforms as T\nfrom torchvision.models import vgg16, VGG16_Weights\nimport itertools as it\n\n# -------------------- \u914d\u7f6e --------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nUSE_AMP = True  # \u56fa\u5b9a\u7528 CUDA AMP\n\n# Kaggle \u8def\u5f84\nVOC2007_ROOT = \"/kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007\"\nVOC2007_ROOT_ALT = \"/kaggle/input/pascal-voc-2007/VOCdevkit/VOC2007\"\nif not os.path.isdir(VOC2007_ROOT) and os.path.isdir(VOC2007_ROOT_ALT):\n    VOC2007_ROOT = VOC2007_ROOT_ALT\n\nVOC2012_ROOT = \"/kaggle/input/pascal-voc-2012/VOC2012\"\n\nNUM_CLASSES = 21\nBATCH_SIZE = 16\nVAL_BATCH_SIZE = 1\nNUM_WORKERS = 6\n\nLEARNING_RATE = 7.5e-5\nWEIGHT_DECAY = 1e-4\nEPOCHS = 50\n\n# \u8bc4\u4f30\u52a0\u901f\u5f00\u5173\nEVAL_COMPUTE_LOSS = False     # True \u4f1a\u8ba1\u7b97 val loss\uff0c\u7a0d\u6162\nEVAL_MAX_BATCHES = None       # \u9650\u5236\u8bc4\u4f30\u6279\u6b21\u6570\uff1bNone \u8868\u793a\u5168\u91cf\nEVAL_MAX_IMAGES = None        # \u9650\u5236\u8bc4\u4f30\u56fe\u7247\u6570\uff1bNone \u8868\u793a\u5168\u91cf\nEVAL_PROGRESS = True          # \u4fdd\u7559 tqdm \u8fdb\u5ea6\u6761\n\nSAVE_DIR = \"/kaggle/working\"\nBEST_PATH_VOC = os.path.join(SAVE_DIR, \"fcn8s_best_voc2012val.pth\")\nLATEST_PATH = os.path.join(SAVE_DIR, \"fcn8s_latest.pth\")\nVIS_DIR = os.path.join(SAVE_DIR, \"vis_voc_val\")\n\nprint(f\"Using device: {DEVICE}\")\nif DEVICE == \"cuda\":\n    torch.backends.cudnn.benchmark = True\n\n# PASCAL VOC \u989c\u8272\u6620\u5c04 (RGB) \u7528\u4e8e\u53ef\u89c6\u5316\nVOC_COLORMAP = [\n    [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n    [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n    [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128],\n    [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n    [0, 64, 128]\n]\n\n# -------------------- \u6570\u636e\u96c6\uff08VOC\uff09 --------------------\nclass VOCSegmentationDataset(Dataset):\n    \"\"\"\n    \u7528\u4e8e VOC2007/VOC2012 \u7684\u8bed\u4e49\u5206\u5272\u6570\u636e\u3002\n    \u82e5\u7f3a\u5c11 ImageSets/Segmentation/{split}.txt\uff0c\u5c06\u56de\u9000\u5230\u626b\u63cf SegmentationClass \u76ee\u5f55\u3002\n    \"\"\"\n    def __init__(self, root, image_set=\"train\", transforms=None, strict=True):\n        self.root = root\n        self.transforms = transforms\n        self.image_set = image_set\n\n        image_dir = os.path.join(root, \"JPEGImages\")\n        mask_dir = os.path.join(root, \"SegmentationClass\")\n        split_file = os.path.join(root, \"ImageSets\", \"Segmentation\", f\"{image_set}.txt\")\n\n        assert os.path.isdir(image_dir), f\"Image dir not found: {image_dir}\"\n        if not os.path.isdir(mask_dir):\n            if strict:\n                raise FileNotFoundError(f\"SegmentationClass not found: {mask_dir}\")\n            else:\n                print(f\"[Warning] SegmentationClass not found in {root}, dataset will be empty.\")\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n\n        ids = []\n        if os.path.isfile(split_file):\n            with open(split_file, \"r\") as f:\n                ids = [line.strip() for line in f if line.strip()]\n        else:\n            if os.path.isdir(mask_dir):\n                ids = [os.path.splitext(fn)[0] for fn in os.listdir(mask_dir) if fn.endswith(\".png\")]\n            else:\n                ids = []\n\n        self.image_paths, self.mask_paths = [], []\n        for id_ in ids:\n            ip = os.path.join(image_dir, f\"{id_}.jpg\")\n            mp = os.path.join(mask_dir, f\"{id_}.png\")\n            if os.path.isfile(ip) and os.path.isfile(mp):\n                self.image_paths.append(ip)\n                self.mask_paths.append(mp)\n        if len(self.image_paths) == 0:\n            print(f\"[Warning] Empty dataset for root={root}, split={image_set}. Check masks/splits.\")\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        mask = Image.open(self.mask_paths[idx])  # palette \u7d22\u5f15\n\n        if self.transforms is not None:\n            image, target = self.transforms(image, mask)\n        else:\n            img = T.functional.to_tensor(image)\n            img = T.functional.normalize(img, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n            target = torch.from_numpy(np.array(mask, dtype=np.uint8)).long()\n            image, target = img, target\n        return image, target\n\n# -------------------- \u6570\u636e\u589e\u5f3a\u4e0e\u9884\u5904\u7406 --------------------\nclass SegmentationTransforms:\n    def __init__(self, is_train=True, base_size=520, crop_size=480,\n                 color_jitter=True, add_noise_prob=0.15, noise_std=0.03):\n        self.is_train = is_train\n        self.base_size = base_size\n        self.crop_size = crop_size\n        self.mean = (0.485, 0.456, 0.406)\n        self.std = (0.229, 0.224, 0.225)\n        self.color_jitter = T.ColorJitter(0.4, 0.4, 0.4, 0.1) if color_jitter and is_train else None\n        self.add_noise_prob = add_noise_prob if is_train else 0.0\n        self.noise_std = noise_std\n\n    def __call__(self, img, mask):\n        if self.is_train:\n            # 1) \u968f\u673a\u7f29\u653e\u77ed\u8fb9\u5230 [0.5, 2.0] * base_size\n            scale = np.random.uniform(0.5, 2.0)\n            short = int(self.base_size * scale)\n            w, h = img.size\n            if w &lt; h:\n                ow, oh = short, int(short * h / w)\n            else:\n                oh, ow = short, int(short * w / h)\n            img = img.resize((ow, oh), Image.BILINEAR)\n            mask = mask.resize((ow, oh), Image.NEAREST)\n\n            # 2) \u82e5\u5c0f\u4e8e crop_size\uff0c\u53f3\u4e0b\u89d2 padding\uff08mask \u7528 255\uff09\n            pad_w = max(0, self.crop_size - img.size[0])\n            pad_h = max(0, self.crop_size - img.size[1])\n            if pad_w &gt; 0 or pad_h &gt; 0:\n                img = T.functional.pad(img, (0, 0, pad_w, pad_h), fill=0)\n                mask = T.functional.pad(mask, (0, 0, pad_w, pad_h), fill=255)\n\n            # 3) \u968f\u673a\u88c1\u526a\n            w, h = img.size\n            x1 = np.random.randint(0, w - self.crop_size + 1)\n            y1 = np.random.randint(0, h - self.crop_size + 1)\n            img = img.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n            mask = mask.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n\n            # 4) \u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n            if np.random.rand() &gt; 0.5:\n                img = T.functional.hflip(img)\n                mask = T.functional.hflip(mask)\n\n            # 5) \u989c\u8272\u6296\u52a8\n            if self.color_jitter is not None:\n                img = self.color_jitter(img)\n\n        # \u8f6c Tensor\n        img = T.functional.to_tensor(img)\n\n        # \u53ef\u9009\u566a\u58f0\uff08\u5f52\u4e00\u5316\u524d\uff09\n        if self.is_train and np.random.rand() &lt; self.add_noise_prob:\n            noise = torch.randn_like(img) * self.noise_std\n            img = torch.clamp(img + noise, 0.0, 1.0)\n\n        # \u6807\u51c6\u5316\n        img = T.functional.normalize(img, self.mean, self.std)\n\n        # \u76f4\u63a5\u628a palette/L \u7d22\u5f15\u56fe\u8f6c\u6210\u7c7b\u522b id\uff080..20\uff0c255 \u5ffd\u7565\uff09\n        target = torch.from_numpy(np.array(mask, dtype=np.uint8)).long()\n        return img, target\n\n# -------------------- \u6a21\u578b\uff08FCN-8s\uff09 --------------------\ndef bilinear_kernel(in_channels, out_channels, kernel_size):\n    factor = (kernel_size + 1) // 2\n    center = factor - 1 if kernel_size % 2 == 1 else factor - 0.5\n    og = np.ogrid[:kernel_size, :kernel_size]\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float32)\n    for i in range(min(in_channels, out_channels)):\n        weight[i, i, :, :] = filt\n    return torch.from_numpy(weight)\n\nclass FCN8s(nn.Module):\n    def __init__(self, num_classes):\n        super(FCN8s, self).__init__()\n        vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n        features = vgg.features\n\n        self.pool3_features = features[:17]\n        self.pool4_features = features[17:24]\n        self.pool5_features = features[24:]\n\n        self.fc6 = nn.Conv2d(512, 4096, kernel_size=7, padding=3)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.drop6 = nn.Dropout2d()\n\n        self.fc7 = nn.Conv2d(4096, 4096, kernel_size=1)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.drop7 = nn.Dropout2d()\n\n        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n        self.score_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n        self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n\n        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1, bias=False)\n\n        with torch.no_grad():\n            fc6_w = vgg.classifier[0].weight.view(4096, 512, 7, 7)\n            fc6_b = vgg.classifier[0].bias\n            self.fc6.weight.copy_(fc6_w)\n            self.fc6.bias.copy_(fc6_b)\n\n            fc7_w = vgg.classifier[3].weight.view(4096, 4096, 1, 1)\n            fc7_b = vgg.classifier[3].bias\n            self.fc7.weight.copy_(fc7_w)\n            self.fc7.bias.copy_(fc7_b)\n\n            self.upscore2.weight.copy_(bilinear_kernel(NUM_CLASSES, NUM_CLASSES, 4))\n            self.upscore_pool4.weight.copy_(bilinear_kernel(NUM_CLASSES, NUM_CLASSES, 4))\n\n    def forward(self, x):\n        input_size = x.shape[2:]\n        pool3 = self.pool3_features(x)\n        pool4 = self.pool4_features(pool3)\n        pool5 = self.pool5_features(pool4)\n\n        h = self.relu6(self.fc6(pool5))\n        h = self.drop6(h)\n        h = self.relu7(self.fc7(h))\n        h = self.drop7(h)\n\n        h = self.score_fr(h)\n        upscore2 = self.upscore2(h)\n\n        score_pool4 = self.score_pool4(pool4)\n        upscore2 = F.interpolate(upscore2, size=score_pool4.size()[2:], mode='bilinear', align_corners=False)\n        fuse_pool4 = upscore2 + score_pool4\n\n        upscore_pool4 = self.upscore_pool4(fuse_pool4)\n\n        score_pool3 = self.score_pool3(pool3)\n        upscore_pool4 = F.interpolate(upscore_pool4, size=score_pool3.size()[2:], mode='bilinear', align_corners=False)\n        fuse_pool3 = upscore_pool4 + score_pool3\n\n        out = F.interpolate(fuse_pool3, size=input_size, mode='bilinear', align_corners=False)\n        return out\n\n# -------------------- \u8bc4\u4f30\u6307\u6807 --------------------\ndef compute_metrics(hist):\n    pixel_accuracy = np.diag(hist).sum() / hist.sum() if hist.sum() &gt; 0 else 0.0\n    denom = (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n    iou = np.divide(np.diag(hist), denom, out=np.full_like(np.diag(hist, k=0), np.nan, dtype=float), where=denom!=0)\n    miou = np.nanmean(iou)\n    return pixel_accuracy, miou\n\n# -------------------- \u8bad\u7ec3 / \u9a8c\u8bc1 --------------------\ndef train_one_epoch(model, optimizer, criterion, data_loader, device, scaler, lr_scheduler, grad_clip=1.0):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n    for images, targets in progress_bar:\n        images = images.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        if grad_clip is not None and grad_clip &gt; 0:\n            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n\n        scaler.step(optimizer)\n        scaler.update()\n\n        lr_scheduler.step()\n\n        total_loss += loss.item()\n        progress_bar.set_postfix(\n            loss=f'{loss.item():.4f}',\n            lr=f'{optimizer.param_groups[0][\"lr\"]:.2e}/{optimizer.param_groups[1][\"lr\"]:.2e}'\n        )\n    return total_loss / len(data_loader)\n\n@torch.no_grad()\ndef evaluate_fast(model, criterion, data_loader, device, num_classes,\n                  compute_loss=False, max_batches=None, max_images=None, progress=True):\n    model.eval()\n    total_loss = 0.0\n    seen_images = 0\n    batches = 0\n\n    conf = torch.zeros((num_classes, num_classes), dtype=torch.int64, device=device)\n    iterator = tqdm(data_loader, desc=\"Evaluating\", leave=False) if progress else data_loader\n\n    with torch.inference_mode():\n        for images, targets in iterator:\n            images = images.to(device, non_blocking=True)\n            targets = targets.to(device, non_blocking=True)\n\n            with torch.amp.autocast(device_type='cuda'):\n                outputs = model(images)\n                if compute_loss:\n                    loss = criterion(outputs, targets)\n                    total_loss += loss.item()\n\n            preds = outputs.argmax(1)\n            valid = targets != 255\n            if valid.any():\n                n = num_classes\n                t = targets[valid].to(torch.int64)\n                p = preds[valid].to(torch.int64)\n                k = (t * n + p).view(-1)\n                conf += torch.bincount(k, minlength=n*n).view(n, n)\n\n            batches += 1\n            seen_images += images.size(0)\n\n            if (max_batches is not None and batches &gt;= max_batches) or \\\n               (max_images is not None and seen_images &gt;= max_images):\n                break\n\n    conf_f = conf.to(torch.float32)\n    total = conf_f.sum()\n    pixel_acc = (torch.diag(conf_f).sum() / total).item() if total &gt; 0 else 0.0\n    denom = (conf_f.sum(dim=1) + conf_f.sum(dim=0) - torch.diag(conf_f))\n    iou = torch.where(denom &gt; 0, torch.diag(conf_f) / denom, torch.full_like(denom, float('nan')))\n    miou = torch.nanmean(iou).item()\n\n    avg_loss = (total_loss / batches) if compute_loss and batches &gt; 0 else float('nan')\n    return avg_loss, pixel_acc, miou\n\n# -------------------- \u53ef\u89c6\u5316 --------------------\ndef decode_segmap(image, nc=21, void_value=255, void_color=(0, 0, 0)):\n    lut = np.zeros((256, 3), dtype=np.uint8)\n    lut[:nc] = np.array(VOC_COLORMAP, dtype=np.uint8)\n    lut[void_value] = np.array(void_color, dtype=np.uint8)\n    return lut[image]\n\ndef denormalize(tensor):\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    arr = tensor.detach().cpu().numpy().transpose(1, 2, 0)\n    arr = std * arr + mean\n    return np.clip(arr, 0, 1)\n\n@torch.no_grad()\ndef visualize_predictions(model, data_loader, device, num_images=20, save_dir=VIS_DIR, overlay_alpha=0.6):\n    os.makedirs(save_dir, exist_ok=True)\n    model.eval()\n    shown = 0\n\n    for images, targets in data_loader:\n        images = images.to(device)\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n\n        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n        images_cpu = images.cpu()\n        targets_np = targets.cpu().numpy()\n\n        bsz = images_cpu.shape[0]\n        for i in range(bsz):\n            if shown &gt;= num_images: break\n\n            original_img = denormalize(images_cpu[i])\n            gt_mask_rgb = decode_segmap(targets_np[i])\n            pred_mask_rgb = decode_segmap(preds[i])\n\n            fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n            axes[0].imshow(original_img); axes[0].set_title(\"Original\"); axes[0].axis('off')\n            axes[1].imshow(gt_mask_rgb);  axes[1].set_title(\"Ground Truth\"); axes[1].axis('off')\n            axes[2].imshow(pred_mask_rgb);axes[2].set_title(\"Prediction\");   axes[2].axis('off')\n            axes[3].imshow(original_img); axes[3].imshow(pred_mask_rgb, alpha=overlay_alpha)\n            axes[3].set_title(\"Overlay\"); axes[3].axis('off')\n            plt.tight_layout()\n\n            out_path = os.path.join(save_dir, f'result_{shown:03d}.png')\n            plt.savefig(out_path, dpi=150, bbox_inches='tight')\n            plt.close(fig)\n            shown += 1\n        if shown &gt;= num_images: break\n\n    print(f\"\u53ef\u89c6\u5316\u7ed3\u679c\u4fdd\u5b58\u5728: {os.path.abspath(save_dir)}\uff08\u5171 {shown} \u5f20\uff09\")\n\n# -------------------- \u51c6\u5907\u6570\u636e\u4e0e\u6a21\u578b --------------------\n# \u8bad\u7ec3\u96c6\uff1aVOC2007 trainval + VOC2012 train\uff08\u82e5 2007 \u4e0d\u53ef\u7528\uff0c\u5219\u4ec5 2012\uff09\ntrain_sets = []\n\n# VOC2007 trainval\uff08\u82e5\u5b58\u5728\u5206\u5272\u6807\u6ce8\uff09\nif os.path.isdir(VOC2007_ROOT):\n    try:\n        train_07 = VOCSegmentationDataset(\n            VOC2007_ROOT, image_set='trainval',\n            transforms=SegmentationTransforms(is_train=True, base_size=520, crop_size=480),\n            strict=False\n        )\n        if len(train_07) &gt; 0:\n            train_sets.append(train_07)\n            print(f\"VOC2007 trainval \u53ef\u7528: {len(train_07)} \u6837\u672c\")\n        else:\n            print(\"VOC2007 trainval \u65e0\u53ef\u7528\u5206\u5272\u6837\u672c\uff0c\u8df3\u8fc7 2007\u3002\")\n    except Exception as e:\n        print(f\"\u52a0\u8f7d VOC2007 \u5931\u8d25\uff0c\u8df3\u8fc7\uff1a{e}\")\nelse:\n    print(f\"\u672a\u627e\u5230 VOC2007 \u8def\u5f84\uff1a{VOC2007_ROOT}\uff08\u5c06\u4ec5\u4f7f\u7528 VOC2012 \u8bad\u7ec3\uff09\")\n\n# VOC2012 train\ntrain_12 = VOCSegmentationDataset(\n    VOC2012_ROOT, image_set='train',\n    transforms=SegmentationTransforms(is_train=True, base_size=520, crop_size=480),\n    strict=True\n)\nprint(f\"VOC2012 train: {len(train_12)} \u6837\u672c\")\ntrain_sets.append(train_12)\n\n# \u5408\u5e76\u8bad\u7ec3\u96c6\nif len(train_sets) == 1:\n    train_dataset = train_sets[0]\nelse:\n    train_dataset = ConcatDataset(train_sets)\n\n# \u9a8c\u8bc1\uff1aVOC2012 val\nval_dataset_voc = VOCSegmentationDataset(\n    VOC2012_ROOT, image_set='val',\n    transforms=SegmentationTransforms(is_train=False, base_size=520, crop_size=480),\n    strict=True\n)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n    num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True\n)\nval_loader_voc = DataLoader(\n    val_dataset_voc, batch_size=VAL_BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True\n)\n\nprint(f\"\u8bad\u7ec3\u96c6\u603b\u6837\u672c\u6570: {len(train_dataset)}\")\nprint(f\"\u9a8c\u8bc1\u96c6\u6837\u672c\u6570 (VOC2012 val): {len(val_dataset_voc)}\")\n\nmodel = FCN8s(num_classes=NUM_CLASSES).to(DEVICE)\ncriterion = nn.CrossEntropyLoss(ignore_index=255)\n\n# \u53c2\u6570\u5206\u7ec4 + poly \u5b66\u4e60\u7387\nbase_lr = LEARNING_RATE\nnew_lr = LEARNING_RATE * 10\nnew_modules = [model.score_fr, model.score_pool3, model.score_pool4, model.upscore2, model.upscore_pool4]\noptimizer = optim.AdamW([\n    {'params': it.chain(model.pool3_features.parameters(),\n                        model.pool4_features.parameters(),\n                        model.pool5_features.parameters(),\n                        model.fc6.parameters(),\n                        model.fc7.parameters()), 'lr': base_lr},\n    {'params': it.chain(*(m.parameters() for m in new_modules)), 'lr': new_lr},\n], weight_decay=WEIGHT_DECAY)\n\nmax_iter = EPOCHS * len(train_loader)\ndef poly_lr_lambda(it_idx):\n    return (1 - it_idx / max_iter) ** 0.9\nlr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=poly_lr_lambda)\n\n# AMP Scaler\uff08\u56fa\u5b9a cuda\uff09\nscaler = torch.amp.GradScaler('cuda')\n\n# \u8bb0\u5f55\u4e0e\u4fdd\u5b58\nhistory = {'train_loss': [], 'val_loss': [], 'val_pa': [], 'val_miou': []}\nbest_miou_voc = -1.0\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# -------------------- \u8bad\u7ec3\u5faa\u73af --------------------\nprint(\"\u5f00\u59cb\u8bad\u7ec3...\")\nstart_time = time.time()\n\nfor epoch in range(EPOCHS):\n    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, DEVICE, scaler, lr_scheduler)\n\n    val_loss_voc, val_pa_voc, val_miou_voc = evaluate_fast(\n        model, criterion, val_loader_voc, DEVICE, NUM_CLASSES,\n        compute_loss=EVAL_COMPUTE_LOSS,\n        max_batches=EVAL_MAX_BATCHES,\n        max_images=EVAL_MAX_IMAGES,\n        progress=EVAL_PROGRESS\n    )\n\n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss_voc)\n    history['val_pa'].append(val_pa_voc)\n    history['val_miou'].append(val_miou_voc)\n\n    if val_miou_voc &gt; best_miou_voc:\n        best_miou_voc = val_miou_voc\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state': model.state_dict(),\n            'optimizer_state': optimizer.state_dict(),\n            'miou_voc': best_miou_voc,\n            'config': {\n                'base_lr': base_lr, 'new_lr': new_lr, 'weight_decay': WEIGHT_DECAY,\n                'epochs': EPOCHS, 'batch_size': BATCH_SIZE\n            }\n        }, BEST_PATH_VOC)\n\n    val_loss_str = f\"{val_loss_voc:.4f}\" if EVAL_COMPUTE_LOSS else \"n/a\"\n    print(\n        f\"Epoch {epoch+1}/{EPOCHS} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"VOC Val: Loss {val_loss_str}, PA {val_pa_voc:.4f}, mIoU {val_miou_voc:.4f} | \"\n        f\"Best VOC mIoU: {best_miou_voc:.4f}\"\n    )\n\nend_time = time.time()\nprint(f\"\\n\u8bad\u7ec3\u5b8c\u6210\uff01\u603b\u8017\u65f6: {(end_time - start_time) / 60:.2f} \u5206\u949f\")\nprint(\"\\n--- \u6700\u7ec8\u8bc4\u4f30\u6307\u6807 (VOC2012 val) ---\")\nfinal_loss_str = f\"{history['val_loss'][-1]:.4f}\" if EVAL_COMPUTE_LOSS else \"n/a\"\nprint(f\"Val Loss: {final_loss_str} | PA: {history['val_pa'][-1]:.4f} | mIoU: {history['val_miou'][-1]:.4f}\")\nprint(f\"\u6700\u4f18\u6743\u91cd\u5df2\u4fdd\u5b58\u81f3: {BEST_PATH_VOC}\")\n\n# \u4fdd\u5b58\u5f53\u524d\uff08latest\uff09\ntorch.save(model.state_dict(), LATEST_PATH)\nprint(f\"\u5df2\u4fdd\u5b58\u5f53\u524d\u6a21\u578b\u6743\u91cd\u5230: {LATEST_PATH}\")\n\n# \u52a0\u8f7d\u6700\u4f18\u6743\u91cd\u7528\u4e8e\u53ef\u89c6\u5316\nif os.path.isfile(BEST_PATH_VOC):\n    ckpt_voc = torch.load(BEST_PATH_VOC, map_location=torch.device(DEVICE))\n    model.load_state_dict(ckpt_voc['model_state'])\n    print(f\"\\n\u5df2\u52a0\u8f7d VOC \u6700\u4f18\u6743\u91cd\u8fdb\u884c\u53ef\u89c6\u5316: {BEST_PATH_VOC} (epoch={ckpt_voc.get('epoch','?')}, mIoU_VOC={ckpt_voc.get('miou_voc', 0):.4f})\")\nelse:\n    print(\"\\n\u672a\u627e\u5230 VOC \u6700\u4f18\u6743\u91cd\uff0c\u4f7f\u7528\u5f53\u524d\u6a21\u578b\u8fdb\u884c\u53ef\u89c6\u5316\u3002\")\n\nprint(\"\\n--- \u53ef\u89c6\u5316\u9884\u6d4b\u7ed3\u679c (VOC2012 val) ---\")\nvisualize_predictions(model, val_loader_voc, DEVICE, num_images=20, save_dir=VIS_DIR)\n</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_6", "title": "\u8bad\u7ec3\u7ed3\u679c", "text": "<p>\u5728 Pascal VOC 07+12 \u4e0a\u8bad\u7ec3 50 \u4e2a Epoch\uff0c\u603b\u7528\u65f6 7796.3s\uff0cmIoU \u8fbe\u5230 0.6277\uff0c\u50cf\u7d20\u51c6\u786e\u7387\u8fbe\u5230 0.9065\uff0c\u5df2\u7ecf\u8d85\u8fc7\u4e86\u539f\u8bba\u6587\u7684\u6307\u6807\u3002</p> <p></p> <p></p> <p></p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#u-net", "title": "U-Net", "text": ""}, {"location": "DNN/model-expr/S-and-D-models-replication/#_7", "title": "\u539f\u7406", "text": "<p>\u6211\u4eec\u5b9e\u8df5\u521a\u521a\u5728 FCN-8s \u91cc\u9762\u63d0\u5230\u7684\u66f4\u6539\uff0c\u4e5f\u5c31\u662f\u628a\u7f51\u7edc\u7ed3\u6784\u6539\u5bf9\u79f0\uff0c\u5e76\u4e14\u8df3\u8dc3\u8fde\u63a5\u7531\u76f8\u52a0\u518d\u5728\u901a\u9053\u7ef4\u62fc\u63a5\uff0c\u6700\u540e\u52a0\u6570\u636e\u589e\u5f3a\u5373\u53ef\u3002</p> <p>\u5176\u5b9e\u4ece FCN \u5230 U-Net\uff0c\u6709\u70b9\u7c7b\u4f3c\u4e8e\u4ece ResNet \u5230 DenseNet\u3002</p> <pre><code># \u57fa\u672c\u7684\u53cc\u5377\u79ef\u5757\uff0c\u8d1f\u8d23\u6574\u5408\u62fc\u63a5\u4e4b\u540e\u7684\u901a\u9053\u7ef4\u3002\nclass DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch, p=0.1):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\n\nclass UNetVGG16(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        # \u9884\u8bad\u7ec3 VGG16 \u7f16\u7801\u5668\n        vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n        features = vgg.features\n\n        # \u8fd9\u91cc\u4fdd\u6301 4 \u6b21\u4e0b\u91c7\u6837\uff0c\u65b9\u5f0f\u5728 FCN-8s \u91cc\u9762\u5df2\u7ecf\u6709\u4ecb\u7ecd\u8fc7\u3002\n        self.conv1 = features[:4]\n        self.pool1 = features[4]\n        self.conv2 = features[5:9]\n        self.pool2 = features[9]\n        self.conv3 = features[10:16]\n        self.pool3 = features[16]\n        self.conv4 = features[17:23]\n        self.pool4 = features[23]\n        self.conv5 = features[24:30]\n        # \u8fd9\u91cc\u4e0d\u542b pool5\uff0c\u6211\u4eec\u4e0d\u60f3\u8ba9\u7f51\u7edc\u7684\u53c2\u6570\u8fc7\u5927\uff0c\u56e0\u6b64\u53ea\u5230 conv5 \u7684\u7279\u5f81\u56fe\u5c31\u591f\u4e86\u3002\n        # \u540c\u65f6\u4e00\u4e2a\u5178\u578b\u7684 U-Net \u6709 4 \u4e2a\u8df3\u8dc3\u8fde\u63a5\u5c31\u8db3\u77e3\u3002\n        # \u4f46\u662f\u76f8\u6bd4\u4e8e\u4e4b\u524d\u7684 FCN-8s\uff0c\u5b9e\u9645\u4e0a\u53c2\u6570\u91cf\u5c0f\u4e86\u5f88\u591a\u3002\n        # \u56e0\u4e3a FCN-8s \u57fa\u672c\u4e0a\u7528\u5230\u4e86 VGG \u7684\u6240\u6709\u9884\u8bad\u7ec3\u6743\u91cd\u3002\n        # \u6240\u4ee5\u6700\u540e\u6548\u679c\u662f\u4ee5\u6bd4 FCN-8s \u5c11\u4e86\u4e94\u5206\u4e4b\u56db\u7684\u53c2\u6570\uff0c\u6362\u53d6\u4e86 9% \u7684 mIoU \u964d\u5e45\u3002\n\n        # \u4e0a\u91c7\u6837\uff1a\u5728 U-Net \u91cc\u9762\u57fa\u672c\u4e0a\u5df2\u7ecf\u820d\u5f03\u4e86\u8f6c\u7f6e\u5377\u79ef\uff0c\u800c\u662f\u76f4\u63a5\u4e0a\u91c7\u6837\u518d\u505a\u5377\u79ef\u3002\n        # \u5176\u5b9e\u6548\u679c\u548c\u8f6c\u7f6e\u5377\u79ef\u8fd8\u5dee\u4e0d\u591a\uff0c\u4f46\u7701\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\u3002\n        self.up4 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(512, 512, kernel_size=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n        )\n        # \u89e3\u7801\u5668\u5c31\u662f\u8df3\u8dc3\u8fde\u63a5\u4e4b\u540e\u505a\u53cc\u5377\u79ef\u3002\n        self.dec4 = DoubleConv(512 + 512, 512)\n\n        # \u540e\u9762\u8fd9\u4e9b\u4e0a\u91c7\u6837+\u89e3\u7801\u5c31\u4f9d\u846b\u82a6\u753b\u74e2\u4e86\uff0c\u53ea\u9700\u8981\u66f4\u6539\u901a\u9053\u6570\u800c\u5df2\u3002\n        self.up3 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(512, 256, kernel_size=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n        self.dec3 = DoubleConv(256 + 256, 256)\n\n        self.up2 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(256, 128, kernel_size=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n        )\n        self.dec2 = DoubleConv(128 + 128, 128)\n\n        self.up1 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(128, 64, kernel_size=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.dec1 = DoubleConv(64 + 64, 64)\n\n        # \u8f93\u51fa\u5c42\n        self.out_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    @staticmethod\n    def _align(x, ref):\n        # \u5bf9\u9f50\u5c3a\u5bf8\uff0c\u907f\u514d\u5947\u5076\u6570\u5bfc\u81f4\u7684 1px \u8bef\u5dee\n        if x.shape[2:] != ref.shape[2:]:\n            x = F.interpolate(x, size=ref.shape[2:], mode='bilinear', align_corners=False)\n        return x\n\n    def forward(self, x):\n        # \u7f16\u7801\u5668\uff0cC \u8868\u793a\u901a\u9053\u6570\uff0c\u540e\u9762\u7684\u5206\u6570\u4ee3\u8868\u7279\u5f81\u56fe\u76f8\u5bf9\u539f\u56fe\u7684\u5c3a\u5bf8\u4e4b\u6bd4\u3002\n        x1 = self.conv1(x)           # C=64,   1/1\n        p1 = self.pool1(x1)          #         1/2\n\n        x2 = self.conv2(p1)          # C=128,  1/2\n        p2 = self.pool2(x2)          #         1/4\n\n        x3 = self.conv3(p2)          # C=256,  1/4\n        p3 = self.pool3(x3)          #         1/8\n\n        x4 = self.conv4(p3)          # C=512,  1/8\n        p4 = self.pool4(x4)          #        1/16\n\n        x5 = self.conv5(p4)          # C=512, 1/16 (bottleneck)\n\n        # \u89e3\u7801\u5668\n        u4 = self.up4(x5)            # -&gt; 1/8\n        u4 = self._align(u4, x4)\n        d4 = self.dec4(torch.cat([u4, x4], dim=1))   # C=512\n\n        u3 = self.up3(d4)            # -&gt; 1/4\n        u3 = self._align(u3, x3)\n        d3 = self.dec3(torch.cat([u3, x3], dim=1))   # C=256\n\n        u2 = self.up2(d3)            # -&gt; 1/2\n        u2 = self._align(u2, x2)\n        d2 = self.dec2(torch.cat([u2, x2], dim=1))   # C=128\n\n        u1 = self.up1(d2)            # -&gt; 1/1\n        u1 = self._align(u1, x1)\n        d1 = self.dec1(torch.cat([u1, x1], dim=1))   # C=64\n\n        out = self.out_conv(d1)      # -&gt; num_classes@HxW\n        return out\n</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_8", "title": "\u8bad\u7ec3\u4ee3\u7801", "text": "U-Net \u7684\u8bad\u7ec3\u4ee3\u7801  <pre><code>import numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision.transforms as T\nfrom torchvision.models import vgg16, VGG16_Weights\nimport itertools as it\n\n# -------------------- \u914d\u7f6e --------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nUSE_AMP = True  # \u56fa\u5b9a\u7528 CUDA AMP\n\n# Kaggle \u5e38\u89c1\u8def\u5f84\uff08\u53ef\u6309\u9700\u4fee\u6539\uff09\nVOC2007_ROOT = \"/kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007\"\nVOC2007_ROOT_ALT = \"/kaggle/input/pascal-voc-2007/VOCdevkit/VOC2007\"\nif not os.path.isdir(VOC2007_ROOT) and os.path.isdir(VOC2007_ROOT_ALT):\n    VOC2007_ROOT = VOC2007_ROOT_ALT\n\nVOC2012_ROOT = \"/kaggle/input/pascal-voc-2012/VOC2012\"\n\nNUM_CLASSES = 21\nBATCH_SIZE = 16\nVAL_BATCH_SIZE = 1  # \u4f60\u8981\u624b\u8c03\u5c31\u6539\u8fd9\u91cc\uff08&gt;1 \u65f6\u9700\u81ea\u5df1\u52a0 padding collate\uff09\nNUM_WORKERS = 6\n\nLEARNING_RATE = 7.5e-5\nWEIGHT_DECAY = 1e-4\nEPOCHS = 80\n\n# \u8bc4\u4f30\u52a0\u901f\u5f00\u5173\nEVAL_COMPUTE_LOSS = False     # True \u4f1a\u8ba1\u7b97 val loss\uff0c\u7a0d\u6162\nEVAL_MAX_BATCHES = None       # \u9650\u5236\u8bc4\u4f30\u6279\u6b21\u6570\uff1bNone \u8868\u793a\u5168\u91cf\nEVAL_MAX_IMAGES = None         # \u9650\u5236\u8bc4\u4f30\u56fe\u7247\u6570\uff1bNone \u8868\u793a\u5168\u91cf\nEVAL_PROGRESS = True          # \u4fdd\u7559 tqdm \u8fdb\u5ea6\u6761\n\nSAVE_DIR = \"/kaggle/working\"\nBEST_PATH_VOC = os.path.join(SAVE_DIR, \"fcn8s_best_voc2012val.pth\")\nLATEST_PATH = os.path.join(SAVE_DIR, \"fcn8s_latest.pth\")\nVIS_DIR = os.path.join(SAVE_DIR, \"vis_voc_val\")\n\nprint(f\"Using device: {DEVICE}\")\nif DEVICE == \"cuda\":\n    torch.backends.cudnn.benchmark = True\n\n# PASCAL VOC \u989c\u8272\u6620\u5c04 (RGB) \u7528\u4e8e\u53ef\u89c6\u5316\nVOC_COLORMAP = [\n    [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n    [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0],\n    [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128],\n    [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n    [0, 64, 128]\n]\n\n# -------------------- \u6570\u636e\u96c6\uff08VOC\uff09 --------------------\nclass VOCSegmentationDataset(Dataset):\n    \"\"\"\n    \u7528\u4e8e VOC2007/VOC2012 \u7684\u8bed\u4e49\u5206\u5272\u6570\u636e\u3002\n    \u82e5\u7f3a\u5c11 ImageSets/Segmentation/{split}.txt\uff0c\u5c06\u56de\u9000\u5230\u626b\u63cf SegmentationClass \u76ee\u5f55\u3002\n    \"\"\"\n    def __init__(self, root, image_set=\"train\", transforms=None, strict=True):\n        self.root = root\n        self.transforms = transforms\n        self.image_set = image_set\n\n        image_dir = os.path.join(root, \"JPEGImages\")\n        mask_dir = os.path.join(root, \"SegmentationClass\")\n        split_file = os.path.join(root, \"ImageSets\", \"Segmentation\", f\"{image_set}.txt\")\n\n        assert os.path.isdir(image_dir), f\"Image dir not found: {image_dir}\"\n        if not os.path.isdir(mask_dir):\n            if strict:\n                raise FileNotFoundError(f\"SegmentationClass not found: {mask_dir}\")\n            else:\n                print(f\"[Warning] SegmentationClass not found in {root}, dataset will be empty.\")\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n\n        ids = []\n        if os.path.isfile(split_file):\n            with open(split_file, \"r\") as f:\n                ids = [line.strip() for line in f if line.strip()]\n        else:\n            if os.path.isdir(mask_dir):\n                ids = [os.path.splitext(fn)[0] for fn in os.listdir(mask_dir) if fn.endswith(\".png\")]\n            else:\n                ids = []\n\n        self.image_paths, self.mask_paths = [], []\n        for id_ in ids:\n            ip = os.path.join(image_dir, f\"{id_}.jpg\")\n            mp = os.path.join(mask_dir, f\"{id_}.png\")\n            if os.path.isfile(ip) and os.path.isfile(mp):\n                self.image_paths.append(ip)\n                self.mask_paths.append(mp)\n        if len(self.image_paths) == 0:\n            print(f\"[Warning] Empty dataset for root={root}, split={image_set}. Check masks/splits.\")\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        mask = Image.open(self.mask_paths[idx])  # palette \u7d22\u5f15\n\n        if self.transforms is not None:\n            image, target = self.transforms(image, mask)\n        else:\n            img = T.functional.to_tensor(image)\n            img = T.functional.normalize(img, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n            target = torch.from_numpy(np.array(mask, dtype=np.uint8)).long()\n            image, target = img, target\n        return image, target\n\n# -------------------- \u6570\u636e\u589e\u5f3a\u4e0e\u9884\u5904\u7406 --------------------\nclass SegmentationTransforms:\n    def __init__(self, is_train=True, base_size=520, crop_size=480,\n                 color_jitter=True, add_noise_prob=0.0, noise_std=0.03):  # \u5173\u95ed\u566a\u58f0\uff1a\u9ed8\u8ba4 0.0\n        self.is_train = is_train\n        self.base_size = base_size\n        self.crop_size = crop_size\n        self.mean = (0.485, 0.456, 0.406)\n        self.std = (0.229, 0.224, 0.225)\n        self.color_jitter = T.ColorJitter(0.4, 0.4, 0.4, 0.1) if color_jitter and is_train else None\n        self.add_noise_prob = add_noise_prob if is_train else 0.0\n        self.noise_std = noise_std\n\n    def __call__(self, img, mask):\n        if self.is_train:\n            # 1) \u968f\u673a\u7f29\u653e\u77ed\u8fb9\u5230 [0.5, 2.0] * base_size\n            scale = np.random.uniform(0.5, 2.0)\n            short = int(self.base_size * scale)\n            w, h = img.size\n            if w &lt; h:\n                ow, oh = short, int(short * h / w)\n            else:\n                oh, ow = short, int(short * w / h)\n            img = img.resize((ow, oh), Image.BILINEAR)\n            mask = mask.resize((ow, oh), Image.NEAREST)\n\n            # 2) \u82e5\u5c0f\u4e8e crop_size\uff0c\u53f3\u4e0b\u89d2 padding\uff08mask \u7528 255\uff09\n            pad_w = max(0, self.crop_size - img.size[0])\n            pad_h = max(0, self.crop_size - img.size[1])\n            if pad_w &gt; 0 or pad_h &gt; 0:\n                img = T.functional.pad(img, (0, 0, pad_w, pad_h), fill=0)\n                mask = T.functional.pad(mask, (0, 0, pad_w, pad_h), fill=255)\n\n            # 3) \u968f\u673a\u88c1\u526a\n            w, h = img.size\n            x1 = np.random.randint(0, w - self.crop_size + 1)\n            y1 = np.random.randint(0, h - self.crop_size + 1)\n            img = img.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n            mask = mask.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n\n            # 4) \u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n            if np.random.rand() &gt; 0.5:\n                img = T.functional.hflip(img)\n                mask = T.functional.hflip(mask)\n\n            # 5) \u989c\u8272\u6296\u52a8\n            if self.color_jitter is not None:\n                img = self.color_jitter(img)\n\n        # \u8f6c Tensor\n        img = T.functional.to_tensor(img)\n\n        # \u53ef\u9009\u566a\u58f0\uff08\u73b0\u5df2\u5173\u95ed\uff0c\u9ed8\u8ba4 add_noise_prob=0.0\uff09\n        if self.is_train and np.random.rand() &lt; self.add_noise_prob:\n            noise = torch.randn_like(img) * self.noise_std\n            img = torch.clamp(img + noise, 0.0, 1.0)\n\n        # \u6807\u51c6\u5316\n        img = T.functional.normalize(img, self.mean, self.std)\n\n        # \u76f4\u63a5\u628a palette/L \u7d22\u5f15\u56fe\u8f6c\u6210\u7c7b\u522b id\uff080..20\uff0c255 \u5ffd\u7565\uff09\n        target = torch.from_numpy(np.array(mask, dtype=np.uint8)).long()\n        return img, target\n\n# -------------------- \u6a21\u578b\uff08U-Net\uff09 --------------------\ndef bilinear_kernel(in_channels, out_channels, kernel_size):\n    factor = (kernel_size + 1) // 2\n    center = factor - 1 if kernel_size % 2 == 1 else factor - 0.5\n    og = np.ogrid[:kernel_size, :kernel_size]\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float32)\n    for i in range(min(in_channels, out_channels)):\n        weight[i, i, :, :] = filt\n    return torch.from_numpy(weight)\n\n# \u89e3\u7801\u5668 DoubleConv\uff1a\u52a0 BN + Dropout2d\nclass DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch, p=0.1):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\n\nclass UNetVGG16(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        # \u9884\u8bad\u7ec3 VGG16 \u7f16\u7801\u5668\n        vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n        features = vgg.features\n\n        # \u62c6\u5206\u4e3a\u201c\u5377\u79ef\u5757 + \u6c60\u5316\u201d\uff0c\u5e76\u79fb\u9664 pool5\uff08\u4fdd\u6301 4 \u6b21\u4e0b\u91c7\u6837\uff09\n        self.conv1 = features[:4]\n        self.pool1 = features[4]\n        self.conv2 = features[5:9]\n        self.pool2 = features[9]\n        self.conv3 = features[10:16]\n        self.pool3 = features[16]\n        self.conv4 = features[17:23]\n        self.pool4 = features[23]\n        self.conv5 = features[24:30]  # \u4e0d\u542b pool5\n\n        # \u89e3\u7801\u5668\uff1a\u4e0a\u91c7\u6837\u6539\u4e3a\u201c\u63d2\u503c + \u5377\u79ef(BN+ReLU)\u201d + \u62fc\u63a5 + \u53cc\u5377\u79ef(DoubleConv: BN+Dropout)\n        self.up4 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(512, 512, kernel_size=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n        )\n        self.dec4 = DoubleConv(512 + 512, 512)\n\n        self.up3 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(512, 256, kernel_size=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n        self.dec3 = DoubleConv(256 + 256, 256)\n\n        self.up2 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(256, 128, kernel_size=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n        )\n        self.dec2 = DoubleConv(128 + 128, 128)\n\n        self.up1 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n            nn.Conv2d(128, 64, kernel_size=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.dec1 = DoubleConv(64 + 64, 64)\n\n        # \u8f93\u51fa\u5c42\n        self.out_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    @staticmethod\n    def _align(x, ref):\n        # \u5bf9\u9f50\u5c3a\u5bf8\uff0c\u907f\u514d\u5947\u5076\u6570\u5bfc\u81f4\u7684 1px \u8bef\u5dee\n        if x.shape[2:] != ref.shape[2:]:\n            x = F.interpolate(x, size=ref.shape[2:], mode='bilinear', align_corners=False)\n        return x\n\n    def forward(self, x):\n        # \u7f16\u7801\u5668\n        x1 = self.conv1(x)           # C=64,   1/1\n        p1 = self.pool1(x1)          #        1/2\n\n        x2 = self.conv2(p1)          # C=128,  1/2\n        p2 = self.pool2(x2)          #        1/4\n\n        x3 = self.conv3(p2)          # C=256,  1/4\n        p3 = self.pool3(x3)          #        1/8\n\n        x4 = self.conv4(p3)          # C=512,  1/8\n        p4 = self.pool4(x4)          #        1/16\n\n        x5 = self.conv5(p4)          # C=512,  1/16 (bottleneck)\n\n        # \u89e3\u7801\u5668\uff08U-Net\uff09\n        u4 = self.up4(x5)            # -&gt; 1/8\n        u4 = self._align(u4, x4)\n        d4 = self.dec4(torch.cat([u4, x4], dim=1))   # C=512\n\n        u3 = self.up3(d4)            # -&gt; 1/4\n        u3 = self._align(u3, x3)\n        d3 = self.dec3(torch.cat([u3, x3], dim=1))   # C=256\n\n        u2 = self.up2(d3)            # -&gt; 1/2\n        u2 = self._align(u2, x2)\n        d2 = self.dec2(torch.cat([u2, x2], dim=1))   # C=128\n\n        u1 = self.up1(d2)            # -&gt; 1/1\n        u1 = self._align(u1, x1)\n        d1 = self.dec1(torch.cat([u1, x1], dim=1))   # C=64\n\n        out = self.out_conv(d1)      # -&gt; num_classes@HxW\n        return out\n\n# -------------------- \u8bc4\u4f30\u6307\u6807 --------------------\ndef compute_metrics(hist):\n    pixel_accuracy = np.diag(hist).sum() / hist.sum() if hist.sum() &gt; 0 else 0.0\n    denom = (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n    iou = np.divide(np.diag(hist), denom, out=np.full_like(np.diag(hist, k=0), np.nan, dtype=float), where=denom!=0)\n    miou = np.nanmean(iou)\n    return pixel_accuracy, miou\n\n# -------------------- \u8bad\u7ec3 / \u9a8c\u8bc1 --------------------\ndef train_one_epoch(model, optimizer, criterion, data_loader, device, scaler, lr_scheduler, grad_clip=1.0):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n    for images, targets in progress_bar:\n        images = images.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        if grad_clip is not None and grad_clip &gt; 0:\n            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n\n        scaler.step(optimizer)\n        scaler.update()\n\n        lr_scheduler.step()\n\n        total_loss += loss.item()\n        progress_bar.set_postfix(\n            loss=f'{loss.item():.4f}',\n            lr=f'{optimizer.param_groups[0][\"lr\"]:.2e}/{optimizer.param_groups[1][\"lr\"]:.2e}'\n        )\n    return total_loss / len(data_loader)\n\n@torch.no_grad()\ndef evaluate_fast(model, criterion, data_loader, device, num_classes,\n                  compute_loss=False, max_batches=None, max_images=None, progress=True):\n    model.eval()\n    total_loss = 0.0\n    seen_images = 0\n    batches = 0\n\n    conf = torch.zeros((num_classes, num_classes), dtype=torch.int64, device=device)\n    iterator = tqdm(data_loader, desc=\"Evaluating\", leave=False) if progress else data_loader\n\n    with torch.inference_mode():\n        for images, targets in iterator:\n            images = images.to(device, non_blocking=True)\n            targets = targets.to(device, non_blocking=True)\n\n            with torch.amp.autocast(device_type='cuda'):\n                outputs = model(images)\n                if compute_loss:\n                    loss = criterion(outputs, targets)\n                    total_loss += loss.item()\n\n            preds = outputs.argmax(1)\n            valid = targets != 255\n            if valid.any():\n                n = num_classes\n                t = targets[valid].to(torch.int64)\n                p = preds[valid].to(torch.int64)\n                k = (t * n + p).view(-1)\n                conf += torch.bincount(k, minlength=n*n).view(n, n)\n\n            batches += 1\n            seen_images += images.size(0)\n\n            if (max_batches is not None and batches &gt;= max_batches) or \\\n               (max_images is not None and seen_images &gt;= max_images):\n                break\n\n    conf_f = conf.to(torch.float32)\n    total = conf_f.sum()\n    pixel_acc = (torch.diag(conf_f).sum() / total).item() if total &gt; 0 else 0.0\n    denom = (conf_f.sum(dim=1) + conf_f.sum(dim=0) - torch.diag(conf_f))\n    iou = torch.where(denom &gt; 0, torch.diag(conf_f) / denom, torch.full_like(denom, float('nan')))\n    miou = torch.nanmean(iou).item()\n\n    avg_loss = (total_loss / batches) if compute_loss and batches &gt; 0 else float('nan')\n    return avg_loss, pixel_acc, miou\n\n# -------------------- \u53ef\u89c6\u5316 --------------------\ndef decode_segmap(image, nc=21, void_value=255, void_color=(0, 0, 0)):\n    lut = np.zeros((256, 3), dtype=np.uint8)\n    lut[:nc] = np.array(VOC_COLORMAP, dtype=np.uint8)\n    lut[void_value] = np.array(void_color, dtype=np.uint8)\n    return lut[image]\n\ndef denormalize(tensor):\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    arr = tensor.detach().cpu().numpy().transpose(1, 2, 0)\n    arr = std * arr + mean\n    return np.clip(arr, 0, 1)\n\n@torch.no_grad()\ndef visualize_predictions(model, data_loader, device, num_images=20, save_dir=VIS_DIR, overlay_alpha=0.6):\n    os.makedirs(save_dir, exist_ok=True)\n    model.eval()\n    shown = 0\n\n    for images, targets in data_loader:\n        images = images.to(device)\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(images)\n\n        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n        images_cpu = images.cpu()\n        targets_np = targets.cpu().numpy()\n\n        bsz = images_cpu.shape[0]\n        for i in range(bsz):\n            if shown &gt;= num_images: break\n\n            original_img = denormalize(images_cpu[i])\n            gt_mask_rgb = decode_segmap(targets_np[i])\n            pred_mask_rgb = decode_segmap(preds[i])\n\n            fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n            axes[0].imshow(original_img); axes[0].set_title(\"Original\"); axes[0].axis('off')\n            axes[1].imshow(gt_mask_rgb);  axes[1].set_title(\"Ground Truth\"); axes[1].axis('off')\n            axes[2].imshow(pred_mask_rgb);axes[2].set_title(\"Prediction\");   axes[2].axis('off')\n            axes[3].imshow(original_img); axes[3].imshow(pred_mask_rgb, alpha=overlay_alpha)\n            axes[3].set_title(\"Overlay\"); axes[3].axis('off')\n            plt.tight_layout()\n\n            out_path = os.path.join(save_dir, f'result_{shown:03d}.png')\n            plt.savefig(out_path, dpi=150, bbox_inches='tight')\n            plt.close(fig)\n            shown += 1\n        if shown &gt;= num_images: break\n\n    print(f\"\u53ef\u89c6\u5316\u7ed3\u679c\u4fdd\u5b58\u5728: {os.path.abspath(save_dir)}\uff08\u5171 {shown} \u5f20\uff09\")\n\n# -------------------- \u51c6\u5907\u6570\u636e\u4e0e\u6a21\u578b --------------------\n# \u8bad\u7ec3\u96c6\uff1aVOC2007 trainval + VOC2012 train\uff08\u82e5 2007 \u4e0d\u53ef\u7528\uff0c\u5219\u4ec5 2012\uff09\ntrain_sets = []\n\n# VOC2007 trainval\uff08\u82e5\u5b58\u5728\u5206\u5272\u6807\u6ce8\uff09\nif os.path.isdir(VOC2007_ROOT):\n    try:\n        train_07 = VOCSegmentationDataset(\n            VOC2007_ROOT, image_set='trainval',\n            transforms=SegmentationTransforms(is_train=True, base_size=520, crop_size=480),  # \u5df2\u9ed8\u8ba4\u5173\u95ed\u566a\u58f0\n            strict=False\n        )\n        if len(train_07) &gt; 0:\n            train_sets.append(train_07)\n            print(f\"VOC2007 trainval \u53ef\u7528: {len(train_07)} \u6837\u672c\")\n        else:\n            print(\"VOC2007 trainval \u65e0\u53ef\u7528\u5206\u5272\u6837\u672c\uff0c\u8df3\u8fc7 2007\u3002\")\n    except Exception as e:\n        print(f\"\u52a0\u8f7d VOC2007 \u5931\u8d25\uff0c\u8df3\u8fc7\uff1a{e}\")\nelse:\n    print(f\"\u672a\u627e\u5230 VOC2007 \u8def\u5f84\uff1a{VOC2007_ROOT}\uff08\u5c06\u4ec5\u4f7f\u7528 VOC2012 \u8bad\u7ec3\uff09\")\n\n# VOC2012 train\ntrain_12 = VOCSegmentationDataset(\n    VOC2012_ROOT, image_set='train',\n    transforms=SegmentationTransforms(is_train=True, base_size=520, crop_size=480),  # \u5df2\u9ed8\u8ba4\u5173\u95ed\u566a\u58f0\n    strict=True\n)\nprint(f\"VOC2012 train: {len(train_12)} \u6837\u672c\")\ntrain_sets.append(train_12)\n\n# \u5408\u5e76\u8bad\u7ec3\u96c6\nif len(train_sets) == 1:\n    train_dataset = train_sets[0]\nelse:\n    train_dataset = ConcatDataset(train_sets)\n\n# \u9a8c\u8bc1\uff1aVOC2012 val\nval_dataset_voc = VOCSegmentationDataset(\n    VOC2012_ROOT, image_set='val',\n    transforms=SegmentationTransforms(is_train=False, base_size=520, crop_size=480),\n    strict=True\n)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n    num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True\n)\nval_loader = DataLoader(\n    val_dataset_voc, batch_size=VAL_BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True\n)\n\nprint(f\"\u8bad\u7ec3\u96c6\u603b\u6837\u672c\u6570: {len(train_dataset)}\")\nprint(f\"\u9a8c\u8bc1\u96c6\u6837\u672c\u6570 (VOC2012 val): {len(val_dataset_voc)}\")\n\nmodel = UNetVGG16(num_classes=NUM_CLASSES).to(DEVICE)\ncriterion = nn.CrossEntropyLoss(ignore_index=255)\n\n# \u53c2\u6570\u5206\u7ec4 + poly \u5b66\u4e60\u7387\nbase_lr = LEARNING_RATE\nnew_lr  = LEARNING_RATE * 10\n\n# \u9884\u8bad\u7ec3\u7684\u7f16\u7801\u5668\uff08VGG16 features\uff09\nencoder_modules = [model.conv1, model.conv2, model.conv3, model.conv4, model.conv5]\n\n# \u65b0\u521d\u59cb\u5316\u7684\u89e3\u7801\u5668\u4e0e\u8f93\u51fa\u5c42\nnew_modules = [\n    model.up4, model.dec4,\n    model.up3, model.dec3,\n    model.up2, model.dec2,\n    model.up1, model.dec1,\n    model.out_conv\n]\n\noptimizer = optim.AdamW([\n    {'params': it.chain(*(m.parameters() for m in encoder_modules)), 'lr': base_lr},\n    {'params': it.chain(*(m.parameters() for m in new_modules)), 'lr': new_lr},\n], weight_decay=WEIGHT_DECAY)\n\nmax_iter = EPOCHS * len(train_loader)\ndef poly_lr_lambda(it_idx):\n    return (1 - it_idx / max_iter) ** 0.9\n\nlr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=poly_lr_lambda)\n\n# AMP Scaler\uff08\u56fa\u5b9a cuda\uff09\nscaler = torch.amp.GradScaler('cuda')\n\n# \u8bb0\u5f55\u4e0e\u4fdd\u5b58\nhistory = {'train_loss': [], 'val_loss': [], 'val_pa': [], 'val_miou': []}\nbest_miou_voc = -1.0\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# -------------------- \u8bad\u7ec3\u5faa\u73af --------------------\nprint(\"\u5f00\u59cb\u8bad\u7ec3...\")\nstart_time = time.time()\n\nfor epoch in range(EPOCHS):\n    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, DEVICE, scaler, lr_scheduler)\n\n    val_loss_voc, val_pa_voc, val_miou_voc = evaluate_fast(\n        model, criterion, val_loader, DEVICE, NUM_CLASSES,\n        compute_loss=EVAL_COMPUTE_LOSS,\n        max_batches=EVAL_MAX_BATCHES,\n        max_images=EVAL_MAX_IMAGES,\n        progress=EVAL_PROGRESS\n    )\n\n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss_voc)\n    history['val_pa'].append(val_pa_voc)\n    history['val_miou'].append(val_miou_voc)\n\n    if val_miou_voc &gt; best_miou_voc:\n        best_miou_voc = val_miou_voc\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state': model.state_dict(),\n            'optimizer_state': optimizer.state_dict(),\n            'miou_voc': best_miou_voc,\n            'config': {\n                'base_lr': base_lr, 'new_lr': new_lr, 'weight_decay': WEIGHT_DECAY,\n                'epochs': EPOCHS, 'batch_size': BATCH_SIZE\n            }\n        }, BEST_PATH_VOC)\n\n    val_loss_str = f\"{val_loss_voc:.4f}\" if EVAL_COMPUTE_LOSS else \"n/a\"\n    print(\n        f\"Epoch {epoch+1}/{EPOCHS} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"VOC Val: Loss {val_loss_str}, PA {val_pa_voc:.4f}, mIoU {val_miou_voc:.4f} | \"\n        f\"Best VOC mIoU: {best_miou_voc:.4f}\"\n    )\n\nend_time = time.time()\nprint(f\"\\n\u8bad\u7ec3\u5b8c\u6210\uff01\u603b\u8017\u65f6: {(end_time - start_time) / 60:.2f} \u5206\u949f\")\nprint(\"\\n--- \u6700\u7ec8\u8bc4\u4f30\u6307\u6807 (VOC2012 val) ---\")\nfinal_loss_str = f\"{history['val_loss'][-1]:.4f}\" if EVAL_COMPUTE_LOSS else \"n/a\"\nprint(f\"Val Loss: {final_loss_str} | PA: {history['val_pa'][-1]:.4f} | mIoU: {history['val_miou'][-1]:.4f}\")\nprint(f\"\u6700\u4f18\u6743\u91cd\u5df2\u4fdd\u5b58\u81f3: {BEST_PATH_VOC}\")\n\n# \u4fdd\u5b58\u5f53\u524d\uff08latest\uff09\ntorch.save(model.state_dict(), LATEST_PATH)\nprint(f\"\u5df2\u4fdd\u5b58\u5f53\u524d\u6a21\u578b\u6743\u91cd\u5230: {LATEST_PATH}\")\n\n# \u52a0\u8f7d\u6700\u4f18\u6743\u91cd\u7528\u4e8e\u53ef\u89c6\u5316\nif os.path.isfile(BEST_PATH_VOC):\n    ckpt_voc = torch.load(BEST_PATH_VOC, map_location=torch.device(DEVICE))\n    model.load_state_dict(ckpt_voc['model_state'])\n    print(f\"\\n\u5df2\u52a0\u8f7d VOC \u6700\u4f18\u6743\u91cd\u8fdb\u884c\u53ef\u89c6\u5316: {BEST_PATH_VOC} (epoch={ckpt_voc.get('epoch','?')}, mIoU_VOC={ckpt_voc.get('miou_voc', 0):.4f})\")\nelse:\n    print(\"\\n\u672a\u627e\u5230 VOC \u6700\u4f18\u6743\u91cd\uff0c\u4f7f\u7528\u5f53\u524d\u6a21\u578b\u8fdb\u884c\u53ef\u89c6\u5316\u3002\")\n\nprint(\"\\n--- \u53ef\u89c6\u5316\u9884\u6d4b\u7ed3\u679c (VOC2012 val) ---\")\nvisualize_predictions(model, val_loader, DEVICE, num_images=20, save_dir=VIS_DIR)\n</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_9", "title": "\u7ed3\u679c", "text": "<p>\u5728 Pascal VOC 07+12 \u4e0a\u8bad\u7ec3 80 \u4e2a Epoch\uff0c\u8017\u65f6 19332s\uff0c\u6700\u540e\u7684 mIoU \u4e3a 0.5342\u3002\u8bf6\uff0c\u60a8\u522b\u77a7\u8fd9 mIoU \u8fd8\u6253\u4e0d\u8fc7 FCN-8s\uff0c\u90a3\u8fb9\u53ef\u662f\u7528\u4e0a\u4e86 VGG \u9884\u8bad\u7ec3\u53c2\u6570\u7684\u5927\u5934\u2014\u2014\u4e5f\u5c31\u662f pool5 \u4e4b\u540e\u7684\u4e24\u4e2a\u7ebf\u6027\u5c42\u554a\uff01</p> <p></p> <p>\u4e0b\u9762\u662f\u51e0\u4e2a\u6837\u4f8b\u56fe\u50cf\uff1a</p> <p></p> <p></p> <p></p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_10", "title": "\u788e\u788e\u5ff5", "text": "<p>\u8bb0\u5f97\u5f53\u65f6\u5b66\u6570\u5b57\u903b\u8f91\u7684\u65f6\u5019\uff0c\u8001\u662f\u6709\u9898\u76ee\u6765\u8003\u5bdf\u591a\u8def\u9009\u62e9\u5668 MUX\uff0c\u4e5f\u5c31\u662f\u6839\u636e n \u4e2a\u8f93\u5165\u7aef\u9ad8\u4f4e\u7535\u5e73\uff0c\u628a\u5b83\u770b\u4f5c\u4e00\u4e2a\u4e8c\u8fdb\u5236\u6570 x\uff0c\u4ece\u800c\u6fc0\u6d3b\u7b2c x \u4e2a\u8f93\u51fa\u7aef\u3002\u8fd9\u79cd\u9898\u76ee\u4e00\u822c\u4e0d\u4f1a\u8ba9\u591a\u8def\u9009\u62e9\u5668\u505a\u81ea\u5df1\u7684\u672c\u804c\u5de5\u4f5c\uff0c\u800c\u662f\u5229\u7528\u81ea\u5df1\u53ef\u4ee5\u8fdb\u884c\u4ece\u4e8c\u8fdb\u5236\u7f16\u7801\u5230\u903b\u8f91\u6700\u5c0f\u9879\u7684\u201c\u8bd1\u7801\u201d\u6765\u5e72\u82b1\u6d3b\u2014\u2014\u6bd4\u5982\u6413\u4e00\u4e2a\u5168\u52a0\u5668\u3002</p> <p>\u5176\u5b9e\u5168\u5377\u79ef\u67b6\u6784\u4e5f\u662f\u5982\u6b64\u3002\u5355\u7eaf\u505a\u8bed\u4e49\u5206\u5272\uff0c\u8fd8\u662f\u592a\u9650\u5236\u5b83\u7684\u53d1\u6325\u4e86\u3002\u4e8b\u5b9e\u4e0a\u5b83\u5c55\u793a\u4e86\u4e00\u79cd\u50cf\u7d20\u7ea7\u7684\u7f16\u7801\u5668\u2014\u2014\u89e3\u7801\u5668\u7684\u901a\u7528\u67b6\u6784\uff0c\u4ece\u800c\u53ef\u4ee5\u7528\u5728\u5404\u79cd\u751f\u6210\u5f0f\u4efb\u52a1\u4e0a\u9762\u3002\u65e0\u8bba\u662f VAE \u8fd8\u662f DC-GAN\uff0c\u6211\u4eec\u90fd\u5728\u5176\u4e2d\u770b\u5230\u4e86\u53cd\u5377\u79ef\u7684\u5e94\u7528\uff1b\u800c\u5927\u540d\u9f0e\u9f0e\u7684 DDPM\uff0c\u5176\u751f\u6210\u6b63\u662f\u4f7f\u7528\u4e86 U-Net \u67b6\u6784\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_11", "title": "\u76ee\u6807\u68c0\u6d4b", "text": "<p>\u76ee\u6807\u68c0\u6d4b\u7684\u7684\u76ee\u7684\u5728\u4e8e\u6253\u76ee\u6807\u6846\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u5982\u4f55\u751f\u6210\u8fd9\u4e00\u76ee\u6807\u6846\u5462\uff1f\u53e4\u65e9\u7684\u7406\u8bba R-CNN \u8ba4\u4e3a\uff1a\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u5f3a\u5927\u7684\u56fe\u50cf\u5206\u7c7b\u7f51\u7edc\u4e86\uff0c\u90a3\u4e48\u6211\u4eec\u53ea\u9700\u8981\u6bcf\u6b21\u9009\u53d6\u56fe\u50cf\u7684\u4e00\u90e8\u5206\u4e22\u7ed9\u5206\u7c7b\u7f51\u7edc\uff0c\u518d\u53d6\u9884\u6d4b\u6982\u7387\u6700\u9ad8\u7684\u90a3\u4e2a\u6846\u5373\u53ef\u3002\u8fd9\u6837\u505a\u786e\u5b9e\u5f88\u6709\u9053\u7406\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e2a\u5f88\u5927\u7684\u56fe\u50cf\uff0c\u6bd4\u5982\u6211\u7684\u76f8\u673a\u62cd\u6444\u7684 5424x3612 \u7684\u4e0b\u9762\u8fd9\u5f20\u56fe\u50cf\uff1a</p> <p></p> <p>\u5982\u679c\u8fd8\u662f\u7528 R-CNN \u7684\u65b9\u6cd5\u505a\uff0c\u96be\u70b9\u5728\u4e8e\uff1a\u5df2\u77e5 R-CNN \u5728 ImageNet \u7684 224x224 \u4e0a\u9762\u90fd\u8981\u751f\u6210\u63a5\u8fd1 2000 \u4e2a\u6846\uff0c\u90a3\u4e48\u8003\u8651\u8fd9\u4e2a\u56fe\u5207\u5f00\u6210 224x224 \u7684\u5757\uff0c\u4e00\u5171\u5c31\u8981\u751f\u6210 780910 \u4e2a\u6846\uff01\u5047\u8bbe\u6bcf\u4e2a\u6846\u63a8\u7406\u65f6\u95f4 1ms\uff0c\u4e14\u5168\u90e8\u90fd\u80fd\u4ee5\u6279\u91cf 128 \u6570\u636e\u5e76\u884c\uff0c\u4ecd\u7136\u9700\u8981 6s \u624d\u80fd\u5b8c\u6210\u57fa\u7840\u7684\u63a8\u7406\uff0c\u800c\u4e14\u8fd9\u8fd8\u4e0d\u5305\u542b\u540e\u7eed\u7684 NMS \u7b49\u64cd\u4f5c\u3002\u5728\u540e\u9762\u6211\u4eec\u4f1a\u770b\u5230\uff0cYOLO v1 \u628a\u6846\u7684\u6570\u91cf\u538b\u7f29\u5230\u4e86 38265 \u4e2a\uff08\u6309\u6bcf\u4e2a cell 32px \u7b97\uff09\uff0c\u4e5f\u5c31\u662f R-CNN \u7684\u4e8c\u5341\u5206\u4e4b\u4e00\u3002\u4e5f\u5c31\u662f\u8bf4 0.3s \u5c31\u53ef\u4ee5\u51fa\u56fe\uff0c\u8fd9\u5c31\u4f7f\u5f97\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u6210\u4e3a\u53ef\u80fd\u3002</p> <p></p> <p>\uff08\u756a\u5916\uff1aSCP-CN-2999 \u662f\u6211\u5fc3\u76ee\u4e2d\u7684\u4e2d\u5206\u5341\u4f73\u6587\u6863\u4e4b\u4e00\u3002\u5982\u679c\u4f60\u538c\u70e6\u4e86\u5bf9\u4eba\u5de5\u667a\u80fd\u7684\u5f17\u6d1b\u80af\u65af\u5766\u53d9\u4e8b\uff0c\u5e76\u8ba4\u4e3a\u90a3\u4e9b\u4eba\u4e0e\u4eba\u5de5\u667a\u80fd\u5408\u4f5c\u5171\u751f\u7684\u70b9\u5b50\u662f\u963f\u897f\u83ab\u592b\u65f6\u4ee3\u5c31\u73a9\u70c2\u4e86\u7684\u4e1c\u897f\uff0c\u90a3\u4e48\u6b22\u8fce\u9605\u8bfb\u8fd9\u7bc7\u6587\u6863\u3002\uff09</p> <p>\u672c\u6587\u5bf9\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u53ea\u4ecb\u7ecd YOLO \u6a21\u578b\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#yolo-v1", "title": "YOLO v1", "text": ""}, {"location": "DNN/model-expr/S-and-D-models-replication/#_12", "title": "\u6a21\u578b\u67b6\u6784", "text": "<p>\u90a3\u4e48\uff0cYOLO \u91c7\u7528\u4e86\u4ec0\u4e48\u65b9\u6cd5\u6765\u7f29\u51cf\u76ee\u6807\u6846\u5462\uff1f\u4e0d\u50cf R-CNN \u4e00\u6837\u9009\u62e9\u5148\u5b66\u4e60\u76ee\u6807\u6846\u7684\u4f4d\u7f6e\u5206\u5e03\u518d\u542f\u53d1\u5f0f\u5730\u641c\u5bfb\uff0cYOLO \u9009\u62e9\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u83b7\u5f97\u76ee\u6807\u6846\u3002\u6bd4\u5982\u6709\u4e00\u5f20 224x224 \u7684 ImageNet \u56fe\u50cf\uff0c\u6211\u4eec\u9996\u5148\u53ef\u4ee5\u5212\u5206\u4e00\u4e2a 7x7 \u7684\u7f51\u683c\uff0c\u6bcf\u4e2a\u5c0f\u683c\u5b50\u7684\u8fb9\u957f\u662f 32px\u3002\u5bf9\u4e8e\u8fd9\u4e2a 32x32 \u7684\u5c0f\u56fe\u50cf\u5e72\u4ec0\u4e48\u5462\uff1f\u96be\u9053\u662f\u50cf R-CNN \u4e00\u6837\u76f4\u63a5\u5206\u7c7b\u5417\uff1f\u4e0d\u7136\u3002</p> <p>\u4fd7\u8bed\u6709\u8a00\uff0c\u201c\u7ba1\u4e2d\u7aa5\u8c79\uff0c\u53ef\u89c1\u4e00\u6591\u201d\u3002\u6211\u4eec\u8003\u8651\u67d0\u4e00\u4e2a\u7269\u4f53\u7684\u4e2d\u5fc3\u843d\u5165\u4e86\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\uff0c\u90a3\u4e48\u8fd9\u4e2a\u683c\u5b50\u5c31\u5f88\u53ef\u80fd\u6709\u4e00\u90e8\u5206\u4fe1\u606f\u77e5\u9053\u8fd9\u4e2a\u7269\u4f53\u662f\u4ec0\u4e48\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5bf9\u4e8e\u8fd9\u4e03\u4e03\u56db\u5341\u4e5d\u4e2a\u683c\u5b50\uff0c\u6211\u4eec\u8ba9\u6bcf\u4e00\u4e2a\u683c\u5b50\u90fd\u6765\u770b\u770b\u843d\u5728\u683c\u5b50\u91cc\u7684\u662f\u4ec0\u4e48\u4e1c\u897f\uff0c\u4e5f\u5c31\u662f\u7ed9\u51fa\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u4e00\u4e2a\u683c\u5b50\u7684\u4fe1\u606f\u57fa\u672c\u4e0a\u4e5f\u5dee\u4e0d\u591a\u80fd\u8ba9\u6211\u4eec\u77e5\u9053\u8fd9\u4e2a\u7269\u4f53\u5927\u6982\u7684\u5c3a\u5bf8\u5982\u4f55\uff0c\u6bd4\u5982\u8bf4\u683c\u5b50\u91cc\u9762\u6709\u4e2a\u4eba\u8138\uff0c\u90a3\u4e48\u5f80\u4e0b\u753b\u4e00\u4e2a6~8\u5934\u8eab\u7684\u6846\u57fa\u672c\u4e0a\u5c31\u6ca1\u9519\u4e86\u3002\u5177\u4f53\u5230\u5e95\u662f\u51e0\u5934\u8eab\uff0c\u6a21\u578b\u4e0d\u786e\u5b9a\uff0c\u90a3\u5c31\u516d\u5934\u8eab\u4e03\u5934\u8eab\u516b\u5934\u8eab\u90fd\u8bd5\u4e00\u4e0b\uff0c\u591a\u6253\u51e0\u4e2a\u6846\uff0c\u603b\u6709\u4e00\u4e2a\u80fd\u8499\u5bf9\u3002</p> <p>\u8fd9\u91cc\u53ef\u80fd\u6709\u4e00\u4e2a\u8bef\u89e3\uff08\u6bd5\u7adf\u8fd9\u79cd\u8bf4\u660e\u5f0f\u7684\u8bed\u8a00\u4e0d\u751a\u7cbe\u786e\uff09\uff0c\u5c31\u662f\u4f1a\u4ee5\u4e3a\u6211\u4eec\u53ea\u6839\u636e\u683c\u5b50\u91cc\u9762\u7684\u4e1c\u897f\u6765\u6253\u6846\u3002\u4f46\u5176\u5b9e\u4e0d\u662f\u7684\uff0c\u6211\u4eec\u4e0d\u662f\u5148\u7ed9\u56fe\u50cf\u5206\u5757\u7136\u540e\u9650\u5236\u6bcf\u4e00\u4e2a\u683c\u5b50\u7684\u611f\u53d7\u91ce\u53ea\u5728\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\u3002\u4e8b\u5b9e\u4e0a\u6211\u4eec\u662f\u57fa\u4e8e\u56fe\u50cf\u6574\u4f53\u7684\u4fe1\u606f\uff0c\u6700\u540e\u751f\u6210 S x S \u4e2a\u683c\u5b50\u548c\u6bcf\u4e2a\u683c\u5b50\u7684 B \u4e2a\u6846\u3002\u4e5f\u5c31\u662f\u8bf4\u63a8\u7b97\u6846\u7684\u5927\u5c0f\u4ee5\u53ca\u8be5\u653e\u8fdb\u54ea\u4e2a\u683c\u5b50\u90fd\u662f\u9aa8\u5e72\u7f51\u5e94\u8be5\u5e72\u7684\u6d3b\uff0c\u5b83\u7684\u611f\u53d7\u91ce\u662f\u6574\u5f20\u56fe\u50cf\u3002\u5982\u679c\u8fd8\u662f\u89c9\u5f97\u542b\u7cca\uff0c\u8bf7\u63a5\u7740\u8bfb\u3002</p> <p>\u7528\u5f62\u5f0f\u5316\u7684\u8bed\u8a00\u6765\u8bf4\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u683c\u5b50\u8d1f\u8d23\u9884\u6d4b \\(B\\) \u4e2a\u6846\uff0c\u6bcf\u4e2a\u6846\u6709 \\(x,y,w,h\\) \u56db\u4e2a\u53c2\u6570\uff0c\u5bf9\u5e94\u6846\u7684\u4e2d\u5fc3\u70b9\u76f8\u5bf9\u56fe\u50cf\u5de6\u4e0a\u89d2\u7684\u5750\u6807 \\(x,y\\) \u4e0e\u6846\u7684\u5c3a\u5bf8 \\(w,h\\)\uff0c\u8fd9\u56db\u4e2a\u53c2\u6570\u5168\u90e8\u6839\u636e\u56fe\u50cf\u5c3a\u5bf8\u5f52\u4e00\u5316\u5230 \\([0,1]\\) \u4e4b\u95f4\u65b9\u4fbf\u53cd\u5411\u4f20\u64ad\u3002\u540c\u65f6\uff0c\u6846\u6253\u7684\u51c6\u4e0d\u51c6\uff0c\u8fd8\u9700\u8981\u4e00\u4e2a\u7f6e\u4fe1\u5ea6 \\(c\\) \u6765\u8861\u91cf\u3002\u5177\u4f53\u89e3\u91ca\u5728\u4e0b\u4e00\u6bb5\u3002\u540c\u65f6 YOLO v1 \u5047\u5b9a\u4e00\u4e2a\u683c\u5b50\u91cc\u9762\u53ea\u6709\u4e00\u4e2a\u7269\u4f53\uff0c\u6240\u4ee5\u8fd8\u8981\u7ed9\u51fa\u7269\u4f53\u6240\u5c5e\u7684\u5404\u7c7b\u522b\u7684\u6982\u7387\uff08\u4e0b\u4e00\u6bb5\u518d\u89e3\u91ca\uff09\u3002\u4ee5\u5728 Pascal VOC \u4e0a\u8bad\u7ec3\u7684 YOLO v1 \u6765\u8bf4\uff0c\u4e00\u5f20\u56fe\u7247\u753b\u6210 \\(S\\times S\\) \u4e5f\u5c31\u662f 7x7 \u7684\u7f51\u683c\uff0c\u6bcf\u4e2a\u7f51\u683c\u8d1f\u8d23\u5bf9\u683c\u5b50\u91cc\u9762\u7684\u5185\u5bb9\u6253\u6846\u3002\u4e00\u4e2a\u683c\u5b50\u6253\u4e24\u4e2a\u6846\uff0c\u8fd8\u8d1f\u8d23\u8f93\u51fa 20 \u4e2a\u7c7b\u522b\uff0c\u90a3\u4e48\u4e00\u4e2a\u683c\u5b50\u7684\u8f93\u51fa\u5c31\u662f \\(2\\times 5+20=30\\) \u7ef4\u7684\u5411\u91cf\uff0c\u800c\u6574\u4e2a\u7f51\u7edc\u7684\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a <code>(7,7,30)</code> \u7684\u5f20\u91cf\u3002</p> <p>\u521a\u521a\u63d0\u5230\u6253\u6846\u4f7f\u7528\u7684\u662f\u7f6e\u4fe1\u5ea6\u3002\u6211\u4eec\u77e5\u9053\u6253\u6846\u65e0\u975e\u5c31\u662f\u8981\u6253\u7684\u51c6\uff0c\u4e0d\u4ec5\u4f4d\u7f6e\u8981\u51c6\uff0c\u8bc6\u522b\u4e5f\u8981\u51c6\u3002\u4f4d\u7f6e\u51c6\u4e0d\u51c6\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u7528\u771f\u5b9e\u6846\u548c\u9884\u6d4b\u6846\u7684 IoU \u5c31\u53ef\u4ee5\u4e86\u3002\u800c\u7531\u4e8e\u4e00\u822c\u7684\u7f51\u7edc\u53ea\u80fd\u8bc6\u522b\u7c7b\u522b\u662f\u4ec0\u4e48\u800c\u4e0d\u80fd\u8bc6\u522b\u7c7b\u522b\u662f\u5426\u5b58\u5728\uff08\u4e4b\u524d\u770b\u5230\u67d0\u540c\u5b66\u7ed9\u4e00\u4e2a MNIST \u5206\u7c7b\u5668\u5582\u4e86\u4e00\u4e2a\u4e94\u89d2\u661f\uff0c\u7136\u540e\u6a21\u578b\u715e\u6709\u4ecb\u4e8b\u5730\u7ed9\u51fa\u4e86\u7c7b\u522b 8 \u7684\u9ad8\u8fbe 99% \u7684\u5206\u7c7b\u6982\u7387\uff09\uff0c\u4e8e\u662f\u6211\u4eec\u8fd8\u9700\u8981\u5f15\u5165\u4e00\u4e2a\u5224\u65ad\u662f\u5426\u5b58\u5728\u5f85\u5206\u7c7b\u5bf9\u8c61\u7684\u6982\u7387 \\(P(\\mathrm{Obj})\\)\uff0c\u4e58\u8d77\u6765\u5c31\u5f97\u5230\u7f6e\u4fe1\u5ea6\u4e86\uff1a\\(c=P(\\mathrm{Obj})\\times \\mathrm{IoU}\\)\u3002\u8fd9\u4ee3\u8868\u6a21\u578b\u5bf9\u5f97\u5230\u7684\u8fd9\u4e2a\u6846\u7684\u4fe1\u5fc3\u3002\u4e5f\u5c31\u662f\u6846\u91cc\u9762\u6709\u7269\u4f53\u5e76\u4e14\u9884\u6d4b\u548c\u771f\u5b9e\u8d8a\u63a5\u8fd1\uff0c\u8fd9\u4e2a\u6846\u5c31\u8d8a\u53ef\u4fe1\u3002\u5f53\u7136\u8fd9\u53ea\u662f\u6211\u4eec\u7684\u4e00\u53a2\u60c5\u613f\uff0c\u5177\u4f53\u7684\u7f6e\u4fe1\u5ea6\u8fd8\u9700\u8981\u53cd\u5411\u4f20\u64ad\u6765\u7b97\u51fa\u6765\u3002</p> <p>\u800c\u7c7b\u522b\u6982\u7387\u5176\u5b9e\u662f\u4e00\u4e2a\u6761\u4ef6\u6982\u7387\uff0c\u662f\u5728\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\u6709\u5bf9\u8c61\u7684\u6761\u4ef6\u4e0b\uff0c\u5bf9\u5bf9\u8c61 \\(i\\) \u7684\u5206\u7c7b\u6982\u7387 \\(P(\\mathrm{Class}_i|\\mathrm{Obj})\\)\u3002\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6846\uff0c\u6211\u4eec\u628a\u5b83\u7684\u7f6e\u4fe1\u5ea6\u4e58\u4e0a\u5206\u7c7b\u6982\u7387\u7684\u5411\u91cf\uff0c\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u5f97\u5206\uff1a\\(s=P(\\mathrm{Class}_i|\\mathrm{Obj})\\times P(\\mathrm{Obj})\\times \\mathrm{IoU}=P(\\mathrm{Class}_i\\mathrm{\\ with\\ Obj\\ exists})\\times \\mathrm{IoU}\\)\u3002\u8fd9\u4e2a\u5f97\u5206\u4ee3\u8868\u4e86\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u7c7b\u522b\uff0c\u6a21\u578b\u5f97\u5230\u7684\u6846\u7684\u8d28\u91cf\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\u5bf9\u4e8e\u80cc\u666f\u683c\u5b50\u800c\u8a00\uff0c\\(s\\) \u5e94\u8be5\u662f\u5168\u96f6\u5411\u91cf\uff1b\u800c\u5bf9\u4e8e\u4e2d\u5fc3\u843d\u5728\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\u7684\u771f\u5b9e\u7684\u6846\u800c\u8a00\uff0c\\(s\\) \u5e94\u8be5\u662f\u4e00\u4e2a one-hot \u5411\u91cf\uff0c\u5176\u4e2d 1 \u5bf9\u5e94\u7684\u5c31\u662f\u90a3\u4e2a\u771f\u5b9e\u6846\u7684\u7c7b\u522b\u3002\u8fd9\u6837\u5728\u63a8\u7406\u65f6\uff0c\u5bf9\u4e8e\u6a21\u578b\u5f97\u5230\u7684\u8bf8\u591a\u6846\u800c\u8a00\uff0c\u6211\u4eec\u53ea\u9700\u8981\u6839\u636e\u5f97\u5206\u6392\u5e8f\uff0c\u5c31\u53ef\u4ee5\u7b5b\u9009\u51fa\u6700\u597d\u7684\u90a3\u4e9b\u6846\u4e86\u3002</p> <p>\u201c\u6bcf\u4e2a\u683c\u5b50\u53ea\u9884\u6d4b\u4e00\u4e2a\u7c7b\u522b\u201d\u56fa\u7136\u7b80\u5316\u4e86\u6a21\u578b\uff0c\u4f46\u4e5f\u5f88\u6709\u53ef\u80fd\u5e26\u6765\u4fe1\u606f\u7684\u635f\u5931\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\uff0cYOLO v1 \u5728\u5c0f\u7269\u4f53\u7684\u9884\u6d4b\u4e0a\u529b\u4e0d\u4ece\u5fc3\u3002\u5047\u8bbe\u4e24\u4e2a\u5c0f\u7269\u4f53\u90fd\u5305\u5728\u4e00\u4e2a\u683c\u5b50\u91cc\u9762\uff0c\u90a3\u8fd9\u4e2a\u683c\u5b50\u8be5\u9884\u6d4b\u4ec0\u4e48\u5462\uff1f\u800c\u5982\u679c\u6211\u4eec\u52a0\u7ec6\u683c\u5b50\uff0c\u5219\u4f1a\u5e26\u6765\u5e73\u65b9\u7ea7\u7684\u590d\u6742\u5ea6\u589e\u957f\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_13", "title": "\u635f\u5931\u51fd\u6570", "text": "<p>\u4e0b\u9762\u6211\u4eec\u9700\u8981\u6307\u6807\u6765\u8bc4\u4f30\u8fd9\u4e2a\u6a21\u578b\u6253\u6846\u7684\u8d28\u91cf\u5982\u4f55\uff0c\u8fd9\u6837\u624d\u80fd\u8ba9\u6a21\u578b\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0\u8fdb\u5316\u3002</p> <p>\u9996\u5148\u6211\u4eec\u6765\u770b\u635f\u5931\u51fd\u6570\u3002\u6211\u4eec\u6765\u56de\u987e\u4e00\u4e0b\u6253\u6846\u7684\u51e0\u4e2a\u8981\u7d20\uff1a\u9996\u5148\u5b9a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u7136\u540e\u7b97\u6846\u7684\u5c3a\u5bf8\uff0c\u7ed9\u51fa\u7f6e\u4fe1\u5ea6\uff0c\u6700\u540e\u4e00\u90e8\u5206\u662f\u6982\u7387\u3002\u5176\u4e2d\u6bcf\u4e00\u4e2a\u8981\u7d20\u90fd\u8981\u517c\u987e\u3002</p> <p>\u9996\u5148\u6211\u4eec\u8981\u786e\u5b9a\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u683c\u5b50\u800c\u8a00\uff0c\u5b83\u7684\u6846\u5728\u9884\u6d4b\u4ec0\u4e48\u3002YOLO v1 \u4e3a\u4e86\u7b80\u5316\uff0c\u9996\u5148\u5bf9\u4e8e\u6bcf\u4e2a\u683c\u5b50\u5148\u7b5b\u4e00\u904d\uff0c\u627e\u5230\u90a3\u4e2a\u4e2d\u5fc3\u70b9\u843d\u5728\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\u7684\u771f\u5b9e\u6846(a ground truth)\uff0c\u5982\u679c\u6709\u771f\u5b9e\u6846\uff08\u539f\u8bba\u6587\u53eb\u8fd9\u4e2a\u7269\u4f53\u51fa\u73b0\u5728\u683c\u5b50\u91cc\u9762\uff09\uff0c\u6211\u4eec\u7528 \\(1_{i}^\\mathrm{obj}\\) \u6765\u6307\u793a\u683c\u5b50 \\(i\\) \u6709\u7269\u4f53\u51fa\u73b0\u5728\u8fd9\u4e2a\u683c\u5b50\u91cc\u9762\u3002</p> <p>\u4e0b\u9762\uff0c\u65e2\u7136\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u771f\u5b9e\u6846\uff0c\u5c31\u53ef\u4ee5\u9009\u683c\u5b50\u91cc\u9762\u548c\u5b83 IoU \u6700\u5927\u7684\u90a3\u4e2a\u9884\u6d4b\u6846(the predictor responsible for the ground truth)\u8fdb\u884c\u914d\u5bf9\uff0c\u6211\u4eec\u628a\u90a3\u4e2a\u771f\u5b9e\u6846\u53eb\u505a\u201c\u76ee\u6807\u6846\u201d(the ground truth)\uff08\u539f\u8bba\u6587\u53eb\u505a\u8fd9\u4e2a\u9884\u6d4b\u6846\u8d1f\u8d23\u8fd9\u4e2a\u771f\u5b9e\u6846\uff0c\u4e5f\u5c31\u662f\u8d1f\u8d23\u5b83\u7684\u76ee\u6807\u6846\uff09\u3002</p> <p>\u6211\u4eec\u7528\u6307\u6807 \\(1_{ij}^\\mathrm{obj}\\) \u8868\u793a\u7b2c \\(i\\) \u4e2a\u683c\u5b50\u7684\u7b2c \\(j\\) \u4e2a\u6846\u5b58\u5728\u4e00\u4e2a\u5bf9\u5e94\u7684\u76ee\u6807\u6846\uff0c\u8fd9\u5c31\u8bf4\u660e\u8fd9\u4e2a\u6846\u662f\u548c\u5b83\u683c\u5b50\u7684\u771f\u5b9e\u6846 IoU \u6700\u5927\u7684\u90a3\u4e2a\u6846\u3002\u5982\u679c\u4e0d\u5b58\u5728\u76ee\u6807\u6846\uff0c\u5c31\u4f7f\u7528 \\(1_{ij}^\\mathrm{noobj}\\) \u6765\u6307\u793a\uff0c\u8bf4\u660e\u5b83\u7684 IoU \u4e0d\u662f\u6700\u5927\u7684\uff0c\u6216\u8005\u5b83\u5bf9\u5e94\u7684\u683c\u5b50\u6839\u672c\u6ca1\u6709\u771f\u5b9e\u6846\u3002\u4e0b\u9762\u6211\u4eec\u5c31\u53ef\u4ee5\u8ba1\u7b97\u6846\u7684\u635f\u5931\uff1a</p> <p>\u5bf9\u4e8e\u7b2c \\(i\\) \u4e2a\u683c\u5b50\u7684\u7b2c \\(j\\) \u4e2a\u6846\uff0c\u5176\u4e2d\u5fc3\u70b9\u7684\u8bef\u5dee\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528\u9884\u6d4b\u6846\u4e2d\u5fc3\u70b9\u5230\u76ee\u6807\u6846\u4e2d\u5fc3\u70b9\u8ddd\u79bb\u6a21\u957f\u7684\u5e73\u65b9\u8861\u91cf\uff1a</p> \\[ \\mathcal{L}_\\mathrm{center}=\\sum_i^{S^2}\\sum_j^{B} 1_{ij}^\\mathrm{obj}\\left[(x_{ij}-x_{ij}^{\\mathrm{true}})^2+(y_{ij}-y_{ij}^{\\mathrm{true}})^2\\right] \\] <p>\u800c\u5c3a\u5bf8\u4e0a\u7684\u8bef\u5dee\u5982\u679c\u4ecd\u7136\u662f\u76f4\u63a5\u76f8\u51cf\u518d\u6c42\u5e73\u65b9\u7684\u7b97\u6cd5\uff0c\u4f1a\u5bfc\u81f4\u76f8\u540c\u7684\u8bef\u5dee\u5bf9\u5927\u6846\u7684\u60e9\u7f5a\u4e0d\u5408\u7406\u5730\u5927\u4e8e\u5c0f\u6846\uff0c\u56e0\u4e3a\u4ece\u89c2\u611f\u548c\u5c3a\u5ea6\u800c\u8a00\uff0c\u540c\u6837\u662f 10px \u7684\u5dee\u503c\uff0c\u5bf9\u4e8e\u5927\u6846\u800c\u8a00\u65e0\u8db3\u8f7b\u91cd\uff0c\u5bf9\u4e8e\u5c0f\u6846\u5374\u662f\u5f88\u5927\u7684\u504f\u79fb\u3002\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u9700\u8981\u628a\u5bf9\u5927\u6846\u7684\u8861\u91cf\u5c3a\u5ea6\u8c03\u5c0f\u800c\u5bf9\u5c0f\u6846\u7684\u8861\u91cf\u5c3a\u5ea6\u8c03\u5927\u3002\u5176\u5b9e \\(x^{1/p}(p&gt;1)\\) \u5c31\u80fd\u505a\u5230\u8fd9\u4e2a\u6620\u5c04\uff0c\u5728\u8bba\u6587\u91cc\u9762\uff0c\u53d6\u5230\u7684\u662f \\(p=2\\)\u3002\u73b0\u5728\u5c31\u53ef\u4ee5\u7c7b\u4f3c\u5730\u5199\u51fa\u5c3a\u5bf8\u7684\u635f\u5931\u4e86\uff1a</p> \\[ \\mathcal{L}_\\mathrm{size}=\\sum_i^{S^2}\\sum_j^{B}1_{ij}^\\mathrm{obj}\\left[(\\sqrt {w_{ij}}-\\sqrt{w_{ij}^{\\mathrm{true}}})^2+(\\sqrt{h_{ij}}-\\sqrt{h_{ij}^{\\mathrm{true}}})^2\\right] \\] <p>\u4e0b\u4e00\u90e8\u5206\u662f\u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u3002\u6211\u4eec\u77e5\u9053\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u6846\uff0c\u7406\u60f3\u7684\u7f6e\u4fe1\u5ea6\u5982\u4e0b\uff1a</p> \\[ c_{ij}^\\mathrm{ideal}=\\left\\{ \\begin{align*}     &amp;\\mathrm{IoU}^{\\mathrm{true}}_{\\mathrm{pred}},&amp;1_{ij}^\\mathrm{obj}=1\\\\     &amp;0,&amp;1_{ij}^\\mathrm{noobj}=1 \\end{align*}\\right. \\] <p>\u8fd9\u91cc\u7684\u7f6e\u4fe1\u5ea6\u635f\u5931\u7684\u5173\u952e\u662f\u8981\u5206\u8fa8\u6b63\u786e\u7684\u76ee\u6807\u548c\u80cc\u666f\uff0c\u5982\u679c\u524d\u9762\u4e24\u9879\u635f\u5931\u90fd\u5f88\u4f4e\uff0cIoU \u81ea\u7136\u76f8\u5f53\u9ad8\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684\u5173\u952e\u5c31\u662f\uff0c\u5bf9\u4e8e\u9884\u6d4b\u6846\u800c\u8a00\uff0c\u6211\u4eec\u9700\u8981\u8ba9\u5b83\u76f8\u5bf9\u5bf9\u5e94\u7684\u76ee\u6807\u6846\u7684\u7f6e\u4fe1\u5ea6\u5c3d\u91cf\u9ad8\uff08\u5bf9\u5e94\u76ee\u6807\uff0c\u662f\u6b63\u6837\u672c\uff09\uff0c\u800c\u5982\u679c\u6ca1\u6709\u5bf9\u5e94\u7684\u76ee\u6807\u6846\uff0c\u5219\u7f6e\u4fe1\u5ea6\u5c3d\u91cf\u4f4e\uff08\u5bf9\u5e94\u80cc\u666f\u6216\u8005\u975e\u6700\u4f18\u7684\u9884\u6d4b\u6846\uff0c\u662f\u8d1f\u6837\u672c\uff09\u3002</p> <p>\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7684\u635f\u5931\u8ba1\u7b97\u5c31\u662f\u628a\u521a\u521a\u7684\u5f0f\u5b50\u62c6\u5f00\uff0c\u4ecd\u65e7\u4f7f\u7528 MSE\u3002\u521a\u521a\u63d0\u5230\u6211\u4eec\u9700\u8981\u8ba9\u4e0d\u540c\u7684\u9884\u6d4b\u6846\u7f6e\u4fe1\u5ea6\u6709\u9ad8\u4f4e\u7684\u5206\u914d\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u8ba9\u9700\u8981\u62c9\u9ad8\u7f6e\u4fe1\u5ea6\u7684\uff0c\u62c9\u5230 \\(1\\)\uff0c\u9700\u8981\u538b\u4f4e\u7684\uff0c\u538b\u5230 \\(0\\)\uff1a</p> \\[ \\begin{align*}     \\mathcal{L}_{\\mathrm{P}}&amp;=\\sum_i^{S^2}\\sum_j^{B}1_{ij}^\\mathrm{obj}\\left(c_{ij}-1\\right)^2\\\\     \\mathcal{L}_{\\mathrm{N}}&amp;=\\sum_i^{S^2}\\sum_j^{B}1_{ij}^\\mathrm{noobj}\\left(c_{ij}-0\\right)^2 \\end{align*} \\] <p>\u6700\u540e\u5c31\u662f\u5206\u7c7b\u8bef\u5dee\u4e86\u3002\u7531\u4e8e\u5206\u7c7b\u662f\u7531\u683c\u5b50\u8fdb\u884c\u7684\uff0c\u56e0\u6b64\u8fd9\u4e00\u90e8\u5206\u662f\u683c\u5b50\u7684\u635f\u5931\u3002\u56de\u5fc6\u4e00\u4e0b\uff0c\u6211\u4eec\u4e4b\u524d\u4f7f\u7528 \\(1_{i}^\\mathrm{obj}\\) \u6765\u6307\u793a\u67d0\u4e2a\u683c\u5b50\u6709\u5bf9\u5e94\u6846\u7684\u4e2d\u5fc3\u70b9\u843d\u5230\u683c\u5b50\u91cc\u9762\u3002\u539f\u8bba\u6587\u8fd8\u662f\u7528\u7684 MSE\uff0c\u4e0d\u8fc7\u6211\u89c9\u5f97\u5206\u7c7b\u4efb\u52a1\u7528\u4ea4\u53c9\u71b5\u663e\u7136\u66f4\u5408\u9002\uff1a</p> \\[ \\mathcal{L}_{\\mathrm{class}}=\\sum_i ^{S^2}1_{i}^\\mathrm{obj}CE(p_i||\\mathrm{one\\_hot}_i^{\\mathrm{obj}}) \\] <p>\u6700\u540e\u628a\u4ed6\u4eec\u52a0\u6743\u8d77\u6765\uff1a</p> \\[ \\mathcal{L}_{\\mathrm{YOLO}}=\\lambda_{\\mathrm{coord}}(\\mathcal{L}_\\mathrm{center}+\\mathcal{L}_\\mathrm{size})+\\mathcal{L}_{\\mathrm{P}}+\\lambda_{\\mathrm{noobj}}\\mathcal{L}_{\\mathrm{N}}+\\mathcal{L}_{\\mathrm{class}} \\] <p>\u8fd9\u4e2a\u52a0\u6743\u4e5f\u662f\u6709\u8bf4\u6cd5\u7684\u3002\u6211\u4eec\u7684\u4f18\u5148\u7ea7\u662f\u6253\u6846\u6253\u5230\u4f4d\uff0c\u8981\u4e0d\u7136\u540e\u9762\u7684\u7f6e\u4fe1\u5ea6\u8fd9\u4e9b\u90fd\u662f\u626f\u6de1\uff0c\u56e0\u6b64\u8981\u7ed9 \\(\\lambda_{\\mathrm{coord}}\\) \u4e00\u4e2a\u5927\u6743\u91cd\uff0c\u8bba\u6587\u91cc\u9762\u7ed9\u5230\u4e86 \\(5\\)\uff0c\u800c\u4e14\u7531\u4e8e\u4e00\u4e2a\u56fe\u80cc\u666f\u80af\u5b9a\u591a\u4e8e\u76ee\u6807\uff0c\u56e0\u6b64\u603b\u7684 \\(\\mathcal{L}_{\\mathrm{N}}\\) \u80af\u5b9a\u76f8\u5f53\u9ad8\uff0c\u5bfc\u81f4\u6a21\u578b\u503e\u5411\u4e8e\u538b\u7f6e\u4fe1\u5206\uff0c\u628a\u6240\u6709\u7684\u6846\u90fd\u9884\u6d4b\u6210\u80cc\u666f\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u63a7\u5236\u8fd9\u90e8\u5206\u635f\u5931\uff0c\u7ed9 \\(\\lambda_{\\mathrm{noobj}}\\) \u4e00\u4e2a\u5c0f\u6743\u91cd\uff0c\u8bba\u6587\u91cc\u9762\u7ed9\u5230 \\(0.5\\)\u3002</p> <p>\u6700\u540e\u603b\u7ed3\u4e00\u4e0b\u8ba1\u7b97\u6d41\u7a0b\uff1a</p> <p>\u5bf9\u4e8e\u62ff\u5230\u7684\u56fe\u7247\uff0c\u5148\u8fc7\u7f51\u7edc\u63a8\u7406\u5f97\u5230 <code>(S, S, B*5+C)</code> \u7684\u9884\u6d4b\u5f20\u91cf\u3002\u7136\u540e\u626b\u4e00\u904d\u6240\u6709\u683c\u5b50\uff1a</p> <ul> <li>\u5982\u679c\u6709\u4e2a\u771f\u5b9e\u6846 T \u7684\u4e2d\u5fc3\u843d\u5728\u683c\u5b50 \\(i\\) \u91cc\u9762\u4e86\uff1a<ul> <li>\u6b64\u65f6 \\(1_i^{\\mathrm{obj}}=1\\)</li> <li>\u4ece\u683c\u5b50 \\(i\\) \u7684 \\(B\\) \u4e2a\u6846\u91cc\u9762\u627e\u5230\u548c T \u7684 IoU \u6700\u5927\u7684\u6846 \\(j\\)\uff0c\u6b64\u65f6 \\(1_{ij}^{\\mathrm{obj}}=1\\)</li> <li>\u5bf9\u4e8e\u8fd9\u4e2a\u6846\uff0c\u8ba1\u7b97 \\(\\mathcal{L}_1=\\lambda_{\\mathrm{coord}}(\\mathcal{L}_\\mathrm{center}+\\mathcal{L}_\\mathrm{size})+\\mathcal{L}_{\\mathrm{P}}\\)</li> <li>\u5bf9\u4e8e\u5269\u4e0b\u7684 \\(B-1\\) \u4e2a\u6846\uff0c\u8ba1\u7b97 \\(\\mathcal{L}_2=\\lambda_{\\mathrm{noobj}}\\sum^{B-1}\\mathcal{L}_{\\mathrm{N}}\\)</li> <li>\u5bf9\u4e8e\u8fd9\u4e2a\u683c\u5b50\u7684\u7c7b\u522b\u6982\u7387\u5411\u91cf \\(p_i\\)\uff0c\u548c T \u7684\u7c7b\u522b\u505a\u4ea4\u53c9\u71b5\uff0c\u5373\u8ba1\u7b97 \\(\\mathcal{L}_{\\mathrm{class}}=\\sum_i ^{S^2}CE(p_i||\\mathrm{one\\_hot}_i^{\\mathrm{T}})\\)</li> <li>\u683c\u5b50\u7684\u603b\u635f\u5931 \\(\\mathcal{L}_{\\mathrm{objcell}}=\\mathcal{L}_1+\\mathcal{L}_2+\\mathcal{L}_{\\mathrm{class}}\\)</li> </ul> </li> <li>\u5982\u679c\u6ca1\u6709\uff1a<ul> <li>\u6b64\u65f6 \\(1_i^{\\mathrm{obj}}=0\\)</li> <li>\u53ea\u9700\u5bf9\u6240\u6709\u6846\u6c42\u548c\uff1a \\(\\mathcal{L}_{\\mathrm{noobjcell}}=\\mathcal{L}_2=\\lambda_{\\mathrm{noobj}}\\sum^{B}\\mathcal{L}_{\\mathrm{N}}\\)</li> </ul> </li> </ul> <p>\u6700\u540e\u53ef\u4ee5\u5f97\u5230\u6574\u4e2a\u56fe\u7247\u7684\u635f\u5931\uff1a\\(\\mathcal{L}_{\\mathrm{YOLO}}=\\sum\\mathcal{L}_{\\mathrm{objcell}}+\\sum\\mathcal{L}_{\\mathrm{noobjcell}}\\)\u3002</p> <p>\u5982\u679c\u4f60\u662f\u50cf\u6211\u4e00\u6837\u4ece\u8fc7\u7a0b\u5f0f\u7684 C/C++ \u5f00\u59cb\u63a5\u89e6\u7a0b\u5e8f\u8bbe\u8ba1\u8bed\u8a00\u7684\uff0c\u5927\u6982\u4f1a\u89c9\u5f97\u8fd9\u5c31\u662f\u4e00\u4e2a for-if \u5c31\u80fd\u89e3\u51b3\u7684\u4e8b\u3002\u4f46\u662f\u5982\u679c\u4f60\u8bfb\u4e86\u4e0b\u9762\u7684\u635f\u5931\u51fd\u6570\u4ee3\u7801\u5c31\u4f1a\u53d1\u73b0\u5b8c\u5168\u4e0d\u662f\u8fd9\u6837\u505a\u7684\uff0c\u800c\u662f\u4e00\u79cd\u63a5\u8fd1\u51fd\u6570\u5f0f\u7684\u601d\u60f3\u3002</p> <p>\u5982\u679c\u60f3\u611f\u53d7\u8fd9\u79cd\u8303\u5f0f\u8f6c\u79fb (Paradigm Shift) \u5e26\u6765\u7684\u9707\u64bc\uff0c\u5f3a\u70c8\u63a8\u8350\u9605\u8bfb\u4e0b\u9762\u8ba1\u7b97\u635f\u5931\u4f7f\u7528\u7684\u4ee3\u7801\u3002\u914d\u5408\u8fd9\u9996 Paradigm Shift \u98df\u7528\u66f4\u4f73\u54e6~</p> <p>\u6700\u540e\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u201c\u9009\u53d6IoU\u6700\u5927\u7684\u6846\u201d\u8fd9\u4e2a\u64cd\u4f5c\u4f3c\u4e4e\u56e0\u4e3a\u6d89\u53ca\u5230 <code>argmax</code> \u64cd\u4f5c\u800c\u4e0d\u53ef\u5bfc\uff0c\u4f46\u662f\u7531\u4e8e\u6211\u4eec\u5bf9\u4e0d\u540c\u7684\u60c5\u51b5\u5206\u914d\u4e86\u4e0d\u540c\u7684\u635f\u5931\uff0c\u56e0\u6b64\u6211\u4eec\u4e8b\u5b9e\u4e0a\u6267\u884c\u7684\u64cd\u4f5c\u662f\u5bf9\u6700\u5927\u6846\u5229\u7528 \\(\\mathcal{L}_1\\) \u56de\u4f20\u68af\u5ea6\u800c\u5bf9\u5176\u4ed6\u6846\u5229\u7528 \\(\\mathcal{L}_{\\mathrm{N}}\\) \u56de\u4f20\u68af\u5ea6\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7\u6761\u4ef6\u5224\u65ad\u6765\u6784\u5efa\u4e0d\u540c\u7684\u635f\u5931\u8def\u5f84\uff0c\u8fd9\u6837\u6574\u4e2a\u7f51\u7edc\u5c31\u5b8c\u5168\u53ef\u5bfc\u4e86\u3002\u8fd9\u4e00\u70b9\u5199\u6210\u4ee3\u7801\u4e5f\u662f\u6709\u8bf4\u6cd5\u7684\uff0c\u8bf7\u770b VCR\uff1a</p> <p></p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_14", "title": "\u7f51\u7edc\u7ed3\u6784", "text": "<p>YOLO v1 \u4f7f\u7528\u81ea\u7814\u67b6\u6784 Darknet \u6765\u5b9e\u73b0\u6253\u6846\u3002\u4ed6\u4eec\u5728 ImageNet \u4e0a\u9762\u9884\u8bad\u7ec3\u4e86\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u7136\u540e\u66ff\u6362\u5206\u7c7b\u5934\u6539\u4e3a\u8f93\u51fa <code>(S, S, B*5+C)</code> \u7684\u9884\u6d4b\u5f20\u91cf\uff0c\u518d\u5728 VOC 07+12 \u4e0a\u9762\u8bad\u7ec3\u3002\u7531\u4e8e Darknet \u7684\u9884\u8bad\u7ec3\u6743\u91cd\u6ca1\u6709\u516c\u5f00\uff08\u53ea\u516c\u5f00\u4e86\u5728\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u4e0a\u9762\u5fae\u8c03\u597d\u7684\uff09\uff0c\u6211\u4eec\u5728\u8fd9\u91cc\u4f7f\u7528 torchvision \u5f00\u6e90\u7684 ResNet-18 \u5728 ImageNet \u4e0a\u9762\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u3002\u5f53\u7136\u8fd9\u4e2a\u7f51\u7edc\u7684\u53c2\u6570\u91cf\u5b8c\u5168\u6bd4\u4e0d\u8fc7 Darknet\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#map", "title": "mAP", "text": "<p>\u6211\u4eec\u77e5\u9053\u4e00\u4e2a\u683c\u5b50\u53ef\u4ee5\u6709\u591a\u4e2a\u6846\uff0c\u4e0d\u540c\u7684\u6846\u6709\u4e0d\u540c\u7684\u7f6e\u4fe1\u5ea6\u3002\u5bf9\u4e8e\u4e00\u4e2a\u7ed9\u5b9a\u7684 IoU \u9608\u503c\uff0c\u6bd4\u5982\u8bf4 0.5\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u9009\u62e9\u7f6e\u4fe1\u5ea6\u9608\u503c\u6765\u7b5b\u9009\u6846\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u628a\u540c\u65f6\u7b26\u5408\u4e0b\u9762\u4e09\u4e2a\u6761\u4ef6\u7684\u6846\u89c6\u4f5cTP\u800c\u8fd9\u4e2a\u683c\u5b50\u6253\u7684\u5176\u4ed6\u6846\u89c6\u4f5cFP\uff1a\u9884\u6d4b\u7c7b\u522b\u548c\u771f\u5b9e\u7c7b\u522b\u4e00\u81f4\u3001\u76f8\u5bf9\u771f\u5b9e\u6846\u7684 IoU \u6ee1\u8db3 IoU \u9608\u503c\u4ee5\u53ca\u6ee1\u8db3\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002\u7136\u540e\u6211\u4eec\u5c31\u53ef\u4ee5\u5f97\u5230\u6df7\u6dc6\u77e9\u9635\uff0c\u4ece\u800c\u5f97\u5230 P-R \u66f2\u7ebf\u4e5f\u5c31\u662f\u7cbe\u51c6\u7387-\u53ec\u56de\u7387\u66f2\u7ebf\u3002</p> <p>\u6211\u4eec\u6309\u7b49\u95f4\u9694\u91c7\u6837 11 \u4e2a\u53ec\u56de\u7387\uff08\u4e8b\u5b9e\u4e0a\u771f\u5b9e P-R \u5206\u5e03\u4e0d\u53ef\u80fd\u7b49\u95f4\u9694\uff0c\u4f46\u662f\u6211\u4eec\u63d2\u503c\u5373\u53ef\uff09\uff0c\u8ba1\u7b97\u5bf9\u5e94\u7cbe\u786e\u7387\u7684\u5e73\u5747\uff0c\u5c31\u5f97\u5230\u4e86\u5e73\u5747\u7cbe\u786e\u7387\u4e5f\u5c31\u662f AP\uff0c\u7531\u4e8e\u6211\u4eec\u8bbe\u7f6e\u7684 IoU \u9608\u503c\u662f 0.5\uff0c\u6240\u4ee5\u5199\u4f5c AP@0.5\uff0c\u540c\u6837\u7684\u5bf9\u7c7b\u522b\u505a\u5e73\u5747\u5c31\u5f97\u5230\u4e86\u6211\u4eec\u4e3b\u8981\u7684\u8bc4\u4ef7\u6307\u6807 mAP@0.5\u3002\u4ece\u51e0\u4f55\u610f\u4e49\u4e0a\u8bb2\uff0c\u662f\u5728\u8fd1\u4f3c\u8ba1\u7b97 P-R \u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff08\u4e5f\u5c31\u662f AUC\uff09\u3002</p> <p>\u56e0\u4e3a\u4e00\u822c\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u662f\u53cd\u5411\u53d8\u5316\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a\u5206\u6570\u8d8a\u9ad8\uff0c\u4e00\u65b9\u9762\u610f\u5473\u7740\u5b83\u6253\u6846\u6709\u57fa\u672c\u7684\u51c6\u786e\u5ea6\uff0c\u4f46\u662f\u66f4\u610f\u5473\u7740\u6a21\u578b\u5728\u7c7b\u522b\u9884\u6d4b\u4e0a\u8d8a\u597d\u3002</p> <p>\u5177\u4f53\u8ba1\u7b97\u89c1\u4ee3\u7801\u3002</p>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_15", "title": "\u8bad\u7ec3", "text": "<p>\u4e0b\u9762\u7684\u4ee3\u7801\uff0c\u4e3b\u8981\u662f\u5728 VOC 07+12 \u4e0a\u8bad\u7ec3 YOLO v1 (ResNet-18 backbone) \u5e76\u8fdb\u884c\u9a8c\u8bc1\u548c\u8bc4\u4f30\u3002\u7531\u4e8e ResNet-18 \u7684\u53c2\u6570\u91cf\u5c0f\u4e14\u4e0d\u662f\u4e3a\u4e86\u76ee\u6807\u68c0\u6d4b\u800c\u4f18\u5316\u7684\uff08\u56e0\u4e3a Darknet \u7528\u4e0a\u4e86\u591a\u5c3a\u5ea6\u5377\u79ef\u6838\uff0c\u901a\u9053\u6570\u4e5f\u66f4\u5bbd\u4ece\u800c\u66f4\u9002\u5408\u50cf FCN \u4e00\u6837\u8f93\u51fa <code>(S, S, 5*B+C)</code> \u7684\u201c\u7279\u5f81\u56fe\u201d\uff0c\u5176\u5b9e\u67d0\u79cd\u610f\u4e49\u4e0a\u7528 VGG \u6216\u8005 GoogLeNet \u90fd\u66f4\u9002\u5408\uff0c\u4f46\u662f\u53c2\u6570\u91cf\u66f4\u5927\uff09\uff0c\u6240\u4ee5\u53ea\u80fd\u83b7\u5f97 mAP@0.5 = 0.4723\uff0c\u5177\u4f53\u7684\u7ed3\u679c\u5982\u4e0b\uff1a</p> <p></p> <p></p> <p>\u4e0b\u9762\u7ed9\u51fa\u6a21\u578b\u7c7b\u7684\u5b9a\u4e49\uff1a</p> <pre><code>class YOLOv1ResNet18(nn.Module):\n    def __init__(self, s=7, b=2, c=20, pretrained=True):\n        super().__init__()\n        self.S, self.B, self.C = s, b, c\n        backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n        # \u4e0b\u9762\u5c31\u662f\u9884\u8bad\u7ec3\u7684\u6743\u91cd\n        self.stem = nn.Sequential(\n            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n            backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4\n        )\n        # \u6269\u5c55\u5230 1024 \u901a\u9053\uff0c\u4e3a\u8f93\u51fa (7,7,30) \u7684\u5f20\u91cf\u505a\u51c6\u5907\u3002 \n        # \u7531\u4e8e\u8f93\u51fa\u5df2\u7ecf\u662f 512@7x7 \u7684\u4e86\uff0c\u5176\u5b9e\u76f8\u5f53\u4e8e\u6211\u4eec\u51c6\u5907\u6574\u5408\u5230 30@7x7\n        self.reduce = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        out_ch = b*5 + c\n        # \u53cc\u5377\u79ef\u5230\u8f93\u51fa\u901a\u9053\uff0c\u8fd9\u4e24\u90e8\u5206\u90fd\u6ca1\u6709\u7528\u4e0a\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u4e5f\u5bfc\u81f4 mAP \u6bd4\u8f83\u4f4e\n        # Leakly ReLU \u548c\u8bba\u6587\u4e00\u81f4\n        self.head = nn.Sequential(\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, out_ch, kernel_size=1)\n        )\n\n    def forward(self, x):\n        x = self.stem(x)     # [N,512,14,14]\n        x = self.reduce(x)   # [N,1024,7,7]\n        x = self.head(x)     # [N,(B*5+C),7,7]\n        x = x.permute(0, 2, 3, 1).contiguous() # [N,7,7,(B*5+C)]\n        # \u8fd9\u91cc\u7531\u4e8e\u7f6e\u6362\u4e86\u5f20\u91cf\u7ef4\uff0c\u6240\u4ee5.contiguous()\u4e00\u4e0b\u8ba9\u5185\u5b58\u8fde\u7eed\u3002\n        return x\n</code></pre> <p>\u4e0b\u9762\u662f\u91cd\u5934\u620f\uff0c\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570\u3002</p> <p>\u4ee3\u7801\u6bd4\u8f83\u957f\uff0c\u56e0\u4e3a\u6211\u5177\u4f53\u5206\u6790\u4e86\u86ee\u591a\u7ec6\u8282\uff0c\u56e0\u6b64\u6298\u53e0\u4e86\u4e00\u4e0b\u3002</p>  YOLO v1 loss \u8be6\u7ec6\u7684\u5b9e\u73b0  <pre><code>class YoloV1Loss(nn.Module):\n    def __init__(self, s=7, b=2, c=20, lambda_coord=5.0, lambda_noobj=0.5,\n                 ignore_iou_thresh=0.5, cls_label_smooth=0.0):\n        super().__init__()\n        # \u5b9a\u4e49 YOLO v1 \u635f\u5931\u51fd\u6570\u7684\u8d85\u53c2\u6570\n        # S \u8868\u793a\u7f51\u683c\u7684\u5c3a\u5bf8\uff0c\u5373\u5c06\u56fe\u50cf\u5212\u5206\u4e3a S\u00d7S \u4e2a\u683c\u5b50\n        self.S, self.B, self.C = s, b, c\n        # \u5750\u6807\u635f\u5931\u7684\u6743\u91cd\u7cfb\u6570\uff0c\u7528\u4e8e\u589e\u5f3a\u5750\u6807\u9884\u6d4b\u7684\u91cd\u8981\u6027\n        self.lambda_coord = lambda_coord\n        # \u65e0\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\u7684\u6743\u91cd\u7cfb\u6570\uff0c\u7528\u4e8e\u964d\u4f4e\u80cc\u666f\u9884\u6d4b\u7684\u6743\u91cd\n        self.lambda_noobj = lambda_noobj\n        # IoU \u5ffd\u7565\u9608\u503c\uff0c\u867d\u7136\u539f\u59cb\u7684 YOLO \u635f\u5931\u6ca1\u6709\uff0c\u4f46\u662f\u4e0b\u9762\u4f1a\u7528\u5230\u7684\u795e\u5947\u5999\u5999\u53c2\u6570\n        self.ignore_iou_thresh = ignore_iou_thresh\n        # \u5206\u7c7b\u6807\u7b7e\u5e73\u6ed1\u7cfb\u6570\uff0c\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\n        self.cls_label_smooth = cls_label_smooth\n\n    def forward(self, pred, target):\n        \"\"\"\n        \u524d\u5411\u4f20\u64ad\u51fd\u6570\uff0c\u8ba1\u7b97 YOLO v1 \u7684\u603b\u635f\u5931\u53ca\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\u7684\u635f\u5931\u503c\u3002\n\n        pred: \u7f51\u7edc\u8f93\u51fa\u7684\u9884\u6d4b\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a [N, S, S, B*5+C]\n        target: \u771f\u5b9e\u6807\u7b7e\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a [N, S, S, 5+C]\uff0c\u5305\u542b\u5f52\u4e00\u5316\u7684\u4e2d\u5fc3\u5750\u6807\u3001\u5bbd\u9ad8\u3001\u7f6e\u4fe1\u5ea6\u548c\u7c7b\u522b one-hot \u7f16\u7801\n        \"\"\"\n        # \u83b7\u53d6\u6279\u91cf\u5927\u5c0f (N)\u3001\u7f51\u683c\u5c3a\u5bf8 (S)\u3001\u6bcf\u4e2a\u683c\u5b50\u7684\u9884\u6d4b\u6846\u6570\u91cf (B) \u548c\u7c7b\u522b\u6570\u91cf (C)\n        N, S, B, C = pred.size(0), self.S, self.B, self.C\n        device = pred.device\n\n        # \u5c06\u9884\u6d4b\u5f20\u91cf\u91cd\u5851\u4e3a [N, S, S, B*5 + C] \u7684\u5f62\u72b6\n        pred = pred.view(N, S, S, B*5 + C)\n        # \u63d0\u53d6\u9884\u6d4b\u6846\u90e8\u5206\u5e76\u91cd\u5851\u4e3a [N, S, S, B, 5]\uff0c\u5305\u542b\u6bcf\u4e2a\u9884\u6d4b\u6846\u7684 (x, y, w, h, conf) \u539f\u59cb\u503c\n        pred_boxes = pred[...,:B*5].view(N, S, S, B, 5)\n        # \u63d0\u53d6\u7c7b\u522b\u9884\u6d4b\u90e8\u5206\uff0c\u5f62\u72b6\u4e3a [N, S, S, C]\n        pred_cls_logits = pred[...,B*5:]\n\n        # \u4ece\u76ee\u6807\u5f20\u91cf\u4e2d\u63d0\u53d6\u771f\u5b9e\u8fb9\u754c\u6846\u7684\u5750\u6807\u3001\u7f6e\u4fe1\u5ea6\u548c\u7c7b\u522b\u4fe1\u606f\n        # t_xywh \u5305\u542b\u5f52\u4e00\u5316\u7684\u4e2d\u5fc3\u5750\u6807\u548c\u5bbd\u9ad8\uff0c\u5f62\u72b6\u4e3a [N, S, S, 4]\n        t_xywh = target[...,:4]\n        # t_obj \u8868\u793a\u6bcf\u4e2a\u683c\u5b50\u662f\u5426\u5b58\u5728\u76ee\u6807\uff0c\u5f62\u72b6\u4e3a [N, S, S]\n        # \u8fd9\u4e2a\u5c31\u5bf9\u5e94\u539f\u8bba\u6587\u7684 1^obj_i\n        t_obj  = target[...,4]\n        # t_cls \u8868\u793a\u6bcf\u4e2a\u683c\u5b50\u7684\u7c7b\u522b one-hot \u7f16\u7801\uff0c\u5f62\u72b6\u4e3a [N, S, S, C]\n        t_cls  = target[...,5:]\n\n        # \u751f\u6210\u7f51\u683c\u5750\u6807\uff0c\u7528\u4e8e\u5c06\u9884\u6d4b\u7684\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\n        # \u521b\u5efa [0, 1, ..., S-1] \u7684\u5e8f\u5217\uff0c\u8868\u793a\u7f51\u683c\u7684\u7d22\u5f15\n        gxv = torch.arange(S, device=device, dtype=torch.float32)\n        gyv = torch.arange(S, device=device, dtype=torch.float32)\n        # \u751f\u6210\u7f51\u683c\u7684 x \u548c y \u5750\u6807\u77e9\u9635\uff0c\u5f62\u72b6\u5747\u4e3a [S, S]\n        gy, gx = torch.meshgrid(gyv, gxv, indexing='ij')\n        # \u6269\u5c55\u7ef4\u5ea6\u4ee5\u4fbf\u540e\u7eed\u5e7f\u64ad\u64cd\u4f5c\uff0c\u5f62\u72b6\u53d8\u4e3a [1, S, S, 1]\n        gx = gx[None, :, :, None]\n        gy = gy[None, :, :, None]\n\n        # \u5bf9\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u53c2\u6570\u8fdb\u884c\u89e3\u7801\u548c\u6fc0\u6d3b\n        # \u4f7f\u7528 sigmoid \u51fd\u6570\u5c06 x \u548c y \u7684\u9884\u6d4b\u503c\u7ea6\u675f\u5230 [0,1] \u8303\u56f4\u5185\uff0c\u8868\u793a\u76f8\u5bf9\u4e8e\u683c\u5b50\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\n        px = torch.sigmoid(pred_boxes[...,0])\n        py = torch.sigmoid(pred_boxes[...,1])\n        # \u4f7f\u7528 softplus \u6fc0\u6d3b\u51fd\u6570\u5904\u7406\u5bbd\u9ad8\u9884\u6d4b\u503c\uff0c\u7136\u540e\u5e73\u65b9\u5e76\u88c1\u526a\u5230 [1e-6, 1.0] \u8303\u56f4\u5185\uff0c\u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\n        # \u8fd9\u91cc\u4f7f\u7528 softplus \u52a0\u4e0a\u5e73\u65b9\u662f\u4e3a\u4e86\u786e\u4fdd\u5bbd\u9ad8\u4e3a\u6b63\u503c\uff0c\u5e76\u4e14\u6291\u5236\u7279\u522b\u5927\u7684\u6846\n        # \u5177\u4f53\u6765\u8bf4\uff0csoftplus \u51fd\u6570\u53ef\u4ee5\u5e73\u6ed1\u5730\u5c06\u8d1f\u503c\u6620\u5c04\u5230\u6b63\u503c\uff08softplus(x)=log(1+exp(x))\uff09\uff0c\u800c\u5e73\u65b9\u64cd\u4f5c\u5219\u8fdb\u4e00\u6b65\u653e\u5927\u4e86\u5c0f\u503c\u7684\u5f71\u54cd\n        # \u5b9e\u8df5\u4e0b\u6765\uff0c\u8fd9\u6837\u5904\u7406\u7684\u6548\u679c\u4f1a\u66f4\u597d\u4e00\u4e9b\n        pw = F.softplus(pred_boxes[...,2]).pow(2).clamp(1e-6, 1.0)\n        ph = F.softplus(pred_boxes[...,3]).pow(2).clamp(1e-6, 1.0)\n        # \u4f7f\u7528 sigmoid \u51fd\u6570\u5c06\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u503c\u7ea6\u675f\u5230 [0,1] \u8303\u56f4\u5185\n        pconf = torch.sigmoid(pred_boxes[...,4])\n        # \u73b0\u5728\uff0c\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u6bcf\u4e00\u4e2a\u9884\u6d4b\u6846\u7684\u4e2d\u5fc3\u5750\u6807 (px, py), \u5bbd\u9ad8 (pw, ph) \u548c\u7f6e\u4fe1\u5ea6 pconf\n        # \u8fd9\u91cc\u9884\u6d4b\u7684 (px, py) \u662f\u76f8\u5bf9\u4e8e\u683c\u5b50\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\uff0c(pw, ph) \u662f\u7ecf\u8fc7\u7279\u6b8a\u5904\u7406\u7684\u5bbd\u9ad8\n        # \u5b83\u4eec\u90fd\u662f\u76f8\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\u5f52\u4e00\u5316\u7684\u503c\n\n        # \u5c06\u9884\u6d4b\u7684\u76f8\u5bf9\u5750\u6807\u8f6c\u6362\u4e3a\u7edd\u5bf9\u5750\u6807\n        # \u76f8\u5bf9\u5750\u6807\u5c31\u662f\u76f8\u5bf9\u4e8e\u3010\u683c\u5b50\u3011\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\n        # \u7edd\u5bf9\u5750\u6807\u662f\u76f8\u5bf9\u4e8e\u3010\u6574\u4e2a\u56fe\u50cf\u3011\u7684\u5de6\u4e0a\u89d2\u7684\u504f\u79fb\uff0c\u8fd8\u8981\u9664\u4ee5 S \u8fdb\u884c\u5f52\u4e00\u5316\n        #\n        # -----------------------------------------------\n        # \n        # \u8fd9\u91cc\u7684\u5750\u6807\u8f6c\u6362\u8fc7\u7a0b\u6bd4\u8f83\u590d\u6742\uff0c\u503c\u5f97\u8be6\u7ec6\u89e3\u91ca\u4e00\u4e0b\uff1a\n        # \u8ba1\u7b97\u9884\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u7edd\u5bf9\u5750\u6807\uff0c\u901a\u8fc7\u5c06\u683c\u5b50\u7d22\u5f15\u52a0\u4e0a\u504f\u79fb\u91cf\u5e76\u9664\u4ee5\u7f51\u683c\u5c3a\u5bf8\u8fdb\u884c\u5f52\u4e00\u5316\n        # px \u7684\u5f62\u72b6\u4e3a [N, S, S, B]\uff0cgx \u7684\u5f62\u72b6\u4e3a [1, S, S, 1]\uff0c\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u8fdb\u884c\u52a0\u6cd5\n        # \u8fd9\u4e2a\u673a\u5236\u7684\u64cd\u4f5c\u8fc7\u7a0b\u5177\u4f53\u662f\uff1agx \u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u9762\u590d\u5236 N \u4efd\uff0c\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u590d\u5236 B \u4efd\n        # \u8fd9\u6837 gx \u7684\u5f62\u72b6\u5c31\u53d8\u6210\u4e86 [N, S, S, B]\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u548c px \u6bcf\u4e2a\u4f4d\u7f6e\u5bf9\u9f50\u76f8\u52a0\u4e86\n        # \u8fd9\u4e00\u5957\u64cd\u4f5c\u4e0b\u6765\uff0c\u5176\u5b9e\u5c31\u662f\u4ece\u4e00\u5f00\u59cb\u7684\u4e00\u7ef4 [S] \u7684\u5411\u91cf gxv\uff0c\u901a\u8fc7 meshgrid \u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4e0a\u590d\u5236 S \u4efd\n        # \u53d8\u6210\u4e86\u4e8c\u7ef4\u7684 [S, S] \u77e9\u9635 gx\uff0c\u518d\u5206\u522b\u6dfb\u52a0\u4e24\u4e2a\u7ef4\u5ea6\u5e76\u590d\u5236 N \u548c B \u4efd\uff0c\u53d8\u6210\u4e86 [N, S, S, B] \u7684\u5e7f\u64ad\u540e\u5f20\u91cf\n        # \u6700\u540e\u548c px \u76f8\u52a0\uff0c\u5f97\u5230\u6bcf\u4e2a\u9884\u6d4b\u6846\u7684\u7edd\u5bf9\u4e2d\u5fc3\u5750\u6807\n        pcx = (gx + px) / float(S)\n        # \u5bf9 y \u5750\u6807\u540c\u7406\uff0c\u6700\u540e\u9664\u4ee5 S \u8fdb\u884c\u5f52\u4e00\u5316\n        pcy = (gy + py) / float(S)\n        # \u7ec4\u5408\u9884\u6d4b\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u548c\u5bbd\u9ad8\uff0c\u5f62\u72b6\u4e3a [N, S, S, B, 4]\n        # dim =-1 \u8868\u793a\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5806\u53e0\n        p_cxcywh = torch.stack([pcx.expand_as(px), pcy.expand_as(py), pw, ph], dim=-1)\n        # \u5c06 (cx, cy, w, h) \u683c\u5f0f\u7684\u8fb9\u754c\u6846\u8f6c\u6362\u4e3a (x1, y1, x2, y2) \u683c\u5f0f\uff0c\u5e76\u88c1\u526a\u5230 [0,1] \u8303\u56f4\u5185\n        p_xyxy = cxcywh_to_xyxy(p_cxcywh).clamp(0, 1)\n        # \u73b0\u5728\uff0c\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u6bcf\u4e00\u4e2a\u9884\u6d4b\u6846\u7684\u7edd\u5bf9\u5750\u6807 p_xyxy\uff0c\u5f62\u72b6\u4e3a [N, S, S, B, 4]\n\n        # \u5bf9\u771f\u5b9e\u8fb9\u754c\u6846\u5750\u6807\u8fdb\u884c\u89e3\u7801\u548c\u5f52\u4e00\u5316\u5904\u7406\n        # \u4ece\u76ee\u6807\u5f20\u91cf\u4e2d\u63d0\u53d6\u771f\u5b9e\u8fb9\u754c\u6846\u7684 (x, y, w, h) \u5750\u6807\n        # \u8fd9\u91cc tw, th \u4f7f\u7528 clamp \u9650\u5236\u5728 [1e-6, 1.0] \u8303\u56f4\u5185\uff0c\u9632\u6b62\u6570\u503c\u4e0d\u7a33\u5b9a\n        # tx \u7684\u5f62\u72b6\u4e3a [N, S, S, 1]\uff0c\u4e0e gx \u5f62\u72b6\u517c\u5bb9\uff0c\u5176\u4ed6\u7c7b\u4f3c\n        tx, ty, tw, th = t_xywh[...,0], t_xywh[...,1], t_xywh[...,2].clamp(1e-6,1.0), t_xywh[...,3].clamp(1e-6,1.0)\n        # \u8ba1\u7b97\u771f\u5b9e\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u5750\u6807 (tcx, tcy)\uff0c\u901a\u8fc7\u5c06\u683c\u5b50\u7d22\u5f15\u52a0\u4e0a\u504f\u79fb\u91cf\u5e76\u9664\u4ee5\u7f51\u683c\u5c3a\u5bf8\u8fdb\u884c\u5f52\u4e00\u5316\n        # \u8fd9\u91cc gx.squeeze(-1) \u662f\u628a\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u6324\u6389\uff0c\u53d8\u6210 [1, S, S] \u7684\u5f62\u72b6\n        # \u8fd9\u4e2a\u65f6\u5019\u4f60\u5c31\u8981\u95ee\u4e86\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u7528 gx \u548c gy \u5462\uff1f\u5f53\u7136\u53ef\u4ee5\uff01\u5e7f\u64ad\u673a\u5236\u548c\u4e4b\u524d\u5b8c\u5168\u4e00\u6837\u3002\n        # \u8fd9\u91cc\u4fdd\u7559\u662f\u56e0\u4e3a\u8fd9\u4e2a\u4ee3\u7801\u4e0d\u662f\u6211\u5199\u7684\uff0c\u6211\u731c\u6d4bgpt\u662f\u4e3a\u4e86\u8ba9\u5f62\u72b6\u66f4\u6e05\u6670\u4e00\u4e9b\n        # \u7136\u540e\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u548c tx \u7684\u5f62\u72b6 [N, S, S, 1] \u8fdb\u884c\u76f8\u52a0\u540e\u518d\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5177\u4f53\u673a\u5236\u540c\u4e0a\n        tcx = (gx.squeeze(-1) + tx) / float(S)\n        tcy = (gy.squeeze(-1) + ty) / float(S)\n        # \u5c06\u4e2d\u5fc3\u5750\u6807\u548c\u5bbd\u9ad8\u7ec4\u5408\u6210 (tcx, tcy, tw, th) \u683c\u5f0f\uff0c\u5f62\u72b6\u4e3a [N, S, S, 4]\n        t_cxcywh = torch.stack([tcx,tcy,tw,th], dim=-1)\n        # \u5c06 (tcx, tcy, tw, th) \u8f6c\u6362\u4e3a (x1, y1, x2, y2) \u683c\u5f0f\uff0c\u5e76\u88c1\u526a\u5230 [0, 1] \u8303\u56f4\u5185\n        t_xyxy = cxcywh_to_xyxy(t_cxcywh).clamp(0, 1)\n        # \u73b0\u5728\uff0c\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u6bcf\u4e00\u4e2a\u771f\u5b9e\u6846\u7684\u7edd\u5bf9\u5750\u6807 t_xyxy\uff0c\u5f62\u72b6\u4e3a [N, S, S, 4]\n\n        # \u4e0b\u9762\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u6846\u7684\u635f\u5931\u4e86\u3002\n\n        # \u8ba1\u7b97\u6bcf\u4e2a\u9884\u6d4b\u6846\u4e0e\u5bf9\u5e94\u683c\u5b50\u4e2d\u771f\u5b9e\u6846\u7684 IoU\n        # \u6269\u5c55\u771f\u5b9e\u6846\u5f20\u91cf\u4ee5\u4fbf\u4e0e\u6bcf\u4e2a\u9884\u6d4b\u6846\u8ba1\u7b97 IoU\uff0c\u5f62\u72b6\u53d8\u4e3a [N, S, S, B, 4]\n        # \u8fd9\u4e00\u884c\u4ee3\u7801\u7684\u64cd\u4f5c\u662f\u628a t_xyxy \u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u9762\u6dfb\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7136\u540e\u5728\u8fd9\u4e2a\u7ef4\u5ea6\u4e0a\u590d\u5236 B \u4efd\n        # \u8fd9\u6837 t_xyxy_exp \u7684\u5f62\u72b6\u5c31\u53d8\u6210\u4e86 [N, S, S, B, 4]\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u548c p_xyxy \u6bcf\u4e2a\u4f4d\u7f6e\u5bf9\u9f50\u8ba1\u7b97 IoU \u4e86\n        t_xyxy_exp = t_xyxy.unsqueeze(3).expand(-1,-1,-1,B,-1)\n        # \u8ba1\u7b97\u6240\u6709\u9884\u6d4b\u6846\u4e0e\u5bf9\u5e94\u771f\u5b9e\u6846\u7684 IoU\uff0c\u5f62\u72b6\u4e3a [N, S, S, B]\n        iou_all = iou_xyxy_aligned(p_xyxy, t_xyxy_exp)\n\n        # \u4e0b\u9762\u6211\u4eec\u8981\u6839\u636e iou_all \u6765\u51b3\u5b9a\u54ea\u4e9b\u6846\u8d1f\u8d23\u9884\u6d4b\uff0c\u54ea\u4e9b\u6846\u4e0d\u8d1f\u8d23\u9884\u6d4b\n\n        # \u6784\u5efa\u8d1f\u8d23\u9884\u6d4b\u7684\u63a9\u7801\uff0c\u7528\u4e8e\u6807\u8bc6\u6bcf\u4e2a\u683c\u5b50\u4e2d\u4e0e\u771f\u5b9e\u6846 IoU \u6700\u5927\u7684\u9884\u6d4b\u6846\n        # obj_cells \u8868\u793a\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\uff0c\u5f62\u72b6\u4e3a [N, S, S]\n        # \u8fd9\u4e2a\u5c31\u662f\u8bba\u6587\u4e2d\u7684 1^obj_i\n        obj_cells = t_obj\n        # \u5c06\u65e0\u76ee\u6807\u683c\u5b50\u7684 IoU \u8bbe\u7f6e\u4e3a -1\uff0c\u4ee5\u4fbf\u540e\u7eed\u5904\u7406\uff0c\u5f62\u72b6\u662f [N, S, S, B]\n        iou_all_masked = iou_all.masked_fill(obj_cells.unsqueeze(-1)==0, -1.0)\n        # \u83b7\u53d6\u6bcf\u4e2a\u683c\u5b50\u4e2d IoU \u6700\u5927\u7684\u9884\u6d4b\u6846\u7d22\u5f15\uff0c\u5f62\u72b6\u4e3a [N, S, S]\n        best_box_idx = iou_all_masked.argmax(dim=-1)\n        # \u6784\u5efa\u8d1f\u8d23\u9884\u6d4b\u7684\u63a9\u7801\uff0c\u5f62\u72b6\u4e3a [N, S, S, B]\uff0c\u5176\u4e2d\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u4f4d\u7f6e\u4e3a 1\uff0c\u5176\u4f59\u4e3a 0\n        # \u8fd9\u4e2a\u5c31\u662f\u8bba\u6587\u4e2d\u7684 1^obj_ij\n        resp_mask = F.one_hot(best_box_idx, num_classes=B).float() * obj_cells.unsqueeze(-1)\n\n        # \u8ba1\u7b97\u5750\u6807\u635f\u5931\uff0c\u5305\u62ec\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u7684\u635f\u5931\n        # \u5bf9\u5bbd\u9ad8\u53d6\u5e73\u65b9\u6839\u4ee5\u5e73\u8861\u5927\u5c0f\u6846\u7684\u635f\u5931\u8d21\u732e\n        # \u8fd9\u4e00\u90e8\u5206\u5bf9\u5e94\u7684 L_coord \u548c L_size\n        # w,h \u7684\u5f62\u72b6\u5747\u4e3a [N, S, S, B]\uff0c\u4f46\u5176\u5b9e\u6709\u610f\u4e49\u7684\u53ea\u6709\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\uff0c\u4e5f\u5c31\u662f IoU \u6700\u5927\u7684\u90a3\u4e2a\u6846\n        # \u76f8\u5f53\u4e8e\u8fd9\u90e8\u5206\u8ba1\u7b97\u91cc\u9762 (B-1)/B \u7684\u90e8\u5206\u662f\u6ca1\u6709\u610f\u4e49\u7684\n        # \u4f46\u662f\u7531\u4e8e\u540e\u9762\u4e58\u4e0a\u4e86 resp_mask\uff0c\u6240\u4ee5\u8fd9\u4e9b\u65e0\u610f\u4e49\u7684\u90e8\u5206\u635f\u5931\u76f4\u63a5\u7f6e\u96f6\u4e86\uff0c\u68af\u5ea6\u4e0d\u4f1a\u56de\u4f20\n        # \u8fd9\u4e2a\u65f6\u5019\u4f60\u5c31\u8981\u95ee\u4e86\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u6765\u4e2a for-if \u6765\u907f\u514d\u8ba1\u7b97\u8fd9\u4e9b\u65e0\u610f\u4e49\u7684\u90e8\u5206\u5462\uff1f\n        # \u8fd9\u6837\u505a\u7684\u539f\u56e0\u662f\uff0cfor-if \u4f1a\u5bfc\u81f4\u8ba1\u7b97\u56fe\u65ad\u88c2\uff0c\u6ca1\u6cd5\u5b50\u6c42\u5bfc\u4e86\uff0c\u800c\u4e14\u9010\u5143\u7d20\u5206\u652f\u9884\u6d4b\u6162\u6b7b\u2026\u2026\n        # \u53cd\u89c2\u8ba1\u7b97\u8fd9\u4e9b\u65e0\u610f\u4e49\u7684\u90e8\u5206\u4e5f\u4e0d\u4f1a\u7279\u522b\u5f71\u54cd\u6548\u7387\uff0c\u6bd5\u7adf B \u4e00\u822c\u90fd\u6bd4\u8f83\u5c0f\uff0c\u800c\u4e14\u53ef\u4ee5\u6570\u636e\u5e76\u884c\u8ba1\u7b97\n        # \u8fd9\u91cc\u52a0\u4e0a\u4e00\u4e2a\u5f88\u5c0f\u7684\u6570\u503c 1e-6 \u8fd8\u662f\u4e3a\u4e86\u9632\u6b62\u6570\u503c\u4e0d\u7a33\u5b9a\n        sqrt_pw, sqrt_ph = torch.sqrt(pw + 1e-6), torch.sqrt(ph + 1e-6)\n        sqrt_tw, sqrt_th = torch.sqrt(tw + 1e-6), torch.sqrt(th + 1e-6)\n        # \u8ba1\u7b97\u4e2d\u5fc3\u70b9 x \u5750\u6807\u7684\u635f\u5931\uff0c\u4ec5\u5bf9\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u8ba1\u7b97\n        coord_x_loss = ((px - tx.unsqueeze(-1))**2) * resp_mask\n        # \u8ba1\u7b97\u4e2d\u5fc3\u70b9 y \u5750\u6807\u7684\u635f\u5931\uff0c\u4ec5\u5bf9\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u8ba1\u7b97\n        coord_y_loss = ((py - ty.unsqueeze(-1))**2) * resp_mask\n        # \u8ba1\u7b97\u5bbd\u5ea6\u7684\u635f\u5931\uff0c\u4f7f\u7528\u5e73\u65b9\u6839\u5904\u7406\u540e\u7684\u503c\n        coord_w_loss = ((sqrt_pw - sqrt_tw.unsqueeze(-1))**2) * resp_mask\n        # \u8ba1\u7b97\u9ad8\u5ea6\u7684\u635f\u5931\uff0c\u4f7f\u7528\u5e73\u65b9\u6839\u5904\u7406\u540e\u7684\u503c\n        coord_h_loss = ((sqrt_ph - sqrt_th.unsqueeze(-1))**2) * resp_mask\n\n        # \u8ba1\u7b97\u6709\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\uff0c\u76ee\u6807\u503c\u4e3a\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 IoU\uff0c\u5bf9\u5e94 L_P\n        # \u90a3\u4f60\u5c31\u8981\u95ee\u4e86\uff0c\u8fd9 IoU \u53c8\u4e0d\u53ef\u5bfc\u4e86\uff0c\u600e\u4e48\u529e\uff1f\n        # \u5176\u5b9e\u4e5f\u6ca1\u4e8b\uff0c\u56e0\u4e3a\u6211\u4eec\u53ea\u662f\u7528\u5b83\u6765\u4f5c\u4e3a\u4e00\u4e2a\u5e38\u6570\u76ee\u6807\u503c\uff0c\u53c8\u4e0d\u662f\u771f\u7684\u8981\u4f18\u5316\u5b83\n        # \u53cd\u800c\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u4f7f\u7528 detach \u6765\u9632\u6b62\u68af\u5ea6\u56de\u4f20\n        iou_target = iou_all.detach()\n        # \u8ba1\u7b97\u6709\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\uff0c\u4ec5\u5bf9\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u8ba1\u7b97\n        conf_obj_terms = ((pconf - iou_target)**2) * resp_mask\n\n        # \u6784\u5efa\u65e0\u76ee\u6807\u63a9\u7801\uff0c\u5305\u62ec\u975e\u8d1f\u8d23\u9884\u6d4b\u6846\u548c\u7eaf\u7cb9\u65e0\u76ee\u6807\u7684\u683c\u5b50\uff0c\u5bf9\u5e94 L_N\n        # \u975e\u8d1f\u8d23\u9884\u6d4b\u6846\u63a9\u7801\uff1a\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u4e2d\u4e0d\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\n        # \u8fd9\u4e2a\u5c31\u662f\u8bba\u6587\u4e2d\u7684 1^noobj_ij\n        not_resp_mask = obj_cells.unsqueeze(-1) * (1.0 - resp_mask)\n        # \u7eaf\u7cb9\u65e0\u76ee\u6807\u683c\u5b50\u63a9\u7801\uff1a\u4e0d\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u4e2d\u7684\u6240\u6709\u9884\u6d4b\u6846\n        # \u7c7b\u6bd4\u4e00\u4e0b\u53ef\u4ee5\u53eb\u505a 1^noobj_i\n        noobj_cells_mask = (1.0 - obj_cells).unsqueeze(-1).expand_as(pconf)\n\n        # \u6784\u5efa\u5ffd\u7565\u63a9\u7801\uff0c\u7528\u4e8e\u5904\u7406\u4e0e\u771f\u5b9e\u6846 IoU \u8f83\u9ad8\u7684\u65e0\u76ee\u6807\u9884\u6d4b\u6846\n        # \u5728 YOLO \u8bad\u7ec3\u4e2d\uff0c\u6709\u4e9b\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u7684 IoU \u8f83\u9ad8\u4f46\u5e76\u4e0d\u662f\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\n        # \u8fd9\u4e9b\u6846\u4e0d\u5e94\u8be5\u88ab\u60e9\u7f5a\u4e3a\u65e0\u76ee\u6807\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684\u9884\u6d4b\u5b9e\u9645\u4e0a\"\u63a5\u8fd1\"\u67d0\u4e2a\u771f\u5b9e\u76ee\u6807\n        # \u6211\u4eec\u4e0d\u80fd\u5426\u5b9a\u5b83\u4eec\u7684\u52aa\u529b\uff0c\u56e0\u6b64\u4f7f\u7528 ignore_iou_thresh \u4f5c\u4e3a\u9608\u503c\u6765\u8bc6\u522b\u8fd9\u4e9b\u6846\n        ignore_mask = torch.zeros_like(pconf)\n        # \u4f7f\u7528 torch.no_grad() \u786e\u4fdd\u5728\u8fd9\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u4e0d\u751f\u6210\u68af\u5ea6\n        # \u56e0\u4e3a\u6211\u4eec\u53ea\u662f\u7528\u5b83\u6765\u6784\u5efa\u4e00\u4e2a\u63a9\u7801\uff0c\u6765\u8fdb\u884c\u9009\u62e9\u6027\u7684\u635f\u5931\u8ba1\u7b97\u548c\u68af\u5ea6\u56de\u4f20\n        # \u63a9\u7801\u672c\u8eab\u4e0d\u9700\u8981\u68af\u5ea6\uff0c\u800c\u4e14\u91cc\u9762\u6d89\u53ca\u5230\u7684 argmax \u4e5f\u662f\u4e0d\u53ef\u5bfc\u7684\n        with torch.no_grad():\n            # \u904d\u5386\u6279\u6b21\u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\n            for n in range(N):\n                # \u83b7\u53d6\u5f53\u524d\u6837\u672c\u4e2d\u5b58\u5728\u76ee\u6807\u7684\u7f51\u683c\u4f4d\u7f6e\u7684\u63a9\u7801\uff0c\u5f62\u72b6\u4e3a [S, S]\n                # \u8fd9\u91cc\u7684\u673a\u5236\u662f obj_cells[n] \u662f [S, S] \u7684\u5f20\u91cf\n                # obj_cells[n] &gt; 0 \u4f1a\u5f97\u5230\u4e00\u4e2a\u5e03\u5c14\u5f20\u91cf\uff0c\u5f62\u72b6\u4e5f\u662f [S, S]\n                # \u8fd9\u4e2a\u5e03\u5c14\u5f20\u91cf\u8868\u793a\u54ea\u4e9b\u683c\u5b50\u662f\u6709\u76ee\u6807\u7684\n                obj_mask_n = obj_cells[n] &gt; 0\n                # \u63d0\u53d6\u5f53\u524d\u6837\u672c\u4e2d\u6240\u6709\u771f\u5b9e\u6846\u7684\u5750\u6807\n                # \u7531\u4e8e t_xyxy[n] \u662f [S, S, 4] \u7684\u5f20\u91cf\uff0c\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u7d22\u5f15\n                # \u90a3\u4f60\u5c31\u8981\u95ee\u4e86\uff0cgt_n \u7684\u5f62\u72b6\u662f [S, S, 4] \u5417\uff1f\n                # \u4e0d\u662f\u7684\uff0c\u56e0\u4e3a obj_mask_n \u662f\u5e03\u5c14\u7d22\u5f15\uff0c\u6240\u4ee5\u4f1a\u628a\u6240\u6709\u4e3a True \u7684\u4f4d\u7f6e\u90fd\u63d0\u53d6\u51fa\u6765\n                # \u5355\u72ec\u653e\u8fdb\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u6240\u4ee5\u6700\u7ec8 gt_n \u7684\u5f62\u72b6\u662f [num_gt, 4]\uff0c\u5176\u4e2d num_gt \u662f\u5f53\u524d\u6837\u672c\u4e2d\u771f\u5b9e\u6846\u7684\u6570\u91cf\n                gt_n = t_xyxy[n][obj_mask_n]\n                # \u5c06\u5f53\u524d\u6837\u672c\u7684\u6240\u6709\u9884\u6d4b\u6846\u91cd\u5851\u4e3a [S*S*B, 4] \u7684\u5f62\u72b6\n                # .reshape(-1, 4) \u4f1a\u5c06 [S, S, B, 4] \u53d8\u6210 [S*S*B, 4]\n                # -1 \u5c31\u662f\u8ba9\u524d\u9762\u7684\u7ef4\u5ea6\u90fd\u5806\u5728\u4e00\u8d77\n                pred_n = p_xyxy[n].reshape(-1, 4)\n                # \u68c0\u67e5\u5f53\u524d\u6837\u672c\u4e2d\u662f\u5426\u5b58\u5728\u771f\u5b9e\u6846\n                # .numel() \u4f1a\u8fd4\u56de\u5f20\u91cf\u4e2d\u5143\u7d20\u7684\u603b\u6570\u91cf\n                if gt_n.numel() == 0:\n                    # \u5982\u679c\u6ca1\u6709\u771f\u5b9e\u6846\uff0c\u6240\u6709\u9884\u6d4b\u6846\u7684\u6700\u5927 IoU \u8bbe\u4e3a 0\n                    max_iou = torch.zeros(pred_n.size(0), device=device)\n                else:\n                    # \u8ba1\u7b97\u6240\u6709\u9884\u6d4b\u6846\u4e0e\u6240\u6709\u771f\u5b9e\u6846\u7684 IoU\uff0c\u5f97\u5230 [num_pred, num_gt] \u7684 IoU \u77e9\u9635\n                    ious = box_iou_xyxy(pred_n, gt_n)\n                    # \u83b7\u53d6\u6bcf\u4e2a\u9884\u6d4b\u6846\u4e0e\u6240\u6709\u771f\u5b9e\u6846\u7684\u6700\u5927 IoU [num_pred]\n                    max_iou = ious.max(dim=1).values\n                # \u5c06\u6700\u5927 IoU \u8d85\u8fc7\u9608\u503c\u7684\u9884\u6d4b\u6846\u6807\u8bb0\u4e3a\u5ffd\u7565 (1.0)\uff0c\u5426\u5219\u4e3a 0\n                # \u4e5f\u5c31\u662f\u6211\u4eec\u53ea\u9700\u8981\u5bf9\u90a3\u4e9b IoU \u8f83\u4f4e\u7684\u9884\u6d4b\u6846\u8ba1\u7b97\u65e0\u76ee\u6807\u635f\u5931 L_N\n                # \u5176\u4ed6\u6846\u6211\u4eec\u5c31\u5ffd\u7565\u6389\uff0c\u4e0d\u8ba1\u7b97\u635f\u5931\uff0c\u80af\u5b9a\u5b83\u4eec\u7684\u52b3\u52a8\u6210\u679c\n                # \u7136\u540e\u5c06\u6807\u8bb0\u91cd\u5851\u4e3a [S, S, B] \u7684\u5f62\u72b6\uff0c\u4e0e ignore_mask \u7684\u5f53\u524d\u6837\u672c\u5f62\u72b6\u5339\u914d\n                ign = (max_iou &gt;= self.ignore_iou_thresh).float().view(S, S, B)\n                # \u5c06\u5f53\u524d\u6837\u672c\u7684\u5ffd\u7565\u63a9\u7801\u8d4b\u503c\u7ed9 ignore_mask\n                ignore_mask[n] = ign\n            # \u8fd8\u6709\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u4e4b\u524d\u8ba8\u8bba\u8fc7\uff1a\u4e3a\u4ec0\u4e48\u5728\u8fd9\u91cc\u8fd8\u5728\u7528 for-if \u8fd9\u4e48\u4f4e\u6548\u7684\u65b9\u6848\u5462\uff1f\n            # \u56e0\u4e3a\u6bcf\u4e2a\u56fe\u50cf\u7684 num_gt \u4e5f\u5c31\u662f\u7269\u54c1\u4e2a\u6570\u4e0d\u4e00\u6837\uff0c\u6ca1\u6cd5\u5728\u7ef4\u5ea6\u4e0a\u5bf9\u9f50\n            # \u5f3a\u884c\u5bf9\u9f50\u4e5f\u4e0d\u662f\u4e0d\u53ef\u4ee5\uff0c\u4f46\u662f\u4f60\u8fd8\u662f\u8981\u904d\u5386\u4e00\u904d\uff0c\u6548\u7387\u5dee\u4e0d\u4e86\u591a\u5c11\n            # \u5e76\u4e14\u8fd9\u65f6\u5019\u4f60\u5c31\u7b49\u7740 CUDA out of memory \u5427\n\n        # \u8ba1\u7b97\u65e0\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\uff0c\u4e0d\u5305\u62ec\u88ab\u5ffd\u7565\u7684\u9884\u6d4b\u6846\uff0c\u4e5f\u5c31\u662f L_N\n        # \u65e0\u76ee\u6807\u635f\u5931\u5305\u62ec\u4e24\u90e8\u5206\uff1a\u975e\u8d1f\u8d23\u9884\u6d4b\u6846 (not_resp_mask) \u548c\u65e0\u76ee\u6807\u683c\u5b50\u4e2d\u7684\u6240\u6709\u9884\u6d4b\u6846 (noobj_cells_mask)\n        # \u4f46\u9700\u8981\u6392\u9664\u90a3\u4e9b\u4e0e\u771f\u5b9e\u6846 IoU \u8f83\u9ad8\u800c\u88ab\u5ffd\u7565\u7684\u9884\u6d4b\u6846 (\u4e58\u4ee5 (1.0 - ignore_mask))\n        conf_noobj_terms = ((pconf - 0.0)**2) * (not_resp_mask + noobj_cells_mask) * (1.0 - ignore_mask)\n\n        # \u5bf9\u6846\u7684\u635f\u5931\u8ba1\u7b97\u5b8c\u6bd5\uff0c\u4e0b\u9762\u662f\u5bf9\u683c\u5b50\u7684\u635f\u5931\u3002\n\n        # \u8ba1\u7b97\u5206\u7c7b\u635f\u5931\uff0c\u4ec5\u5bf9\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\n        # \u9996\u5148\u8ba1\u7b97\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u6570\u91cf\uff0c\u7528\u4e8e\u540e\u7eed\u5f52\u4e00\u5316\uff0c\u4f7f\u7528 clamp(min=1.0) \u9632\u6b62\u9664\u96f6\n        num_objcells = obj_cells.sum().clamp(min=1.0)\n        # \u4ece one-hot \u7f16\u7801\u7684\u771f\u5b9e\u6807\u7b7e\u4e2d\u83b7\u53d6\u7c7b\u522b\u7d22\u5f15\uff0c\u5f62\u72b6\u4e3a [N, S, S]\n        t_cls_idx = t_cls.argmax(dim=-1)\n        # \u6784\u5efa\u5b58\u5728\u76ee\u6807\u7684\u5e03\u5c14\u63a9\u7801\uff0c\u5f62\u72b6\u4e3a [N, S, S]\uff0c\u7528\u4e8e\u7d22\u5f15\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\n        obj_mask_bool = (obj_cells &gt; 0)\n\n        # \u68c0\u67e5\u662f\u5426\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u5305\u542b\u76ee\u6807\u7684\u683c\u5b50\n        if obj_mask_bool.any():\n            # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4f7f\u7528\u6807\u7b7e\u5e73\u6ed1\n            # \u9996\u5148\u4ece\u9884\u6d4b\u7684\u5206\u7c7blogits\u4e2d\u63d0\u53d6\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u90e8\u5206\uff0c\u5e76\u91cd\u5851\u4e3a [N*S*S, C] \u5f62\u72b6\n            # \u540c\u65f6\u4ece\u771f\u5b9e\u6807\u7b7e\u4e2d\u63d0\u53d6\u5bf9\u5e94\u7684\u7c7b\u522b\u7d22\u5f15\uff0c\u5e76\u91cd\u5851\u4e3a [N*S*S] \u5f62\u72b6\n            ce = F.cross_entropy(\n                pred_cls_logits[obj_mask_bool].reshape(-1, C),\n                t_cls_idx[obj_mask_bool].long().reshape(-1),\n                reduction='sum',  # \u4f7f\u7528\u6c42\u548c\u800c\u4e0d\u662f\u5747\u503c\uff0c\u56e0\u4e3a\u540e\u9762\u4f1a\u9664\u4ee5 num_objcells\n                label_smoothing=self.cls_label_smooth  # \u5e94\u7528\u6807\u7b7e\u5e73\u6ed1\n            )\n            # \u5c06\u4ea4\u53c9\u71b5\u635f\u5931\u9664\u4ee5\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\u6570\u91cf\uff0c\u5f97\u5230\u5e73\u5747\u5206\u7c7b\u635f\u5931\n            class_loss = ce / num_objcells\n        else:\n            # \u5982\u679c\u6ca1\u6709\u5b58\u5728\u76ee\u6807\u7684\u683c\u5b50\uff0c\u5c06\u5206\u7c7b\u635f\u5931\u8bbe\u4e3a 0\n            class_loss = torch.tensor(0.0, device=device)\n\n        # \u5bf9\u5404\u4e2a\u635f\u5931\u7ec4\u4ef6\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\n        # \u8ba1\u7b97\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u6570\u91cf\uff0c\u7528\u4e8e\u5750\u6807\u635f\u5931\u548c\u6709\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\u7684\u5f52\u4e00\u5316\n        num_resp = resp_mask.sum().clamp(min=1.0)\n        # \u8ba1\u7b97\u9700\u8981\u8ba1\u7b97\u65e0\u76ee\u6807\u635f\u5931\u7684\u6846\u6570\u91cf\uff0c\u5305\u62ec\u975e\u8d1f\u8d23\u9884\u6d4b\u6846\u548c\u65e0\u76ee\u6807\u683c\u5b50\u4e2d\u7684\u9884\u6d4b\u6846\n        # \u4f46\u8981\u6392\u9664\u88ab\u5ffd\u7565\u7684\u9884\u6d4b\u6846 (\u4e58\u4ee5 (1.0 - ignore_mask))\n        num_noobj = ( ((not_resp_mask + noobj_cells_mask) * (1.0 - ignore_mask)).sum() ).clamp(min=1.0)\n\n        # \u8ba1\u7b97\u52a0\u6743\u540e\u7684\u5750\u6807\u635f\u5931\uff0c\u5305\u62ec\u4e2d\u5fc3\u70b9\u5750\u6807\u548c\u5bbd\u9ad8\u635f\u5931\n        # \u4f7f\u7528 lambda_coord \u589e\u5f3a\u5750\u6807\u9884\u6d4b\u7684\u91cd\u8981\u6027\n        coord_loss = self.lambda_coord * (\n            coord_x_loss.sum() + coord_y_loss.sum() + \n            coord_w_loss.sum() + coord_h_loss.sum()\n        ) / num_resp\n\n        # \u8ba1\u7b97\u6709\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\uff0c\u4f7f\u7528\u8d1f\u8d23\u9884\u6d4b\u7684\u6846\u6570\u91cf\u8fdb\u884c\u5f52\u4e00\u5316\n        conf_obj_loss = conf_obj_terms.sum() / num_resp\n\n        # \u8ba1\u7b97\u52a0\u6743\u540e\u7684\u65e0\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\n        # \u4f7f\u7528 lambda_noobj \u964d\u4f4e\u80cc\u666f\u9884\u6d4b\u7684\u6743\u91cd\uff0c\u907f\u514d\u80cc\u666f\u4e3b\u5bfc\u8bad\u7ec3\u8fc7\u7a0b\n        conf_noobj_loss = self.lambda_noobj * conf_noobj_terms.sum() / num_noobj\n\n        # \u8ba1\u7b97\u603b\u635f\u5931\uff0c\u5c06\u6240\u6709\u635f\u5931\u7ec4\u4ef6\u76f8\u52a0\n        total_loss = coord_loss + conf_obj_loss + conf_noobj_loss + class_loss\n\n        # \u6784\u5efa\u635f\u5931\u5b57\u5178\uff0c\u7528\u4e8e\u8bb0\u5f55\u5404\u4e2a\u635f\u5931\u7ec4\u4ef6\u7684\u503c\n        # \u4f7f\u7528 detach().item() \u5c06\u5f20\u91cf\u8f6c\u6362\u4e3a Python \u6570\u503c\uff0c\u907f\u514d\u5728\u65e5\u5fd7\u8bb0\u5f55\u4e2d\u4fdd\u7559\u8ba1\u7b97\u56fe\n        loss_dict = {\n            'loss_total': total_loss.detach().item(),          # \u603b\u635f\u5931\n            'loss_coord': coord_loss.detach().item(),          # \u5750\u6807\u635f\u5931\n            'loss_conf_obj': conf_obj_loss.detach().item(),    # \u6709\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\n            'loss_conf_noobj': conf_noobj_loss.detach().item(),# \u65e0\u76ee\u6807\u7f6e\u4fe1\u5ea6\u635f\u5931\n            'loss_class': class_loss.detach().item(),          # \u5206\u7c7b\u635f\u5931\n        }\n\n        # \u8fd4\u56de\u603b\u635f\u5931\u548c\u635f\u5931\u5b57\u5178\n        return total_loss, loss_dict\n</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_16", "title": "\u63a8\u7406\u4e0e\u8bc4\u4f30", "text": "<p>\u552f\u4e00\u503c\u5f97\u4e00\u63d0\u7684\u5c31\u662f\u63a8\u7406\u65f6\u4f7f\u7528\u7684 NMS \u624b\u6bb5\u3002\u7531\u4e8e\u6253\u6846\u7684\u65f6\u5019\u6a21\u578b\u60f3\u63d0\u9ad8\u53ec\u56de\uff08\u5c24\u5176\u5728\u6211\u4eec\u4e4b\u524d\u9b54\u6539\u8fc7\u7684 YOLO Loss \u91cc\u9762\uff09\uff0c\u5c31\u4f1a\u7ed9\u540c\u4e00\u4e2a\u76ee\u6807\u6253\u5f88\u591a\u76f8\u4e92\u91cd\u53e0\u7684\u6846\uff0c\u4e8e\u662f\u6211\u4eec\u5c31\u9700\u8981\u5bf9\u8fd9\u4e9b\u6846\u8fdb\u884c\u7b5b\u9009\u3002</p> <p>\u9996\u5148\u8bc4\u5224\u4e00\u4e2a\u6846\u597d\u4e0d\u597d\u6700\u4f73\u6807\u51c6\u662f\u7f6e\u4fe1\u5ea6 \\(c\\)\uff0c\u56e0\u6b64\u6211\u4eec\u6309\u7f6e\u4fe1\u5ea6\u6392\u5e8f\uff0c\u6700\u9ad8\u7684\u6846\u5c31\u662f\u8d28\u91cf\u6700\u597d\u7684\u6846\u3002\u6211\u4eec\u8bb0\u5f55\u4e0b\u6765\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u4e0d\u80fd\u4fdd\u7559\u592a\u591a\u91cd\u53e0\u7684\u6846\uff0c\u5c31\u4e22\u5f03\u548c\u8fd9\u4e2a\u6700\u4f73\u6846 IoU \u5927\u4e8e\u67d0\u4e2a\u9608\u503c <code>NMS_IoU</code> \u7684\u6240\u6709\u6846\u3002\u7136\u540e\u5bf9\u5269\u4e0b\u7684\u6846\uff08\u4e0d\u542b\u90a3\u4e2a\u6700\u4f73\u6846\uff09\u91cd\u590d\u6267\u884c\u521a\u521a\u7684\u6392\u5e8f\u2014\u2014\u4e22\u5f03\u64cd\u4f5c\u3002\u6700\u540e\u8bb0\u5f55\u4e0b\u6765\u7684\u6240\u6709\u6846\u5c31\u662f\u7b5b\u9009\u597d\u7684\u6846\u4e86\u3002</p> <p>\u8fd9\u53eb\u505a Non-Max Suppression(NMS)\uff0c\u975e\u6781\u5927\u503c\u6291\u5236\u3002</p> <p>\u5176\u4ed6\u7684\u5185\u5bb9\uff0c\u8bf7\u5177\u4f53\u770b\u4ee3\u7801\u5427\u3002\u8fd9\u91cc\u6ca1\u6709\u7ed9 <code>yolo_decode</code> \u51fd\u6570\uff0c\u56e0\u4e3a\u89e3\u7801\u7684\u90e8\u5206\u5728 <code>YOLOV1Loss</code> \u7c7b\u91cc\u9762\u5df2\u7ecf\u6709\u5448\u73b0\u4e86\u3002</p>  \u5229\u7528 NMS \u8bc4\u4f30 mAP, P-R \u7b49\u6307\u6807  <pre><code>def nms_classwise(dets, iou_thr=0.45):\n    \"\"\"\n    \u6309\u7c7b\u522b\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236 (NMS)\uff0c\u53bb\u9664\u91cd\u53e0\u5ea6\u9ad8\u7684\u68c0\u6d4b\u6846\n\n    Args:\n        dets: \u68c0\u6d4b\u7ed3\u679c\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a [num_detections, 6]\uff0c\u6bcf\u884c\u5305\u542b [x1, y1, x2, y2, score, class]\n        iou_thr: IoU \u9608\u503c\uff0c\u7528\u4e8e\u5224\u65ad\u4e24\u4e2a\u6846\u662f\u5426\u91cd\u53e0\u8fc7\u9ad8\uff0c\u9ed8\u8ba4\u4e3a 0.45\n\n    Returns:\n        \u7ecf\u8fc7 NMS \u5904\u7406\u540e\u7684\u68c0\u6d4b\u7ed3\u679c\u5f20\u91cf\n    \"\"\"\n    # \u68c0\u67e5\u662f\u5426\u6709\u68c0\u6d4b\u7ed3\u679c\n    if dets.numel() == 0:\n        return dets\n\n    out = []\n    # \u5bf9\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u5904\u7406\n    for cls in dets[:,5].unique():\n        cls = int(cls.item())\n        # \u521b\u5efa\u5f53\u524d\u7c7b\u522b\u7684\u63a9\u7801\n        mask = dets[:,5] == cls\n        # \u63d0\u53d6\u5f53\u524d\u7c7b\u522b\u7684\u68c0\u6d4b\u7ed3\u679c\n        d = dets[mask]\n        # \u4f7f\u7528 TorchVision \u7684 NMS \u51fd\u6570\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236\n        # \u6ce8\u610f\uff1a\u8fd9\u91cc\u5e94\u7528\u4e86 NMS\uff0c\u8fd9\u662f\u53bb\u9664\u91cd\u53e0\u6846\u7684\u5173\u952e\u6b65\u9aa4\n        # NMS \u4f1a\u4fdd\u7559\u5f97\u5206\u6700\u9ad8\u7684\u6846\uff0c\u5e76\u79fb\u9664\u4e0e\u5176 IoU \u8d85\u8fc7\u9608\u503c\u7684\u5176\u4ed6\u6846\n        keep_idx = torchvision.ops.nms(d[:, :4], d[:, 4], iou_thr)\n        # \u5c06\u4fdd\u7559\u7684\u68c0\u6d4b\u7ed3\u679c\u6dfb\u52a0\u5230\u8f93\u51fa\u5217\u8868\n        out.append(d[keep_idx])\n\n    # \u5408\u5e76\u6240\u6709\u7c7b\u522b\u7684\u68c0\u6d4b\u7ed3\u679c\n    return torch.cat(out, dim=0) if out else dets\n\ndef evaluate_map_pr(dataset, model, device, conf_thresh=1e-4, nms_iou=0.45, iou_match=0.5, subsample=None):\n    \"\"\"\n    \u5168\u9762\u8bc4\u4f30 YOLO \u6a21\u578b\u7684\u6027\u80fd\uff0c\u8ba1\u7b97 mAP (mean Average Precision) \u548c\u7cbe\u786e\u7387-\u53ec\u56de\u7387\u6307\u6807\n\n    Args:\n        dataset: \u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e94\u63d0\u4f9b\u56fe\u50cf\u548c\u6807\u6ce8\n        model: \u8bad\u7ec3\u597d\u7684 YOLO \u6a21\u578b\n        device: \u8ba1\u7b97\u8bbe\u5907 ('cpu' \u6216 'cuda')\n        conf_thresh: \u7f6e\u4fe1\u5ea6\u9608\u503c\uff0c\u8fc7\u6ee4\u4f4e\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6846\uff0c\u9ed8\u8ba4 1e-4\n        nms_iou: NMS \u64cd\u4f5c\u7684 IoU \u9608\u503c\uff0c\u7528\u4e8e\u53bb\u9664\u91cd\u53e0\u6846\uff0c\u9ed8\u8ba4 0.45\n        iou_match: \u5224\u65ad\u9884\u6d4b\u6846\u4e0e\u771f\u5b9e\u6846\u5339\u914d\u7684 IoU \u9608\u503c\uff0c\u9ed8\u8ba4 0.5 (PASCAL VOC \u6807\u51c6)\n        subsample: \u8bc4\u4f30\u5b50\u96c6\u5927\u5c0f\uff0c\u7528\u4e8e\u5feb\u901f\u9a8c\u8bc1\uff0c\u9ed8\u8ba4\u8bc4\u4f30\u5168\u90e8\u6570\u636e\n\n    Returns:\n        dict: \u5305\u542b\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u7684\u5b57\u5178\n    \"\"\"\n    # \u8bbe\u7f6e\u6a21\u578b\u4e3a\u8bc4\u4f30\u6a21\u5f0f\uff0c\u5173\u95ed dropout \u548c batch normalization \u7684\u968f\u673a\u6027\n    model.eval()\n\n    # \u521b\u5efa\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u8bbe\u7f6e\u5408\u9002\u7684\u6279\u91cf\u5927\u5c0f\u548c\u5de5\u4f5c\u7ebf\u7a0b\u6570\n    loader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=NUM_WORKERS,\n                        pin_memory=PIN_MEMORY, persistent_workers=False, collate_fn=collate_fn)\n\n    # \u521d\u59cb\u5316\u6570\u636e\u7ed3\u6784\u5b58\u50a8\u6240\u6709\u771f\u5b9e\u6846\u548c\u9884\u6d4b\u6846\n    # all_gts: \u6309\u7c7b\u522b\u7ec4\u7ec7\u7684\u771f\u5b9e\u6846\uff0c\u7ed3\u6784\u4e3a {class_id: {image_id: [bboxes]}}\n    # all_preds: \u6309\u7c7b\u522b\u7ec4\u7ec7\u7684\u9884\u6d4b\u6846\uff0c\u7ed3\u6784\u4e3a {class_id: [(image_id, confidence, bbox)]}\n    all_gts = {c: {} for c in range(C_global)}\n    all_preds = {c: [] for c in range(C_global)}\n\n    # \u4f7f\u7528\u65e0\u68af\u5ea6\u8ba1\u7b97\u548c\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08\u5982\u679c\u542f\u7528\uff09\u4ee5\u63d0\u9ad8\u6548\u7387\n    with torch.no_grad(), torch.amp.autocast(device_type='cuda', enabled=AUTOCAST_ENABLED):\n        processed = 0  # \u5df2\u5904\u7406\u56fe\u50cf\u8ba1\u6570\u5668\n\n        # \u4f7f\u7528\u8fdb\u5ea6\u6761\u904d\u5386\u6570\u636e\u52a0\u8f7d\u5668\n        for images, targets, gts, ids in tqdm(loader, desc='Eval', leave=False):\n            # \u5c06\u56fe\u50cf\u6570\u636e\u8f6c\u79fb\u5230\u6307\u5b9a\u8bbe\u5907\uff08CPU/GPU\uff09\n            images = images.to(device, non_blocking=True)\n\n            # \u524d\u5411\u4f20\u64ad\u83b7\u53d6\u6a21\u578b\u9884\u6d4b\n            preds = model(images)\n\n            # \u89e3\u7801\u539f\u59cb\u9884\u6d4b\u8f93\u51fa\uff0c\u8f6c\u6362\u4e3a\u8fb9\u754c\u6846\u683c\u5f0f\n            dets_batch = yolo_decode(preds, conf_thresh=conf_thresh)\n\n            # \u5904\u7406\u6279\u6b21\u4e2d\u7684\u6bcf\u4e2a\u56fe\u50cf\n            for bi, dets in enumerate(dets_batch):\n                # \u5bf9\u68c0\u6d4b\u7ed3\u679c\u5e94\u7528\u975e\u6781\u5927\u503c\u6291\u5236 (NMS)\uff0c\u53bb\u9664\u91cd\u53e0\u6846\n                # \u8fd9\u662f\u8bc4\u4f30\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u786e\u4fdd\u6bcf\u4e2a\u76ee\u6807\u53ea\u6709\u4e00\u4e2a\u6700\u4f73\u9884\u6d4b\u6846\n                dets = nms_classwise(dets.detach().cpu(), iou_thr=nms_iou)\n\n                # \u83b7\u53d6\u5f53\u524d\u56fe\u50cf\u7684ID\u548c\u771f\u5b9e\u6807\u6ce8\n                img_id = ids[bi]\n                gt = gts[bi].cpu()  # \u771f\u5b9e\u6807\u6ce8\uff0c\u683c\u5f0f\u4e3a [x1, y1, x2, y2, class]\n\n                # \u5b58\u50a8\u771f\u5b9e\u6846\u4fe1\u606f\u5230\u5168\u5c40\u6570\u636e\u7ed3\u6784\n                for g in gt:\n                    x1, y1, x2, y2, cls = g.tolist()\n                    # \u521d\u59cb\u5316\u8be5\u7c7b\u522b\u7684\u56fe\u50cf\u5b57\u5178\uff08\u5982\u679c\u4e0d\u5b58\u5728\uff09\n                    if img_id not in all_gts[int(cls)]:\n                        all_gts[int(cls)][img_id] = []\n                    # \u6dfb\u52a0\u771f\u5b9e\u6846\u5750\u6807\n                    all_gts[int(cls)][img_id].append([x1, y1, x2, y2])\n\n                # \u5b58\u50a8\u9884\u6d4b\u6846\u4fe1\u606f\u5230\u5168\u5c40\u6570\u636e\u7ed3\u6784\n                for d in dets:\n                    x1, y1, x2, y2, score, cls = d.tolist()\n                    all_preds[int(cls)].append((img_id, score, [x1, y1, x2, y2]))\n\n            # \u66f4\u65b0\u5df2\u5904\u7406\u56fe\u50cf\u8ba1\u6570\n            processed += len(ids)\n\n            # \u5982\u679c\u8bbe\u7f6e\u4e86\u5b50\u91c7\u6837\u4e14\u5df2\u8fbe\u5230\u91c7\u6837\u6570\u91cf\uff0c\u63d0\u524d\u7ec8\u6b62\u8bc4\u4f30\n            if subsample is not None and processed &gt;= subsample:\n                break\n\n    # \u521d\u59cb\u5316\u8bc4\u4f30\u6307\u6807\n    aps = []  # \u5b58\u50a8\u6bcf\u4e2a\u7c7b\u522b\u7684 AP (Average Precision)\n    iou_list = []  # \u5b58\u50a8\u6240\u6709\u5339\u914d\u6846\u7684 IoU \u503c\uff0c\u7528\u4e8e\u8ba1\u7b97\u5e73\u5747 IoU\n    tp_total = fp_total = fn_total = 0  # \u5168\u5c40\u7684\u771f\u6b63\u4f8b\u3001\u5047\u6b63\u4f8b\u3001\u5047\u53cd\u4f8b\u8ba1\u6570\n\n    # \u5bf9\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\n    for cls in range(C_global):\n        # \u6309\u7f6e\u4fe1\u5ea6\u964d\u5e8f\u6392\u5e8f\u5f53\u524d\u7c7b\u522b\u7684\u6240\u6709\u9884\u6d4b\u6846\n        # \u8fd9\u662f\u8ba1\u7b97 PR \u66f2\u7ebf\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u6309\u7f6e\u4fe1\u5ea6\u4ece\u9ad8\u5230\u4f4e\u5904\u7406\u9884\u6d4b\n        preds = sorted(all_preds[cls], key=lambda x: -x[1])\n\n        # \u83b7\u53d6\u5f53\u524d\u7c7b\u522b\u7684\u6240\u6709\u771f\u5b9e\u6846\uff0c\u6309\u56fe\u50cf\u5206\u7ec4\n        gt_per_image = all_gts[cls]\n\n        # \u521b\u5efa\u5339\u914d\u6807\u8bb0\u5b57\u5178\uff0c\u8bb0\u5f55\u6bcf\u4e2a\u771f\u5b9e\u6846\u662f\u5426\u5df2\u88ab\u9884\u6d4b\u6846\u5339\u914d\n        # \u7ed3\u6784: {image_id: numpy_array_of_booleans}\n        gt_matched = {}\n        for img_id, boxes in gt_per_image.items():\n            gt_matched[img_id] = np.zeros(len(boxes), dtype=bool)\n\n        # \u521d\u59cb\u5316\u771f\u6b63\u4f8b(TP)\u3001\u5047\u6b63\u4f8b(FP)\u548c\u5f97\u5206\u5217\u8868\n        TPs, FPs, scores = [], [], []\n\n        # \u6309\u7f6e\u4fe1\u5ea6\u4ece\u9ad8\u5230\u4f4e\u904d\u5386\u6240\u6709\u9884\u6d4b\u6846\n        for (img_id, score, box) in preds:\n            scores.append(score)  # \u8bb0\u5f55\u5f53\u524d\u9884\u6d4b\u6846\u7684\u5f97\u5206\n\n            # \u83b7\u53d6\u5f53\u524d\u56fe\u50cf\u4e2d\u8be5\u7c7b\u522b\u7684\u6240\u6709\u771f\u5b9e\u6846\n            gt_boxes = gt_per_image.get(img_id, [])\n\n            # \u5982\u679c\u5f53\u524d\u56fe\u50cf\u6ca1\u6709\u8be5\u7c7b\u522b\u7684\u771f\u5b9e\u6846\uff0c\u6240\u6709\u9884\u6d4b\u90fd\u662f\u5047\u6b63\u4f8b(FP)\n            if len(gt_boxes) == 0:\n                TPs.append(0)\n                FPs.append(1)\n                continue\n\n            # \u8ba1\u7b97\u5f53\u524d\u9884\u6d4b\u6846\u4e0e\u6240\u6709\u771f\u5b9e\u6846\u7684 IoU\n            box_t = torch.tensor([box], dtype=torch.float32)  # \u5f53\u524d\u9884\u6d4b\u6846\n            gt_t = torch.tensor(gt_boxes, dtype=torch.float32)  # \u6240\u6709\u771f\u5b9e\u6846\n\n            # \u8ba1\u7b97 IoU \u77e9\u9635\u5e76\u83b7\u53d6\u6700\u5927\u503c\u548c\u7d22\u5f15\n            ious = box_iou_xyxy(box_t, gt_t).squeeze(0).numpy()\n            best_idx = ious.argmax()  # \u6700\u9ad8 IoU \u7684\u7d22\u5f15\n            best_iou = ious[best_idx]  # \u6700\u9ad8 IoU \u503c\n\n            # \u5224\u65ad\u662f\u5426\u4e3a\u771f\u6b63\u4f8b(TP)\u7684\u6761\u4ef6\uff1a\n            # 1. IoU \u8d85\u8fc7\u5339\u914d\u9608\u503c (\u901a\u5e38\u4e3a 0.5)\n            # 2. \u5bf9\u5e94\u7684\u771f\u5b9e\u6846\u5c1a\u672a\u88ab\u5339\u914d\n            if best_iou &gt;= iou_match and not gt_matched[img_id][best_idx]:\n                TPs.append(1)  # \u771f\u6b63\u4f8b\n                FPs.append(0)  # \u4e0d\u662f\u5047\u6b63\u4f8b\n                gt_matched[img_id][best_idx] = True  # \u6807\u8bb0\u8be5\u771f\u5b9e\u6846\u5df2\u88ab\u5339\u914d\n                iou_list.append(best_iou)  # \u8bb0\u5f55\u5339\u914d\u6846\u7684 IoU\n            else:\n                TPs.append(0)  # \u4e0d\u662f\u771f\u6b63\u4f8b\n                FPs.append(1)  # \u5047\u6b63\u4f8b\n\n        # \u8f6c\u6362\u4e3a numpy \u6570\u7ec4\u4ee5\u4fbf\u5411\u91cf\u5316\u8ba1\u7b97\n        TPs, FPs, scores = np.array(TPs), np.array(FPs), np.array(scores)\n\n        # \u8ba1\u7b97\u7d2f\u79ef\u771f\u6b63\u4f8b\u548c\u5047\u6b63\u4f8b\u6570\u91cf\n        cum_TP = np.cumsum(TPs)\n        cum_FP = np.cumsum(FPs)\n\n        # \u8ba1\u7b97\u5f53\u524d\u7c7b\u522b\u7684\u771f\u5b9e\u6846\u603b\u6570\n        total_gts = sum(len(v) for v in gt_per_image.values())\n\n        # \u5982\u679c\u6ca1\u6709\u771f\u5b9e\u6846\uff0cAP \u8bbe\u4e3a 0\n        if total_gts == 0:\n            aps.append(0.0)\n            continue\n\n        # \u8ba1\u7b97\u53ec\u56de\u7387\u548c\u7cbe\u786e\u7387\u66f2\u7ebf\n        # \u53ec\u56de\u7387 = \u771f\u6b63\u4f8b\u6570 / \u603b\u771f\u5b9e\u6846\u6570\n        recalls = cum_TP / (total_gts + 1e-8)\n\n        # \u7cbe\u786e\u7387 = \u771f\u6b63\u4f8b\u6570 / (\u771f\u6b63\u4f8b\u6570 + \u5047\u6b63\u4f8b\u6570)\n        precisions = cum_TP / (cum_TP + cum_FP + 1e-8)\n\n        # \u4f7f\u7528 11\u70b9\u63d2\u503c\u6cd5\u8ba1\u7b97 AP (Average Precision)\n        # \u8fd9\u662f PASCAL VOC \u6311\u6218\u8d5b\u7684\u6807\u51c6\u8bc4\u4f30\u65b9\u6cd5\n        ap = 0.0\n        for t in np.linspace(0, 1, 11):  # \u5728 [0, 1] \u533a\u95f4\u5747\u5300\u53d611\u4e2a\u70b9\n            # \u5bf9\u4e8e\u6bcf\u4e2a\u53ec\u56de\u7387\u9608\u503c t\uff0c\u627e\u5230\u6240\u6709\u53ec\u56de\u7387 \u2265 t \u7684\u7cbe\u786e\u7387\u6700\u5927\u503c\n            p = precisions[recalls &gt;= t].max() if np.any(recalls &gt;= t) else 0.0\n            ap += p / 11.0  # \u5e73\u5747\u8fd9\u4e9b\u7cbe\u786e\u7387\u503c\n\n        aps.append(ap)  # \u8bb0\u5f55\u5f53\u524d\u7c7b\u522b\u7684 AP\n\n        # \u8ba1\u7b97\u7f6e\u4fe1\u5ea6\u9608\u503c 0.5 \u4e0b\u7684 TP, FP, FN\n        # \u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f88\u6709\u7528\uff0c\u56e0\u4e3a\u5b83\u53cd\u6620\u4e86\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\n        mask = scores &gt;= 0.5  # \u9009\u62e9\u7f6e\u4fe1\u5ea6 \u2265 0.5 \u7684\u9884\u6d4b\n        tp = int(TPs[mask].sum())  # \u771f\u6b63\u4f8b\u6570\n        fp = int(FPs[mask].sum())  # \u5047\u6b63\u4f8b\u6570\n        fn = total_gts - tp  # \u5047\u53cd\u4f8b\u6570 = \u603b\u771f\u5b9e\u6846\u6570 - \u771f\u6b63\u4f8b\u6570\n\n        # \u7d2f\u52a0\u5230\u5168\u5c40\u8ba1\u6570\n        tp_total += tp\n        fp_total += fp\n        fn_total += fn\n\n    # \u8ba1\u7b97\u6700\u7ec8\u8bc4\u4f30\u6307\u6807\n    # mAP: \u6240\u6709\u7c7b\u522b AP \u7684\u5e73\u5747\u503c\uff0c\u662f\u76ee\u6807\u68c0\u6d4b\u7684\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\n    mAP = float(np.mean(aps)) if len(aps) else 0.0\n\n    # \u5e73\u5747 IoU: \u6240\u6709\u5339\u914d\u6846\u7684 IoU \u5e73\u5747\u503c\uff0c\u53cd\u6620\u5b9a\u4f4d\u7cbe\u5ea6\n    mean_iou_matched = float(np.mean(iou_list)) if len(iou_list) else 0.0\n\n    # \u7f6e\u4fe1\u5ea6\u9608\u503c 0.5 \u4e0b\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\n    precision_05 = tp_total / (tp_total + fp_total + 1e-8)\n    recall_05 = tp_total / (tp_total + fn_total + 1e-8)\n\n    # \u8fd4\u56de\u5305\u542b\u6240\u6709\u8bc4\u4f30\u6307\u6807\u7684\u5b57\u5178\n    return {\n        'mAP_50': mAP,  # \u4f7f\u7528 IoU \u9608\u503c 0.5 \u7684 mAP\n        'mean_iou_matched': mean_iou_matched,  # \u5339\u914d\u6846\u7684\u5e73\u5747 IoU\n        'precision@0.5': precision_05,  # \u7f6e\u4fe1\u5ea6\u9608\u503c 0.5 \u4e0b\u7684\u7cbe\u786e\u7387\n        'recall@0.5': recall_05,  # \u7f6e\u4fe1\u5ea6\u9608\u503c 0.5 \u4e0b\u7684\u53ec\u56de\u7387\n        'AP_per_class': aps  # \u6bcf\u4e2a\u7c7b\u522b\u7684 AP \u503c\uff0c\u7528\u4e8e\u5206\u6790\u7c7b\u522b\u7279\u5f02\u6027\u6027\u80fd\n    }\n</code></pre>"}, {"location": "DNN/model-expr/S-and-D-models-replication/#_17", "title": "\u53ef\u89c6\u5316", "text": "<p>\u8fd9\u91cc\u5b9e\u73b0\u4e86\u901a\u8fc7\u6444\u50cf\u5934\u89c6\u9891\u6d41\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u3002</p>  \u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u4f7f\u7528\u7684\u4ee3\u7801  <pre><code>import os\nimport math\nimport time\nfrom pathlib import Path\n\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torchvision.models import resnet18, ResNet18_Weights\nfrom torchvision.models import regnet_y_1_6gf, RegNet_Y_1_6GF_Weights\n\n# --------------------\n# \u5168\u5c40\u914d\u7f6e (\u4ec5\u4fdd\u7559\u63a8\u7406\u5fc5\u8981\u53c2\u6570)\n# --------------------\nS = 7   # \u7f51\u683c\u5927\u5c0f\nB = 2   # \u6bcf\u4e2a\u7f51\u683c\u7684\u8fb9\u754c\u6846\u6570\u91cf\nC = 20  # VOC\u7c7b\u522b\u6570\u91cf\nIMG_SIZE = 448  # \u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\nDEVICE = 'cuda' if torch.cuda.is_available() else 'xpu' if torch.xpu.is_available() else 'cpu'\nAUTOCAST_ENABLED = (DEVICE == 'cuda' or DEVICE == 'xpu')\n\n# VOC\u7c7b\u522b\u6620\u5c04\nVOC_CLASSES = [\n    'aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair',\n    'cow','diningtable','dog','horse','motorbike','person','pottedplant',\n    'sheep','sofa','train','tvmonitor'\n]\nCLASS_TO_IDX = {c:i for i,c in enumerate(VOC_CLASSES)}\nIDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n\n# --------------------\n# \u8fb9\u754c\u6846\u5de5\u5177\u51fd\u6570\n# --------------------\ndef box_iou_xyxy(boxes1, boxes2):\n    # boxes1: [N, 4], boxes2: [M, 4]\n    N = boxes1.size(0)\n    M = boxes2.size(0)\n    if N == 0 or M == 0:\n        return torch.zeros((N, M), device=boxes1.device)\n    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])   # [N,M,2]\n    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])   # [N,M,2]\n    wh = (rb - lt).clamp(min=0)\n    inter = wh[:, :, 0] * wh[:, :, 1]\n    area1 = (boxes1[:, 2] - boxes1[:, 0]).clamp(min=0) * (boxes1[:, 3] - boxes1[:, 1]).clamp(min=0)\n    area2 = (boxes2[:, 2] - boxes2[:, 0]).clamp(min=0) * (boxes2[:, 3] - boxes2[:, 1]).clamp(min=0)\n    union = area1[:, None] + area2 - inter\n    iou = inter / (union + 1e-8)\n    return iou\n\ndef cxcywh_to_xyxy(boxes):\n    cx, cy, w, h = boxes[..., 0], boxes[..., 1], boxes[..., 2], boxes[..., 3]\n    x1 = (cx - w / 2.0)\n    y1 = (cy - h / 2.0)\n    x2 = (cx + w / 2.0)\n    y2 = (cy + h / 2.0)\n    return torch.stack([x1, y1, x2, y2], dim=-1)\n\n# --------------------\n# YOLOv1\u6a21\u578b\u5b9a\u4e49\n# --------------------\nclass YOLOv1ResNet18(nn.Module):\n    def __init__(self, s=7, b=2, c=20, pretrained=True):\n        super().__init__()\n        self.S, self.B, self.C = s, b, c\n        backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n        self.stem = nn.Sequential(\n            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n            backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4\n        )\n        self.reduce = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        out_ch = b*5 + c\n        self.head = nn.Sequential(\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, out_ch, kernel_size=1)\n        )\n\n    def forward(self, x):\n        x = self.stem(x)     # [N,512,14,14] \u8f93\u5165\u4e3a448x448\u65f6\n        x = self.reduce(x)   # [N,1024,7,7]\n        x = self.head(x)     # [N,(B*5+C),7,7]\n        x = x.permute(0, 2, 3, 1).contiguous()\n        return x  # [N,S,S,B*5+C]\n\n# --------------------\n# \u9884\u6d4b\u89e3\u7801\u4e0e\u540e\u5904\u7406\n# --------------------\ndef yolo_decode(pred, conf_thresh=0.05):\n    \"\"\"\u5c06\u6a21\u578b\u8f93\u51fa\u89e3\u7801\u4e3a\u8fb9\u754c\u6846 [x1,y1,x2,y2,score,cls] (\u5f52\u4e00\u5316\u5750\u6807)\"\"\"\n    N = pred.size(0)\n    pred = pred.view(N, S, S, B*5+C)\n    boxes = pred[...,:B*5].view(N, S, S, B, 5)\n    cls_logits = pred[...,B*5:]  # [N,S,S,C]\n    cls_prob = F.softmax(cls_logits, dim=-1)\n\n    # \u751f\u6210\u7f51\u683c\u5750\u6807\n    grid_x = torch.arange(S, device=pred.device).float()\n    grid_y = torch.arange(S, device=pred.device).float()\n    gy, gx = torch.meshgrid(grid_y, grid_x, indexing='ij')\n    gx = gx[None, :, :, None]\n    gy = gy[None, :, :, None]\n\n    # \u89e3\u7801\u8fb9\u754c\u6846\n    px = boxes[...,0].sigmoid()\n    py = boxes[...,1].sigmoid()\n    pw = F.softplus(boxes[...,2]).pow(2).clamp(min=1e-6, max=1.0)\n    ph = F.softplus(boxes[...,3]).pow(2).clamp(min=1e-6, max=1.0)\n    pconf = boxes[...,4].sigmoid()\n\n    # \u8f6c\u6362\u4e3a\u5f52\u4e00\u5316\u5750\u6807\n    pcx = (gx + px) / float(S)\n    pcy = (gy + py) / float(S)\n    p_cxcywh = torch.stack([pcx.expand_as(px), pcy.expand_as(py), pw, ph], dim=-1)\n    p_xyxy = cxcywh_to_xyxy(p_cxcywh).clamp(0, 1)\n\n    dets_per_image = []\n    for n in range(N):\n        boxes_n = p_xyxy[n].view(-1, 4)      # [S*S*B,4]\n        conf_n = pconf[n].view(-1, 1)        # [S*S*B,1]\n        cls_prob_n = cls_prob[n].view(S*S, C)\n        cls_prob_expand = cls_prob_n.repeat_interleave(B, dim=0)  # [S*S*B,C]\n        scores = conf_n * cls_prob_expand                          # [S*S*B,C]\n        max_scores, max_cls = scores.max(dim=1)\n        keep = max_scores &gt; conf_thresh\n\n        if keep.sum() == 0:\n            dets_per_image.append(torch.zeros((0,6), device=pred.device))\n            continue\n\n        boxes_keep = boxes_n[keep]\n        scores_keep = max_scores[keep]\n        cls_keep = max_cls[keep].float()\n        dets = torch.cat([boxes_keep, scores_keep.unsqueeze(1), cls_keep.unsqueeze(1)], dim=1)\n        dets_per_image.append(dets)\n\n    return dets_per_image\n\ndef nms_classwise(dets, iou_thr=0.45):\n    \"\"\"\u6309\u7c7b\u522b\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236\"\"\"\n    if dets.numel() == 0:\n        return dets\n    out = []\n    for cls in dets[:,5].unique():\n        cls = int(cls.item())\n        mask = dets[:,5] == cls\n        class_dets = dets[mask]\n        keep_idx = torchvision.ops.nms(class_dets[:, :4], class_dets[:, 4], iou_thr)\n        out.append(class_dets[keep_idx])\n    return torch.cat(out, dim=0) if len(out) else dets\n\n# --------------------\n# \u6444\u50cf\u5934\u5b9e\u65f6\u68c0\u6d4b\u529f\u80fd\n# --------------------\ndef preprocess_frame(frame, img_size=448):\n    \"\"\"\u9884\u5904\u7406\u6444\u50cf\u5934\u5e27\u7528\u4e8e\u6a21\u578b\u8f93\u5165\"\"\"\n    # \u8c03\u6574\u5927\u5c0f\n    frame_resized = cv2.resize(frame, (img_size, img_size))\n    # BGR\u8f6cRGB\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    # \u8f6c\u6362\u4e3a\u5f20\u91cf\u5e76\u5f52\u4e00\u5316\n    frame_tensor = torch.from_numpy(frame_rgb).permute(2, 0, 1).float() / 255.0\n    # \u5e94\u7528ImageNet\u6807\u51c6\u5316\n    normalize = transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n    frame_tensor = normalize(frame_tensor)\n    # \u6dfb\u52a0\u6279\u6b21\u7ef4\u5ea6\n    return frame_tensor.unsqueeze(0)\n\ndef draw_detections(frame, detections, img_size):\n    \"\"\"\u5728\u539f\u59cb\u5e27\u4e0a\u7ed8\u5236\u68c0\u6d4b\u7ed3\u679c\"\"\"\n    h, w = frame.shape[:2]\n    for det in detections:\n        x1, y1, x2, y2, score, cls_idx = det\n        # \u5c06\u5f52\u4e00\u5316\u5750\u6807\u8f6c\u6362\u4e3a\u539f\u59cb\u56fe\u50cf\u5c3a\u5bf8\n        x1 = int(x1 * w)\n        y1 = int(y1 * h)\n        x2 = int(x2 * w)\n        y2 = int(y2 * h)\n\n        # \u7ed8\u5236\u8fb9\u754c\u6846\n        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n        # \u7ed8\u5236\u7c7b\u522b\u548c\u7f6e\u4fe1\u5ea6\n        cls_name = IDX_TO_CLASS[int(cls_idx)]\n        label = f\"{cls_name} {score:.2f}\"\n        cv2.putText(frame, label, (x1, max(0, y1-10)), \n                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    return frame\n\ndef run_camera_detection(model, fps=15, conf_thresh=0.6, nms_iou=0.45):\n    \"\"\"\u8fd0\u884c\u6444\u50cf\u5934\u5b9e\u65f6\u68c0\u6d4b\"\"\"\n    # \u6253\u5f00\u6444\u50cf\u5934\n    cap = cv2.VideoCapture(0)\n    if not cap.isOpened():\n        print(\"\u65e0\u6cd5\u6253\u5f00\u6444\u50cf\u5934\")\n        return\n\n    # \u8bbe\u7f6e\u6444\u50cf\u5934\u53c2\u6570\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n    cap.set(cv2.CAP_PROP_FPS, fps)\n\n    model.eval()\n    model.to(DEVICE)\n    print(\"\u5f00\u59cb\u5b9e\u65f6\u68c0\u6d4b (\u6309 'q' \u9000\u51fa)\")\n\n    try:\n        while True:\n            start_time = time.time()\n\n            # \u8bfb\u53d6\u4e00\u5e27\n            ret, frame = cap.read()\n            if not ret:\n                print(\"\u65e0\u6cd5\u83b7\u53d6\u89c6\u9891\u5e27\")\n                break\n\n            # \u9884\u5904\u7406\n            input_tensor = preprocess_frame(frame, IMG_SIZE).to(DEVICE)\n\n            # \u6a21\u578b\u63a8\u7406\n            with torch.no_grad(), torch.amp.autocast(device_type='cuda' if DEVICE == 'cuda' else 'cpu', \n                                                  enabled=AUTOCAST_ENABLED):\n                pred = model(input_tensor)\n\n            # \u89e3\u7801\u548c\u540e\u5904\u7406\n            dets = yolo_decode(pred, conf_thresh=conf_thresh)[0].detach().cpu()\n            dets = nms_classwise(dets, iou_thr=nms_iou)\n\n            # \u7ed8\u5236\u68c0\u6d4b\u7ed3\u679c\n            frame_with_dets = draw_detections(frame, dets, IMG_SIZE)\n\n            # \u8ba1\u7b97\u5e76\u663e\u793aFPS\n            elapsed = time.time() - start_time\n            current_fps = 1.0 / elapsed if elapsed &gt; 0 else 0\n            cv2.putText(frame_with_dets, f\"FPS: {current_fps:.1f}\", (10, 30),\n                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n\n            # \u663e\u793a\u7ed3\u679c\n            cv2.imshow(\"YOLOv1 Real-time Detection\", frame_with_dets)\n\n            # \u6309'q'\u9000\u51fa\n            if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n                break\n\n    finally:\n        cap.release()\n        cv2.destroyAllWindows()\n\n# --------------------\n# \u4e3b\u51fd\u6570 - \u52a0\u8f7d\u6a21\u578b\u5e76\u542f\u52a8\u68c0\u6d4b\n# --------------------\ndef main():\n    # \u521b\u5efa\u6a21\u578b\n    model = YOLOv1ResNet18(s=S, b=B, c=C, pretrained=True)\n\n    # \u52a0\u8f7d\u6743\u91cd\n    checkpoint_path = './yolov1_resnet18_voc0712.pth'\n    if os.path.exists(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, map_location=torch.device(DEVICE))\n        # \u52a0\u8f7d\u6a21\u578b\u6743\u91cd\n        model.load_state_dict(checkpoint['model_state_dict'])\n        print(f\"\u6210\u529f\u52a0\u8f7d\u6a21\u578b\u6743\u91cd: {checkpoint_path}\")\n    else:\n        print(f\"\u8b66\u544a: \u672a\u627e\u5230\u6a21\u578b\u6743\u91cd\u6587\u4ef6 {checkpoint_path}\uff0c\u4f7f\u7528\u968f\u673a\u6743\u91cd\")\n\n    # \u542f\u52a8\u6444\u50cf\u5934\u68c0\u6d4b\n    run_camera_detection(\n        model,\n        fps=15,           # \u76ee\u6807\u5e27\u7387\n        conf_thresh=0.50, # \u7f6e\u4fe1\u5ea6\u9608\u503c\n        nms_iou=0.45      # NMS\u7684IOU\u9608\u503c\n    )\n\nif __name__ == \"__main__\":\n    print(f\"using device: {DEVICE}\")\n    import torchvision  # \u5ef6\u8fdf\u5bfc\u5165\uff0c\u4ec5\u5728\u4e3b\u7a0b\u5e8f\u8fd0\u884c\u65f6\u9700\u8981\n    print(\"\u521d\u59cb\u5316\u5b8c\u6bd5\uff0c\u5f00\u59cb\u52a0\u8f7d\u6743\u91cd...\")\n    main()\n</code></pre> <p>\u6700\u540e\u5728\u771f\u5b9e\u4e16\u754c\u6837\u672c\u7684\u68c0\u6d4b\u6548\u679c\u5982\u4e0b\uff1a\uff08\u5e27\u7387\u5f88\u4f4e\u662f\u7531\u4e8e\u7b14\u8bb0\u672c\u6ca1\u6709\u72ec\u663e\u5bfc\u81f4\u53ea\u80fd\u5728 CPU \u4e0a\u9762\u63a8\u7406\uff09</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 13, 2025). \u56fe\u50cf\u8bed\u4e49\u5206\u5272\u548c\u76ee\u6807\u68c0\u6d4b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/model-expr/S-and-D-models-replication</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{S-and-D-models-replication,\n    title={\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u548c\u76ee\u6807\u68c0\u6d4b\u76f8\u5173\u6a21\u578b\u590d\u73b0\u624b\u8bb0},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/model-expr/S-and-D-models-replication}},\n}\n</code></pre></p>"}, {"location": "DNN/optimizer/", "title": "\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5668\u6982\u8ff0", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 6 \u5206\u949f\u3000|\u3000\u7ea6 930 \u5b57\u3000|\u3000\u7ea6 8 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 187 \u884c\u4ee3\u7801</p>"}, {"location": "DNN/optimizer/#_2", "title": "\u5199\u5728\u524d\u9762", "text": "<p>\u672c\u6587\u8bd5\u56fe\u5bf9 1951(SGD) \u5230 2024 (Muon) \u7684\u5927\u90e8\u5206\u4e3b\u6d41\u4f18\u5316\u5668\u53d1\u5c55\u53f2\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u6982\u8ff0\u3002\u5c3d\u7ba1\u201c\u7b80\u5355\u201d\uff0c\u4f46\u4e5f\u5df2\u7ecf\u8fbe\u5230\u4e86\u4e0a\u4e07\u5b57\u7684\u89c4\u6a21\u3002\u8fd9\u662f\u56e0\u4e3a\u6211\u5e76\u4e0d\u6ee1\u8db3\u4e8e\u5e02\u9762\u4e0a\u5927\u90e8\u5206\u535a\u5ba2\u5bf9\u4f18\u5316\u5668\u7684\u4ecb\u7ecd\u4ec5\u9650\u4e8e\u7b80\u5355\u7684\u7f57\u5217\u516c\u5f0f\uff0c\u76f8\u53cd\uff0c\u6211\u66f4\u5e0c\u671b\u627e\u51fa\u4f18\u5316\u5668\u8fdb\u5316\u7684\u4e00\u4e24\u6761\u8d2f\u7a7f\u6574\u4e2a\u5386\u53f2\u957f\u6cb3\u7684\u4f0f\u7b14\u4e0e\u7ebf\u7d22\uff08\u6bd4\u5982\u4f18\u5316\u5668\u91cc\u9762\u6709\u4e00\u5806 \u03b1\u03b2\u03b4\u03b7 \u4ec0\u4e48\u7684\u8bf4\u660e\u4f5c\u8005\u4eec\u90fd\u559c\u6b22\u73a9osu!mania\u8fd8\u662f\u6bb5\u4f4d\u5403\uff09\uff0c\u4ece\u800c\u5e0c\u671b\u80fd\u591f\u7ed9\u5217\u4f4d\u770b\u5b98\u4e00\u70b9\u542f\u53d1\u3002\u884c\u7b14\u4ed3\u4fc3\uff0c\u9519\u8bef\u5728\u6240\u96be\u514d\uff0c\u6073\u8bf7\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u672c\u6587\u7684\u53ef\u89c6\u5316\u501f\u52a9\u4e86 <code>pytorch-optimizer</code> \u5e93\u7684 <code>viz_optimizers.py</code>\uff0c\u7136\u540e\u9b54\u6539\u4e86\u4e00\u4e0b\u4f7f\u5176\u80fd\u9002\u5e94\u8f83\u65b0\u7684\u5e93\u7248\u672c\uff0c\u5e76\u652f\u6301\u751f\u6210\u52a8\u56fe\u3002\u4ee3\u7801\u5982\u4e0b\uff1a</p>  viz_optimizers_animated.py <pre><code>import glob\nimport math\nimport os\nimport shutil\nimport subprocess\nimport time\n\nimport matplotlib\nmatplotlib.use('Agg')\n\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nfrom hyperopt import fmin, hp, tpe\n\nimport torch_optimizer as optim\n\nsns.set_theme(style=\"whitegrid\")\n\ndef rosenbrock(tensor):\n    x, y = tensor\n    return (1 - x) ** 2 + 100 * (y - x**2) ** 2\n\ndef rastrigin(tensor, lib=torch):\n    x, y = tensor\n    A = 10\n    f = (A * 2 + (x**2 - A * lib.cos(x * math.pi * 2)) + (y**2 - A * lib.cos(y * math.pi * 2)))\n    return f\n\ndef execute_steps(func, initial_state, optimizer_class, optimizer_config, num_iter=500):\n    x = torch.Tensor(initial_state).requires_grad_(True)\n    optimizer = optimizer_class([x], **optimizer_config)\n    steps = np.zeros((2, num_iter + 1))\n    steps[:, 0] = np.array(initial_state)\n    for i in range(1, num_iter + 1):\n        optimizer.zero_grad()\n        f = func(x)\n        f.backward(create_graph=True, retain_graph=True)\n        torch.nn.utils.clip_grad_norm_(x, 1.0)\n        optimizer.step()\n        steps[:, i] = x.detach().numpy()\n    return steps\n\ndef objective_rastrigin(params):\n    optimizer_config = dict(lr=params[\"lr\"])\n    steps = execute_steps(rastrigin, (-2.0, 3.5), params[\"optimizer_class\"], optimizer_config, 100)\n    minimum = (0, 0)\n    return (steps[0][-1] - minimum[0]) ** 2 + (steps[1][-1] - minimum[1]) ** 2\n\ndef objective_rosenbrock(params):\n    optimizer_config = dict(lr=params[\"lr\"])\n    steps = execute_steps(rosenbrock, (-2.0, 2.0), params[\"optimizer_class\"], optimizer_config, 100)\n    minimum = (1.0, 1.0)\n    return (steps[0][-1] - minimum[0]) ** 2 + (steps[1][-1] - minimum[1]) ** 2\n\n\ndef plot_static_image(steps, func_name, optimizer_name, lr, X, Y, Z, minimum):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    if func_name == \"rosenbrock\":\n        ax.contour(X, Y, Z, np.logspace(-0.5, 3.5, 20, base=10), cmap=\"jet\")\n    else:\n        ax.contour(X, Y, Z, 20, cmap=\"jet\")\n    iter_x, iter_y = steps[0, :], steps[1, :]\n    ax.plot(iter_x, iter_y, \"r-x\", label=\"Optimizer Path\")\n    ax.plot(iter_x[0], iter_y[0], 'go', markersize=10, label='Start')\n    ax.plot(iter_x[-1], iter_y[-1], \"rD\", markersize=10, label=\"End\")\n    ax.plot(*minimum, \"gD\", markersize=10, label=\"Global Minimum\")\n    ax.legend()\n    ax.set_title(f\"{func_name.capitalize()} Function: {optimizer_name}\\n{len(iter_x)-1} iterations, lr={lr:.6f}\")\n    output_path = f\"docs/{func_name}_{optimizer_name}.png\"\n    plt.savefig(output_path)\n    plt.close(fig)\n\n\ndef create_animation_with_fading_tail(\n    steps, func_name, optimizer_name, lr, X, Y, Z, minimum,\n    gif_resolution=256, tail_length=20, fade_length=30\n):\n    fig_size_inches = 8\n    dpi = gif_resolution / fig_size_inches\n    num_frames = steps.shape[1]\n    images = []\n\n    print(f\"    - Step 1/3: Rendering {num_frames} frames into memory (with fading tail)...\")\n    for i in range(num_frames):\n        fig, ax = plt.subplots(figsize=(fig_size_inches, fig_size_inches), dpi=dpi)\n\n        if func_name == \"rosenbrock\":\n            ax.contour(X, Y, Z, np.logspace(-0.5, 3.5, 20, base=10), cmap=\"jet\")\n        else:\n            ax.contour(X, Y, Z, 20, cmap=\"jet\")\n        ax.plot(*minimum, \"gD\", markersize=10, label=\"Global Minimum\")\n\n        start_solid = max(0, i - tail_length)\n        solid_path = steps[:, start_solid : i + 1]\n        ax.plot(solid_path[0], solid_path[1], \"r-\", lw=1.5)\n        ax.plot(solid_path[0], solid_path[1], \"rx\", markersize=4)\n\n        start_fade = max(0, start_solid - fade_length)\n        for j in range(start_solid - 1, start_fade - 1, -1):\n            age = start_solid - j\n            alpha = 1.0 - (age / fade_length)\n\n            segment = steps[:, j : j + 2]\n            ax.plot(segment[0], segment[1], color='red', lw=1.5, alpha=alpha)\n\n        ax.plot(steps[0, i], steps[1, i], \"rD\", markersize=8, label=\"Current Position\")\n\n        ax.legend()\n        ax.set_title(f\"{func_name.capitalize()} Function: {optimizer_name}\\nIteration: {i}/{num_frames-1}, lr={lr:.6f}\")\n\n        fig.canvas.draw()\n        argb_buffer = fig.canvas.tostring_argb()\n        image_argb = np.frombuffer(argb_buffer, dtype='uint8').reshape(fig.canvas.get_width_height()[::-1] + (4,))\n        image_rgb = image_argb[:, :, 1:]\n        images.append(image_rgb)\n        plt.close(fig)\n\n        print(f\"\\r      Rendered frame {i + 1}/{num_frames}\", end=\"\")\n    print()\n\n    output_path = f\"gifs/{func_name}_{optimizer_name}.gif\"\n\n    print(f\"    - Step 2/3: Creating initial GIF with imageio...\")\n    imageio.mimsave(output_path, images, fps=25)\n    size_before = os.path.getsize(output_path) / 1024\n    print(f\"      Initial GIF saved ({size_before:.1f} KB).\")\n\n    print(f\"    - Step 3/3: Compressing GIF with gifsicle...\")\n    try:\n        subprocess.run(\n            [\"gifsicle\", \"-O2\", \"--colors\", \"256\", \"-o\", output_path, output_path],\n            check=True, capture_output=True, text=True\n        )\n        size_after = os.path.getsize(output_path) / 1024\n        reduction = (1 - size_after / size_before) * 100 if size_before &gt; 0 else 0\n        print(f\"      GIF compressed successfully. Size reduced by {reduction:.1f}% to {size_after:.1f} KB.\")\n    except (subprocess.CalledProcessError, FileNotFoundError) as e:\n        print(\"\\n      [WARNING] Gifsicle compression failed.\")\n        print(\"      Please ensure 'gifsicle' is installed and in your system's PATH.\")\n        if isinstance(e, subprocess.CalledProcessError):\n            print(f\"      Gifsicle stderr: {e.stderr}\")\n\n\ndef execute_experiments(optimizers, objective, func, func_name, plot_params, initial_state, gif_config, seed=1):\n    total_optimizers = len(optimizers)\n    print(\"=\" * 60)\n    print(f\"STARTING EXPERIMENTS FOR: {func_name.capitalize()} Function\")\n    print(f\"Total optimizers to test: {total_optimizers}\")\n    print(\"=\" * 60)\n\n    if not os.path.exists(\"docs\"): os.makedirs(\"docs\")\n    if not os.path.exists(\"gifs\"): os.makedirs(\"gifs\")\n\n    x = np.linspace(plot_params['xlim'][0], plot_params['xlim'][1], 250)\n    y = np.linspace(plot_params['ylim'][0], plot_params['ylim'][1], 250)\n    X, Y = np.meshgrid(x, y)\n    Z = func([X, Y], lib=np) if func_name == 'rastrigin' else func([X, Y])\n\n    for i, item in enumerate(optimizers):\n        optimizer_class, lr_low, lr_hi = item\n        optimizer_name = optimizer_class.__name__\n\n        print(f\"\\n[{i + 1}/{total_optimizers}] PROCESSING: {optimizer_name}\")\n        print(\"-\" * 40)\n\n        print(\"  1. Finding best learning rate with Hyperopt...\")\n        start_time = time.time()\n        space = {\"optimizer_class\": hp.choice(\"optimizer_class\", [optimizer_class]), \"lr\": hp.loguniform(\"lr\", lr_low, lr_hi)}\n        best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, rstate=np.random.default_rng(seed), verbose=0)\n        end_time = time.time()\n        print(f\"    - Best LR found: {best['lr']:.6f} (search took {end_time - start_time:.2f}s)\")\n\n        print(\"  2. Generating full optimization path...\")\n        steps = execute_steps(func, initial_state, optimizer_class, {\"lr\": best[\"lr\"]}, num_iter=500)\n        print(\"    - Path generated.\")\n\n        print(\"  3. Creating and saving static image...\")\n        plot_static_image(steps, func_name, optimizer_name, best['lr'], X, Y, Z, plot_params['minimum'])\n        print(f\"    - Static image saved to docs/{func_name}_{optimizer_name}.png\")\n\n        print(\"  4. Creating and saving animated GIF with fading tail...\")\n        start_time = time.time()\n        create_animation_with_fading_tail(\n            steps, func_name, optimizer_name, best['lr'], X, Y, Z, plot_params['minimum'],\n            gif_resolution=gif_config['resolution'],\n            tail_length=gif_config['tail_length'],\n            fade_length=gif_config['fade_length']\n        )\n        end_time = time.time()\n        print(f\"    - Animation created successfully in {end_time - start_time:.2f} seconds.\")\n\n        print(f\"--- Finished processing {optimizer_name} ---\")\n\n\ndef LookaheadYogi(*a, **kw):\n    base = optim.Yogi(*a, **kw)\n    return optim.Lookahead(base)\n\nif __name__ == \"__main__\":\n    GIF_CONFIG = {\n        \"resolution\": 800,\n        \"tail_length\": 20,\n        \"fade_length\": 30\n    }\n\n    optimizers_to_test = [\n        (torch.optim.Adamax, -8, 0.5), (torch.optim.Adagrad, -8, 0.5),\n        (torch.optim.Adadelta, -8, 0.5), (torch.optim.RMSprop, -8, -2),\n        (torch.optim.Rprop, -8, 0.5), (torch.optim.NAdam, -8, -1)\n    ]\n\n    plot_params_rastrigin = {'xlim': (-4.5, 4.5), 'ylim': (-4.5, 4.5), 'minimum': (0, 0)}\n    execute_experiments(\n        optimizers_to_test, objective_rastrigin, rastrigin, 'rastrigin', \n        plot_params_rastrigin, initial_state=(-2.0, 3.5), gif_config=GIF_CONFIG\n    )\n\n    plot_params_rosenbrock = {'xlim': (-2, 2), 'ylim': (-1, 3), 'minimum': (1.0, 1.0)}\n    execute_experiments(\n        optimizers_to_test, objective_rosenbrock, rosenbrock, 'rosenbrock', \n        plot_params_rosenbrock, initial_state=(-2.0, 2.0), gif_config=GIF_CONFIG\n    )\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"ALL EXPERIMENTS COMPLETE!\")\n    print(\"Check the 'docs' directory for static images and 'gifs' for animations.\")\n    print(\"=\"*60)\n</code></pre> <p>\u540c\u65f6\uff0c\u6211\u4e5f\u5728 Fashion-MNIST \u4e0a\u9762\u5229\u7528\u6587\u4e2d\u63d0\u5230\u7684\u5404\u4e2a\u4f18\u5316\u5668\u8bad\u7ec3\u4e86\u4e00\u4e2a\u7b80\u5355\u7684 CNN \u6a21\u578b\uff0c\u5e76\u753b\u51fa\u4e86\u968f batch \u7684\u635f\u5931\u66f2\u7ebf\uff0c\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u66f2\u7ebf\u7b49\uff0c\u8fd8\u53ef\u89c6\u5316\u4e86\u635f\u5931\u5730\u5f62\u3002\u4ee3\u7801\u653e\u5728\u8fd9\u4e2a Kaggle notebook \u4e0a\u9762\u4e86\u3002</p>"}, {"location": "DNN/optimizer/#_3", "title": "\u4f55\u4ee5\u4f18\u5316", "text": "<p>\u795e\u7ecf\u7f51\u7edc\u7684\u76ee\u7684\u662f\u5728\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u7ed3\u6784\u98ce\u9669\u6700\u5c0f\u5316\u4ee5\u83b7\u5f97\u826f\u597d\u7684\u62df\u5408\u548c\u6cdb\u5316\u80fd\u529b\u3002\u7b80\u5355\u8bf4\uff0c\u5982\u679c\u6211\u4eec\u5728\u8bad\u7ec3\u96c6 \\(X\\) \u4e0a\u6709\u4e00\u4e2a\u5b9a\u4e49\u660e\u786e\u7684\u635f\u5931\u51fd\u6570 \\(\\mathcal{L}(X;\\theta)\\)\uff08\u8868\u793a\u6211\u4eec\u7684\u7ed3\u6784\u98ce\u9669\uff09\uff0c\u90a3\u4e48\u6240\u6709\u4f18\u5316\u5668\u7684\u76ee\u7684\u90fd\u662f\u8bbe\u8ba1\u4e00\u4e2a\u7b97\u6cd5\u6765\u5bfb\u627e\u5408\u9002\u7684 \\(\\theta\\) \u4ee5\u83b7\u5f97 \\(\\mathrm{argmin}_\\theta\\ \\mathcal{L}(X;\\theta)\\)\u3002</p>"}, {"location": "DNN/optimizer/#_4", "title": "\u5bfb\u627e\u6700\u5c0f\u503c", "text": "<p>\u8ba9\u6211\u4eec\u56de\u5fc6\u719f\u6089\u7684\u6781\uff08\u5c0f\uff09\u503c\u5bfb\u627e\u65b9\u6cd5\u3002\u5bf9\u4e8e\u4e8c\u6b21\u51fd\u6570\u800c\u8a00\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u83b7\u5f97\u6781\u5c0f\u503c\u7684\u95ed\u578b\u8868\u8fbe\u5f0f\u3002\u4e14\u8fd9\u4e00\u6781\u5c0f\u503c\u662f\u5168\u5c40\u7684\u3002</p> <p>\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u4e00\u5143\u51fd\u6570\uff0c\u6211\u4eec\u5f88\u5bb9\u6613\u53ef\u4ee5\u8bc1\u660e\u90a3\u4e9b\u524d \\(2k-1(k = 1,2,\\cdots)\\) \u9636\u5bfc\u6570\u4e3a \\(0\\)\uff0c\u4e14\u7b2c \\(2k\\) \u9636\u5bfc\u6570\u4e0d\u4e3a \\(0\\) \u7684\u70b9\u4e3a\u4e00\u4e2a\u6781\u503c\u70b9\u3002\uff08\u8bc1\u660e\u4e0d\u96be\uff0c\u53cd\u590d\u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\u5373\u53ef\uff09\u3002</p> <p>\u53ef\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u635f\u5931\u51fd\u6570\u662f\u4e00\u4e2a\u6781\u4e3a\u590d\u6742\u7684\u591a\u5143\u53c2\u6570\u6c42\u6781\u5c0f\u503c\u7684\u8fc7\u7a0b\u3002\u6211\u4eec\u51e0\u4e4e\u65e0\u6cd5\u627e\u5230\u4e00\u4e2a\u8868\u8fbe\u5f0f\u6765\u8868\u8ff0\u8fd9\u4e2a\u6781\u5c0f\u503c\u3002</p> <p>\u4f46\u662f\uff0c\u6211\u4eec\u4ecd\u6709\u80fd\u529b\u53bb\u7814\u7a76\u8fd9\u4e2a\u6781\u5c0f\u503c\u9644\u8fd1\u7684\u6570\u5b66\u6027\u8d28\u3002\u6362\u8a00\u4e4b\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u4e0b\u5c71\uff0c\u5373\u4fbf\u6211\u4eec\u4e0d\u77e5\u9053\u5c71\u8c37\u7684\u5177\u4f53\u4f4d\u7f6e\uff0c\u4f46\u662f\u5411\u4e0b\u8d70\u4e00\u5b9a\u80fd\u8d70\u5230\u771f\u6b63\u7684\u8c37\u5e95\u3002\u552f\u4e00\u7684\u533a\u522b\u5c31\u662f\u6211\u4eec\u7684\u7528\u65f6\u3001\u8def\u5f84\u548c\u7ed3\u679c\u4f4d\u7f6e\u4e0d\u4e00\u6837\u7f62\u4e86\u3002\u8fd9\u6837\uff0c\u5c31\u5f15\u5165\u4e86\u6211\u4eec\u8bc4\u5224\u4f18\u5316\u5668\u7684\u51e0\u4e2a\u6838\u5fc3\u6307\u6807\u3002</p>"}, {"location": "DNN/optimizer/#_5", "title": "\u4ec0\u4e48\u6837\u7684\u4f18\u5316\u5668\u662f\u597d\u7684\u4f18\u5316\u5668\uff1f", "text": "<p>\u8fd8\u662f\u6cbf\u7528\u4e0b\u5c71\u7684\u6bd4\u55bb\u3002</p> <ul> <li>\u6211\u4eec\u5e0c\u671b\u5c3d\u53ef\u80fd\u5feb\u901f\u5730\u4e0b\u5c71\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u5e0c\u671b\u4f18\u5316\u5668\u7684\u6536\u655b\u901f\u7387\u5c3d\u53ef\u80fd\u5feb\u3002</li> <li>\u6211\u4eec\u5e0c\u671b\u6211\u4eec\u4e0d\u4f1a\u56f0\u5728\u5c0f\u5c71\u6c9f\u91cc\u9762\uff0c\u800c\u662f\u6df1\u5165\u771f\u6b63\u7684\u8c37\u5e95\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u5e0c\u671b\u4f18\u5316\u5668\u4e0d\u4f1a\u56f0\u4e8e\u4e00\u4e9b\u5f88\u574f\u7684\u70b9\uff0c\u6bd4\u5982\u8bf4\u5bf9\u4e8e\u505a\u4f20\u7edf\u7b97\u6cd5\u7684\u540c\u5b66\u800c\u8a00\u6bd4\u8f83\u719f\u6089\u7684\u5c40\u90e8\u6700\u4f18\u70b9\uff08e.g. \u4f8b\u5982\u4e00\u4e9b\u6027\u8d28\u4e0d\u597d\u7684\u8d2a\u5fc3\uff09\u6216\u8005\u73b0\u5728\u4e3b\u6d41\u7814\u7a76\u7684\u978d\u70b9\uff08\u68af\u5ea6\u5e73\u7f13\u7684\u975e\u6781\u503c\u70b9\uff09\uff0c\u800c\u662f\u6709\u8d70\u51fa\u53bb\u5bfb\u627e\u5168\u5c40\u6700\u5c0f\u503c\u7684\u80fd\u529b\u3002\u4e8b\u5b9e\u4e0a\uff0c\u73b0\u5728\u4e3b\u6d41\u7684\u7814\u7a76\u65b9\u5411\u5e76\u975e\u5173\u7cfb\u5168\u5c40\u6700\u5c0f\uff0c\u800c\u662f\u978d\u70b9\u9003\u9038\u3002\u6bd5\u7adf\u524d\u8005\u53ea\u8f7b\u5fae\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\uff0c\u800c\u540e\u8005\u5728\u66f4\u5927\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u8bad\u7ec3\u901f\u5ea6\u3002</li> <li>\u6211\u4eec\u5e0c\u671b\u4e0d\u8981\u6307\u9519\u8def\uff0c\u4e0d\u8981\u4e71\u6307\u8def\u3002\u4e5f\u5c31\u662f\u6211\u4eec\u5e0c\u671b\u5728\u5feb\u901f\u6536\u655b\u7684\u60c5\u51b5\u4e0b\u8bad\u7ec3\u7a33\u5b9a\uff0c\u4e0d\u8981\u51fa\u73b0\u635f\u5931\u5c16\u5cf0\u6216\u662f\u5927\u5e45\u5ea6\u9707\u8361\u3002</li> </ul> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 1, 2025). \u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5668\u6982\u8ff0 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/optimizer</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{optimizer,\n    title={\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5668\u6982\u8ff0},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/optimizer}},\n}\n</code></pre></p>"}, {"location": "DNN/optimizer/Adaptive/", "title": "\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6539\u8fdb\u7b56\u7565", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 49 \u5206\u949f\u3000|\u3000\u7ea6 4921 \u5b57\u3000|\u3000\u7ea6 151 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 960 \u884c\u4ee3\u7801</p> <p>\u6211\u6ca1\u8981\u6c42\u4f60\u4e00\u5b9a\u5f97\u7528\u90a3\u79cd\u6700\u65b0\u6700\u597d\u7684 Optimizer\uff0c\u6211\u4e0d\u662f\u6076\u9b54\u3002</p> <p>\u53ef\u662f\uff0c\u7528 SGD \u4f18\u5316 LLM \u662f\u4ec0\u4e48\u610f\u601d\uff1f\u4f60\u624d 21 \u5c81\u5427\uff1f\u518d\u8fd9\u6837\u4e0b\u53bb\uff0c\u4f60 21 \u5c81\u7528 SGD\uff0c42 \u5c81\u7528 SGD with Momentum\uff0c84 \u5c81\u5c31\u8be5\u95ee Who is Adam \u4e86\u3002</p> <p>\u4f5c\u4e3a \\(\\theta\\)\uff0c\u6211\u53ef\u80fd\u771f\u8be5\u6536\u655b\u5230\u978d\u70b9\uff0c\u771f\u7684\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adagrad", "title": "AdaGrad", "text": ""}, {"location": "DNN/optimizer/Adaptive/#_2", "title": "\u5916\u79ef\u8fd1\u4f3c", "text": "<p>AdaGrad \u7684\u7cbe\u9ad3\u662f\u62ff\u68af\u5ea6\u8fd1\u4f3c\u6d77\u68ee\u77e9\u9635 \\(H\\)\uff0c\u4ee5\u6b64\u5b9e\u73b0\u81ea\u9002\u5e94\u8c03\u6574\u3002\u4f46\u662f\u8fd9\u9700\u8981\u6211\u4eec\u5bf9\u635f\u5931\u5730\u5f62\u6709\u66f4\u591a\u7684\u63a2\u7d22\u3002</p> <p>\u8fd9\u4e00\u90e8\u5206\uff0c\u6211\u4e3b\u8981\u662f\u53c2\u8003 arXiv:2304.09871 \u548c\u82cf\u5251\u6797\u7684\u8fd9\u7bc7\u535a\u5ba2\u7684\u5185\u5bb9\u6765\u63a8\u5bfc\u3002</p> <p>\u5728\u76ee\u6807\u53c2\u6570 \\(\\theta\\) \u9644\u8fd1\u53d6\u8fd1\u4f3c\u89e3 \\(\\theta_n\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u68af\u5ea6\u505a\u4e00\u4e2a\u4e00\u9636\u8fd1\u4f3c\uff1a\\(g_n=H(\\theta-\\theta_n)\\)</p> <p>\u8fd1\u4f3c\u89e3\u53ef\u4ee5\u968f\u673a\u9009\u53d6\uff0c\u56e0\u6b64\u8003\u8651\u5176\u670d\u4ece \\(N(\\theta, \\sigma^2 I)\\)\uff0c\u4e3a\u4e86\u5f04\u51fa\u5e73\u65b9\u6211\u4eec\u628a\u5b83\u4e58\u4e0a\u81ea\u5df1\u7684\u8f6c\u7f6e\uff1a</p> \\[ g_ng_n^\\top=H(\\theta-\\theta_n)(\\theta-\\theta_n)^\\top H^\\top \\] <p>\u4e8b\u5b9e\u4e0a\u4e00\u5f00\u59cb AdaGrad \u5c31\u662f\u8003\u8651\u7684\u91c7\u7528\u7684\u8fd9\u79cd\u5916\u79ef\u65b9\u6848\uff0c\u4f46\u662f\u8ba1\u7b97\u91cf\u8fc7\u5927\uff0c\u6211\u4eec\u8003\u8651\u53ea\u53d6 \\(H\\) \u7684\u5bf9\u89d2\u5143\uff08\u8fd9\u4e2a\u5728 SGD \u4e2d\u5df2\u7ecf\u6709\u6548\u5730\u4f7f\u7528\u8fc7\u4e00\u6b21\u4e86\uff09\uff0c\u5e76\u4e14\u5728\u671f\u671b\u610f\u4e49\u4e0b \\((\\theta-\\theta_n)(\\theta-\\theta_n)^\\top=E=\\sigma^2I\\)\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u5199\u6210</p> \\[ H\\approx\\dfrac{1}{\\sigma}\\sqrt{g_n\\odot g_n} \\] <p>\u7531\u6b64\uff0c\u4fbf\u53ef\u4ee5\u796d\u51fa AdaGrad \u5927\u6cd5\u4e86\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     G_{n}&amp;=G_{n-1}+g_n\\odot g_n\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+G_n}} g_n \\end{align*} \\] <p>\u4e3a\u4e86\u9632\u6b62\u9664\u96f6\u9519\u8bef\uff0c\\(\\epsilon\\) \u662f\u4e00\u4e2a\u5c0f\u6b63\u6570\u3002\u5728\u5b9e\u8df5\u4e0a\u4e5f\u4f1a\u6709\u628a \\(\\epsilon\\) \u63d0\u5230\u6839\u53f7\u5916\u7684\u60c5\u51b5\uff0c\u90fd\u662f\u7b49\u4ef7\u7684\u3002</p> <p>\u4e0b\u9762\u662f AdaGrad \u7684\u8f68\u8ff9\u6f14\u793a\uff1a</p> <p></p> <p></p> <p>\u53ef\u89c1 AdaGrad \u5bf9\u4e8e\u5927\u68af\u5ea6\u6709\u66f4\u5927\u7684\u6b65\u957f\uff0c\u5e76\u4e14\u968f\u7740\u8fdb\u5165\u5e73\u7f13\u7684\u90e8\u5206\u9010\u6e10\u8870\u51cf\u3002\u4f46\u662f\u8fd9\u4ec5\u4ec5\u7c7b\u4f3c\u4e8e SGD \u52a0\u4e0a\u4e00\u4e2a\u81ea\u9002\u5e94\uff0c\u5e76\u6ca1\u6709\u5bf9 rosenbrock \u8fd9\u79cd\u5730\u5f62\u505a\u5f88\u597d\u7684\u9002\u5e94\uff0c\u5c24\u5176\u5728\u540e\u671f\u4e00\u76f4\u5728\u68af\u5ea6\u65b9\u5411\u6a2a\u8df3\u3002</p> <p>\u4e0b\u9762\u662f AdaGrad \u5728 Fashion-MNIST \u4e0a\u9762\u7684\u8868\u73b0\uff0c\u53ef\u80fd\u662f CNN \u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4e0d\u5927\u5bf9\u4ed8\uff0c\u8fd9\u91cc\u7684\u4e00\u7cfb\u5217\u7b97\u6cd5\u7684 train_loss \u90fd\u964d\u5f97\u6bd4\u8f83\u96be\u3002\u5177\u4f53\u53ef\u4ee5\u770b\u8fd9\u7bc7\u8bba\u6587\uff1aarXiv:1705.08292\u3002\u6240\u4ee5\u4e0b\u9762\u6bd4\u8f83\u5c31\u5728\u8fd9\u51e0\u4e2a\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4f18\u5316\u5668\u5185\u90e8\u6bd4\uff0c\u6bd5\u7adf\u5b58\u5728\u8fd9\u4e48\u4e00\u4e2a\u4e0d\u516c\u5e73\uff0c\u6211\u53ef\u7528\u7684 GPU \u6027\u80fd\u4e5f\u4e0d\u652f\u6301\u5728\u4e00\u4e2a\u53ef\u884c\u7684\u65f6\u95f4\u5185\u8bad\u7ec3\u591a\u4e2a\u5927\u53c2\u6570\u91cf\u7684 Transformer \u6a21\u578b\u2026\u2026\u6240\u4ee5\u5927\u5bb6\u5c06\u5c31\u770b\u5427\uff0c\u6709\u65b0\u7684\u5b9e\u9a8c\u4e5f\u6b22\u8fce\u8865\u5145\u6570\u636e\u3002</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u5c31\u8fde 6000 \u4e2a Batch \u540e train_loss \u90fd\u6ca1\u6709\u964d\u5230 0.1 \u5de6\u53f3\u3002\u4e0d\u8fc7\u6211\u4eec\u786e\u5b9e\u770b\u5230\u4e86 AdaGrad \u5728\u52aa\u529b\u81ea\u9002\u5e94\u635f\u5931\u5730\u5f62\uff0c\u76f8\u6bd4 SGD \u7cfb\u5217\u7b97\u6cd5\uff0cAdaGrad \u5728\u5f00\u5934\u7684\u4e0b\u964d\u662f\u76f8\u5f53\u8fc5\u901f\u7684\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adagrad_1", "title": "AdaGrad \u7684\u4ee3\u7801\u5b9e\u73b0", "text": "<p>\u540c\u6837\u8ba9\u6211\u4eec\u770b\u770b <code>PyTorch</code> \u5bf9\u8fd9\u4e2a\u7b97\u6cd5\u7684\u5b9e\u73b0\u3002</p> AdaGrad \u7684\u5b9e\u73b0 <pre><code># _get_value(t: Tensor) -&gt; float: \u4ece\u5355\u5143\u7d20\u5f20\u91cf\u4e2d\u63d0\u53d6\u5176\u6d6e\u70b9\u6570\u503c\uff0c\u7c7b\u4f3c\u4e8e t.item()\n# _make_sparse(grad, grad_indices, grad_values): \u4f7f\u7528\u7ed9\u5b9a\u7684\u7d22\u5f15\u548c\u503c\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u7a00\u758f\u5f20\u91cf\n\ndef _single_tensor_adagrad(\n    params: list[Tensor],\n    grads: list[Tensor],\n    state_sums: list[Tensor],\n    state_steps: list[Tensor],\n    grad_scale: Optional[Tensor],\n    found_inf: Optional[Tensor],\n    *,\n    lr: float,\n    weight_decay: float,\n    lr_decay: float,\n    eps: float,\n    has_sparse_grad: bool,\n    maximize: bool,\n    differentiable: bool,\n    has_complex: bool,\n):\n    # \u8fd9\u4e24\u4e2a\u53c2\u6570\u4e0e\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08AMP\uff09\u7684\u68af\u5ea6\u7f29\u653e\u6709\u5173\uff0c\u6b64\u7279\u5b9a\u5b9e\u73b0\u4e0d\u652f\u6301\uff0c\u56e0\u6b64\u65ad\u8a00\u5b83\u4eec\u4e3a None\n    assert grad_scale is None and found_inf is None\n\n    # \u4f7f\u7528 zip \u540c\u65f6\u904d\u5386\u53c2\u6570\u3001\u68af\u5ea6\u3001\u72b6\u6001\u7d2f\u52a0\u548c\u3001\u6b65\u6570\u8fd9\u56db\u4e2a\u5217\u8868\n    for param, grad, state_sum, step_t in zip(params, grads, state_sums, state_steps):\n        # \u66f4\u65b0\u6b65\u6570\u8ba1\u6570\u5668\uff08\u539f\u5730\u64cd\u4f5c\uff09\n        step_t += 1\n        # \u4ece Tensor \u4e2d\u83b7\u53d6\u6b65\u6570\u7684\u6807\u91cf\u503c\uff08\u4f8b\u5982\u901a\u8fc7 .item()\uff09\n        step = _get_value(step_t)\n        # \u5982\u679c\u662f\u6700\u5927\u5316\u95ee\u9898\uff08maximize=True\uff09\uff0c\u5219\u53cd\u8f6c\u68af\u5ea6\u65b9\u5411\uff0c\u6267\u884c\u68af\u5ea6\u4e0a\u5347\n        grad = grad if not maximize else -grad\n\n        # \u5e94\u7528\u6743\u91cd\u8870\u51cf\uff08L2 \u6b63\u5219\u5316\uff09\n        if weight_decay != 0:\n            # Adagrad \u7684\u6743\u91cd\u8870\u51cf\u4e0e\u7a00\u758f\u68af\u5ea6\u4e0d\u517c\u5bb9\uff0c\u56e0\u4e3a add \u64cd\u4f5c\u5728\u7a00\u758f\u5f20\u91cf\u4e0a\u5b9a\u4e49\u4e0d\u540c\n            if grad.is_sparse:\n                raise RuntimeError(\n                    \"weight_decay option is not compatible with sparse gradients\" # \u6743\u91cd\u8870\u51cf\u9009\u9879\u4e0e\u7a00\u758f\u68af\u5ea6\u4e0d\u517c\u5bb9\n                )\n            # \u5bf9\u4e8e\u7a20\u5bc6\u68af\u5ea6\uff0c\u5c06\u6743\u91cd\u8870\u51cf\u9879\u52a0\u5230\u68af\u5ea6\u4e0a\u3002\u516c\u5f0f: grad = grad + param * weight_decay\n            grad = grad.add(param, alpha=weight_decay)\n\n        # \u6839\u636e\u5b66\u4e60\u7387\u8870\u51cf\u516c\u5f0f\uff0c\u8ba1\u7b97\u5f53\u524d\u6b65\u9aa4\u7684\u6709\u6548\u5b66\u4e60\u7387 (clr)\n        # \u516c\u5f0f: clr = lr / (1 + (step - 1) * lr_decay)\n        clr = lr / (1 + (step - 1) * lr_decay)\n\n        # \u6839\u636e\u68af\u5ea6\u662f\u7a00\u758f\u8fd8\u662f\u7a20\u5bc6\uff0c\u9009\u62e9\u4e0d\u540c\u7684\u66f4\u65b0\u8def\u5f84\n        if grad.is_sparse:\n            # --- \u7a00\u758f\u68af\u5ea6\u66f4\u65b0\u8def\u5f84 ---\n            # \u5408\u5e76\u7a00\u758f\u68af\u5ea6\u4e2d\u76f8\u540c\u7d22\u5f15\u7684\u503c\uff0c\u786e\u4fdd\u7d22\u5f15\u552f\u4e00\u3002\u8fd9\u5bf9\u4e8e\u540e\u7eed\u7684\u975e\u7ebf\u6027\u64cd\u4f5c\uff08\u5982\u5e73\u65b9\uff09\u662f\u5fc5\u9700\u7684\u3002\n            grad = grad.coalesce()\n            grad_indices = grad._indices()  # \u83b7\u53d6\u7a00\u758f\u68af\u5ea6\u7684\u975e\u96f6\u5143\u7d20\u7d22\u5f15\n            grad_values = grad._values()   # \u83b7\u53d6\u7a00\u758f\u68af\u5ea6\u7684\u975e\u96f6\u5143\u7d20\u503c\n\n            # \u5c06\u5f53\u524d\u68af\u5ea6\u503c\u7684\u5e73\u65b9\uff0c\u4ee5\u7a00\u758f\u5f20\u91cf\u7684\u5f62\u5f0f\uff0c\u7d2f\u52a0\u5230\u5386\u53f2\u72b6\u6001 `state_sum` \u4e2d\n            state_sum.add_(_make_sparse(grad, grad_indices, grad_values.pow(2)))\n            # \u4ece `state_sum` \u4e2d\u4ec5\u62bd\u53d6\u51fa\u4e0e\u5f53\u524d\u68af\u5ea6\u975e\u96f6\u4f4d\u7f6e\u76f8\u5bf9\u5e94\u7684\u7d2f\u79ef\u503c\n            std = state_sum.sparse_mask(grad)\n            # \u8ba1\u7b97\u5206\u6bcd\uff1a\u5bf9\u62bd\u51fa\u7684\u7d2f\u79ef\u503c\u5f00\u65b9\uff0c\u7136\u540e\u52a0\u4e0a eps \u4ee5\u4fdd\u8bc1\u6570\u503c\u7a33\u5b9a\u6027\n            std_values = std._values().sqrt_().add_(eps)\n            # \u66f4\u65b0\u53c2\u6570\uff1a\u4ec5\u66f4\u65b0\u68af\u5ea6\u4e2d\u975e\u96f6\u7d22\u5f15\u5bf9\u5e94\u7684\u53c2\u6570\u5143\u7d20\n            # \u66f4\u65b0\u516c\u5f0f\uff1aparam[indices] -= clr * (grad_values / std_values)\n            param.add_(\n                _make_sparse(grad, grad_indices, grad_values / std_values), alpha=-clr\n            )\n        else:\n            # --- \u7a20\u5bc6\u68af\u5ea6\u66f4\u65b0\u8def\u5f84 ---\n            # \u68c0\u67e5\u53c2\u6570\u662f\u5426\u4e3a\u590d\u6570\u7c7b\u578b\n            is_complex = torch.is_complex(param)\n            if is_complex:\n                # \u5982\u679c\u662f\u590d\u6570\uff0c\u5219\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u5b9e\u6570\u5f20\u91cf\u8fdb\u884c\u540e\u7eed\u8ba1\u7b97\uff0c\u5176\u5f62\u72b6\u4f1a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea62\uff08\u5b9e\u90e8\u548c\u865a\u90e8\uff09\n                grad = torch.view_as_real(grad)\n                state_sum = torch.view_as_real(state_sum)\n                param = torch.view_as_real(param)\n\n            # Adagrad \u6838\u5fc3\u6b65\u9aa4\uff1a\u5c06\u68af\u5ea6\u7684\u5e73\u65b9\u7d2f\u52a0\u5230 state_sum \u4e2d\uff08\u539f\u5730\u64cd\u4f5c\uff09\n            # \u516c\u5f0f: state_sum = state_sum + grad * grad\n            state_sum.addcmul_(grad, grad, value=1)\n\n            # \u8ba1\u7b97\u5206\u6bcd std = sqrt(state_sum) + eps\n            if differentiable:\n                # \u5982\u679c\u8981\u6c42\u6574\u4e2a\u4f18\u5316\u8fc7\u7a0b\u53ef\u5fae\u5206\uff0c\u5219\u4f7f\u7528\u8fd4\u56de\u65b0\u5f20\u91cf\u7684 `+` \u64cd\u4f5c\n                std = state_sum.sqrt() + eps\n            else:\n                # \u5426\u5219\uff0c\u4f7f\u7528\u539f\u5730\u64cd\u4f5c `add_` \u4ee5\u8282\u7701\u5185\u5b58\u5e76\u53ef\u80fd\u63d0\u9ad8\u901f\u5ea6\n                std = state_sum.sqrt().add_(eps)\n\n            # \u6267\u884c\u53c2\u6570\u66f4\u65b0\uff08\u539f\u5730\u64cd\u4f5c\uff09\n            # \u516c\u5f0f: param = param - clr * (grad / std)\n            param.addcdiv_(grad, std, value=-clr)\n\n            # \u5982\u679c\u53c2\u6570\u662f\u590d\u6570\uff0c\u9700\u8981\u5c06\u4f5c\u4e3a\u5b9e\u6570\u89c6\u56fe\u7684\u53d8\u91cf\u8f6c\u6362\u56de\u5176\u590d\u6570\u8868\u793a\n            if is_complex:\n                param = torch.view_as_complex(param)\n                state_sum = torch.view_as_complex(state_sum)\n</code></pre> <p>AdaGrad \u901a\u8fc7\u7d2f\u79ef\u7684 \\(G\\) \u6765\u5b9e\u73b0\u5bf9 Hessian \u7684\u8fd1\u4f3c\uff0c\u6309\u7406\u8bf4\u5e94\u8be5\u5177\u6709\u66f4\u52a0\u4f18\u79c0\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u3002\u6bd5\u7adf\uff0cAdaGrad \u5c31\u662f Adaptive Gradient \u7684\u7701\u7565\u561b\uff01</p> <p>\u4f46\u662f\u4e8b\u5b9e\u4e0a\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\uff0c\u5982\u679c\u5728\u4e00\u4e2a\u5e76\u4e0d\u597d\u7684\uff0c\u68af\u5ea6\u5f88\u5927\u7684\u521d\u59cb\u4f4d\u7f6e\u5f00\u59cb\u8fdb\u884c\u4f18\u5316\uff0c\u90a3\u7d2f\u79ef\u5728 \\(G_n\\) \u91cc\u9762\u7684\u68af\u5ea6\u5c06\u4f1a\u662f\u201c\u4e00\u8f88\u5b50\u90fd\u62b9\u4e0d\u53bb\u7684\u4e1c\u897f\u201d\uff0c\\(G_n\\) \u7684\u503c\u53ea\u4f1a\u8d8a\u6765\u8d8a\u5927\uff0c\u5373\u4f7f\u8d70\u51fa\u8fd9\u6837\u7684\u5730\u65b9\uff0c\u4ecd\u7136\u4f1a\u56e0\u4e3a\u8fd9\u4e2a\u201c\u5386\u53f2\u5305\u88b1\u201d\u800c\u5bf8\u6b65\u96be\u884c\uff08\u4e5f\u5c31\u662f\u521d\u59cb\u68af\u5ea6\u5bf9\u5168\u5c40\u5f71\u54cd\u8fc7\u5927\uff09\u3002\u5c24\u5176\u662f\u521a\u521a\u7684\u8fd1\u4f3c\u53ea\u662f\u5bf9\u9760\u8fd1\u6700\u4f18\u70b9\u80fd\u591f\u5f88\u6709\u6548\uff0c\u6709\u6ca1\u6709\u529e\u6cd5\u4ece\u68af\u5ea6\u80fd\u591f\u83b7\u5f97\u5bf9 Hessian \u77e9\u9635\u7684\u66f4\u597d\u4f30\u8ba1\u5462\uff1f\u8fd9\u5c31\u8981\u796d\u51fa RMSprop \u4e86\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#rmsprop", "title": "RMSprop", "text": "<p>\u5176\u5b9e\u6211\u4eec\u60f3\u8981\u7684\u662f\u4e00\u79cd\u201c\u7a97\u53e3\u5e73\u5747\u201d\uff0c\u56e0\u4e3a \\(H\\approx\\dfrac{1}{\\sigma}\\sqrt{g_n\\odot g_n}\\) \u662f\u5728\u63a5\u8fd1\u6700\u4f18\u70b9\u7684\u7edf\u8ba1\u610f\u4e49\u4e0b\u8fd1\u4f3c\u7684\uff0c\u5982\u679c\u79bb\u6700\u4f18\u70b9\u6bd4\u8f83\u8fdc\uff0c\u90a3\u53c2\u6570\u66f4\u65b0\u91cf\u5927\u4e00\u4e9b\u4e5f\u65e0\u59a8\uff0c\u79bb\u6700\u4f18\u70b9\u6bd4\u8f83\u8fd1\uff0c\u5c31\u4e0d\u8981\u8ba9\u4e4b\u524d\u7684\u7ed3\u679c\u5f71\u54cd\u5230\u3002</p> <p>\u8fd9\u79cd\u7a97\u53e3\u5e73\u5747\u80af\u5b9a\u4e0d\u80fd\u76f4\u63a5\u4fdd\u5b58\u6700\u8fd1 \\(k\\) \u4e2a\u68af\u5ea6\u7684\u5217\u8868\u518d\u6c42\u5e73\u5747\uff0c\u8fd9\u663e\u7136\u592a\u8d39\u663e\u5b58\uff1a</p> \\[ G_{n+1}=\\frac 1k (kG_n+p_n-p_{n-k}) \\] <p>\u5176\u4e2d \\(p_n = g_n\\odot g_n\\)\u3002\u4e0d\u8fc7\u6211\u4eec\u53ef\u4ee5\u628a \\(p_{n-k}\\) \u8fd1\u4f3c\u6210 \\(G_n\\)\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u5e73\u5747\u503c\u6765\u8fd1\u4f3c\u5355\u4e00\u503c\uff0c\u7136\u540e\u505a\u4e00\u4e2a\u53d8\u91cf\u66ff\u6362 \\(\\beta_2=\\dfrac{k-1}{k}\\) \u6765\u4f7f\u5f0f\u5b50\u597d\u770b\uff0c\u8fd9\u6837\u6211\u4eec\u76f8\u6bd4\u4e8e AdaGrad\uff0c\u5c31\u4e0d\u7528\u589e\u52a0\u4efb\u4f55\u4e34\u65f6\u5b58\u50a8\u4e86\uff01\u7531\u6b64\u5f97\u5230\u7684\u662f\u6ed1\u52a8\u7a97\u53e3\u5e73\u5747\uff0c\u5373\uff1a</p> \\[ G_{n+1} = \\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n \\] <p>\u8fd9\u79cd\u5e73\u5747\u662f\u4e0d\u662f\u4f3c\u66fe\u76f8\u8bc6\uff1f\u56de\u60f3\u8d77\u4e4b\u524d\u5173\u4e8e\u52a8\u91cf\u6cd5\u7684\u8ba8\u8bba\uff08\u53d6 \\(\\beta_3=(1-\\beta_1)\\) \uff09\uff1a</p> \\[ M_n=(1-\\beta_1)g_n+\\beta_1M_{n-1} \\] <p>\u770b\uff0c\u8fd9\u91cc\u7684\u52a8\u91cf\u8ba1\u7b97\u5176\u5b9e\u4e5f\u662f\u5728\u53d6\u68af\u5ea6\u7684\u6ed1\u52a8\u7a97\u53e3\u5e73\u5747\u3002</p> <p>\u8fd9\u5c31\u5f97\u5230\u4e86 RMSprop \u7b97\u6cd5\u4e86\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+G_n}} g_n \\end{align*} \\] <p>RMS \u6307\u7684\u5c31\u662f \\(\\sqrt{\\epsilon+G_n}\\)\uff0c\u65e2\u6709\u6ed1\u52a8\u7a97\u53e3\u7684\u5e73\u65b9\u5e73\u5747 (Mean Square)\uff0c\u53c8\u5728\u6700\u540e\u5f00\u4e86\u6839(Root)\u3002</p> <p>prop\u7684\u610f\u601d\u5c31\u662f\u4f20\u64ad\u4e86\u3002\u6bd5\u7adf\u6211\u4eec\u662f\u5bf9\u795e\u7ecf\u7f51\u7edc\u505a\u7684\u4f18\u5316\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u770b\u770b RMSprop \u7684\u8f68\u8ff9\u6f14\u793a\uff1a</p> <p></p> <p></p> <p>RMSprop \u76f8\u6bd4\u4e8e AdaGrad \u5176\u5b9e\u53ea\u662f\u66f4\u6539\u4e86\u5b66\u4e60\u7387\u81ea\u9002\u5e94\u7a0b\u5ea6\uff0c\u8fd8\u662f\u6ca1\u6709\u9003\u8131\u5728 rosenbrock \u4e0b\u53cd\u590d\u6a2a\u8df3\u7684\u5bbf\u547d\u3002\u8fd9\u5df2\u7ecf\u4e0d\u662f\u4e00\u822c\u7684\u635f\u5931\u5730\u5f62\u4e86\uff0c\u5fc5\u987b\u8981\u51fa\u91cd\u62f3\uff08\u96fe\uff09\u5fc5\u987b\u8981\u5f15\u5165\u52a8\u91cf\u6765\u8c03\u6574\u53c2\u6570\u66f4\u65b0\u65b9\u5411\uff01\u2014\u2014\u4e0d\u8fc7\u8fd9\u90fd\u662f\u540e\u8bdd\u4e86\uff0c\u6709\u5173\u8ba8\u8bba\u656c\u8bf7\u53c2\u9605 Adam \u4e00\u8282\u3002</p> <p>\u4e0b\u9762\u770b\u770b RMSprop \u5728 Fashion-MNIST \u4e0a\u9762\u7684\u6027\u80fd\uff1a</p> <p></p> <p></p> <p>\u5728\u7ea6 5000 \u4e2a Batch \u540e RMSprop \u7684 train_loss \u964d\u5230\u4e86 0.1 \u9644\u8fd1\uff1b\u7ea6 2000 \u4e2a Batch \u540e acc \u5347\u5230\u4e86 0.9 \u4ee5\u4e0a\u3002\u76f8\u6bd4\u4e8e AdaGrad \u6709\u76f8\u5f53\u7684\u63d0\u5347\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#rmsprop_1", "title": "RMSprop \u7684\u4ee3\u7801\u5b9e\u73b0", "text": "RMSprop \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_rmsprop(\n    params: list[Tensor],\n    grads: list[Tensor],\n    square_avgs: list[Tensor],\n    grad_avgs: list[Tensor],\n    momentum_buffer_list: list[Tensor],\n    state_steps: list[Tensor],\n    *,\n    lr: float,\n    alpha: float,\n    eps: float,\n    weight_decay: float,\n    momentum: float,\n    centered: bool,\n    maximize: bool,\n    differentiable: bool,\n    capturable: bool,\n    has_complex: bool,\n):\n    # \u5faa\u73af\u904d\u5386\u6bcf\u4e00\u4e2a\u53c2\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u68af\u5ea6\u548c\u72b6\u6001\n    for i, param in enumerate(params):\n        # \u83b7\u53d6\u5f53\u524d\u53c2\u6570\u7684\u66f4\u65b0\u6b65\u6570\n        step = state_steps[i]\n\n        # --- CUDA Graph \u6355\u83b7\u76f8\u5173\u7684\u68c0\u67e5 ---\n        # \u5982\u679c\u4ee3\u7801\u6b63\u5728\u88ab torch.compile \u7f16\u8bd1\uff0c\u7f16\u8bd1\u5668\u4f1a\u5904\u7406\u56fe\u6355\u83b7\u7684\u68c0\u67e5\u3002\n        # \u89c1 note [torch.compile x capturable]\n        if not torch.compiler.is_compiling() and capturable:\n            # \u83b7\u53d6\u652f\u6301 CUDA Graph \u6355\u83b7\u7684\u8bbe\u5907\u5217\u8868\uff08\u901a\u5e38\u662f 'cuda'\uff09\n            capturable_supported_devices = _get_capturable_supported_devices()\n            # \u65ad\u8a00\uff1a\u5982\u679c\u542f\u7528\u4e86 capturable\uff0c\u53c2\u6570\u548c\u5176\u72b6\u6001\u5fc5\u987b\u5728\u652f\u6301\u7684\u8bbe\u5907\u4e0a\n            assert (\n                param.device.type == step.device.type\n                and param.device.type in capturable_supported_devices\n            ), f\"If capturable=True, params and state_steps must be on supported devices: {capturable_supported_devices}.\"\n\n        # \u83b7\u53d6\u5f53\u524d\u53c2\u6570\u7684\u68af\u5ea6\n        grad = grads[i]\n        # \u5982\u679c\u662f\u6700\u5927\u5316\u95ee\u9898 (maximize=True)\uff0c\u5219\u53cd\u8f6c\u68af\u5ea6\u65b9\u5411\uff08\u68af\u5ea6\u4e0a\u5347\uff09\n        grad = grad if not maximize else -grad\n        # \u83b7\u53d6\u5f53\u524d\u53c2\u6570\u7684\u68af\u5ea6\u5e73\u65b9\u7684\u79fb\u52a8\u5e73\u5747\u503c\n        square_avg = square_avgs[i]\n\n        # \u6b65\u6570\u52a0 1\n        step += 1\n\n        # --- \u6743\u91cd\u8870\u51cf (Weight Decay) ---\n        # \u5982\u679c\u8bbe\u7f6e\u4e86\u6743\u91cd\u8870\u51cf\uff08L2 \u6b63\u5219\u5316\uff09\n        if weight_decay != 0:\n            # \u5c06\u6743\u91cd\u8870\u51cf\u9879\u52a0\u5230\u68af\u5ea6\u4e0a\u3002\u516c\u5f0f: grad = grad + param * weight_decay\n            # \u4e5f\u5c31\u662f\u89e3\u8026\u7684\u6743\u91cd\u8870\u51cf\u3002\n            grad = grad.add(param, alpha=weight_decay)\n\n        # --- \u5904\u7406\u590d\u6570\u5f20\u91cf ---\n        # \u68c0\u67e5\u53c2\u6570\u662f\u5426\u4e3a\u590d\u6570\u7c7b\u578b\n        is_complex_param = torch.is_complex(param)\n        if is_complex_param:\n            # \u5982\u679c\u662f\u590d\u6570\uff0c\u5c06\u5176\u89c6\u4e3a\u5b9e\u6570\u5f20\u91cf\u8fdb\u884c\u5904\u7406\u3002\n            # \u4f8b\u5982\uff0c\u4e00\u4e2a\u5f62\u72b6\u4e3a [N] \u7684\u590d\u6570\u5f20\u91cf\u4f1a\u53d8\u6210\u5f62\u72b6\u4e3a [N, 2] \u7684\u5b9e\u6570\u5f20\u91cf\uff0c\n            # \u6700\u540e\u4e00\u7ef4\u5206\u522b\u4ee3\u8868\u5b9e\u90e8\u548c\u865a\u90e8\u3002\n            param = torch.view_as_real(param)\n            grad = torch.view_as_real(grad)\n            square_avg = torch.view_as_real(square_avg)\n\n        # --- \u66f4\u65b0\u68af\u5ea6\u5e73\u65b9\u7684\u79fb\u52a8\u5e73\u5747\u503c (RMS) ---\n        # \u516c\u5f0f: square_avg = alpha * square_avg + (1 - alpha) * grad^2\n        square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n\n        # --- \u8ba1\u7b97\u5206\u6bcd `avg` ---\n        if centered:\n            # --- Centered RMSprop ---\n            # \u83b7\u53d6\u68af\u5ea6\u7684\u79fb\u52a8\u5e73\u5747\u503c\n            grad_avg = grad_avgs[i]\n            if is_complex_param:\n                # \u540c\u6837\u5904\u7406\u590d\u6570\u60c5\u51b5\n                grad_avg = torch.view_as_real(grad_avg)\n\n            # \u66f4\u65b0\u68af\u5ea6\u7684\u79fb\u52a8\u5e73\u5747\u503c\u3002\u516c\u5f0f: grad_avg = alpha * grad_avg + (1 - alpha) * grad\n            grad_avg.lerp_(grad, 1 - alpha)\n\n            # \u8ba1\u7b97\u5206\u6bcd\u3002\u516c\u5f0f: avg = sqrt(square_avg - grad_avg^2)\n            # \u8fd9\u5b9e\u9645\u4e0a\u662f\u68af\u5ea6\u7684\uff08\u79fb\u52a8\uff09\u65b9\u5dee\u7684\u5e73\u65b9\u6839\n            avg = square_avg.addcmul(grad_avg, grad_avg, value=-1).sqrt_()\n        else:\n            # --- \u6807\u51c6 RMSprop ---\n            # \u8ba1\u7b97\u5206\u6bcd\u3002\u516c\u5f0f: avg = sqrt(square_avg)\n            avg = square_avg.sqrt()\n\n        # --- \u6dfb\u52a0 epsilon \u4ee5\u4fdd\u8bc1\u6570\u503c\u7a33\u5b9a\u6027 ---\n        if differentiable:\n            # \u5982\u679c\u8981\u6c42\u64cd\u4f5c\u53ef\u5fae\u5206\uff0c\u4f7f\u7528 `add` (\u8fd4\u56de\u65b0\u5f20\u91cf) \u800c\u4e0d\u662f `add_` (\u539f\u5730\u4fee\u6539)\n            avg = avg.add(eps)\n        else:\n            # \u5426\u5219\uff0c\u4f7f\u7528\u539f\u5730\u64cd\u4f5c `add_` \u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u9632\u6b62\u5206\u6bcd\u4e3a\u96f6\n            avg = avg.add_(eps)\n\n        # --- \u53c2\u6570\u66f4\u65b0\u6b65\u9aa4 ---\n        if momentum &gt; 0:\n            # --- \u5e26\u52a8\u91cf\u7684\u66f4\u65b0 ---\n            # \u83b7\u53d6\u52a8\u91cf\u7f13\u51b2\n            buf = momentum_buffer_list[i]\n            if is_complex_param:\n                 # \u540c\u6837\u5904\u7406\u590d\u6570\u60c5\u51b5\n                buf = torch.view_as_real(buf)\n\n            # \u66f4\u65b0\u52a8\u91cf\u7f13\u51b2\u3002\u516c\u5f0f: buf = momentum * buf + grad / avg\n            buf.mul_(momentum).addcdiv_(grad, avg)\n            # \u4f7f\u7528\u52a8\u91cf\u7f13\u51b2\u66f4\u65b0\u53c2\u6570\u3002\u516c\u5f0f: param = param - lr * buf\n            param.add_(buf, alpha=-lr)\n        else:\n            # --- \u4e0d\u5e26\u52a8\u91cf\u7684\u6807\u51c6\u66f4\u65b0 ---\n            # \u76f4\u63a5\u66f4\u65b0\u53c2\u6570\u3002\u516c\u5f0f: param = param - lr * (grad / avg)\n            param.addcdiv_(grad, avg, value=-lr)\n</code></pre> <p>\u4ee3\u7801\u91cc\u9762\u63d0\u5230\u4e86 Centered RMSprop\uff0c\u5176\u5b9e\u8fd8\u662f\u4e3a\u4e86\u89e3\u51b3\u201c\u4e0d\u5728\u6700\u5c0f\u503c\u5468\u56f4\u201d\u7684\u95ee\u9898\u3002\u56e0\u4e3a\u6211\u4eec\u5728\u6700\u5c0f\u503c\u5468\u56f4\u9009\u70b9\uff0c\u68af\u5ea6\u7684\u671f\u671b\u662f \\(0\\)\uff0c\u4f46\u662f\u5982\u679c\u4e0d\u5728\u5468\u56f4\uff0c\u68af\u5ea6\u7684\u671f\u671b\u5c31\u8981\u53e6\u884c\u8ba1\u7b97\uff0c\u600e\u4e48\u8ba1\u7b97\u5462\uff1f\u548c\u4e4b\u524d\u7684\u601d\u8def\u4e00\u6837\uff0c\u540c\u6b65\u5bf9\u68af\u5ea6\u505a\u6ed1\u52a8\u7a97\u53e3\u5e73\u5747\u5373\u53ef\uff0c\u7136\u540e\u8ba1\u7b97 \\(G_n\\) \u7684\u9002\u5408\uff0c\u51cf\u53bb\u8fd9\u4e2a\u671f\u671b\u5e73\u65b9\u503c\uff0c\u5c31\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u6b21\u4e2d\u5fc3\u5316\u4e86\u3002</p> <p>\u4ee3\u7801\u91cc\u9762\u8fd8\u63d0\u5230\u4e86\u201c\u52a8\u91cf\u7f13\u51b2\u201d\uff0c\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3\uff1aRMSprop \u662f\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7684 SGD\uff0c\u90a3\u4e48\u6211\u4eec\u7528\u76f8\u540c\u7684\u65b9\u5f0f\u7ed9 SGDM \u6dfb\u52a0\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5c31\u5f97\u5230\u4e86 RMSprop with Momentum \u4e86\uff0c\u5177\u4f53\u5b9e\u73b0\u53c2\u8003\u521a\u521a\u7684\u4ee3\u7801\uff0c\u5176\u5b9e\u5c31\u662f\u4f7f\u7528\u52a8\u91cf\u9879 \\(M_n = \\beta_3 M_{n-1} + \\dfrac{\\eta}{\\sqrt{\\epsilon+G_n}} g_n\\) \u518d\u4e58\u4ee5\u5b66\u4e60\u7387\u4f5c\u4e3a\u53c2\u6570\u66f4\u65b0\u91cf\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adadelta", "title": "AdaDelta", "text": "<p>\u8ba9\u6211\u4eec\u56de\u5230\u5728 AdaGrad \u91cc\u9762\u8ba8\u8bba\u7684\u6d77\u68ee\u77e9\u9635\u8fd1\u4f3c\uff1a</p> \\[ H\\approx\\dfrac{1}{\\sigma}\\sqrt{g_n\\odot g_n} \\] <p>\u5728 RMSprop \u4e2d\uff0c\u6211\u4eec\u80fd\u591f\u9ad8\u6548\u8ba1\u7b97 \\(\\sqrt{g_n\\odot g_n}\\)\uff0c\u800c\u5bf9\u4e8e \\(\\sigma\\)\uff0c\u6211\u4eec\u76f4\u63a5\u7528\u5b66\u4e60\u7387\u4f30\u8ba1\u7684\uff0c\u4f46\u8003\u8651\u5230 \\(\\sigma\\) \u81ea\u8eab\u7684\u610f\u4e49\uff08\u4e5f\u5c31\u662f \\(\\mathbb{E}[(\\theta_n-\\theta)(\\theta_n-\\theta)^\\top]\\) \u5373\u53c2\u6570\u79bb\u6700\u4f18\u89e3\u7684\u671f\u671b\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\uff09\uff0c\u5982\u679c\u5f53\u524d\u9884\u671f\u53c2\u6570\u6bd4\u8f83\u8fdc\uff0c\\(\\sigma\\) \u5c31\u8be5\u6bd4\u8f83\u5927\uff0c\u53cd\u4e4b\u5219\u8f83\u5c0f\u3002\u600e\u4e48\u4f30\u8ba1\u8fd9\u4e2a\u8ddd\u79bb\u5462\uff1fAdaDelta \u63d0\u51fa\u7684\u65b9\u6848\u662f\u4f7f\u7528\u53c2\u6570\u66f4\u65b0\u91cf\u7684\u6ed1\u52a8\u7a97\u53e3\u5e73\u5747\u3002\u4e5f\u5c31\u662f\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     X_n&amp;=\\beta_4X_{n-1}+(1-\\beta_4)\\Delta\\theta_{n-1}\\odot\\Delta\\theta_{n-1}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\sqrt{\\epsilon+X_n}}{\\sqrt{\\epsilon+G_n}} g_n \\end{align*} \\] <p>\u53ef\u4ee5\u770b\u5230 AdaDelta \u5df2\u7ecf\u5b8c\u5168\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u8c03\u8282\uff0c\u8fde\u5b66\u4e60\u7387\u7684\u4f30\u8ba1\u90fd\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u8c03\u6574\u3002</p> <p>\u8ba9\u6211\u4eec\u770b\u770b\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u76f8\u6bd4\u4e8e\u4e4b\u524d\u7684\u51e0\u4e2a Ada\uff08Adaptive \u7684\u7701\u5199\uff09\u4f18\u5316\u5668\uff0c\u5c3d\u7ba1 AdaDelta \u7684\u5b66\u4e60\u7387\u5927\u4e86\u597d\u51e0\u500d\uff0c\u5728\u53c2\u6570\u66f4\u65b0\u91cf\u4e0a\u9762\u8fd8\u662f\u504f\u4fdd\u5b88\u3002</p> <p></p> <p></p> <p>\u5728 Fashion-MNIST \u4e0a\u9762 AdaDelta \u7684\u6548\u679c\u4ecd\u7136\u53d7\u9650\u4e8e\u4fdd\u5b88\u7684\u53c2\u6570\u66f4\u65b0\u91cf\uff0c\u8fc7\u4e86 6000 \u4e2a batch \u540e train_loss \u8fd8\u6ca1\u6536\u655b\u5230 0.1\uff0c\u4e0d\u8fc7\u5927\u6982\u5728 3000 \u4e2a batch \u540e acc \u80fd\u4e0a 0.9\u3002</p> <p>\u4e0b\u9762\u662f AdaDelta \u7684\u4ee3\u7801\u5b9e\u73b0\uff1a</p> AdaDelta \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_adadelta(\n    params: list[Tensor],\n    grads: list[Tensor],\n    square_avgs: list[Tensor],\n    acc_deltas: list[Tensor],\n    state_steps: list[Tensor], # \u6ce8\u610f\uff1a\u6b64\u51fd\u6570\u4e2d state_steps \u4ec5\u88ab\u9012\u589e\uff0c\u4f46\u672a\u5728\u6838\u5fc3\u7b97\u6cd5\u4e2d\u4f7f\u7528\n    *,\n    lr: float,\n    rho: float,\n    eps: float,\n    weight_decay: float,\n    maximize: bool,\n    differentiable: bool,\n    capturable: bool,\n    has_complex: bool,\n):\n    # --- CUDA Graph \u6355\u83b7\u76f8\u5173\u7684\u68c0\u67e5 ---\n    # \u5982\u679c\u4ee3\u7801\u6b63\u5728\u88ab torch.compile \u7f16\u8bd1\uff0c\u7f16\u8bd1\u5668\u4f1a\u5904\u7406\u56fe\u6355\u83b7\u7684\u68c0\u67e5\u3002\n    if not torch.compiler.is_compiling() and capturable:\n        # \u83b7\u53d6\u652f\u6301 CUDA Graph \u6355\u83b7\u7684\u8bbe\u5907\u5217\u8868\n        capturable_supported_devices = _get_capturable_supported_devices(\n            supports_xla=False\n        )\n        # \u65ad\u8a00\uff1a\u5982\u679c\u542f\u7528 capturable\uff0c\u6240\u6709\u53c2\u6570\u548c\u72b6\u6001\u90fd\u5fc5\u987b\u5728\u652f\u6301\u7684\u8bbe\u5907\u4e0a\n        assert all(\n            p.device.type == step.device.type\n            and p.device.type in capturable_supported_devices\n            for p, step in zip(params, state_steps)\n        ), f\"\u5982\u679c capturable=True, params \u548c state_steps \u5fc5\u987b\u5728\u652f\u6301\u7684\u8bbe\u5907\u4e0a: {capturable_supported_devices}.\"\n\n    # \u5faa\u73af\u904d\u5386\u6bcf\u4e00\u4e2a\u53c2\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u68af\u5ea6\u548c\u72b6\u6001\n    for param, grad, square_avg, acc_delta, step in zip(\n        params, grads, square_avgs, acc_deltas, state_steps\n    ):\n        # \u6b65\u6570\u52a0 1 (\u5728 Adadelta \u6838\u5fc3\u7b97\u6cd5\u4e2d\u672a\u4f7f\u7528\uff0c\u4f46\u4e3a\u4fdd\u6301\u4f18\u5316\u5668\u63a5\u53e3\u4e00\u81f4\u6027\u800c\u4fdd\u7559)\n        step += 1\n        # \u5982\u679c\u662f\u6700\u5927\u5316\u95ee\u9898\uff0c\u5219\u53cd\u8f6c\u68af\u5ea6\n        grad = grad if not maximize else -grad\n\n        # --- \u5e94\u7528\u6743\u91cd\u8870\u51cf ---\n        if weight_decay != 0:\n            grad = grad.add(param, alpha=weight_decay)\n\n        # --- \u5904\u7406\u590d\u6570\u5f20\u91cf ---\n        if torch.is_complex(param):\n            # \u5c06\u6240\u6709\u72b6\u6001\u548c\u68af\u5ea6\u90fd\u89c6\u4e3a\u5b9e\u6570\u5f20\u91cf\u8fdb\u884c\u8ba1\u7b97\n            square_avg = torch.view_as_real(square_avg)\n            acc_delta = torch.view_as_real(acc_delta)\n            grad = torch.view_as_real(grad)\n\n        # --- Adadelta \u7b97\u6cd5\u6838\u5fc3\u6b65\u9aa4 ---\n\n        # 1. \u66f4\u65b0\u68af\u5ea6\u5e73\u65b9\u7684\u79fb\u52a8\u5e73\u5747\u503c E[g^2]_t\n        # \u516c\u5f0f: E[g^2]_t = rho * E[g^2]_{t-1} + (1 - rho) * g_t^2\n        square_avg.mul_(rho).addcmul_(grad, grad, value=1 - rho)\n\n        # 2. \u8ba1\u7b97\u68af\u5ea6\u7684\u5747\u65b9\u6839 RMS[g]_t\n        # \u516c\u5f0f: RMS[g]_t = sqrt(E[g^2]_t + eps)\n        std = square_avg.add(eps).sqrt_()\n\n        # 3. \u8ba1\u7b97\u4e0a\u4e00\u6b65\u53c2\u6570\u66f4\u65b0\u91cf\u7684\u5747\u65b9\u6839 RMS[\u0394x]_{t-1}\n        # \u516c\u5f0f: RMS[\u0394x]_{t-1} = sqrt(E[\u0394x^2]_{t-1} + eps)\n        # \u8fd9\u91cc\u7684 acc_delta \u5b58\u50a8\u7684\u662f E[\u0394x^2]_{t-1}\n        delta = acc_delta.add(eps).sqrt_()\n\n        # \u4e3a\u4e86\u53ef\u5fae\u6027\uff0c\u5982\u679c\u9700\u8981\uff0c\u514b\u9686 delta\uff0c\u4ee5\u9632\u540e\u7eed\u7684\u539f\u5730\u64cd\u4f5c\u7834\u574f\u8ba1\u7b97\u56fe\n        if differentiable:\n            delta = delta.clone()\n\n        # 4. \u8ba1\u7b97\u5f53\u524d\u7684\u53c2\u6570\u66f4\u65b0\u91cf \u0394x_t\n        # \u516c\u5f0f: \u0394x_t = (RMS[\u0394x]_{t-1} / RMS[g]_t) * g_t\n        # delta.div_(std) \u5bf9\u5e94 -&gt; / RMS[g]_t\n        # .mul_(grad)    \u5bf9\u5e94 -&gt; * g_t\n        # \u6b64\u65f6\uff0c`delta` \u53d8\u91cf\u5b58\u50a8\u7684\u662f\u8ba1\u7b97\u51fa\u7684\u66f4\u65b0\u91cf \u0394x_t\n        delta.div_(std).mul_(grad)\n\n        # 5. \u66f4\u65b0\u53c2\u6570\u66f4\u65b0\u91cf\u5e73\u65b9\u7684\u79fb\u52a8\u5e73\u5747\u503c E[\u0394x^2]_t\uff0c\u4e3a\u4e0b\u4e00\u6b65\u505a\u51c6\u5907\n        # \u516c\u5f0f: E[\u0394x^2]_t = rho * E[\u0394x^2]_{t-1} + (1 - rho) * (\u0394x_t)^2\n        # acc_delta \u6b64\u65f6\u4ecd\u662f E[\u0394x^2]_{t-1}\n        acc_delta.mul_(rho).addcmul_(delta, delta, value=1 - rho)\n\n        # --- \u5e94\u7528\u6700\u7ec8\u66f4\u65b0 ---\n\n        # \u5982\u679c\u662f\u590d\u6570\uff0c\u5c06\u8ba1\u7b97\u51fa\u7684\u5b9e\u6570\u66f4\u65b0\u91cf\u8f6c\u6362\u56de\u590d\u6742\u7684\u89c6\u56fe\n        if torch.is_complex(param):\n            delta = torch.view_as_complex(delta)\n\n        # 6. \u66f4\u65b0\u53c2\u6570\n        # \u516c\u5f0f: x_{t+1} = x_t - lr * \u0394x_t\n        # PyTorch \u7684\u5b9e\u73b0\u4e2d\u4fdd\u7559\u4e86 lr \u4f5c\u4e3a\u7f29\u653e\u7cfb\u6570\uff0c\u9ed8\u8ba4\u4e3a 1\n        param.add_(delta, alpha=-lr)\n</code></pre> <p>\u56de\u5230\u6211\u4eec\u521a\u521a\u5728 RMSprop \u7684\u8ba8\u8bba\u4e0a\uff0c\u5176\u5b9e\u6211\u4eec\u5df2\u7ecf\u5728\u52a8\u91cf\u52a0\u901f\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4e24\u6761\u9053\u8def\u4e0a\u8d70\u4e86\u5f88\u8fdc\u4e86\uff0c\u90a3\u4e48\uff0c\u6709\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\uff0c\u80fd\u591f\u65e0\u7f1d\u878d\u5408\uff0c\u771f\u6b63\u96c6\u8fd9\u4e24\u5bb6\u6b66\u529f\u4e4b\u5927\u6210\u5462\uff1f\u6709\u7684\uff0c\u8fd9\u5c31\u662f\u63a5\u4e0b\u6765\u8981\u8ba8\u8bba\u7684 Adam \u4f18\u5316\u5668\uff0c\u4e5f\u5c31\u662f\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e00\u4e2a\u4f18\u5316\u5668\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adam", "title": "Adam", "text": "<p>\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u5e73\u5747\u68af\u5ea6\u7684\u5e73\u65b9\uff0c\u53ef\u4ee5\u5f97\u5230\u5b66\u4e60\u7387\u7684\u4e00\u4e2a\u81ea\u9002\u5e94\u8c03\u6574\uff1b\u901a\u8fc7\u5f15\u5165\u52a8\u91cf\uff0c\u53ef\u4ee5\u8ba9\u6211\u4eec\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u7387\u3002\u5982\u679c\u6211\u4eec\u5c06\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u6574\u878d\u5165\u52a8\u91cf\u6cd5\u4e4b\u4e2d\uff0cAdam \u4f18\u5316\u5668\u5c31\u81ea\u7136\u800c\u7136\u5730\u8bde\u751f\u4e86\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0cAdam \u4f18\u5316\u5668\u662f\u8fd9\u6837\u8ba1\u7b97\u7684\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=(1-\\beta_1)g_n+\\beta_1M_{n-1}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\hat M_n&amp;=\\dfrac{M_n}{1-\\beta_1^{n}}\\\\     \\hat G_n&amp;=\\dfrac{G_n}{1-\\beta_2^{n}}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}} \\hat M_n \\end{align*} \\] <p>\u53ef\u4ee5\u770b\u5230\uff0c\\(M_n\\) \u548c \\(G_n\\) \u7684\u8ba1\u7b97\u4e0e\u5148\u524d\u7684\u4f18\u5316\u5668\u5e76\u65e0\u4e8c\u81f4\uff0c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u6574\u4e5f\u548c RMSprop \u4e00\u6837\u3002\u4f46\u662f Adam \u8fd8\u989d\u5916\u505a\u4e86\u4e00\u4e2a\u968f\u6b65\u6570\u8870\u51cf\u7684\u7f29\u653e\uff0c\u8fd9\u662f\u56e0\u4e3a\u8fed\u4ee3\u521d\u671f\u65f6\u6ca1\u6709\u586b\u6ee1\u6ed1\u52a8\u7a97\u53e3\u5bfc\u81f4 \\(M_n\\) \u548c \\(G_n\\) \u4e8b\u5b9e\u4e0a\u504f\u5c0f\uff0c\u6240\u4ee5\u9700\u8981\u8fd9\u4e2a \\(\\dfrac{1}{1-\\beta^n}\\) \u6765\u8865\u507f\u3002</p> <p>\u73b0\u5728\u6765\u770b\u770b\u4e24\u4e2a\u51fd\u6570\u4e0b Adam \u4f18\u5316\u5668\u7684\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u52a8\u91cf\u4e4b\u540e\uff0cAdam \u7684\u6027\u80fd\u76f8\u6bd4 RMSprop \u53ef\u4ee5\u8bf4\u662f\u7a81\u98de\u731b\u8fdb\uff01\u5728 rastrigin \u5730\u5f62\u4e0b\u901a\u8fc7\u521d\u59cb\u7684\u5927\u5b66\u4e60\u7387\u627e\u5230\u6b63\u786e\u7684\u8c37\u5730\u7136\u540e\u6162\u6162\u8870\u51cf\u5b66\u4e60\u7387\u4e0b\u964d\u5230\u7cbe\u786e\u89e3\uff1b\u5728 rosenbrock \u5730\u5f62\u4e0b\u4e0d\u4ec5\u4e0d\u518d\u53cd\u590d\u6a2a\u8df3\uff0c\u8fd8\u80fd\u6cbf\u7740\u8c37\u5e95\u6709\u6548\u524d\u8fdb\u3002</p> <p>\u4e0b\u9762\u770b\u770b Adam \u5728 Fashion-MNIST \u4e0a\u7684\u8868\u73b0\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230 Adam \u4f18\u5316\u5668\u53d6\u5f97\u4e86\u76f8\u5f53\u4f18\u79c0\u7684\u7ed3\u679c\uff1a\u5728 3500 \u4e2a Batch \u540e train_loss \u964d\u5230\u4e86 0.1 \u9644\u8fd1\uff1b900 \u4e2a Batch \u540e acc \u7a33\u5b9a\u5728 0.9 \u4ee5\u4e0a\u3002</p> <p>\u7b49\u7740\u770b\u4ee3\u7801\u5417\uff1f\u522b\u6025\uff0cAdam \u4f18\u5316\u5668\u5728\u63d0\u51fa\u4e4b\u540e\uff0c\u4e5f\u662f\u7ecf\u5386\u4e86\u5982\u8fc7\u5c71\u8f66\u4e00\u822c\u8d77\u4f0f\u7684\u6ce2\u6298\uff0c\u73b0\u5728\u7684 Adam \u5b9e\u73b0\u65e9\u5c31\u4e0d\u662f\u539f\u6765\u90a3\u4e2a Adam \u4e86\u3002</p> <p>\u4f55\u4ee5\u89c1\u5f97\uff1f\u4e14\u542c\u4e0b\u56de\u5206\u89e3\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adam_1", "title": "Adam \u7684\u53d8\u4f53\u4eec", "text": ""}, {"location": "DNN/optimizer/Adaptive/#amsgrad", "title": "AMSGrad", "text": "<p>\u4eba\u6015\u51fa\u540d\u732a\u6015\u58ee\uff0c Adam \u81ea\u5ba3\u5e03\u81ea\u5df1\u62e5\u6709 SOTA \u7ea7\u522b\u7684\u6536\u655b\u6548\u679c\u540e\uff0c\u4fbf\u906d\u5230\u4e86\u8bb8\u591a\u6279\u8bc4\uff0c\u5176\u4e2d\u8bb8\u591a\u4e0d\u65e0\u9053\u7406\u3002\u7b2c\u4e00\u4e2a\u6254\u8fc7\u6765\u7684\u70b8\u5f39\u662f\u6536\u655b\u6027\u95ee\u9898\uff0c\u5728 On the Convergence of Adam and Beyond \u8fd9\u7bc7\u6587\u7ae0\u91cc\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5b66\u4e60\u7387\u5012\u6570\u7684\u5dee\u5206\u5373</p> \\[ \\Gamma_n = \\dfrac{\\sqrt{G_n}}{\\eta}-\\dfrac{\\sqrt{G_{n+1}}}{\\eta} \\] <p>\u7531\u4e8e\u6ed1\u52a8\u5e73\u5747\u7684\u7f18\u6545\uff0c\u6ca1\u6cd5\u505a\u5230\u50cf SGD \u548c AdaGrad \u4e00\u6837\uff0c\u8ba9\u5b83\u6052\u4e3a\u6b63\u3002\u8fd9\u610f\u5473\u7740\u5b66\u4e60\u7387\u867d\u7136\u81ea\u9002\u5e94\u8c03\u6574\u4e86\uff0c\u4f46\u662f\u4e00\u4f1a\u8c03\u5927\u4e00\u4f1a\u8c03\u5c0f\uff0c\u5728\u8fd9\u53cd\u590d\u6a2a\u8df3\uff0c\u54ea\u6765\u7684\u6536\u655b\uff1f\uff1f\uff1f</p> <p>\u4e0d\u8fc7\u5b58\u5728\u4e00\u4e2a\u7b80\u5355\u7c97\u66b4\u7684 clip \u65b9\u6848\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u65e2\u7136\u4f60\u5acc\u5f03\u5b66\u4e60\u7387\u4e00\u4f1a\u5927\uff0c\u4e00\u4f1a\u5c0f\uff0c\u800c\u9020\u6210\u8fd9\u4e2a\u51fa\u73b0\u53d8\u52a8\u7684\u6838\u5fc3\u539f\u56e0\u5c31\u662f \\(G_n\\) \u4e0d\u5355\u8c03\u9012\u589e\uff0c\u90a3\u6211\u76f4\u63a5\u8ba9 \\(G_n\\) \u53d6\u76ee\u524d\u6240\u6709 \\(G\\) \u7684\u6700\u5927\u503c\uff0c\u4e5f\u5c31\u662f\u53ea\u6709\u51fa\u73b0\u65b0\u7684\u6700\u5927\u503c\u624d\u66f4\u65b0 \\(G_n\\)\uff0c\u4e0d\u5c31\u5b8c\u7f8e\u89e3\u51b3\u4e86\u561b\uff01</p> <p>\u4e5f\u5c31\u662f\u8bf4\u76f8\u5bf9 Adam\uff0cAMSGrad \u53ea\u505a\u4e86\u4e00\u70b9\u5c0f\u4fee\u6539\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=(1-\\beta_1)g_n+\\beta_1M_{n-1}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\hat M_n&amp;=\\dfrac{M_n}{1-\\beta_1^n}\\\\     \\hat G_n&amp;=\\max\\{\\hat G_{n-1},G_n\\}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}} \\hat M_n \\end{align*} \\] <p>\u4e5f\u5c31\u76f8\u5f53\u4e8e\u628a Adam \u5bf9 \\(G_n\\) \u7684\u4fee\u504f\u4f30\u8ba1\u6362\u6210\u4e86\u53d6\u6781\u5927\u503c\uff0c\u8fd9\u6837\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5acc \\(G_n\\) \u504f\u5c0f\u7684\u95ee\u9898\uff0c\u8fd8\u89e3\u51b3\u4e86\u5b66\u4e60\u7387\u53cd\u590d\u6a2a\u8df3\u7684\u95ee\u9898\uff0c\u53ef\u8c13\u4e00\u77f3\u4e8c\u9e1f\u3002</p>"}, {"location": "DNN/optimizer/Adaptive/#adamw", "title": "AdamW", "text": "<p>\u4e0d\u8fc7\u4e00\u6ce2\u672a\u5e73\u4e00\u6ce2\u53c8\u8d77\uff0c\u5728 arXiv:1711.05101v1 \u8fd9\u7bc7\u6587\u7ae0\u91cc\u9762\uff0c\u4f5c\u8005\u63ed\u9732\u4e86 Adam \u4f18\u5316\u5668\u548c \\(L_2\\) \u6b63\u5219\u5316\u4e00\u540c\u4f7f\u7528\u65f6\u51fa\u73b0\u7684\u95ee\u9898\u3002</p> <p>\u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u600e\u4e48\u5728 SGD \u4e0a\u9762\u505a\u6743\u91cd\u8870\u51cf\uff1a</p> \\[ \\begin{align*}     g_{n} &amp;= -\\eta\\nabla\\left(\\mathcal{L}({x};\\theta_{n-1})+\\dfrac{\\lambda}{2}|\\theta_{n-1}|^2\\right)\\\\     &amp;=-\\eta\\nabla\\mathcal{L}({x};\\theta_{n-1})-\\eta\\lambda\\theta_{n-1}\\\\     \\theta_n&amp;=\\theta_{n-1}+g_n\\\\     &amp;=(1-\\eta\\lambda)\\theta_{n-1}-\\eta\\nabla\\mathcal{L}(x;\\theta_{n-1}) \\end{align*} \\] <p>\u5728 SGD \u4e2d\uff0c\u5c06 \\(L_2\\) \u6b63\u5219\u5316\u9879\u7684\u68af\u5ea6\uff08\u5373 \\(\\lambda\\theta_{n-1}\\)\uff09\u52a0\u5230\u635f\u5931\u68af\u5ea6\u4e0a\uff0c\u4e0e\u6700\u540e\u5bf9\u6743\u91cd\u8fdb\u884c\u4e58\u6027\u8870\u51cf\uff08\u5373\u4e58\u4ee5 \\((1-\\eta\\lambda)\\)\uff09\u662f\u7b49\u6548\u7684\u3002\u7136\u800c\uff0c\u5728 Adam \u8fd9\u6837\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4f18\u5316\u5668\u4e2d\uff0c\u8fd9\u79cd\u7b49\u6548\u6027\u88ab\u6253\u7834\u4e86\u3002</p> <p>\u5f53\u65f6\u51e0\u4e4e\u6240\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5b9e\u73b0 Adam \u7684\u6743\u91cd\u8870\u51cf\u65f6\uff0c\u90fd\u91c7\u7528\u4e86\u5c06 \\(L_2\\) \u6b63\u5219\u9879\u7684\u68af\u5ea6\u52a0\u5230 \\(\\nabla\\mathcal{L}\\) \u4e0a\u7684\u65b9\u5f0f\u3002\u8fd9\u610f\u5473\u7740\uff0c\u6743\u91cd\u8870\u51cf\u9879 \\(\\lambda\\theta_{n-1}\\) \u4e5f\u4f1a\u88ab Adam \u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387 \\(\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}}\\) \u6240\u7f29\u653e\u3002\u8fd9\u4f1a\u4ea7\u751f\u4e00\u4e2a\u610f\u60f3\u4e0d\u5230\u7684\u540e\u679c\uff1a\u5bf9\u4e8e\u90a3\u4e9b\u5386\u53f2\u68af\u5ea6\u5f88\u5927\uff08\u5373 \\(G_n\\) \u5f88\u5927\uff09\u7684\u6743\u91cd\uff0c\u5b83\u4eec\u83b7\u5f97\u7684\u6743\u91cd\u8870\u51cf\u6548\u679c\u4f1a\u53d8\u5c0f\uff1b\u800c\u5bf9\u4e8e\u90a3\u4e9b\u4e0d\u7ecf\u5e38\u66f4\u65b0\u3001\u5386\u53f2\u68af\u5ea6\u5f88\u5c0f\uff08\u5373 \\(G_n\\) \u5f88\u5c0f\uff09\u7684\u6743\u91cd\uff0c\u5b83\u4eec\u7684\u6743\u91cd\u8870\u51cf\u6548\u679c\u53cd\u800c\u66f4\u5f3a\u3002\u8fd9\u4e0e\u6211\u4eec\u4f7f\u7528\u6743\u91cd\u8870\u51cf\u7684\u521d\u8877\u2014\u2014\u5bf9\u6240\u6709\u7684\u5927\u6743\u91cd\u8fdb\u884c\u540c\u7b49\u60e9\u7f5a\u2014\u2014\u662f\u76f8\u6096\u7684\u3002</p> <p>AdamW \u7684\u63d0\u51fa\u5c31\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\u89e3\u8026\u6743\u91cd\u8870\u51cf\u3002\u5b83\u4e0d\u518d\u5c06\u6743\u91cd\u8870\u51cf\u4f2a\u88c5\u6210 \\(L_2\\) \u6b63\u5219\u5316\u5e76\u52a0\u5165\u68af\u5ea6\u8ba1\u7b97\uff0c\u800c\u662f\u5c06\u5176\u4ece\u68af\u5ea6\u66f4\u65b0\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u76f4\u63a5\u5728\u53c2\u6570\u66f4\u65b0\u7684\u6700\u540e\u4e00\u6b65\u5b9e\u73b0\uff0c\u5c31\u50cf\u5728 SGD \u4e2d\u90a3\u6837\u3002</p> <p>\u8fd9\u6837\u6211\u4eec\u5c31\u5f97\u5230\u4e86 AdamW \u5373\u5e26\u6709\u89e3\u8026\u6743\u91cd\u8870\u51cf\u7684 Adam \u4f18\u5316\u5668\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=(1-\\beta_1)g_n+\\beta_1M_{n-1}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\hat M_n&amp;=\\dfrac{M_n}{1-\\beta_1^n}\\\\     \\hat G_n&amp;=\\dfrac{G_n}{1-\\beta_2^n}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}} \\hat M_n-\\eta\\lambda\\theta_{n-1} \\end{align*} \\] <p>\u81f3\u6b64\uff0cAdamW \u5927\u6740\u56db\u65b9\uff0c\u73b0\u5728\u5df2\u7ecf\u6210\u4e3atransformer\u8bad\u7ec3\u4e2d\u7684\u9ed8\u8ba4\u4f18\u5316\u5668\u4e86\u3002</p> <p>\u8bb2\u4e86\u8fd9\u4e48\u591a\uff0c\u8ba9\u6211\u4eec\u4e00\u7aa5\u4ee3\u7801\u771f\u5bb9\uff1a</p>  Adam, AMSGrad, AdamW \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_adam(\n    params: list[Tensor],\n    grads: list[Tensor],\n    exp_avgs: list[Tensor],             # \u4e00\u9636\u77e9\u4f30\u8ba1\uff08\u52a8\u91cf\uff09 m_t\n    exp_avg_sqs: list[Tensor],          # \u4e8c\u9636\u77e9\u4f30\u8ba1\uff08\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u9879\uff09 v_t\n    max_exp_avg_sqs: list[Tensor],      # AMSGrad \u7528\u7684\u5386\u53f2\u6700\u5927\u4e8c\u9636\u77e9\n    state_steps: list[Tensor],          # \u6b65\u6570 t\n    grad_scale: Optional[Tensor],\n    found_inf: Optional[Tensor],\n    *,\n    amsgrad: bool,                      # \u662f\u5426\u542f\u7528 AMSGrad\n    has_complex: bool,\n    beta1: Union[float, Tensor],        # \u4e00\u9636\u77e9\u7684\u6307\u6570\u8870\u51cf\u7387\n    beta2: Union[float, Tensor],        # \u4e8c\u9636\u77e9\u7684\u6307\u6570\u8870\u51cf\u7387\n    lr: Union[float, Tensor],           # \u5b66\u4e60\u7387\n    weight_decay: float,                # \u6743\u91cd\u8870\u51cf\u7cfb\u6570\n    eps: float,                         # \u9632\u6b62\u9664\u4ee5\u96f6\u7684\u6781\u5c0f\u503c\n    maximize: bool,\n    capturable: bool,                   # \u662f\u5426\u652f\u6301 CUDA Graph \u6355\u83b7\n    differentiable: bool,               # \u662f\u5426\u8981\u6c42\u64cd\u4f5c\u53ef\u5fae\u5206\n    decoupled_weight_decay: bool,       # \u662f\u5426\u4f7f\u7528 AdamW \u7684\u89e3\u8026\u6743\u91cd\u8870\u51cf\n):\n    assert grad_scale is None and found_inf is None\n\n    # \u5982\u679c\u5728 TorchScript (JIT) \u73af\u5883\u4e0b\uff0c\u7531\u4e8e JIT \u5bf9\u7c7b\u578b\u63a8\u65ad\u7684\u9650\u5236\uff0c\u76f4\u63a5\u65ad\u8a00\u8d85\u53c2\u6570\u4e3a float\n    if torch.jit.is_scripting():\n        assert isinstance(lr, float)\n        assert isinstance(beta1, float)\n        assert isinstance(beta2, float)\n\n    # \u4e3a\u4e86\u4f18\u5316\uff0c\u5982\u679c beta1 \u662f Tensor\uff0c\u9884\u5148\u5c06\u5176\u6309\u8bbe\u5907\u548c\u7c7b\u578b\u5b58\u5165\u5b57\u5178\uff0c\u907f\u514d\u5faa\u73af\u5185\u91cd\u590d\u8f6c\u6362\n    if isinstance(beta1, Tensor):\n        beta1_dict: Optional[DeviceDtypeDict] = {(beta1.device, beta1.dtype): beta1}\n    else:\n        beta1_dict = None\n\n    # \u5faa\u73af\u5904\u7406\u6bcf\u4e2a\u53c2\u6570\n    for i, param in enumerate(params):\n        grad = grads[i] if not maximize else -grads[i]\n        exp_avg = exp_avgs[i]\n        exp_avg_sq = exp_avg_sqs[i]\n        step_t = state_steps[i]\n\n        # --- CUDA Graph \u6355\u83b7\u68c0\u67e5 ---\n        if not torch.compiler.is_compiling() and capturable:\n            capturable_supported_devices = _get_capturable_supported_devices()\n            assert (\n                param.device.type == step_t.device.type\n                and param.device.type in capturable_supported_devices\n            ), f\"If capturable=True, params and state_steps must be on supported devices: {capturable_supported_devices}.\"\n\n        # \u6b65\u6570\u52a0 1\n        step_t += 1\n\n        # --- \u6b65\u9aa4 1: \u5e94\u7528\u6743\u91cd\u8870\u51cf ---\n        if weight_decay != 0:\n            if decoupled_weight_decay:\n                # AdamW: \u89e3\u8026\u6743\u91cd\u8870\u51cf\u3002\u76f4\u63a5\u5728\u53c2\u6570\u4e0a\u4e58\u4ee5\u4e00\u4e2a\u8870\u51cf\u56e0\u5b50\u3002\n                # \u516c\u5f0f: param_t = param_t * (1 - lr * weight_decay)\n                param.mul_(1 - lr * weight_decay)\n            else:\n                # \u6807\u51c6 Adam: \u6743\u91cd\u8870\u51cf\u4f5c\u4e3a L2 \u6b63\u5219\u5316\u9879\u52a0\u5165\u68af\u5ea6\u3002\n                # \u516c\u5f0f: grad_t = grad_t + weight_decay * param_{t-1}\n                # \u5d4c\u5957 if \u662f\u4e3a\u4e86\u5904\u7406\u53ef\u5fae\u5206\u548c JIT \u7684\u60c5\u51b5\n                if differentiable and isinstance(weight_decay, Tensor):\n                    if weight_decay.requires_grad:\n                        grad = grad.addcmul(param.clone(), weight_decay)\n                    else:\n                        grad = grad.add(param, alpha=weight_decay)\n                else:\n                    grad = grad.add(param, alpha=weight_decay)\n\n        # --- \u5904\u7406\u590d\u6570 ---\n        if torch.is_complex(param):\n            # \u5c06\u6240\u6709\u76f8\u5173\u5f20\u91cf\u90fd\u89c6\u4e3a\u5b9e\u6570\u8fdb\u884c\u8ba1\u7b97\n            grad = torch.view_as_real(grad)\n            exp_avg = torch.view_as_real(exp_avg)\n            exp_avg_sq = torch.view_as_real(exp_avg_sq)\n            if amsgrad:\n                max_exp_avg_sqs[i] = torch.view_as_real(max_exp_avg_sqs[i])\n            param = torch.view_as_real(param)\n\n        device = param.device\n\n        # \u5982\u679c beta1 \u662f Tensor\uff0c\u4ece\u5b57\u5178\u4e2d\u83b7\u53d6\u5bf9\u5e94\u8bbe\u5907\u548c\u7c7b\u578b\u7684\u7248\u672c\n        if beta1_dict is not None:\n            dtype = param.dtype\n            key = (device, dtype)\n            if key not in beta1_dict:\n                beta1_dict[key] = beta1.to(device=device, dtype=dtype, non_blocking=True)\n            device_beta1: Union[float, Tensor] = beta1_dict[key]\n        else:\n            device_beta1 = beta1\n\n        # --- \u6b65\u9aa4 2: \u66f4\u65b0\u4e00\u9636\u548c\u4e8c\u9636\u77e9\u4f30\u8ba1 ---\n        # \u66f4\u65b0\u4e00\u9636\u77e9\u4f30\u8ba1 m_t (exp_avg)\n        # \u516c\u5f0f: m_t = beta1 * m_{t-1} + (1 - beta1) * grad_t\n        exp_avg.lerp_(grad, 1 - device_beta1)\n\n        # \u66f4\u65b0\u4e8c\u9636\u77e9\u4f30\u8ba1 v_t (exp_avg_sq)\n        # \u516c\u5f0f: v_t = beta2 * v_{t-1} + (1 - beta2) * grad_t^2\n        # \u540c\u6837\uff0c\u5d4c\u5957 if \u662f\u4e3a\u4e86\u5904\u7406\u53ef\u5fae\u5206\u60c5\u51b5\n        if differentiable and isinstance(beta2, Tensor):\n            if beta2.requires_grad:\n                # \u4f7f\u7528 lerp \u5b9e\u73b0\u53ef\u5fae\u5206\u7684\u66f4\u65b0\uff0c\u6570\u5b66\u4e0a\u7b49\u4ef7\u4e8e\u4e0b\u9762\u7684 addcmul\n                exp_avg_sq.lerp_(torch.square(grad), weight=1 - beta2)\n            else:\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n        else:\n            exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n        # --- \u6b65\u9aa4 3: \u53c2\u6570\u66f4\u65b0 ---\n        # capturable \u6216 differentiable \u6a21\u5f0f\u4e0b\uff0c\u6240\u6709\u8ba1\u7b97\u90fd\u4f7f\u7528\u5f20\u91cf\u64cd\u4f5c\u4ee5\u4fdd\u7559\u8ba1\u7b97\u56fe\n        if capturable or differentiable:\n            step = step_t\n\n            # --- \u8ba1\u7b97\u504f\u5dee\u4fee\u6b63\u9879 ---\n            # \u5d4c\u5957 if \u7528\u4e8e\u5904\u7406 beta \u662f\u53ef\u5fae\u5f20\u91cf\u7684\u60c5\u51b5\n            if differentiable and isinstance(beta1, Tensor):\n                if beta1.requires_grad:\n                    bias_correction1 = 1 - beta1 ** step.clone()\n                else:\n                    bias_correction1 = 1 - beta1**step\n            else:\n                bias_correction1 = 1 - beta1**step\n\n            if differentiable and isinstance(beta2, Tensor):\n                if beta2.requires_grad:\n                    bias_correction2 = 1 - beta2 ** step.clone()\n                else:\n                    bias_correction2 = 1 - beta2**step\n            else:\n                bias_correction2 = 1 - beta2**step\n\n            # --- \u8ba1\u7b97\u66f4\u65b0\u6b65\u957f\u548c\u5206\u6bcd ---\n            step_size = lr / bias_correction1\n            step_size_neg = step_size.neg()\n            bias_correction2_sqrt = bias_correction2.sqrt()\n\n            if amsgrad:\n                # AMSGrad: \u7ef4\u62a4\u5386\u53f2\u6700\u5927\u4e8c\u9636\u77e9\n                if differentiable:\n                    max_exp_avg_sq = max_exp_avg_sqs[i].clone()\n                else:\n                    max_exp_avg_sq = max_exp_avg_sqs[i]\n\n                torch.maximum(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sqs[i])\n\n                # \u4f7f\u7528\u6700\u5927\u4e8c\u9636\u77e9\u8ba1\u7b97\u5206\u6bcd\n                # \u8fd9\u91cc\u505a\u4e86\u4e00\u4e9b\u6570\u5b66\u53d8\u6362\uff0c\u5c06 step_size \u5408\u5e76\u8ba1\u7b97\uff0c\u4ee5\u51cf\u5c11\u5f20\u91cf\u8bfb\u5199\n                denom = (\n                    max_exp_avg_sqs[i].sqrt() / (bias_correction2_sqrt * step_size_neg)\n                ).add_(eps / step_size_neg)\n            else:\n                # \u6807\u51c6 Adam: \u4f7f\u7528\u5f53\u524d\u4e8c\u9636\u77e9\u8ba1\u7b97\u5206\u6bcd\n                denom = (\n                    exp_avg_sq.sqrt() / (bias_correction2_sqrt * step_size_neg)\n                ).add_(eps / step_size_neg)\n\n            # \u6267\u884c\u6700\u7ec8\u66f4\u65b0\n            if differentiable:\n                param.addcdiv_(exp_avg.clone(), denom)\n            else:\n                param.addcdiv_(exp_avg, denom)\n\n        # \u975e capturable/differentiable \u7684\u5e38\u89c4\u8def\u5f84\uff08\u6548\u7387\u66f4\u9ad8\uff09\n        else:\n            step = _get_value(step_t)\n\n            # --- \u8ba1\u7b97\u504f\u5dee\u4fee\u6b63\u9879 ---\n            bias_correction1 = 1 - beta1**step\n            bias_correction2 = 1 - beta2**step\n\n            # --- \u8ba1\u7b97\u6b65\u957f\u548c\u5206\u6bcd ---\n            step_size = lr / bias_correction1\n            bias_correction2_sqrt = bias_correction2**0.5\n\n            if amsgrad:\n                # AMSGrad: \u66f4\u65b0\u5e76\u4f7f\u7528\u5386\u53f2\u6700\u5927\u4e8c\u9636\u77e9\n                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])\n                denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n            else:\n                # \u6807\u51c6 Adam: \u4f7f\u7528\u5f53\u524d\u4e8c\u9636\u77e9\n                denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\n            # --- \u6267\u884c\u6700\u7ec8\u66f4\u65b0 ---\n            # \u516c\u5f0f: param_t = param_{t-1} - step_size * (m_hat / (sqrt(v_hat) + eps))\n            param.addcdiv_(exp_avg, denom, value=-step_size)\n\n        # --- \u590d\u6570\u8f6c\u6362\u56de\u6765 ---\n        # \u5982\u679c\u542f\u7528\u4e86 AMSGrad \u5e76\u4e14\u53c2\u6570\u662f\u590d\u6570\uff0c\u5c06 max_exp_avg_sqs \u89c6\u56fe\u8f6c\u6362\u56de\u6765\n        if amsgrad and torch.is_complex(params[i]):\n            max_exp_avg_sqs[i] = torch.view_as_complex(max_exp_avg_sqs[i])\n</code></pre>"}, {"location": "DNN/optimizer/Adaptive/#adamax", "title": "Adamax", "text": "<p>\u5148\u524d\u63d0\u5230 Adam \u7531\u4e8e\u65e0\u6cd5\u63a7\u5236 \\(G_n\\) \u7684\u5355\u8c03\u6027\u800c\u53ef\u80fd\u9677\u5165\u65e0\u6cd5\u6536\u655b\u7684\u72b6\u51b5\uff0c\u5e76\u4e14\u4e5f\u4ecb\u7ecd\u4e86 AMSGrad \u63d0\u51fa\u7684 clip \u65b9\u6848\u3002\u800c Adamax \u5374\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u6240\u4e0d\u540c\u7684 clip \u65b9\u6848\u3002</p> <p>Adamax \u7684\u601d\u60f3\uff0c\u6700\u521d\u662f\u60f3\u628a \\(G_n\\) \u5bf9\u5e73\u5747\u68af\u5ea6\u7684 \\(L_2\\) \u4f30\u8ba1\uff08\u4e5f\u5c31\u662f \\(g_n\\odot g_n\\) \u9879\uff09\u6269\u5c55\u5230 \\(L_p\\) \u4f30\u8ba1\uff1a</p> \\[ G_{n}=\\beta_2 G_n + (1-\\beta_2)g_n^p\\\\ \\theta_n=\\theta_{n-1}-\\dfrac{\\eta}{G_n^{\\frac 1p}} M_n \\] <p>\u6211\u4eec\u5355\u72ec\u628a\u5b66\u4e60\u7387\u81ea\u9002\u5e94\u6743\u91cd \\(G_n^{\\frac 1p}\\) \u63d0\u53d6\u51fa\u6765\u5c55\u5f00\u7b97\uff1a</p> \\[ \\begin{align*}     G_n^{\\frac 1p} &amp;= \\beta_2 G_n + (1-\\beta_2)g_n^p\\\\     &amp;=(1-\\beta_2)^{\\frac 1p}\\left(\\sum_{i=1}^{n}\\beta_2^i g^p_{n-i}\\right)^{\\frac 1p} \\end{align*} \\] <p>\u663e\u7136\u8fd9\u79cd\u63a8\u5e7f\u5728\u4efb\u610f\u7684 \\(p\\) \u4e0b\u662f\u65e0\u6cd5\u89e3\u51b3\u4efb\u4f55\u95ee\u9898\u7684\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u8ba9 \\(p\\rightarrow\\infty\\) \u4e5f\u5c31\u662f\u53d6 \\(L_\\infty\\) \u8303\u6570\uff0c\u5c31\u4f1a\u5f97\u5230\uff1a</p> \\[ \\begin{align*}     \\lim_{p\\rightarrow\\infty}(1-\\beta_2)^{\\frac 1p}\\left(\\sum_{i=1}^{n}\\beta_2^i g^p_{n-i}\\right)^{\\frac 1p}&amp;=\\lim_{p\\rightarrow\\infty}\\left(\\sum_{i=1}^{n}\\beta_2^i g^p_{n-i}\\right)^{\\frac 1p}\\\\     &amp;=\\max\\left\\{\\beta_2^i |g_{n-i}|\\right\\}_{i=1\\dots n} \\end{align*} \\] <p>\u5199\u6210\u9012\u63a8\u5f0f\u5b50\u5c31\u662f</p> \\[ G_n = \\max\\{\\beta_2G_{n-1}, |g_n|\\} \\] <p>\u56e0\u6b64 Adamax \u5ba3\u79f0\u81ea\u5df1\u76f8\u5bf9 Adam\uff0c\u80fd\u591f\u89e3\u51b3\u4e0d\u6536\u655b\u95ee\u9898\uff0c\u8fd8\u53ef\u4ee5\u7b80\u7701\u8ba1\u7b97\u91cf\u3002\u4e0d\u8fc7\u8fd9\u6837\u9b54\u6539\uff0c\u771f\u7684\u80fd\u5bf9 Hessian \u505a\u66f4\u597d\u7684\u4f30\u8ba1\u5417\u2026\u2026</p> <p>\u770b\u5b83\u5728\u8fd9\u4e24\u4e2a\u635f\u5931\u5730\u5f62\u4e0a\u7684\u8868\u73b0\uff0c\u5176\u5b9e\u8fd8\u4e0d\u9519\uff1a</p> <p></p> <p></p> <p>\u518d\u770b\u770b\u5b9e\u9645\u4efb\u52a1\u4e0a\u9762\u7684\u8868\u73b0\uff1a</p> <p></p> <p></p> <p>\u8fd8\u662f\u8f83 Adam \u7565\u900a\u4e00\u7b79\u554a\uff0ctrain_loss \u964d\u5230 0.1 \u9644\u8fd1\u8981\u82b1\u8d39\u63a5\u8fd1 6000 \u4e2a Batch\uff1bacc \u5347\u5230 0.9 \u9644\u8fd1\u9700\u8981\u63a5\u8fd1 1500 \u4e2a Batch\u3002</p> <p>\u8fd8\u662f\u6765\u770b\u770b\u4ee3\u7801\u5b9e\u73b0\u5427\uff1a</p>  Adamax \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_adamax(\n    params: list[Tensor],\n    grads: list[Tensor],\n    exp_avgs: list[Tensor],\n    exp_infs: list[Tensor],\n    state_steps: list[Tensor],\n    *,\n    eps: float,\n    beta1: float,\n    beta2: float,\n    lr: float,\n    weight_decay: float,\n    maximize: bool,\n    differentiable: bool,\n    capturable: bool,\n    has_complex: bool,\n):\n    # \u5faa\u73af\u5904\u7406\u6bcf\u4e2a\u53c2\u6570\n    for i, param in enumerate(params):\n        grad = grads[i]\n        grad = grad if not maximize else -grad\n        exp_avg = exp_avgs[i]  # \u4e00\u9636\u77e9 m_t\n        exp_inf = exp_infs[i]  # \u65e0\u7a77\u8303\u6570 u_t\n        step_t = state_steps[i]\n\n        # --- CUDA Graph \u6355\u83b7\u68c0\u67e5 ---\n        if not torch.compiler.is_compiling() and capturable:\n            capturable_supported_devices = _get_capturable_supported_devices()\n            assert (\n                param.device.type == step_t.device.type\n                and param.device.type in capturable_supported_devices\n            ), f\"If capturable=True, params and state_steps must be on supported devices: {capturable_supported_devices}.\"\n\n        # \u6b65\u6570\u52a0 1\n        step_t += 1\n\n        # --- \u5e94\u7528\u6743\u91cd\u8870\u51cf ---\n        if weight_decay != 0:\n            grad = grad.add(param, alpha=weight_decay)\n\n        # --- \u5904\u7406\u590d\u6570 ---\n        if torch.is_complex(param):\n            param = torch.view_as_real(param)\n            grad = torch.view_as_real(grad)\n            exp_avg = torch.view_as_real(exp_avg)\n            exp_inf = torch.view_as_real(exp_inf)\n\n        # --- Adamax \u7b97\u6cd5\u6838\u5fc3\u6b65\u9aa4 ---\n\n        # 1. \u66f4\u65b0\u6709\u504f\u4e00\u9636\u77e9\u4f30\u8ba1 m_t (\u548c Adam \u4e00\u6837)\n        # \u516c\u5f0f: m_t = beta1 * m_{t-1} + (1 - beta1) * g_t\n        exp_avg.lerp_(grad, 1 - beta1)\n\n        # 2. \u66f4\u65b0\u6307\u6570\u52a0\u6743\u65e0\u7a77\u8303\u6570 u_t\n        # \u516c\u5f0f: u_t = max(beta2 * u_{t-1}, |g_t|)\n        # \u6ce8\u610f\uff1aPyTorch \u7684\u5b9e\u73b0\u4e2d\uff0c\u4e3a\u4e86\u9632\u6b62 u_t \u5728\u68af\u5ea6\u4e3a\u96f6\u65f6\u4e5f\u4e3a\u96f6\uff0c\n        # \u5b9e\u9645\u6bd4\u8f83\u7684\u662f `beta2 * u_{t-1}` \u548c `|g_t| + eps`\u3002\n        if not differentiable:\n            # \u5bf9\u4e8e\u975e\u53ef\u5fae\u6a21\u5f0f\uff0c\u4f7f\u7528 torch.maximum \u66f4\u9ad8\u6548\n            torch.maximum(\n                exp_inf.mul_(beta2),      # \u8ba1\u7b97 beta2 * u_{t-1}\n                grad.abs().add_(eps),     # \u8ba1\u7b97 |g_t| + eps\n                out=exp_inf,              # \u5c06\u7ed3\u679c\u539f\u5730\u5199\u5165 exp_inf\n            )\n        else:\n            # \u5bf9\u4e8e\u53ef\u5fae\u6a21\u5f0f\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u64cd\u4f5c\u5e8f\u5217\n            # \u5c06\u4e24\u4e2a\u8981\u6bd4\u8f83\u7684\u5f20\u91cf\u5728\u65b0\u7684\u7ef4\u5ea6\u4e0a\u62fc\u63a5\u8d77\u6765\n            norm_buf = torch.cat(\n                [exp_inf.mul_(beta2).unsqueeze(0), grad.abs().add_(eps).unsqueeze_(0)],\n                0,\n            )\n            # \u7136\u540e\u4f7f\u7528 amax\uff08\u7b49\u4ef7\u4e8e max\uff09\u5728\u90a3\u4e2a\u65b0\u7ef4\u5ea6\u4e0a\u6c42\u6700\u5927\u503c\n            exp_inf.copy_(torch.amax(norm_buf, 0, keepdim=False))\n\n        # --- \u6b65\u9aa4 3: \u53c2\u6570\u66f4\u65b0 ---\n\n        # \u9488\u5bf9 Capturable \u6a21\u5f0f\u7684\u7279\u6b8a\u5904\u7406\u8def\u5f84\n        if capturable:\n            # \u8fd9\u91cc\u7684\u6570\u5b66\u53d8\u6362\u662f\u4e3a\u4e86\u5728 capturable \u6a21\u5f0f\u4e0b\u907f\u514d\u67d0\u4e9b\u64cd\u4f5c\u7684\u9650\u5236\u3002\n            # \u539f\u59cb\u516c\u5f0f\u662f: clr = lr / (1 - beta1^t), \u66f4\u65b0\u91cf\u662f -clr * (m_t / u_t)\n            # \u8fd9\u91cc\u8ba1\u7b97 neg_bias_correction = beta1^t - 1\n            neg_bias_correction = beta1**step_t - 1\n            # \u7136\u540e\u9664\u4ee5 lr\uff0c\u5f97\u5230 (beta1^t - 1) / lr\n            neg_bias_correction.div_(lr)\n            # \u5206\u6bcd denom = u_t * (beta1^t - 1) / lr\n            denom = exp_inf * neg_bias_correction\n            # \u66f4\u65b0: param += m_t / denom = param - lr * m_t / ((1 - beta1^t) * u_t)\n            param.addcdiv_(exp_avg, denom)\n        else:\n            # \u5e38\u89c4\u6a21\u5f0f\u4e0b\u7684\u66f4\u65b0\u8def\u5f84\n            # \u8ba1\u7b97\u504f\u5dee\u4fee\u6b63\u9879\n            bias_correction = 1 - beta1 ** _get_value(step_t)\n            # \u8ba1\u7b97\u4fee\u6b63\u540e\u7684\u5b66\u4e60\u7387\n            clr = lr / bias_correction\n\n            # \u6267\u884c\u53c2\u6570\u66f4\u65b0\n            # \u516c\u5f0f: \u03b8_t = \u03b8_{t-1} - (lr / (1 - beta1^t)) * (m_t / u_t)\n            # exp_inf \u5c31\u662f\u5206\u6bcd u_t\n            param.addcdiv_(exp_avg, exp_inf, value=-clr)\n</code></pre>"}, {"location": "DNN/optimizer/Adaptive/#nadam", "title": "Nadam", "text": "<p>\u8bfb\u5230\u8fd9\u91cc\uff0c\u6211\u76f8\u4fe1\u4efb\u4f55\u4e00\u4f4d\u8bfb\u8005\u90fd\u53ef\u4ee5\u72ec\u7acb\u53d1\u660e\u51fa Nadam\uff0c\u6bd5\u7adf\u6211\u4eec\u5728\u8bb2 SGDM \u7684\u65f6\u5019\u82b1\u4e86\u5927\u529b\u6c14\u63a8\u5bfc\u4e86 Nesterov \u52a0\u901f\u7684\u5f0f\u5b50\uff0c\u603b\u4e0d\u53ef\u80fd\u5230\u4e86 Adam \u8fd9\u4e00\u5757\u5c31\u5b8c\u5168\u4e0d\u7ba1\u4e86\u5427\u3002\u662f\u7684\uff0cNadam \u7684 novelty \u5c31\u5728\u4e8e\u628a Nesterov \u52a0\u901f\u68af\u5ea6\u5f15\u5165\u5230\u4e86 Adam \u7684\u8ba1\u7b97\u4e4b\u4e2d\u3002 \u6211\u4eec\u8003\u8651\u76f4\u63a5\u5f15\u5165 Nesterov \u52a0\u901f\u9879\uff0c\u4e5f\u5c31\u662f\u6743\u91cd\u66f4\u65b0\u9879\u4ece \\(\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}}\\hat M_n\\) \u6362\u6210 \\(\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}}[\\dfrac{\\beta_1 M_n}{1-\\beta_1^{n-1}}+\\dfrac{(1-\\beta_1) g_n}{1-\\beta_1^{n-1}}]\\)\u3002\u8fd9\u4e2a\u4e5f\u662f arXiv/1609.04747 \u63a8\u5bfc\u51fa\u6765\u7684\u7684\u3002</p> <p>\u4f46\u662f\u8003\u8651\u5230 Adam \u589e\u52a0\u4e86\u5bf9\u68af\u5ea6\u4e8c\u9636\u77e9\u7684\u4f30\u8ba1\uff0c\u56e0\u6b64\u5982\u679c\u4e00\u76f4\u4f7f\u7528\u56fa\u5b9a\u7684 \\(\\beta_1\\) \u7684\u8bdd\uff0c\u5176\u5b9e\u662f\u504f\u5927\u7684\u3002\u5982\u679c\u6211\u4eec\u770b\u63d0\u51fa Nadam \u7684\u539f\u8bba\u6587 Incorporating Nesterov Momentum into Adam\uff0c\u5c31\u53ef\u4ee5\u53d1\u73b0\u5b83\u7684\u601d\u8def\u6709\u4e00\u5b9a\u7684\u5dee\u5f02\u3002</p> <p>\u5728\u540e\u9762\u4e00\u7bc7\u8bba\u6587\u4e2d\uff0c\u4f5c\u8005\u5e76\u6ca1\u6709\u56fa\u5b9a\u89c4\u5b9a\u4e00\u4e2a \\(\\beta_1\\)\uff0c\u800c\u662f\u4f7f\u7528 \\(\\mu_{n}\\) \u6765\u8c03\u6574\u66f4\u65b0\u6bd4\u4f8b\uff0c\u4e5f\u5c31\u662f\u5b83\u8ba4\u4e3a\u52a8\u91cf\u548c\u6743\u91cd\u7684\u66f4\u65b0\u5e94\u8be5\u662f\u5982\u4e0b\u7684\uff1a</p> \\[ \\begin{align*}     M_n&amp;=\\mu_{n}M_{n-1}+\\beta_3 g_n\\\\     \\theta_n&amp;=\\theta_{n-1}-(\\mu_{n+1}M_n+\\beta_3 g_n) \\end{align*} \\] <p>\u8fd9\u91cc \\(\\mu_{n+1}\\) \u4ee3\u8868\u7684\u5c31\u662f Nesterov \u52a0\u901f\u7684\u524d\u77bb\u6027\u3002\u4e0b\u9762\u6211\u4eec\u53d6 \\(\\beta_3=(1-\\mu_n)\\)\uff0c\u7531\u4e8e\u662f\u5bf9 \\(\\mu_n\\) \u8fdb\u884c\u8fde\u4e58\uff0c\u6743\u91cd\u66f4\u65b0\u9879\u4e5f\u5c31\u53d8\u6210\u4e86 \\(\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}}[\\dfrac{\\mu_{n+1} M_n}{1-\\prod_{i=1}^{n+1}\\mu_i}+\\dfrac{(1-\\mu_{n}) g_n}{1-\\prod_{i=1}^{n}\\mu_i}]\\)</p> <p>\u4e3a\u4e86\u89e3\u51b3\u4e4b\u524d\u504f\u5927\u7684\u95ee\u9898\uff0cPyTorch \u5728 Nadam \u7684\u5b9e\u73b0\u91cc\u5bf9 \\(\\beta_1\\) \u91c7\u7528\u4e86\u8870\u51cf\u7684\u7b56\u7565\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u5b83\u5f15\u5165\u4e86 \\(\\mu_n=\\beta_1 \\left(1 - 0.5 \\cdot 0.96^{n \\cdot d}\\right)\\) \u7684\u4f30\u8ba1\uff0c\u90a3\u4e48\u6700\u540e\u6743\u91cd\u7684\u66f4\u65b0\u65b9\u5f0f\u53d8\u6210\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=(1-\\beta_1)g_n+\\beta_1M_{n-1}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\mu_n&amp;=\\beta_1 \\left(1 - 0.5 \\cdot 0.96^{n \\cdot d}\\right)\\\\     \\mu_{n+1}&amp;=\\beta_1 \\left(1 - 0.5 \\cdot 0.96^{(n+1) \\cdot d}\\right)\\\\     \\hat \\mu_{n+1} &amp;=\\hat\\mu_n \\mu_{n+1}\\\\     \\hat M_n&amp;=\\dfrac{\\mu_{n+1}M_n}{1-\\hat \\mu_{n+1}}\\\\     \\hat G_n&amp;=\\dfrac{G_n}{1-\\beta_2^{n-1}}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}} (\\hat M_n+\\dfrac{(1-\\mu_n)g_n}{1-\\hat\\mu_n}) \\end{align*} \\] <p>\u8fd9\u662f\u4f18\u5316\u5668\u7684\u8f68\u8ff9\u52a8\u56fe\uff1a</p> <p></p> <p></p> <p>\u770b\u6765 Nadam \u548c Adam \u5dee\u4e0d\u592a\u591a\uff0c\u5e76\u6ca1\u6709\u50cf SGD \u5f15\u5165 NAG \u90a3\u6837\u60ca\u8273\u3002\u8fd8\u662f\u770b\u770b\u5b83\u5728\u771f\u5b9e\u4efb\u52a1\u4e0a\u9762\u7684\u8868\u73b0\u5427\uff1a</p> <p></p> <p></p> <p>\u4e8b\u5b9e\u4e0a\u548c Adam \u4e5f\u6ca1\u6709\u7279\u522b\u5927\u7684\u533a\u522b\uff1a\u5728\u7ea6 2900 \u4e2a Batch \u540e train_loss \u964d\u5230\u4e86 0.1 \u9644\u8fd1\uff1b\u548c Adam \u4e00\u6837\u5728\u7ea6 900 \u4e2a Batch \u540e acc \u5347\u5230\u4e86 0.9\u3002</p> <p>\u4e0b\u9762\u662f\u4ee3\u7801\uff1a</p>  Nadam \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_nadam(\n    params: list[Tensor],\n    grads: list[Tensor],\n    exp_avgs: list[Tensor],\n    exp_avg_sqs: list[Tensor],\n    mu_products: list[Tensor],\n    state_steps: list[Tensor],\n    *,\n    beta1: float,\n    beta2: float,\n    lr: float,\n    weight_decay: float,\n    momentum_decay: float,\n    eps: float,\n    decoupled_weight_decay: bool,\n    maximize: bool,\n    capturable: bool,\n    differentiable: bool,\n    has_complex: bool,\n):\n    # \u5faa\u73af\u5904\u7406\u6bcf\u4e2a\u53c2\u6570\n    for i, param in enumerate(params):\n        grad = grads[i] if not maximize else -grads[i]\n        exp_avg = exp_avgs[i]\n        exp_avg_sq = exp_avg_sqs[i]\n        mu_product = mu_products[i]\n        step_t = state_steps[i]\n\n        # --- \u5904\u7406\u590d\u6570 ---\n        if torch.is_complex(param):\n            param = torch.view_as_real(param)\n            grad = torch.view_as_real(grad)\n            exp_avg = torch.view_as_real(exp_avg)\n            exp_avg_sq = torch.view_as_real(exp_avg_sq)\n\n        # --- CUDA Graph \u6355\u83b7\u68c0\u67e5 ---\n        if not torch.compiler.is_compiling() and capturable:\n            capturable_supported_devices = _get_capturable_supported_devices()\n            assert (\n                param.device.type == mu_product.device.type == step_t.device.type\n                and param.device.type in capturable_supported_devices\n            ), \"\u5982\u679c capturable=True, params, mu_products \u548c state_steps \u5fc5\u987b\u5728\u652f\u6301\u7684\u8bbe\u5907\u4e0a\u3002\"\n\n        # \u6b65\u6570\u52a0 1\n        step_t += 1\n\n        # \u6839\u636e\u6a21\u5f0f\u83b7\u53d6\u6b65\u6570\u503c\uff08Tensor \u6216 float\uff09\n        if capturable:\n            step = step_t\n        else:\n            step = _get_value(step_t)\n\n        # \u8ba1\u7b97\u4e8c\u9636\u77e9\u7684\u504f\u5dee\u4fee\u6b63\u9879\n        bias_correction2 = 1 - beta2**step\n\n        # --- \u5e94\u7528\u6743\u91cd\u8870\u51cf ---\n        if weight_decay != 0:\n            if decoupled_weight_decay:\n                # NAdamW: \u4f7f\u7528\u89e3\u8026\u6743\u91cd\u8870\u51cf\n                param.mul_(1 - lr * weight_decay)\n            else:\n                # \u6807\u51c6 NAdam: \u5c06\u6743\u91cd\u8870\u51cf\u4f5c\u4e3a L2 \u6b63\u5219\u5316\u52a0\u5165\u68af\u5ea6\n                grad = grad.add(param, alpha=weight_decay)\n\n        # --- NAdam \u6838\u5fc3\u6b65\u9aa4 ---\n\n        # 1. \u8ba1\u7b97\u5f53\u524d\u6b65(t)\u548c\u4e0b\u4e00\u6b65(t+1)\u7684\u52a8\u91cf\u8870\u51cf\u8c03\u5ea6\u56e0\u5b50 \u03bc\n        # \u8fd9\u4e2a\u8c03\u5ea6\u4f7f\u5f97\u52a8\u91cf\u8870\u51cf\u7387\u5728\u8bad\u7ec3\u521d\u671f\u8f83\u5c0f\uff0c\u540e\u671f\u63a5\u8fd1 beta1\n        mu = beta1 * (1.0 - 0.5 * (0.96 ** (step * momentum_decay)))\n        mu_next = beta1 * (1.0 - 0.5 * (0.96 ** ((step + 1) * momentum_decay)))\n\n        # 2. \u66f4\u65b0\u52a8\u91cf\u8870\u51cf\u56e0\u5b50\u7684\u7d2f\u79ef\u4e58\u79ef\n        # \u516c\u5f0f: mu_product_t = mu_product_{t-1} * mu_t\n        mu_product *= mu\n\n        # 3. \u66f4\u65b0\u4e00\u9636\u77e9 m_t \u548c\u4e8c\u9636\u77e9 v_t (\u548c Adam \u76f8\u540c)\n        # m_t = beta1 * m_{t-1} + (1 - beta1) * g_t\n        exp_avg.lerp_(grad, 1 - beta1)\n        # v_t = beta2 * v_{t-1} + (1 - beta2) * g_t^2\n        exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n        # 4. \u8ba1\u7b97\u5f52\u4e00\u5316\u7684\u5206\u6bcd\n        # denom = sqrt(v_t / bias_correction2)\n        denom = exp_avg_sq.div(bias_correction2).sqrt()\n\n        # --- \u6b65\u9aa4 5: \u53c2\u6570\u66f4\u65b0 ---\n        # NAdam \u7684\u66f4\u65b0\u89c4\u5219\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e24\u90e8\u5206\uff1a\u4e00\u90e8\u5206\u4e0e\u5f53\u524d\u68af\u5ea6\u6709\u5173\uff0c\u4e00\u90e8\u5206\u4e0e\u52a8\u91cf\u6709\u5173\u3002\n        # \u66f4\u65b0\u516c\u5f0f: param_t = param_{t-1} - lr * ( (1-\u03bc_t)*g_hat_t + \u03bc_{t+1}*m_hat_t ) / (sqrt(v_hat_t) + eps)\n        # \u5176\u4e2d g_hat_t \u548c m_hat_t \u662f\u7ecf\u8fc7\u504f\u5dee\u4fee\u6b63\u7684\u68af\u5ea6\u548c\u52a8\u91cf\u3002\n        # PyTorch \u7684\u5b9e\u73b0\u5c06\u8fd9\u4e2a\u516c\u5f0f\u62c6\u5206\u6210\u4e86\u4e24\u4e2a addcdiv \u64cd\u4f5c\u3002\n\n        # \u53ef\u5fae\u5206\u6216\u53ef\u6355\u83b7\u6a21\u5f0f\u4e0b\u7684\u8def\u5f84\n        if differentiable or capturable:\n            denom = denom.add(eps)\n            # \u4e3a\u4e86\u8ba9 Autograd \u8ddf\u8e2a\u64cd\u4f5c\uff0c\u76f4\u63a5\u4fee\u6539\u68af\u5ea6\u548c\u52a8\u91cf\u9879\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a addcdiv \u7684\u6807\u91cf\u503c\n            mu_product_next = mu_product * mu_next\n            # \u8ba1\u7b97\u4e0e\u68af\u5ea6\u76f8\u5173\u7684\u66f4\u65b0\u90e8\u5206\n            grad_update_part = grad * (-lr * (1.0 - mu) / (1.0 - mu_product))\n            # \u8ba1\u7b97\u4e0e\u52a8\u91cf\u76f8\u5173\u7684\u66f4\u65b0\u90e8\u5206\n            exp_avg_update_part = exp_avg * (-lr * mu_next / (1.0 - mu_product_next))\n            # \u5e94\u7528\u66f4\u65b0\n            param.addcdiv_(grad_update_part, denom)\n            param.addcdiv_(exp_avg_update_part, denom)\n        else:\n            # \u5e38\u89c4\u6a21\u5f0f\u4e0b\u7684\u8def\u5f84 (\u66f4\u9ad8\u6548)\n            mu_product_next = _get_value(mu_product) * mu_next\n            denom.add_(eps)\n            # \u5e94\u7528\u4e0e\u68af\u5ea6\u76f8\u5173\u7684\u66f4\u65b0\u90e8\u5206\n            param.addcdiv_(\n                grad, denom, value=(-lr * (1.0 - mu) / (1.0 - _get_value(mu_product)))\n            )\n            # \u5e94\u7528\u4e0e\u52a8\u91cf\u76f8\u5173\u7684\u66f4\u65b0\u90e8\u5206\n            param.addcdiv_(\n                exp_avg, denom, value=(-lr * mu_next) / (1.0 - mu_product_next)\n            )\n</code></pre>"}, {"location": "DNN/optimizer/Adaptive/#lamb", "title": "LAMB", "text": "<p>Researchers \u7684\u5947\u602a\u7684\u547d\u540d\u54c1\u5473\u554a\u2026\u2026\u540e\u9762\u6211\u4eec\u8fd8\u80fd\u770b\u5230 Lion \u4f18\u5316\u5668\uff0c\u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u4e13\u95e8\u5403 LAMB \u7684\u2026\u2026\u65e0\u8bba\u5982\u4f55\u8ba9\u6211\u4eec\u6765\u770b\u770b\u5427\u3002</p> <p>LAMB \u5728 Adam \u4e0a\u9762\u7684\u6539\u8fdb\u70b9\u5728\u4e8e\u5bf9\u201c\u4f55\u65f6\u5e94\u8be5\u591a\u66f4\u65b0\u53c2\u6570\u201d\u7684\u4e00\u4e2a\u5148\u9a8c\u4f30\u8ba1\uff1a\u5982\u679c\u672c\u6765\u53c2\u6570\u5927\uff0c\u5e76\u4e14\u7b97\u51fa\u6765\u7684\u66f4\u65b0\u91cf\u5c0f\uff0c\u90a3\u5c31\u610f\u5473\u7740\u672c\u6765\u5e94\u8be5\u4f18\u5316\u7684\u53c2\u6570\u6ca1\u6709\u5f97\u5230\u6709\u6548\u4f18\u5316\uff0c\u4e5f\u5c31\u662f\uff0c\u5982\u679c\u53cd\u8fc7\u6765\u6211\u4eec\u53d6 \\(r=\\dfrac{|\\theta_{n-1}|}{|\\Delta\\theta|}\\) \uff08\u88ab\u79f0\u4f5c\u4fe1\u4efb\u6bd4\u7387\uff09\u518d\u4e58\u4ee5\u539f\u6765\u7684\u53c2\u6570\u66f4\u65b0\u91cf\uff0c\u5c31\u53ef\u4ee5\u5b9e\u73b0\u6709\u6548\u4f18\u5316\u3002\u5177\u4f53\u800c\u8a00\uff0cLAMB \u4f18\u5316\u5668\u7684\u66f4\u65b0\u516c\u5f0f\u662f\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=(1-\\beta_1)g_n+\\beta_1M_{n-1}\\\\     G_{n}&amp;=\\beta_2 G_n + (1-\\beta_2)g_n\\odot g_n\\\\     \\hat M_n&amp;=\\dfrac{M_n}{1-\\beta_1^n}\\\\     \\hat G_n&amp;=\\dfrac{G_n}{1-\\beta_2^n}\\\\     \\tilde M_n&amp;=\\dfrac{\\eta}{\\sqrt{\\epsilon+\\hat G_n}} \\hat M_n-\\eta\\lambda\\theta_{n-1}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\dfrac{\\Phi(\\theta_{n-1})}{|\\tilde M_n|}\\tilde{M}_n \\end{align*} \\] <p>\u8fd9\u91cc\u7684 \\(\\Phi(x)\\) \u53ef\u4ee5\u53d6 \\(x\\) \u4e5f\u53ef\u4ee5\u505a\u88c1\u526a\u53d6 \\(\\max{(\\min{(x,\\gamma_a)},\\gamma_b)}\\) \u6765\u628a\u53c2\u6570\u63a7\u5236\u5728\u8fd9\u6837\u4e00\u4e2a\u8303\u56f4\u5185\u3002</p> <p>LAMB \u7684\u521d\u8877\u5c31\u662f\u89e3\u51b3 Adam \u5728\u5927\u6279\u91cf\u8bad\u7ec3\u7684\u65f6\u5019\u68af\u5ea6\u65b9\u5dee\u8fc7\u5c0f\uff08\u5c31\u662f\u524d\u9762\u63d0\u5230\u7684\u90a3\u79cd\u60c5\u51b5\uff09\u5bfc\u81f4\u8bad\u4e0d\u52a8\u6216\u8005\u8bad\u70b8\u7684\u95ee\u9898\u3002\u8fd9\u6837\u505a\u770b\u6765\u786e\u5b9e\u6bd4\u8f83\u6709\u7528\uff0c\u8ba9\u6211\u4eec\u6765\u770b\u770b\u8868\u73b0\u5427\uff1a</p> <p></p> <p></p> <p>\u8fd9\u91cc rosenbrock \u7591\u4f3c\u53c2\u6570\u6709\u4e9b\u5c0f\u4e86\u3002\u4e0b\u9762\u662f\u5b9e\u9645\u4efb\u52a1\u7684\u6d4b\u8bd5\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230 LAMB \u53d6\u5f97\u4e86\u548c Adam \u5dee\u4e0d\u591a\u7684\u6c34\u5e73\u3002\u5728\u7ea6 4000 \u4e2a Batch \u540e train_loss \u964d\u5230\u4e86 0.1 \u9644\u8fd1\uff1b\u7ea6 1000 \u4e2a Batch \u540e acc \u7a33\u5b9a\u5728 0.9 \u4ee5\u4e0a\u3002</p> <p>\u4e0b\u9762\u662f <code>torch_optimizer</code> \u5e93\u5bf9 LAMB \u7684\u5b9e\u73b0\uff1a</p>  LAMB \u4f18\u5316\u5668\u7684\u5b9e\u73b0  <pre><code>import math\n\nimport torch\n# \u4ece PyTorch \u4f18\u5316\u5668\u57fa\u7c7b\u4e2d\u5bfc\u5165 Optimizer\nfrom torch.optim.optimizer import Optimizer\n\n# \u4ece\u672c\u5730\u7c7b\u578b\u5b9a\u4e49\u6587\u4ef6\u4e2d\u5bfc\u5165\u7c7b\u578b\u63d0\u793a\nfrom .types import Betas2, OptFloat, OptLossClosure, Params\n\n# \u5b9a\u4e49\u5f53 `from module import *` \u65f6\uff0c\u54ea\u4e9b\u5bf9\u8c61\u4f1a\u88ab\u5bfc\u51fa\n__all__ = ('Lamb',)\n\n\n# \u5b9a\u4e49 Lamb \u4f18\u5316\u5668\u7c7b\uff0c\u7ee7\u627f\u81ea Optimizer\nclass Lamb(Optimizer):\n    r\"\"\"\u5b9e\u73b0\u4e86 Lamb \u7b97\u6cd5\u3002\n\n    \u8be5\u7b97\u6cd5\u5728\u8bba\u6587 `Large Batch Optimization for Deep Learning:\n    Training BERT in 76 minutes`__ \u4e2d\u88ab\u63d0\u51fa\u3002\n\n    \u53c2\u6570:\n        params: \u9700\u8981\u4f18\u5316\u7684\u3001\u53ef\u8fed\u4ee3\u7684\u53c2\u6570\uff0c\u6216\u5b9a\u4e49\u4e86\u53c2\u6570\u7ec4\u7684\u5b57\u5178\u3002\n        lr: \u5b66\u4e60\u7387 (\u9ed8\u8ba4: 1e-3)\u3002\n        betas: \u7528\u4e8e\u8ba1\u7b97\u68af\u5ea6\u7684\u4e00\u9636\u548c\u4e8c\u9636\u77e9\u7684\u8fd0\u884c\u5e73\u5747\u503c\u7684\u7cfb\u6570 (\u9ed8\u8ba4: (0.9, 0.999))\u3002\n        eps: \u4e3a\u4e86\u63d0\u9ad8\u6570\u503c\u7a33\u5b9a\u6027\u800c\u52a0\u5230\u5206\u6bcd\u4e0a\u7684\u4e00\u9879 (\u9ed8\u8ba4: 1e-6)\u3002\n        weight_decay: \u6743\u91cd\u8870\u51cf (L2 \u60e9\u7f5a\u9879) (\u9ed8\u8ba4: 0)\u3002\n        clamp_value: \u5c06 weight_norm \u88c1\u526a\uff08clamp\uff09\u5728 (0, clamp_value) \u8303\u56f4\u5185 (\u9ed8\u8ba4: 10)\u3002\n                     \u53ef\u4ee5\u5c06\u5176\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u5f88\u5927\u7684\u503c (\u4f8b\u5982 10e3) \u6765\u907f\u514d\u88c1\u526a\u3002\n        adam: \u5982\u679c\u4e3a True\uff0c\u5219\u603b\u662f\u4f7f\u7528 trust_ratio = 1\uff0c\u8fd9\u4f1a\u4f7f\u7b97\u6cd5\u9000\u5316\u4e3a AdamW\u3002\n              \u8fd9\u5bf9\u4e8e\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u5f88\u6709\u7528\u3002(\u9ed8\u8ba4: False)\u3002\n        debias: \u901a\u8fc7 (1 - beta**step) \u6765\u5bf9 Adam \u7684\u77e9\u4f30\u8ba1\u8fdb\u884c\u504f\u5dee\u4fee\u6b63 (\u9ed8\u8ba4: False)\u3002\n                \u8bba\u6587\u7684\u6700\u7ec8\u7248\u672c\u6ca1\u6709\u4f7f\u7528\u6b64\u9879\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; import torch_optimizer as optim\n        &gt;&gt;&gt; optimizer = optim.Lamb(model.parameters(), lr=0.1)\n        &gt;&gt;&gt; optimizer.zero_grad()\n        &gt;&gt;&gt; loss_fn(model(input), target).backward()\n        &gt;&gt;&gt; optimizer.step()\n\n    __ https://arxiv.org/abs/1904.00962\n\n    \u6ce8\u610f:\n        \u53c2\u8003\u4ee3\u7801: https://github.com/cybertronai/pytorch-lamb\n    \"\"\"\n\n    # \u7c7b\u7684\u6784\u9020\u51fd\u6570\n    def __init__(\n        self,\n        params: Params,\n        lr: float = 1e-3,\n        betas: Betas2 = (0.9, 0.999),\n        eps: float = 1e-6,\n        weight_decay: float = 0,\n        clamp_value: float = 10,\n        adam: bool = False,\n        debias: bool = False,\n    ) -&gt; None:\n        # --- \u8f93\u5165\u53c2\u6570\u5408\u6cd5\u6027\u68c0\u67e5 ---\n        if lr &lt;= 0.0:\n            raise ValueError('\u65e0\u6548\u7684\u5b66\u4e60\u7387: {}'.format(lr))\n        if eps &lt; 0.0:\n            raise ValueError('\u65e0\u6548\u7684 epsilon \u503c: {}'.format(eps))\n        if not 0.0 &lt;= betas[0] &lt; 1.0:\n            raise ValueError(\n                '\u65e0\u6548\u7684 beta \u53c2\u6570 (\u7d22\u5f15 0): {}'.format(betas[0])\n            )\n        if not 0.0 &lt;= betas[1] &lt; 1.0:\n            raise ValueError(\n                '\u65e0\u6548\u7684 beta \u53c2\u6570 (\u7d22\u5f15 1): {}'.format(betas[1])\n            )\n        if weight_decay &lt; 0:\n            raise ValueError(\n                '\u65e0\u6548\u7684 weight_decay \u503c: {}'.format(weight_decay)\n            )\n        if clamp_value &lt; 0.0:\n            raise ValueError('\u65e0\u6548\u7684 clamp \u503c: {}'.format(clamp_value))\n\n        # \u5c06\u8d85\u53c2\u6570\u6253\u5305\u6210\u4e00\u4e2a\u5b57\u5178\uff0c\u4f5c\u4e3a\u9ed8\u8ba4\u914d\u7f6e\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        # \u5c06 Lamb \u7279\u6709\u7684\u53c2\u6570\u4fdd\u5b58\u4e3a\u7c7b\u7684\u5c5e\u6027\n        self.clamp_value = clamp_value\n        self.adam = adam\n        self.debias = debias\n\n        # \u8c03\u7528\u7236\u7c7b (Optimizer) \u7684\u6784\u9020\u51fd\u6570\n        super(Lamb, self).__init__(params, defaults)\n\n    # `step` \u65b9\u6cd5\u662f\u4f18\u5316\u5668\u7684\u6838\u5fc3\uff0c`@torch.no_grad()` \u88c5\u9970\u5668\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\n    def step(self, closure: OptLossClosure = None) -&gt; OptFloat:\n        r\"\"\"\u6267\u884c\u5355\u6b65\u4f18\u5316\u3002\n\n        \u53c2\u6570:\n            closure: \u4e00\u4e2a\u53ef\u4ee5\u91cd\u65b0\u8bc4\u4f30\u6a21\u578b\u5e76\u8fd4\u56de\u635f\u5931\u7684\u95ed\u5305\u51fd\u6570 (\u53ef\u9009)\u3002\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        # \u904d\u5386\u6240\u6709\u53c2\u6570\u7ec4\n        for group in self.param_groups:\n            # \u904d\u5386\u5f53\u524d\u53c2\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e00\u4e2a\u53c2\u6570 (p)\n            for p in group['params']:\n                # \u5982\u679c\u53c2\u6570\u6ca1\u6709\u68af\u5ea6\uff0c\u5219\u8df3\u8fc7\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                # Lamb \u7b97\u6cd5\u4e0d\u652f\u6301\u7a00\u758f\u68af\u5ea6\n                if grad.is_sparse:\n                    msg = (\n                        'Lamb \u4e0d\u652f\u6301\u7a00\u758f\u68af\u5ea6, '\n                        '\u8bf7\u8003\u8651\u4f7f\u7528 SparseAdam'\n                    )\n                    raise RuntimeError(msg)\n\n                state = self.state[p] # \u83b7\u53d6\u8be5\u53c2\u6570\u7684\u72b6\u6001\u5b57\u5178\n\n                # --- \u72b6\u6001\u521d\u59cb\u5316 (State Initialization) ---\n                if len(state) == 0:\n                    state['step'] = 0\n                    # \u68af\u5ea6\u7684\u4e00\u9636\u77e9\uff08\u52a8\u91cf\uff09\n                    state['exp_avg'] = torch.zeros_like(\n                        p, memory_format=torch.preserve_format\n                    )\n                    # \u68af\u5ea6\u7684\u4e8c\u9636\u77e9\uff08\u672a\u5f00\u65b9\u7684\u65b9\u5dee\uff09\n                    state['exp_avg_sq'] = torch.zeros_like(\n                        p, memory_format=torch.preserve_format\n                    )\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                state['step'] += 1\n\n                # --- Adam \u6838\u5fc3\u8ba1\u7b97\u90e8\u5206 ---\n                # 1. \u66f4\u65b0\u68af\u5ea6\u7684\u4e00\u9636\u548c\u4e8c\u9636\u77e9\u4f30\u8ba1\n                # \u66f4\u65b0\u4e00\u9636\u77e9 (\u52a8\u91cf): m_t = beta1 * m_{t-1} + (1 - beta1) * g_t\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n                # \u66f4\u65b0\u4e8c\u9636\u77e9: v_t = beta2 * v_{t-1} + (1 - beta2) * g_t^2\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n                # 2. \u504f\u5dee\u4fee\u6b63 (\u53ef\u9009)\n                # \u8bba\u6587\u7684 v3 \u7248\u672c\uff08\u6700\u7ec8\u7248\uff09\u5e76\u672a\u4f7f\u7528\u504f\u5dee\u4fee\u6b63\u3002\n                if self.debias:\n                    bias_correction = math.sqrt(1 - beta2 ** state['step'])\n                    bias_correction /= 1 - beta1 ** state['step']\n                else:\n                    bias_correction = 1\n\n                # \u5c06\u504f\u5dee\u4fee\u6b63\u9879\u548c\u5b66\u4e60\u7387\u5408\u5e76\uff0c\u907f\u514d\u540e\u7eed\u7684\u5e7f\u64ad\u64cd\u4f5c\n                step_size = group['lr'] * bias_correction\n\n                # --- LAMB \u6838\u5fc3\u8ba1\u7b97\u90e8\u5206 ---\n                # 3. \u8ba1\u7b97\u6743\u91cd\u7684\u8303\u6570\uff0c\u5e76\u8fdb\u884c\u88c1\u526a\n                weight_norm = torch.norm(p.data).clamp(0, self.clamp_value)\n\n                # 4. \u8ba1\u7b97 Adam \u7684\u66f4\u65b0\u6b65\u957f (Adam Step)\uff0c\u5e76\u52a0\u5165\u89e3\u8026\u6743\u91cd\u8870\u51cf (AdamW)\n                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n                if group['weight_decay'] != 0:\n                    adam_step.add_(p.data, alpha=group['weight_decay'])\n\n                # 5. \u8ba1\u7b97 Adam \u66f4\u65b0\u6b65\u957f\u7684\u8303\u6570\n                adam_norm = torch.norm(adam_step)\n\n                # 6. \u8ba1\u7b97\u4fe1\u4efb\u6bd4\u7387 (Trust Ratio)\n                # \u8fd9\u662f LAMB \u7b97\u6cd5\u7684\u7cbe\u9ad3\uff1atrust_ratio = ||w|| / ||g_update||\n                if weight_norm == 0 or adam_norm == 0:\n                    trust_ratio = 1  # \u907f\u514d\u9664\u4ee5\u96f6\n                else:\n                    trust_ratio = weight_norm / adam_norm\n\n                # (\u53ef\u9009) \u5c06\u4e2d\u95f4\u53d8\u91cf\u5b58\u5165 state\uff0c\u4fbf\u4e8e\u8c03\u8bd5\n                state['weight_norm'] = weight_norm\n                state['adam_norm'] = adam_norm\n                state['trust_ratio'] = trust_ratio\n\n                # \u5982\u679c adam \u6807\u5fd7\u4e3a True\uff0c\u5219\u5f3a\u5236 trust_ratio=1\uff0c\u4f7f\u7b97\u6cd5\u9000\u5316\u4e3a AdamW\n                if self.adam:\n                    trust_ratio = 1\n\n                # 7. \u5e94\u7528\u6700\u7ec8\u66f4\u65b0\n                # \u66f4\u65b0\u516c\u5f0f: p_new = p_old - (step_size * trust_ratio) * adam_step\n                # \u8fd9\u91cc\u7684 `trust_ratio` \u52a8\u6001\u5730\u7f29\u653e\u4e86\u6bcf\u4e2a\u53c2\u6570\uff08\u6216\u6bcf\u5c42\uff09\u7684\u5b66\u4e60\u7387\u3002\n                p.data.add_(adam_step, alpha=-step_size * trust_ratio)\n\n        return loss\n</code></pre>"}, {"location": "DNN/optimizer/Adaptive/#shampoo", "title": "Shampoo", "text": "<p>\u8ba9\u6211\u4eec\u56de\u987e\u90a3\u4e2a\u5728\u6700\u4f18\u70b9\u9644\u8fd1\u7684 Hessian \u8fd1\u4f3c\uff1a \\(H\\approx\\dfrac{1}{\\sigma^2} \\sqrt{GG^\\top}\\)\uff0cShampoo \u7684\u601d\u60f3\u662f\u9009\u53d6\u66f4\u7cbe\u786e\u7684\u8fd1\u4f3c\u4ee5\u903c\u8fdb \\(GG^\\top\\)\u3002</p> <p>\u63d0\u4e00\u5634\uff0c\u8fd9\u91cc\u7684 \\(GG^\\top\\) \u6307\u7684\u662f\u5c06 \\(g\\) \u5c55\u5e73\u4e4b\u540e\u7684\u5916\u79ef\uff0c\u4e5f\u5c31\u662f \\(\\mathrm{vec}(g)\\mathrm{vec}(g)^\\top\\)\uff0c\u9274\u4e8e\u4e4b\u524d\u6211\u4eec\u4e00\u76f4\u7814\u7a76\u7684\u90fd\u662f \\(g\\) \u7684\u5bf9\u89d2\u7ebf\u4e58\u79ef\u8fd1\u4f3c\uff0c\u7531\u4e8e\u7b80\u5316\u5f88\u591a\u6240\u4ee5\u6ca1\u6709\u7279\u522b\u660e\u786e\u8fd9\u4e2a\u7ef4\u5ea6\u95ee\u9898\uff0c\u56e0\u6b64\u5728\u8fd9\u91cc\u660e\u786e\u4e00\u4e0b\u3002</p> <p>Shampoo \u4f18\u5316\u5668\u7684\u7b2c\u4e00\u6b65\uff0c\u662f\u8003\u8651\u73b0\u5728\u7684\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5185\uff0c\u5c42\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\u3002\u56e0\u6b64\u53ef\u4ee5\u628a\u5927\u578b\u7684 \\(GG^\\top\\) \u7ed9\u5206\u5757\u5bf9\u89d2\u5316\uff0c\u6bcf\u4e00\u4e2a\u5bf9\u89d2\u5757\u5bf9\u5e94\u67d0\u4e2a\u5c42\u7684\u68af\u5ea6\u5916\u79ef\u3002</p> <p>\u4f46\u662f\u5373\u4f7f\u8fd9\u6837\uff0c\u5355\u5c42\u7684\u53c2\u6570\u91cf\u4e5f\u5f88\u5927\uff0c\u8003\u8651\u4e00\u4e2a \\(n\\times m\\) \u7684 fc layer\uff0c\\(GG^\\top\\) \u7684\u53c2\u6570\u91cf\u5c31\u6765\u5230\u4e86 \\((mn)\\times(nm)\\)\uff0c\u76f4\u63a5\u5e73\u65b9\u3002\u800c\u8fd9\u5c31\u5e26\u9886\u6211\u4eec\u8fdb\u5165 Shampoo \u4f18\u5316\u5668\u63a8\u5bfc\u7684\u771f\u6b63\u7cbe\u5999\u4e4b\u5904\u3002</p> <p>\u4f5c\u8005\u8ba4\u4e3a\uff0c\u6d77\u68ee\u77e9\u9635\u53ef\u4ee5\u7531\u4e24\u4e2a\u5c0f\u77e9\u9635\u7684 Kronecker \u79ef\u8fd1\u4f3c\uff0c\u4e5f\u5c31\u662f</p> \\[ H=(GG^\\top)^{-1}=L\\otimes R \\] <p>\u8fd9\u6837\u4e00\u62c6\u5f00\u53c2\u6570\u91cf\u66b4\u964d\u5230 \\(L\\) \u7684 \\(n^2\\) \u52a0\u4e0a \\(R\\) \u7684 \\(m^2\\)\u3002\u53ef\u4ee5\u7406\u89e3\u6210 \\(L\\) \u6355\u83b7\u8f93\u5165\u7ef4\u7684\u4fe1\u606f\uff0c\\(R\\) \u6355\u83b7\u8f93\u51fa\u4e3a\u7684\u4fe1\u606f\uff08\u4e0d\u8fc7\u6211\u89c9\u5f97\u6709\u70b9\u5f3a\u884c\u89e3\u91ca\u4e86\u54c8\u54c8\uff0c\u56e0\u4e3a\u5173\u952e\u662f\u8282\u7701\u8ba1\u7b97\u91cf\uff0c\u770b\u4e00\u8def\u8fc7\u6765\u6211\u4eec\u90fd\u662f\u5728\u5bfb\u6c42\u5c3d\u53ef\u80fd\u9ad8\u6548\u800c\u4e0d\u662f\u6700\u6709\u9053\u7406\u7684\u4f18\u5316\u5668\uff09\u3002</p> <p>\u4e0b\u9762\u63a8\u5bfc \\(L\\) \u548c \\(R\\) \u7684\u66f4\u65b0\u5f0f\u3002\u5148\u4ecb\u7ecd Kronecker \u79ef\u7684\u51e0\u4e2a\u5c0f\u6027\u8d28\uff1a\\(\\mathrm{vec}(BXA^\\top)=(A\\otimes B)\\mathrm{vec}(X)\\) \u548c \\((A\\otimes B)^{-1}=(A^{-1}\\otimes B^{-1})\\) \uff08\u8f6c\u7f6e\u4ea6\u7136\uff09\u3002</p> <p>\u53d6 \\(B=A=G\\)\uff0c \\(X = I\\) \u90a3\u4e48 \\(\\mathrm{vec}(GG^\\top)=(G\\otimes G)\\mathrm{vec}(I)\\) \u4f46\u8fd9\u548c\u6211\u4eec\u671f\u5f85\u7684\u7ed3\u6784\u4ecd\u6709\u8ddd\u79bb\uff0c\u4e0d\u8fc7\u6211\u4eec\u53ef\u4ee5\u6362\u6210\u672a\u5c55\u5e73\u7684\u539f\u77e9\u9635\u4e5f\u5c31\u662f\u5229\u7528\uff1a</p> \\[ (g\\otimes g)(g\\otimes g)^\\top=(g\\otimes g)(g^\\top\\otimes g^\\top)=gg^\\top \\otimes g^\\top g \\] <p>\u6765\u8fd1\u4f3c \\(H^2\\)\u3002</p> <p>\u4e0a\u8ff0\u63a8\u5bfc\u975e\u5e38\u7c7b\u4f3c K-FAC \u7b97\u6cd5\uff0c\u5177\u4f53\u8bf7\u53c2\u8003\u8fd9\u4e2a\u535a\u5ba2\u3002</p> <p>\u65e0\u8bba\u5982\u4f55\u6839\u636e\u6211\u4eec\u4e4b\u524d\u7684\u7ecf\u9a8c\uff0c\u8fd9\u91cc\u7684 \\(L\\) \u548c \\(R\\) \u4e5f\u5fc5\u7136\u662f\u8981\u53d6\u6ed1\u52a8\u5e73\u5747\u7684\uff08\u6216\u8005\u5229\u7528\u7c7b\u4f3c AdaGrad \u7684\u601d\u8def\uff0c\u5982\u679c\u4e0b\u9762 \\(\\beta=1\\) \u7684\u8bdd\uff09\uff0c\u4e5f\u5c31\u662f</p> \\[ L_n = \\beta L_{n-1} + g_n g_n^\\top\\\\ R_n = \\beta R_{n-1} + g_n^\\top g_n \\] <p>\u90a3\u4e48\u6211\u4eec\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u5c31\u662f\u8ba1\u7b97 \\(H^{-1}g\\)\uff0c\u5c55\u5f00\uff0c\u5e76\u5229\u7528 Kronecker \u79ef\u7684\u6027\u8d28\uff0c\u5f97\u5230</p> \\[ H^{-\\frac 12}g=L^{- \\frac 14}gR^{- \\frac 14} \\] <p>\u5176\u4e2d \\(\\frac 14 + \\frac 14 = \\frac 12\\)\uff0c\u8fd9\u6837\u5c31\u5f97\u5230\u4e86\u6211\u4eec\u7684\u5bf9\u5355\u5c42\u7684\u66f4\u65b0\u3002</p> <p>\u5bf9\u4e8e \\(k-1\\) \u5c42\u7684\u7f51\u7edc\uff08\u5373 \\(k\\) \u9636\u5f20\u91cf\uff09\uff0c\u6211\u4eec\u9700\u8981\u91cd\u590d\u8ba1\u7b97 \\(k\\) \u6b21\u518d\u7ec4\u5408\u6210\u5927\u7684 \\(H^{-\\frac 12}\\)\uff0c\u90a3\u4e48\u6bcf\u4e00\u6b21\u8ba1\u7b97\u7684\u91cf\u5c31\u5e94\u8be5\u662f \\(H^{-\\frac 1{2k}}\\)\u3002</p> <p>\u8fd9\u91cc\u8981\u5bf9\u5f20\u91cf\u7684\u60c5\u51b5\u505a\u4e00\u4e9b\u8bf4\u660e\uff1a\u7531\u4e8e \\(g_n\\) \u662f\u4e00\u4e2a\u5f20\u91cf\uff0c\u6240\u4ee5\u5728\u8fd9\u4e2a\u904d\u5386\u5f20\u91cf \\(k\\) \u4e2a\u9636\u7684\u8fc7\u7a0b\u4e2d\uff0c\u8981\u6267\u884c\u5c55\u5e73\u64cd\u4f5c\uff0c\u5373 \\(\\mathrm{Flatten}(i;g_n)\\) \u7684\u610f\u601d\u662f\u53d6\u7b2c \\(i\\) \u9636\u7684\u7ef4\u5ea6\u4f5c\u4e3a\u77e9\u9635\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u518d\u628a\u5176\u4ed6\u9636\u7684\u7ef4\u5ea6\u4e58\u8d77\u6765\u4f5c\u4e3a\u77e9\u9635\u7684\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\uff0c\u7531\u6b64\u5c06 \\(k\\) \u9636\u5f20\u91cf\u5c55\u5e73\u5230\u4e8c\u7ef4\u7684\u77e9\u9635\u3002\u8fd9\u6837\u5c31\u80fd\u628a\u4e8c\u7ef4\u60c5\u51b5\u63a8\u5e7f\u5230 \\(k\\) \u9636\u5f20\u91cf\u3002</p> \\[ \\begin{align*} g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\ \\tilde{G}_n&amp;:=g_n\\\\ \\mathrm{for}\\ i &amp;=1,\\dots,k:\\\\ &amp;L^{(i)}_n = \\beta L^{(i)}_{n-1} + \\mathrm{Flatten}(i;g_n) \\mathrm{Flatten}(i;g_n)^\\top\\\\ &amp;P^{(i)}_{t}=(L^{(i)}_n)^{-\\frac 1{2k}}\\\\ &amp;\\tilde{G}_n\\ \\ = P^{(i)}_{t} \\times_i \\tilde{G}_n\\\\ \\theta_{n} &amp;= \\theta_{n-1} - \\eta \\tilde{G}_n \\end{align*} \\] <p>\u6b64\u5916\uff0c\\(P^{(i)}_{t} \\times_i \\tilde{G}_n\\) \u7684\u610f\u601d\u662f mode-i product\uff0c\u4e5f\u5c31\u662f\u6cbf\u7740\u5f20\u91cf \\(\\tilde G_n\\) \u7684\u7b2c \\(i\\) \u7684\u7ef4\u5ea6\u53d6\u51fa\u5411\u91cf\u5206\u522b\u548c \\(P^{(i)}_{t}\\) \u76f8\u4e58\u7136\u540e\u653e\u56de\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u7b49\u4ef7\u4e8e\u5bf9 \\(\\tilde G_n\\) \u6cbf\u7740\u7b2c \\(i\\) \u4e2a\u7ef4\u5ea6\u5c55\u5e73\u4e4b\u540e\u518d\u6c42\u4e58\u79ef\u518d\u6298\u53e0\u3002\u6240\u4ee5\u4e5f\u53ef\u4ee5\u770b\u5230\u4e8c\u7ef4\u60c5\u51b5\u7684 \\(R\\) \u5728\u8fd9\u91cc\u6d88\u5931\u4e86\uff0c\u56e0\u4e3a\u6cbf\u7740\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u5c55\u5f00\u8ba1\u7b97\u76f8\u5f53\u4e8e\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u7684\u8f6c\u7f6e\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u7edf\u4e00\u8bb0\u53f7\u3002</p> <p>\u8fd9\u91cc\u4e0b\u6807\u51fa\u73b0\u4e86 \\(t\\) \u662f\u56e0\u4e3a\u8003\u8651\u5230\u53d6\u9006 $2k $ \u6b21\u6839\u7684\u590d\u6742\u6027\uff0c\u6211\u4eec\u4e0d\u5fc5\u6bcf\u4e00\u8f6e\u8fed\u4ee3\u90fd\u53bb\u8ba1\u7b97\u8fd9\u9884\u6761\u4ef6\u5b50 \\(P_{t}\\)\uff0c\u800c\u662f\u53ef\u4ee5\u9009\u62e9\u5728\u591a\u8f6e\u5468\u671f\u4e4b\u540e\u518d\u66f4\u65b0\u3002</p> <p>\u5f88\u9057\u61be\u7684\u662f\uff0c<code>torch_optimizer</code> \u5e93\u5b9e\u73b0\u7684 Shampoo \u4f18\u5316\u5668\u6162\u5230\u4e86\u51e0\u4e4e\u4e0d\u53ef\u7528\u7684\u6c34\u5e73\u3002\u600e\u4e48\u9ad8\u6548\u8ba1\u7b97\u8fd9\u4e2a\u6839\u5462\uff1f\u7b54\u6848\u8981\u7b49\u5230\u540e\u9762\u7684 Muon \u4f18\u5316\u5668\u4e86\u3002</p> <p>\u4e0b\u9762\u662f Shampoo \u4f18\u5316\u5668\u7684\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u6709\u4e86\u5bf9\u4e8c\u9636\u4fe1\u606f\u66f4\u7cbe\u786e\u7684\u4f30\u8ba1\uff0cShampoo \u7684\u6548\u679c\u4e0d\u8f93 Adam\u3002\u5728\u8c37\u5e95\u5904 Shampoo \u57fa\u672c\u4e0a\u6ca1\u6709\u4e86\u6a2a\u8df3\u73b0\u8c61\u3002\u4e0d\u8fc7\uff0c\u6211\u4eec\u80fd\u4e0d\u80fd\u628a\u53c2\u6570\u66f4\u65b0\u65b9\u5411\u518d\u4f18\u5316\u4e00\u4e0b\uff1f\u6b32\u77e5\u5982\u4f55\u4f18\u5316\uff0c\u4e14\u770b\u540e\u6587\u201c\u7b26\u53f7\u68af\u5ea6\u4e0b\u964d\u201d\u3002</p> <p>\u7531\u4e8e\u5e93\u5b9e\u73b0\u592a\u6162\u4e86\uff0c\u8dd1\u4e00\u4e2a batch \u5c31\u8981\u597d\u51e0\u79d2\uff0c\u8fd9\u91cc\u6c42\u9006\u6839\u91c7\u7528\u7684\u662f\u82cf\u5251\u6797\u8fd9\u4e2a\u535a\u5ba2\u63d0\u5230\u7684 Newton-Schulz \u8fed\u4ee3\uff0c\u5982\u679c\u770b\u4e0d\u660e\u767d\uff0c\u53ef\u4ee5\u5148\u53bb\u8bfb Muon \u90a3\u4e00\u7ae0\uff0c\u518d\u53bb\u8bfb\u8fd9\u4e2a\u535a\u5ba2\u5373\u53ef\u3002</p> <p></p> <p></p> <p>\u5c3d\u7ba1\u505a\u4e86\u4f18\u5316\uff0c\u8fd9\u4e2a\u7248\u672c\u7684 Shampoo \u4ecd\u7136\u8dd1\u5f97\u975e\u5e38\u6162\u4ee5\u81f3\u4e8e\u8dd1\u6ee1 P100 \u4e5f\u53ea\u80fd\u6709 5.6 it/s \u7684\u8bad\u7ec3\u901f\u5ea6\u3002\u5b83\u5728\u7b2c 6000 \u591a batch \u540e train_loss \u624d\u52c9\u5f3a\u6536\u655b\u5230 0.1\uff0c\u4e0d\u8fc7\u5012\u662f\u5728\u7b2c 1200 \u5de6\u53f3 batch \u5c31\u80fd\u8ba9 acc \u4e0a\u5347\u5230 0.9 \u4ee5\u4e0a\u3002\u4e0d\u8fc7\u635f\u5931\u5730\u5f62\u4e0a\u9762\u4f18\u5316\u5668\u5012\u662f\u51fa\u73b0\u4e86\u5947\u602a\u7684\u6a2a\u8df3\uff0c\u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u5b9e\u73b0\u7684\u95ee\u9898\uff0c\u611f\u89c9\u6ca1\u6709\u53d1\u6325\u51fa\u7406\u8bba\u7684\u6f5c\u529b\u554a\u2026\u2026</p>  Shampoo \u7684\u5b9e\u73b0\uff08Newton-Schulz \u8fed\u4ee3\u7248\uff09 <pre><code>import torch\nfrom torch.optim.optimizer import Optimizer\n\n# \u5bfc\u5165\u7c7b\u578b\u63d0\u793a\uff0c\u517c\u5bb9\u4e0d\u540c\u7248\u672c\u7684 PyTorch \u548c torch_optimizer\ntry:\n    from torch.optim.optimizer import Params, OptLossClosure, OptFloat\nexcept ImportError:\n    from torch_optimizer.types import Params, OptLossClosure, OptFloat\n\n# --- \u8fed\u4ee3\u6c42\u9006\u6839\u7b97\u6cd5\u7684\u9884\u8ba1\u7b97\u7cfb\u6570 ---\n# \u8fd9\u662f\u4e00\u4e2a\u786c\u7f16\u7801\u7684\u7cfb\u6570\u8868\uff0c\u7528\u4e8e\u4e0d\u540c\u9636\u6570 (r) \u7684\u77e9\u9635\u6c42\u9006\u6839\u7684\u591a\u9879\u5f0f\u8fd1\u4f3c\u3002\n# \u6bcf\u4e00\u884c\u5bf9\u5e94\u4e00\u4e2a r \u503c (r=1, 2, 3, ...)\u3002\n# \u6bcf\u4e2a\u5143\u7ec4 (a, b, c) \u662f\u591a\u9879\u5f0f p(x) = a + bx + cx^2 \u7684\u7cfb\u6570\u3002\n# \u8fd9\u662f\u7b97\u6cd5\u7684\u6838\u5fc3\u201c\u9ed1\u9b54\u6cd5\u201d\uff0c\u662f\u9884\u5148\u901a\u8fc7\u6570\u503c\u4f18\u5316\u5f97\u5230\u7684\u3002\ncoefs = [\n    None,  # r=0 \u65e0\u610f\u4e49\n    # r=1\n    [\n        (14.2975, -31.2203, 18.9214), (7.12258, -7.78207, 2.35989),\n        (6.9396, -7.61544, 2.3195), (5.98456, -6.77016, 2.12571),\n        (3.79109, -4.18664, 1.39555), (3, -3, 1),\n    ],\n    # r=2 (\u7528\u4e8e\u56db\u9636\u5f20\u91cf\uff0c\u5982\u5377\u79ef\u6838)\n    [\n        (7.42487, -18.3958, 12.8967), (3.48773, -2.33004, 0.440469),\n        (2.77661, -2.07064, 0.463023), (1.99131, -1.37394, 0.387593),\n        (15 / 8, -5 / 4, 3 / 8), # \u7406\u8bba\u6700\u4f18\u7cfb\u6570\n    ],\n    # r=3\n    [\n        (5.05052, -13.5427, 10.2579), (2.31728, -1.06581, 0.144441),\n        (1.79293, -0.913562, 0.186699), (1.56683, -0.786609, 0.220008),\n        (14 / 9, -7 / 9, 2 / 9),\n    ],\n    # r=4\n    [\n        (3.85003, -10.8539, 8.61893), (1.80992, -0.587778, 0.0647852),\n        (1.50394, -0.594516, 0.121161), (45 / 32, -9 / 16, 5 / 32),\n    ],\n    # r=5\n    [\n        (3.11194, -8.28217, 6.67716), (1.5752, -0.393327, 0.0380364),\n        (1.3736, -0.44661, 0.0911259), (33 / 25, -11 / 25, 3 / 25),\n    ],\n]\n\ndef abc(r=1, steps=None, scale=1):\n    \"\"\"\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u7528\u4e8e\u6309\u9700\u63d0\u4f9b\u4e0a\u8ff0\u7cfb\u6570\u3002\"\"\"\n    w, steps = coefs[r], steps or len(coefs[r])\n    # \u6309\u7167\u8fed\u4ee3\u6b65\u6570\u63d0\u4f9b\u7cfb\u6570\uff0c\u5982\u679c\u6b65\u6570\u8d85\u8fc7\u7cfb\u6570\u8868\u957f\u5ea6\uff0c\u5219\u91cd\u590d\u4f7f\u7528\u6700\u540e\u4e00\u4e2a\u7cfb\u6570\n    for a, b, c in w[:steps] + w[-1:] * max(steps - len(w), 0):\n        # \u6839\u636e\u7f29\u653e\u56e0\u5b50 scale \u5bf9\u7cfb\u6570\u8fdb\u884c\u8c03\u6574\n        yield a / scale, b / scale**(r + 1), c / scale**(2 * r + 1)\n\ndef _compute_inv_root_iterative(P: torch.Tensor, r: int, eps: float) -&gt; torch.Tensor:\n    \"\"\"\u4f7f\u7528\u8fed\u4ee3\u77e9\u9635\u4e58\u6cd5\u65b9\u6cd5\uff0c\u9ad8\u6548\u8ba1\u7b97 P^(-1/r)\u3002\"\"\"\n    s = 1  # \u8bba\u6587\u4e2d\u5b9a\u4e49\u7684\u5e38\u91cf\n    I = torch.eye(P.shape[0], dtype=P.dtype, device=P.device) # \u521b\u5efa\u5355\u4f4d\u77e9\u9635\n\n    # \u4e3a\u4e86\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u5bf9\u8f93\u5165\u77e9\u9635 P \u8fdb\u884c\u5f52\u4e00\u5316\n    t = torch.sqrt((P * P).sum()) # \u8ba1\u7b97 P \u7684 Frobenius \u8303\u6570\n    P_norm = P / t + eps * I # \u5f52\u4e00\u5316\u5e76\u52a0\u4e0a\u4e00\u4e2a\u5c0f\u7684\u6270\u52a8\u9879\n\n    G = I.clone() # G \u5c06\u4f1a\u662f\u6700\u7ec8\u7684 P^(-1/r)\n\n    # steps=None \u4f1a\u8ba9 abc \u4f7f\u7528\u8be5\u9636\u6570\u4e0b\u6240\u6709\u53ef\u7528\u7684\u7cfb\u6570\n    for a, b, c in abc(r, steps=None, scale=1.001): # scale &gt; 1.0 \u4fdd\u8bc1\u6536\u655b\n        # \u8ba1\u7b97\u591a\u9879\u5f0f W = a*I + b*P_norm + c*P_norm^2\n        W = a * I + b * P_norm + c * (P_norm @ P_norm)\n        # \u8fd9\u662f\u4e00\u4e2a\u8026\u5408\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u540c\u65f6\u66f4\u65b0 G \u548c P_norm\n        W1 = torch.linalg.matrix_power(W, s)\n        W2 = torch.linalg.matrix_power(W, r)\n        G = G @ W1\n        P_norm = P_norm @ W2\n\n    # \u6700\u540e\uff0c\u5bf9\u7ed3\u679c\u8fdb\u884c\u53cd\u5f52\u4e00\u5316\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u9006\u6839\u77e9\u9635\n    return G * (t ** (-s / r))\n\n\nclass Shampoo(Optimizer):\n    r\"\"\"\u5b9e\u73b0\u4e86 Shampoo \u4f18\u5316\u5668\u7b97\u6cd5\u3002\n\n    **\u6ce8\u610f**: \u8fd9\u4e2a\u7248\u672c\u88ab\u4fee\u6539\u4e3a\u4f7f\u7528\u4e00\u79cd\u5feb\u901f\u7684\u3001\u57fa\u4e8e\u8fed\u4ee3\u77e9\u9635\u4e58\u6cd5\u7684\u65b9\u6cd5\u6765\u8ba1\u7b97\u77e9\u9635\u7684\u9006\u6839\uff0c\n    \u800c\u4e0d\u662f\u539f\u59cb\u7684\u57fa\u4e8e SVD \u7684\u65b9\u6cd5\u3002\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Params,\n        lr: float = 1e-1,\n        momentum: float = 0.0,\n        weight_decay: float = 0.0,\n        epsilon: float = 1e-4,     # \u7528\u4e8e\u7a33\u5b9a\u9884\u5904\u7406\u5668 (preconditioner)\n        update_freq: int = 1,      # \u6bcf\u9694\u591a\u5c11\u6b65\u66f4\u65b0\u4e00\u6b21\u9006\u6839\u77e9\u9635\n        iter_eps: float = 1e-5,    # \u8fed\u4ee3\u6c42\u9006\u6839\u7b97\u6cd5\u4e2d\u7684\u6270\u52a8\u9879\n    ):\n        # --- \u8f93\u5165\u53c2\u6570\u5408\u6cd5\u6027\u68c0\u67e5 ---\n        if lr &lt;= 0.0:\n            raise ValueError('\u65e0\u6548\u7684\u5b66\u4e60\u7387: {}'.format(lr))\n        if momentum &lt; 0.0:\n            raise ValueError('\u65e0\u6548\u7684\u52a8\u91cf\u503c: {}'.format(momentum))\n        if weight_decay &lt; 0.0:\n            raise ValueError(\n                '\u65e0\u6548\u7684 weight_decay \u503c: {}'.format(weight_decay)\n            )\n        if epsilon &lt; 0.0:\n            raise ValueError('\u65e0\u6548\u7684 epsilon \u503c: {}'.format(epsilon))\n        if update_freq &lt; 1:\n            raise ValueError('\u65e0\u6548\u7684 update_freq \u503c: {}'.format(update_freq))\n        if iter_eps &lt; 0.0:\n            raise ValueError('\u65e0\u6548\u7684 iter_eps \u503c: {}'.format(iter_eps))\n\n        defaults = dict(\n            lr=lr,\n            momentum=momentum,\n            weight_decay=weight_decay,\n            epsilon=epsilon,\n            update_freq=update_freq,\n            iter_eps=iter_eps, \n        )\n        super(Shampoo, self).__init__(params, defaults)\n\n    def step(self, closure: OptLossClosure = None) -&gt; OptFloat:\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                order = grad.ndimension() # \u83b7\u53d6\u68af\u5ea6\u5f20\u91cf\u7684\u9636\u6570 (\u7ef4\u5ea6\u6570\u91cf)\n                original_size = grad.size()\n                state = self.state[p]\n                momentum = group['momentum']\n\n                # \u786e\u5b9a\u4f7f\u7528\u7684\u6c42\u9006\u6839\u7684\u9636\u6570 r\uff0c\u6700\u5927\u4e0d\u8d85\u8fc7\u7cfb\u6570\u8868\u4e2d\u5b9a\u4e49\u7684\u6700\u5927\u9636\u6570\n                inv_root_order = min(order, len(coefs) - 1)\n\n                # --- \u72b6\u6001\u521d\u59cb\u5316 ---\n                if len(state) == 0:\n                    state['step'] = 0\n                    if momentum &gt; 0:\n                        state['momentum_buffer'] = grad.clone()\n                    # \u4e3a\u5f20\u91cf\u7684\u6bcf\u4e2a\u7ef4\u5ea6\u521d\u59cb\u5316\u4e00\u4e2a\u9884\u5904\u7406\u5668 (preconditioner) \u77e9\u9635\n                    for dim_id, dim in enumerate(grad.size()):\n                        # precond_i \u662f\u7b2c i \u7ef4\u7684\u534f\u65b9\u5dee\u77e9\u9635\n                        state[f'precond_{dim_id}'] = group[\n                            'epsilon'\n                        ] * torch.eye(dim, dtype=grad.dtype, device=grad.device)\n                        # inv_precond_i \u662f\u5176\u5bf9\u5e94\u7684\u9006\u6839\u77e9\u9635\n                        state[\n                            f'inv_precond_{dim_id}'\n                        ] = torch.zeros_like(state[f'precond_{dim_id}'])\n\n                # 1. \u5e94\u7528\u52a8\u91cf (Momentum)\n                if momentum &gt; 0:\n                    if 'momentum_buffer' not in state:\n                         buf = state['momentum_buffer'] = grad.clone()\n                    else:\n                         buf = state['momentum_buffer']\n                         buf.mul_(momentum).add_(grad, alpha=1 - momentum)\n                    grad = buf # \u540e\u7eed\u64cd\u4f5c\u5728\u52a8\u91cf\u7f13\u51b2\u4e0a\u8fdb\u884c\n\n                # 2. \u5e94\u7528\u6743\u91cd\u8870\u51cf (Weight Decay)\n                if group['weight_decay'] &gt; 0:\n                    grad.add_(p.data, alpha=group['weight_decay'])\n\n                # --- \u6838\u5fc3\uff1a\u9010\u7ef4\u5ea6\u8fdb\u884c\u9884\u5904\u7406 ---\n                # \u904d\u5386\u5f20\u91cf\u7684\u6bcf\u4e00\u4e2a\u7ef4\u5ea6\n                for dim_id, dim in enumerate(grad.size()):\n                    precond = state[f'precond_{dim_id}']\n                    inv_precond = state[f'inv_precond_{dim_id}']\n\n                    # a. \u5c06\u5f53\u524d\u7ef4\u5ea6\u6362\u5230\u7b2c0\u7ef4\uff0c\u5e76\u5c06\u5176\u4ed6\u7ef4\u5ea6\u5c55\u5e73\n                    grad = grad.transpose_(0, dim_id).contiguous()\n                    transposed_size = grad.size()\n                    grad = grad.view(dim, -1)\n\n                    # b. \u66f4\u65b0\u9884\u5904\u7406\u5668 (\u534f\u65b9\u5dee\u77e9\u9635)\n                    # \u8fd9\u662f\u5728\u7d2f\u79ef\u4e8c\u9636\u77e9\u4fe1\u606f\n                    grad_t = grad.t()\n                    precond.add_(grad @ grad_t)\n\n                    # c. \u5b9a\u671f\u66f4\u65b0\u9006\u6839\u77e9\u9635 (\u8fd9\u662f\u8ba1\u7b97\u6210\u672c\u6700\u9ad8\u7684\u90e8\u5206)\n                    if state['step'] % group['update_freq'] == 0:\n                        inv_precond.copy_(_compute_inv_root_iterative(\n                            precond,\n                            r=inv_root_order, # \u4f7f\u7528\u4e0e\u5f20\u91cf\u9636\u6570\u5339\u914d\u7684\u6839\n                            eps=group['iter_eps']\n                        ))\n\n                    # d. \u4f7f\u7528\u9006\u6839\u77e9\u9635\u5bf9\u68af\u5ea6\u8fdb\u884c\u9884\u5904\u7406\n                    if dim_id == order - 1:\n                        # \u5bf9\u4e8e\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u9700\u8981\u53f3\u4e58\n                        grad = grad_t @ inv_precond\n                        grad = grad.view(original_size) # \u6062\u590d\u539f\u59cb\u5f62\u72b6\n                    else:\n                        # \u5bf9\u4e8e\u5176\u4ed6\u7ef4\u5ea6\uff0c\u5de6\u4e58\n                        grad = inv_precond @ grad\n                        grad = grad.view(transposed_size) # \u6062\u590d\u8f6c\u7f6e\u540e\u7684\u5f62\u72b6\n\n                state['step'] += 1\n                # 3. \u6700\u540e\u4e00\u6b65\uff1a\u7528\u6700\u7ec8\u5904\u7406\u8fc7\u7684\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\n                p.data.add_(grad, alpha=-group['lr'])\n\n        return loss\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 1, 2025). \u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6539\u8fdb\u7b56\u7565 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/optimizer/Adaptive</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{Adaptive,\n    title={\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6539\u8fdb\u7b56\u7565},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/optimizer/Adaptive}},\n}\n</code></pre></p>"}, {"location": "DNN/optimizer/SGD/", "title": "SGD \u7cfb\u5217\u7b97\u6cd5", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 27 \u5206\u949f\u3000|\u3000\u7ea6 3446 \u5b57\u3000|\u3000\u7ea6 107 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 77 \u884c\u4ee3\u7801</p>"}, {"location": "DNN/optimizer/SGD/#sgd_1", "title": "\u968f\u673a\u68af\u5ea6\u4e0b\u964d SGD", "text": "<p>\u6240\u6709\u7684SGD\u7406\u8bba\u8bb2\u89e3\u90fd\u4f1a\u4f7f\u7528\u4e0b\u5c71\u7684\u6bd4\u55bb\u3002\u6211\u4eec\u4e5f\u63a5\u7740\u6cbf\u7528\u3002\u8003\u8651\u6211\u4eec\u5728\u534a\u5c71\u8170\uff0c\u6d53\u96fe\u7b3c\u7f69\uff0c\u53ea\u80fd\u770b\u5230\u811a\u5e95\u4e00\u7247\u5730\u3002\u5982\u679c\u6211\u4eec\u8981\u5c3d\u53ef\u80fd\u5feb\u5730\u4e0b\u5c71\uff0c\u80af\u5b9a\u662f\u6cbf\u7740\u6700\u9661\u7684\u65b9\u5411\u5f80\u4e0b\u8d70\u3002</p> <p>\u8003\u8651\u6cdb\u51fd \\(\\mathcal{L(x; \\theta)}\\) \u662f\u5f53\u524d\u7684\u6a21\u578b \\(\\theta\\) \u5728\u67d0\u4e00\u8bad\u7ec3\u6570\u636e \\(x\\) \u4e0b\u7684\u635f\u5931\u5730\u5f62\u3002\u4ec0\u4e48\u5730\u65b9\u6700\u9661\u5462\uff1f\u5f53\u7136\u662f \\(\\nabla\\mathcal{L(x;\\theta)} = \\sum_{i=1}^{n} \\dfrac{\\partial\\mathcal{L(x;\\theta)}}{\\partial \\theta_i}\\vec{e}_i\\) \u4e5f\u5c31\u662f\u68af\u5ea6\u65b9\u5411\u4e86\u3002\u8bc1\u660e\u4e5f\u5f88\u7b80\u5355\uff0c\u7531\u4e8e\u5404\u4e2a\u5206\u91cf \\(\\vec{e}_i\\) \u6b63\u4ea4\uff0c\u8ba9\u6bcf\u4e2a\u65b9\u5411\u90fd\u671d\u81ea\u5df1\u7684\u65b9\u5411\u53d8\u5316\u5c31\u53ef\u4ee5\u53e0\u52a0\u51fa\u6700\u5927\u7684\u53d8\u5316\u7387\u3002</p> <p>\u4f46\u662f\u6211\u4eec\u4e0d\u80fd\u5149\u770b\u4e00\u4e2a\u6570\u636e\uff0c\u90a3\u6837\u7684\u8bdd\u9488\u5bf9\u6027\u8fc7\u5f3a\u4e86\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u90a3\u600e\u4e48\u529e\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u4e00\u6b21\u6027\u53d6\u591a\u4e2a\u6570\u636e\uff0c\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u5728\u8bad\u7ec3\u96c6\u91cc\u9762\u968f\u673a\u53d6 \\(|\\mathcal{B}|\\) \u4e2a\u6570\u636e\uff0c\u79f0\u4f5c\u4e00\u4e2a Batch\uff08\u6279\u91cf\uff09\uff0c\u5728\u8fd9\u4e2a Batch \u4e0b\u9762\u6211\u4eec\u8ba1\u7b97\u5e73\u5747\u68af\u5ea6 \\(\\dfrac{1}{|\\mathcal{B}|}\\sum_{i=1}^{|\\mathcal{B}|} \\nabla\\mathcal{L}(x_i;\\theta)\\)\uff0c\u4f5c\u4e3a\u201c\u6700\u9661\u201d\u65b9\u5411\u7684\u53c2\u8003\u3002</p> <p>\u4e0b\u9762\u7684\u95ee\u9898\u5c31\u662f\u5f80\u8fd9\u4e2a\u65b9\u5411\u8d70\u591a\u8fdc\u7684\u95ee\u9898\u4e86\u3002\u8fd9\u662f\u4e00\u4e2a\u6211\u4eec\u53ef\u4ee5\u8c03\u6574\u7684\u8d85\u53c2\u6570\uff0c\u5927\u4e86\uff0c\u8d70\u5f97\u66f4\u5feb\uff0c\u4f46\u662f\u5bb9\u6613\u9707\u8361\uff1b\u5c0f\u4e86\uff0c\u6536\u655b\u53c8\u592a\u6162\u3002\uff08\u6b64\u5904\u57cb\u4e00\u4e2a\u4f0f\u7b14\uff0c\u563b\u563b\uff09\u8fd9\u4e2a\u8d85\u53c2\u6570\u53eb\u505a\u5b66\u4e60\u7387\uff0c\u7528\u6765\u8868\u5f81\u5f53\u524d\u7684\u68af\u5ea6\u5bf9\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u66f4\u65b0\u7684\u53c2\u8003\u4ef7\u503c\u3002</p> <p>\u73b0\u5728\u5c31\u53ef\u4ee5\u796d\u51fa\u6211\u4eec\u7684 mini-batch SGD \u7b97\u6cd5\u4e86\uff01\u5bf9\u4e8e\u6570\u636e\u96c6 \\(X\\) \u800c\u8a00\uff0c\u6bcf\u6b21\u968f\u673a\u62bd\u53d6 \\(|\\mathcal{B}|\\) \u6761\u6570\u636e \\(x\\)\u3002\u8ba1\u7b97\u4e0a\u4e00\u4ee3\u6a21\u578b \\(\\theta_{n-1}\\) \u7684\u66f4\u65b0\u6b65\u957f</p> \\[ \\begin{align*}     \\Delta \\theta &amp;= -\\dfrac{\\eta}{|\\mathcal{B}|}\\sum^{|\\mathcal{B}|}_{i=1}\\nabla\\mathcal{L}(x_i;\\theta_{n-1})\\\\     \\theta_n &amp;= \\theta_{n-1}+\\Delta \\theta \\end{align*} \\] <p>\u8fd9\u91cc\u52a0\u8d1f\u53f7\u610f\u601d\u662f\u201c\u4e0b\u964d\u201d\u3002</p> <p>\u8fd9\u6837\u4e0d\u4ec5\u4f7f\u7528\u7684\u5e73\u5747\u68af\u5ea6\uff0c\u53c2\u8003\u4ef7\u503c\u8f83\u5f3a\uff08\u800c\u4e14\u5982\u679c batch size \u66f4\u5927\uff0c\u5bf9\u539f\u6709\u6570\u636e\u96c6\u5206\u5e03\u7684\u4f30\u8ba1\u5c31\u66f4\u597d\uff09\uff0c\u66f4\u8d5e\u7684\u662f\u4e00\u4e2a Batch \u91cc\u9762\u6240\u6709\u68af\u5ea6\u7684\u8ba1\u7b97\u90fd\u662f\u72ec\u7acb\u7684\uff0c\u6240\u4ee5\u5929\u751f\u9002\u5408\u5229\u7528 GPU \u8fdb\u884c\u9ad8\u5ea6\u5e76\u884c\u5316\u7684\u8ba1\u7b97\uff01</p> <p>\u4e0b\u9762\u6211\u4eec\u6765\u8bc4\u4f30\u4e00\u4e0b\u8fd9\u4e2a mini-batch SGD \u7b97\u6cd5\u3002</p> <ul> <li>\u6536\u655b\u901f\u7387\u4e0a\uff0c\u5bf9\u4e8e\u68af\u5ea6\u5927\u7684\u65b9\u5411\u6536\u655b\u5feb\uff0c\u68af\u5ea6\u5c0f\u7684\u65b9\u5411\u6536\u655b\u6162\u3002\u5982\u679c\u8bf4\u635f\u5931\u5730\u5f62\u7684\u6700\u4f4e\u70b9\u56db\u5468\u90fd\u662f\u5f88\u9661\u7684\u659c\u5761\uff0c\u90a3\u5f88\u597d\uff0c\u4f46\u5b58\u5728\u8fd9\u79cd\u6df7\u5408\u60c5\u51b5\uff1a\u8003\u8651\u4e00\u4e2a\u5f00\u53e3\u5411\u4e0a\u7684\u692d\u5706\u629b\u7269\u9762\uff0c\u5e76\u5047\u8bbe\u6211\u4eec\u521d\u59cb\u70b9\u5728\u692d\u5706\u957f\u8f74\u7aef\u70b9\u9644\u8fd1\uff0c\u8fd9\u6837\u68af\u5ea6\u65b9\u5411\u8fd1\u4f3c\u548c\u77ed\u8f74\u65b9\u5411\u5e73\u884c\uff0c\u6a21\u578b\u5c31\u4e00\u76f4\u5728\u524d\u540e\u6a2a\u8df3\uff0c\u771f\u6b63\u5411\u4e0b\u79fb\u52a8\uff08\u957f\u8f74\u5206\u91cf\uff09\u5f88\u5c11\u3002\u4e8b\u5b9e\u4e0a\u8fd9\u79cd\u60c5\u51b5\u5bf9\u5e94\u7684\u662f\u4e00\u4e2a\u6761\u4ef6\u6570\u5f88\u5927\u7684\u6d77\u68ee\u77e9\u9635\uff0c\u76f8\u5173\u5206\u6790\u53c2\u8003\u540e\u6587\u3002</li> <li>\u5bfb\u627e\u5168\u5c40\u6700\u5c0f\u503c\u7684\u80fd\u529b\uff1a\u5728\u4e00\u4e2a\u5e73\u7f13\u7684\u978d\u70b9\u5904\u7b97\u6cd5\u8868\u73b0\u5f97\u5f88\u201c\u61d2\u201d\uff0c\u9664\u975e\u628a\u5b66\u4e60\u7387\u8c03\u5927\uff0c\u4f46\u662f\u8fc7\u5927\u7684\u5b66\u4e60\u7387\u4f1a\u5bfc\u81f4\u635f\u5931\u4e0d\u6536\u655b\u3002</li> <li>\u5c0f\u5b66\u4e60\u7387\u5f53\u7136\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u7a33\u5b9a\u3002\u4f46\u662f\u8fd8\u662f\u90a3\u4e2a\u8001\u751f\u5e38\u8c08\u7684\u95ee\u9898\u2026\u2026</li> </ul> <p>\u4e3a\u4e86\u66f4\u76f4\u89c2\u5730\u7406\u89e3 SGD \u7684\u8fc7\u7a0b\u548c\u7f3a\u9677\uff0c\u6211\u5236\u4f5c\u4e86\u4e24\u4e2a\u52a8\u56fe\uff0c\u5b83\u4eec\u662f SGD \u5728\u4e24\u4e2a\u4e8c\u5143\u51fd\u6570\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u4e0b\u7684\u8fd0\u52a8\u8f68\u8ff9\u3002\u7b2c\u4e00\u4e2a\u53eb\u505a rosenbrock\uff0c\u89e3\u6790\u5f0f\u4e3a</p> \\[ z=(1 - x)^2 + 100  (y - x^2)^2 \\] <p>\u5b83\u4f53\u73b0\u4e3a\u4e00\u4e2a\u9999\u8549\u72b6\u5f2f\u66f2\u7684\u5ce1\u8c37\u5730\u5f62\uff0c\u53ef\u4ee5\u7528\u6765\u89c2\u5bdf\u4f18\u5316\u5668\u5728\u9762\u5bf9\u6761\u4ef6\u6570\u5927\u7684\u6d77\u68ee\u77e9\u9635\u91c7\u7528\u7684\u7b56\u7565\u3002</p> <p>\u7b2c\u4e8c\u4e2a\u53eb\u505a rastrigin\uff0c\u89e3\u6790\u5f0f\u4e3a</p> \\[ \\begin{align*}     A &amp;= 10\\\\     z &amp;= 2A+ (x^2 - A\\cos(2\\pi x))+ (y^2 - A\\cos(2\\pi y)) \\end{align*} \\] <p>\u5b83\u4f53\u73b0\u4e3a\u4e00\u4e2a\u9e21\u86cb\u6258\u5730\u5f62\uff0c\u5177\u6709\u5f88\u591a\u5c40\u90e8\u6781\u5c0f\u503c\u548c\u978d\u70b9\u3002</p> <p>\u8fd9\u662f SGD \u5728 rosenbrock \u51fd\u6570\u4e0b\u7684\u8868\u73b0\uff1a</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u786e\u5b9e\u51fa\u73b0\u4e86\u8fd9\u79cd\u201c\u53cd\u590d\u6a2a\u8df3\u201d\u3002</p> <p>\u8fd9\u662f SGD \u5728 rastrigin \u51fd\u6570\u4e0b\u7684\u8868\u73b0\uff1a</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u5b83\u786e\u5b9e\u53d8\u5f97\u5f88\u201c\u61d2\u201d\uff0c\u9677\u5165\u79bb\u521d\u59cb\u70b9\u6700\u8fd1\u7684\u5c40\u90e8\u6700\u5c0f\u503c\u4e86\u3002</p> <p>\u6211\u4e5f\u5728 Fashion-MNIST \u4e0a\u9762\u5229\u7528 SGD \u4f18\u5316\u4e86\u4e00\u4e2a CNN\uff0c\u8fd9\u662f\u5176\u635f\u5931\u66f2\u7ebf\u548c\u635f\u5931\u5730\u5f62\u4e0b\u7684\u4f18\u5316\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u6536\u655b\u901f\u5ea6\u4e0a\uff0c\u5927\u6982\u5728\u7b2c 4500 \u4e2a batch \u4e0b\u7684 train_loss \u80fd\u591f\u964d\u5230 0.1 \u7684\u91cf\u7ea7\uff0c\u5e76\u5728\u7b2c 1000 \u4e2a batch \u4e0b\u9762 acc \u80fd\u57fa\u672c\u4e0a\u7a33\u5b9a\u6536\u655b\u5230 0.9 \u4ee5\u4e0a\u3002\u6700\u7ec8\u5f97\u5230\u7684\u6700\u4f18\u89e3\u9644\u8fd1\u7684\u635f\u5931\u5730\u5f62\u7c7b\u4f3c\u4e00\u4e2a\u5177\u6709\u4e00\u5b9a\u6761\u4ef6\u6570\u7684\u6d77\u68ee\u77e9\u9635\uff08\u540e\u9762\u4f1a\u8bb2\u5230\uff09\uff0c\u5e76\u4e14\u76f8\u5bf9\u5e73\u5766\u3002</p>"}, {"location": "DNN/optimizer/SGD/#sgdm", "title": "\u52a8\u91cf\u6cd5\u968f\u673a\u68af\u5ea6\u4e0b\u964d SGDM", "text": ""}, {"location": "DNN/optimizer/SGD/#_1", "title": "\u52a8\u91cf\u7684\u5f15\u5165", "text": "<p>\u4eba\u5f80\u9ad8\u5904\u8d70\uff0c\u6c34\u5f80\u4f4e\u5904\u6d41\u3002\u6211\u4eec\u53ef\u4ee5\u611f\u6027\u4f53\u4f1a\u4e00\u4e0b\uff0c\u76f8\u6bd4\u5176\u6211\u4eec\u6839\u636e\u5761\u5ea6\uff08\u68af\u5ea6\uff09\u5c0f\u5fc3\u7ffc\u7ffc\u5730\u4e0b\u5c71\uff0c\u4ece\u5c71\u9876\u6eda\u843d\u7684\u5de8\u77f3\u4f3c\u4e4e\u80fd\u6bd4\u6211\u4eec\u66f4\u5feb\u4e14\u66f4\u597d\u5730\u627e\u5230\u771f\u6b63\u8c37\u5e95\u7684\u4f4d\u7f6e\u3002</p> <p>\u8ba9\u6211\u4eec\u5bf9\u8fd9\u5757\u77f3\u5934\u8fdb\u884c\u5efa\u6a21\u3002\u8003\u8651\u4e00\u4e2a\u5355\u4f4d\u7269\u4f53\u5728\u52bf\u573a \\(U\\) \u4e2d\u505a\u5e26\u963b\u5c3c\u7684\u81ea\u7531\u8fd0\u52a8\u3002\uff08\u5e26\u963b\u5c3c\u662f\u4e3a\u4e86\u8ba9\u7269\u4f53\u7684\u52a8\u80fd\u8017\u6563\uff0c\u4ee5\u505c\u6b62\u5728\u6700\u5c0f\u503c\uff09\u90a3\u4e48\u5b83\u6240\u53d7\u68af\u5ea6\u529b \\(F=-\\nabla U\\)\uff0c\u5373 \\(ma = -\\nabla U\\)\u3002\u53d6\u65f6\u95f4\u5fae\u5143 \\(\\beta_3\\)\uff0c\u5219\u901f\u5ea6\u66f4\u65b0\u4e3a \\(-v_{n+1} = -\\beta_1v_n - \\beta_3 a = -\\beta_1v_n - \\beta_3\\dfrac{\\nabla U}{m}\\)\uff0c\u5176\u4e2d \\(\\beta_1&lt;1\\) \u8868\u5f81\u963b\u5c3c\u635f\u8017\uff0c\u4f4d\u7f6e\u66f4\u65b0\u4e3a \\(\\theta_{n+1} = \\theta_n - \\beta_3v_n\\)\u3002\u4e8b\u5b9e\u4e0a\u8fd9\u91cc \\(m\\) \u8868\u5f81\u60ef\u6027\u7684\u5927\u5c0f\uff0c\u60ef\u6027\u5927\uff0c\u4e0d\u6613\u53d7\u529b\u79fb\u52a8\uff1b\u60ef\u6027\u5c0f\uff0c\u5bb9\u6613\u5f80\u4e0b\u79fb\u52a8\u3002\u8fd9\u4e5f\u4f53\u73b0\u51fa\u5b66\u4e60\u7387\u7684\u4e00\u70b9\u6027\u8d28\u3002\u5728\u66f4\u65b0\u6743\u91cd\u7684\u65f6\u5019\u6211\u4eec\u53ef\u4ee5\u628a\u65f6\u95f4\u6b65\u957f\u548c\u8d28\u91cf\u4e24\u4e2a\u53c2\u91cf\u7edf\u4e00\u8003\u8651\u6210\u5b66\u4e60\u7387 \\(\\eta\\)\u3002\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u628a\u8d28\u91cf\u4e58\u4e0a\u53bb\uff0c\u4e5f\u5c31\u662f\u8003\u8651\u52a8\u91cf\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_{n}&amp;=\\beta_1M_{n-1}+\\beta_3g_n\\\\     \\theta_n&amp;=\\theta_{n-1}-\\eta M_n \\end{align*} \\] <p>\uff08\u82e5\u4e0d\u505a\u7279\u6b8a\u8bf4\u660e\uff0c\\(\\nabla\\mathcal{L({x};\\theta_{n-1})}\\) \u4e00\u6982\u6307\u4e00\u4e2a mini-batch \u7684\u5e73\u5747\u68af\u5ea6\u5373 \\(\\dfrac{1}{|\\mathcal{B}|}\\sum^{|\\mathcal{B}|}_{i=1}\\nabla\\mathcal{L}(x_i;\\theta_{n-1})\\)\uff09</p> <p>\u8fd9\u6837\u5c31\u5f97\u5230\u4e86\u52a8\u91cf\u6cd5\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u5373 SGD with Momentum \u6216 SGDM \u7b97\u6cd5\u4e86\u3002\u5f0f\u5b50\u91cc\u9762\u7684 \\(\\beta_1\\) \u6307\u7684\u662f\u52a8\u91cf\u8870\u51cf\u56e0\u5b50\uff0c\u53ef\u4ee5\u7406\u89e3\u6210\u67d0\u79cd\u6469\u64e6\u963b\u529b\uff0c\u8981\u4e0d\u7136\u5c31\u4f1a\u4e00\u76f4\u5728\u6781\u5c0f\u503c\u5468\u56f4\u505a\uff08\u8fd1\u4f3c\uff09\u7684\u692d\u5706\u5929\u4f53\u8fd0\u52a8\u4e0d\u6536\u655b\uff0c \\(\\beta_3\\) \u662f\u68af\u5ea6\u7684\u53c2\u8003\u7cfb\u6570\uff0c\u800c \\(\\eta\\) \u5c31\u662f\u5b66\u4e60\u7387\u4e86\u3002</p> <p>\u8fd9\u662f\u52a8\u91cf\u6cd5\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u5728\u4e4b\u524d\u4e24\u4e2a\u51fd\u6570\u7684\u8fd0\u52a8\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u89c1\u5728\u7b97\u6cd5\u521d\u671f\uff0cSGDM \u7684\u6b65\u957f\u8f83\u957f\uff08\u56e0\u4e3a\u7d2f\u79ef\u7684\u52a8\u91cf\u8f83\u5927\uff09\uff0c\u8fd9\u6709\u5229\u4e8e\u589e\u5927\u641c\u7d22\u7a7a\u95f4\uff0c\u76f4\u5230\u8fdb\u5165\u4e00\u4e2a\u5e73\u7f13\u7684\u8c37\u5e95\u4e4b\u540e\uff0c\u52a8\u91cf\u5f00\u59cb\u8870\u51cf\u5e76\u4e14\u5411\u6700\u5c0f\u503c\u9760\u8fd1\u3002</p> <p>\u4e0b\u9762\u770b\u770b SGDM \u5728 Fashion-MNIST \u4e0b\u9762\u7684\u8868\u73b0\uff1a</p> <p></p> <p></p> <p>SGDM \u5728\u7ea6 4000 \u4e2a Batch \u540e train_loss \u6536\u655b\u5230 0.1 \u91cf\u7ea7\uff0c\u7ea6 1000 \u4e2a Batch \u540e acc \u6536\u655b\u5230 0.9 \u4ee5\u4e0a\u3002\u635f\u5931\u5730\u5f62\u5e73\u7f13\u3002\u76f8\u6bd4\u4e8e SGD \u53ef\u89c1\u6709\u66f4\u9ad8\u7684\u6536\u655b\u901f\u5ea6\u3002</p>"}, {"location": "DNN/optimizer/SGD/#nesterov-nag", "title": "Nesterov \u52a0\u901f\u68af\u5ea6\uff08NAG\uff09", "text": "<p>\u5982\u679c\u628a\u521a\u521a SGDM \u7684\u5f0f\u5b50\u5c55\u5f00\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\eta (\\beta_1M_{n-1}+\\beta_3g_n)\\\\     &amp;=\\theta_{n-1}-\\eta \\beta_1M_{n-1}-\\eta\\beta_3g_n \\end{align*} \\] <p>\u53ef\u4ee5\u770b\u5230\u5176\u5b9e\u6211\u4eec\u5bf9\u53c2\u6570\u8fdb\u884c\u4e86\u4e24\u6b65\u66f4\u65b0\uff0c\u800c\u7b2c\u4e8c\u6b65\u66f4\u65b0\u4f7f\u7528\u7684\u68af\u5ea6\u5374\u662f\u66f4\u65b0\u524d\u53c2\u6570\u7684\u68af\u5ea6\u3002\u5982\u679c\u6211\u4eec\u8003\u8651\u8ba9\u7b2c\u4e8c\u6b65\u66f4\u65b0\u4f7f\u7528\u7684\u68af\u5ea6\u662f\u7b2c\u4e00\u6b65\u66f4\u65b0\u540e\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u4e5f\u5c31\u662f\u8ba9 \\(g'_n=\\nabla\\mathcal{L}({x};\\theta_{n-1}-\\eta \\beta_1M_{n-1})\\)\uff0c\u5c31\u5f97\u5230\u4e86 Nesterov \u52a0\u901f\u4f18\u5316\u540e\u7684 SGDM\u3002</p> <p>\u867d\u7136\u7f51\u4e0a99%\u5bf9\u8fd9\u4e2a\u7684\u8bb2\u89e3\u90fd\u662f\u505c\u7559\u5728\u8fd9\u91cc\u5c31\u5b8c\u4e86\uff0c\u4f46\u662f\u6211\u4eec\u5f88\u96be\u5bf9 \\(\\theta_{n-1}-\\eta \\beta_1M_{n-1}\\) \u8fd9\u4e2a\u524d\u77bb\u4f4d\u7f6e\u7684\u53c2\u6570\u76f4\u63a5\u6c42\u4e00\u6b21\u68af\u5ea6\u3002\u4e3a\u4ec0\u4e48\uff1f\u56e0\u4e3a\u6211\u4eec\u6700\u540e\u8981\u5728\u4ee3\u7801\u91cc\u9762\u4f7f\u7528 <code>loss.backward()</code> \u628a\u68af\u5ea6\u6c42\u51fa\u6765\uff0c\u4f46\u662f\u8fd9\u4e2a\u68af\u5ea6\u4e0d\u662f\u524d\u77bb\u4f4d\u7f6e\u7684\u68af\u5ea6\uff0c\u8fd9\u4e0d\u5c31\u5e9f\u4e86\u5417\uff0c\u8bf4\u597d\u7684\u52a0\u901f\uff0c\u8ba1\u7b97\u91cf\u53cd\u5012\u7ffb\u500d\u4e86\u2026\u2026</p> <p>\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5bfb\u627e\u65e0\u9700\u8fdb\u884c\u524d\u77bb\u4f4d\u7f6e\u68af\u5ea6\u8ba1\u7b97\u7684\u7b49\u6548\u5f62\u5f0f\u3002</p>"}, {"location": "DNN/optimizer/SGD/#_2", "title": "\u8fdb\u9636\u63a8\u5bfc", "text": "<p>\u4e3a\u7b80\u4fbf\u8d77\u89c1\uff0c\u4e0b\u9762\u7684\u63a8\u5bfc\u7edf\u4e00\u8bbe \\(\\beta_3=1\\)\u3002</p> <p>\u8ba9\u6211\u4eec\u4ece</p> \\[ \\theta_n=\\theta_{n-1}-\\eta \\beta_1M_{n-1}-\\eta g'_n \\] <p>\u5165\u624b\uff08\u5176\u4e2d \\(g'_n=\\nabla\\mathcal{L}({x};\\theta_{n-1}-\\eta \\beta_1M_{n-1})\\)\uff09\uff0c\u4e3a\u4e86\u8ba9\u8fd9\u4e2a \\(g'_n\\) \u80fd\u591f\u8f83\u597d\u5730\u88ab\u5206\u79bb\u51fa\u53bb\uff0c\u9996\u5148\u5728\u5de6\u53f3\u4e24\u8fb9\u914d\u4e0a\u4e00\u4e2a \\(-\\eta \\beta_1M_n\\)\uff0c\u6709\u70b9\u7c7b\u4f3c\u4e8e\u53bb\u627e\u524d\u77bb\u4f4d\u7f6e\u3002\u7136\u540e\uff1a</p> \\[ \\begin{align*}     \\theta_n-\\eta\\beta_1M_n&amp;=\\theta_{n-1}-\\eta(1+\\beta_1)M_n\\\\     &amp;=\\theta_{n-1}-\\eta(1+\\beta_1)(\\beta_1M_{n-1}+g'_n)\\\\     &amp;=(\\theta_{n-1}-\\eta\\beta_1M_{n-1})-\\eta[(1+\\beta_1)g'_n+\\beta_1^2M_{n-1}] \\end{align*} \\] <p>\u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e2a\u4ee3\u6362\uff1a</p> \\[ \\begin{align*}     \\hat\\theta_n&amp;=\\theta_n-\\eta\\beta_1M_n\\\\     \\hat M_n &amp;= (1+\\beta_1)g'_n+\\beta_1^2M_{n-1} \\end{align*} \\] <p>\u8fd9\u6837\u5c31\u6709\u4e86</p> \\[ \\hat\\theta_n=\\hat\\theta_{n-1}-\\eta\\hat M_n \\] <p>\u5e76\u4e14\u5faa\u73af\u5e26\u5165 \\(M_n\\) \u7684\u5b9a\u4e49\u5f0f\u5c55\u5f00 \\(\\hat M_n\\)\uff1a</p> \\[ \\begin{align*}     \\hat M_n &amp;= (1+\\beta_1)g'_n+\\beta_1^2M_{n-1}\\\\     &amp;=(1+\\beta_1)g'_n+\\beta_1^2g'_{n-1}+\\beta_1^3g'_{n-2}+\\cdots \\end{align*} \\] <p>\u5229\u7528\u9ad8\u4e2d\u5c31\u5b66\u8fc7\u7684\u9519\u4f4d\u76f8\u51cf\uff08\u8ba9 \\(\\hat M_n\\) \u548c  \\(\\beta\\hat M_{n-1}\\) \u76f8\u51cf\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 \\(\\hat M_n\\) \u7684\u9012\u63a8\u5f0f\uff1a</p> \\[ \\hat M_n = \\beta_1\\hat M_{n-1}+g'_n+\\beta_1(g'_n-g'_{n-1}) \\] <p>\u6574\u7406\u4e00\u4e0b\u6211\u4eec\u5f97\u5230\u9012\u63a8\u516c\u5f0f\uff1a</p> \\[ \\begin{align*}     g'_n&amp;=\\nabla\\mathcal{L({x};\\hat\\theta_{n-1})}\\\\     \\hat M_{n}&amp;=\\beta_1\\hat M_{n-1}+g'_n+\\beta_1(g'_n-g'_{n-1})\\\\     \\hat\\theta_n&amp;=\\hat\\theta_{n-1}-\\eta\\hat M_n \\end{align*} \\] <p>\u7531\u4e8e\u521d\u59cb\u65f6\u7684 Nesterov \u4fee\u6b63\u9879\u662f \\(0\\)\uff0c\u8fd9\u4e2a\u9012\u63a8\u5f0f\u53ef\u4ee5\u4fdd\u8bc1\u4e0e\u539f\u6765\u7684\u5f62\u5f0f\u5b8c\u5168\u7b49\u6548\u3002</p> <p>\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\uff0c\u5373\u4f7f\u8fd9\u4e2a \\(g_n\\) \u53d6\u5230\u539f\u6765\u7684\u68af\u5ea6\uff0c\u4e5f\u80fd\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff08\u4e24\u6b21\u8fed\u4ee3\u7684\u68af\u5ea6\u4e4b\u5dee\uff09\u6765\u5f97\u5230 Nesterov \u52a0\u901f\u7b49\u6548\u7684\u7ed3\u679c\u3002</p> <p>\u4f46\u662f\u8fd9\u6837\u505a\u8981\u6211\u4eec\u4fdd\u5b58\u4e24\u4efd\u68af\u5ea6\uff0c\u6709\u6ca1\u6709\u66f4\u7701\u663e\u5b58\u7684\u505a\u6cd5\u5462\uff1f\u6709\u7684\u3002</p> <p>\u8fd8\u662f\u4e00\u4e2a\u548c\u9ad8\u4e2d\u6570\u5217\u9898\u5f88\u50cf\u7684\u601d\u8def\uff0c\u6211\u4eec\u628a\u5728 \\(\\hat M_n\\) \u7684\u8ba1\u7b97\u4e2d\u957f\u5f97\u6bd4\u8f83\u50cf\u7684\u62c9\u5230\u4e00\u8fb9\u53bb\uff1a</p> \\[ \\begin{align*}     \\hat M_n - g'_n &amp;= \\beta_1 g'_n + \\beta_1(\\hat M_{n-1} - g'_{n-1})\\\\     \\dfrac{\\hat M_n - g'_n}{\\beta_1}&amp;=g'_n + (\\hat M_{n-1} - g'_{n-1}) \\end{align*} \\] <p>\u8fd9\u91cc\u6709\u4e00\u4e2a\u5206\u6bcd \\(\\beta_1\\) \u4e0d\u597d\u770b\uff0c\u6211\u4eec\u505a\u4ee3\u6362 \\(\\beta_1\\tilde M_n = \\hat M_n - g'_n\\)\uff0c\u5c31\u6709\uff1a</p> \\[ \\tilde M_n=g'_n+\\beta_1\\tilde M_{n-1} \\] <p>\u6574\u7406\u4e00\u4e0b\u6211\u4eec\u5f97\u5230\u9012\u63a8\u516c\u5f0f\uff1a</p> \\[ \\begin{align*}     g'_n&amp;=\\nabla\\mathcal{L({x};\\hat\\theta_{n-1})}\\\\     \\tilde M_n&amp;=g'_n+\\beta_1\\tilde M_{n-1}\\\\     \\hat\\theta_n&amp;=\\hat\\theta_{n-1}-\\eta(\\beta_1\\tilde M_n+ g'_n) \\end{align*} \\] <p>\u7531\u4e8e\u6211\u4eec\u5728\u6574\u4e2a\u53d8\u6362\u8fc7\u7a0b\u4e2d\u53ea\u662f\u4f7f\u7528\u4e86\u53d8\u91cf\u4ee3\u6362\uff0c\u548c\u4e00\u5f00\u59cb\u7684 Nesterov \u52a0\u901f\u6cd5\u662f\u7b49\u6548\u7684\uff0c\u6240\u4ee5\u5bf9\u4e8e\u8fd9\u4e2a\u5f0f\u5b50\u800c\u8a00\uff0c\u6211\u4eec\u5b8c\u5168\u53ef\u4ee5\u8fd9\u6837\u5199\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x};\\theta_{n-1})}\\\\     M_n&amp;=g_n+\\beta_1M_{n-1}\\\\     \\theta_n&amp;=\\theta_{n-1}-\\eta(\\beta_1 M_n+ g_n) \\end{align*} \\] <p>\u8fd9\u6837\u5bf9 Nesterov \u52a0\u901f\u7684\u5b9e\u73b0\u5c31\u975e\u5e38\u7b80\u5355\u4e86\uff01\u53ea\u9700\u8981\u628a\u6743\u91cd\u66f4\u65b0\u9879\u4ece \\(\\eta M_n\\) \u6362\u6210 \\(\\eta(\\beta_1 M_n+ g_n)\\) \u5373\u53ef\u3002</p> <p>\u5f53\u7136\u6709\u7684\u5b9e\u73b0\u4f1a\u8003\u8651 \\(\\beta_3=(1-\\beta_1)\\)\uff0c\u8fd9\u4e2a\u65f6\u5019\u6743\u91cd\u66f4\u65b0\u9879\u5c31\u53d8\u6210\u4e86 \\(\\eta[\\beta_1 M_n+ (1-\\beta_1)g_n]\\)\u3002</p>"}, {"location": "DNN/optimizer/SGD/#_3", "title": "\u8bc4\u8ff0", "text": "<p>\u8ba9\u6211\u4eec\u770b\u770b NAG \u7684\u8f68\u8ff9\uff1a</p> <p></p> <p></p> <p>\u4e0b\u9762\u662f NAG \u5728 Fashion-MNIST \u4e0b\u9762\u7684\u8868\u73b0\uff1a</p> <p></p> <p></p> <p>\u5bf9\u6bd4\u4e00\u4e0b\u53ef\u4ee5\u53d1\u73b0 NAG \u548c\u6734\u7d20\u7684 SGDW \u6548\u679c\u6709\u63d0\u5347\uff0c\u4f46\u662f\u63d0\u5347\u4e0d\u5927\u3002</p> <p>SGDM \u80fd\u591f\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u7387\uff0c\u5c24\u5176\u5bf9\u4e8e\u68af\u5ea6\u4e0d\u5bf9\u79f0\u573a\u666f\u4e0b\uff0c\u80fd\u591f\u5b9e\u73b0\u5747\u8861\u7684\u68af\u5ea6\u7d2f\u79ef\uff0c\u5373\u51cf\u7f13\u524d\u540e\u6a2a\u8df3\uff0c\u52a0\u901f\u5411\u4e0b\u6eda\u52a8\u3002\u52a8\u91cf\u5c45\u529f\u81f3\u4f1f\u3002\u5c24\u5176\u662f\u5f15\u5165 Nesterov \u52a0\u901f\u540e\uff0c\u52a8\u91cf\u7684\u9488\u5bf9\u6027\u66f4\u5f3a\uff0c\u6536\u655b\u901f\u7387\u4e5f\u66f4\u5feb\u4e86\u3002</p>"}, {"location": "DNN/optimizer/SGD/#_4", "title": "\u6b63\u5219\u5316\u4f18\u5316", "text": "<p>\u6211\u4eec\u8003\u8651\u4e00\u822c\u7684 \\(L_2\\) \u6b63\u5219\u5316\u7528\u4ee5\u5bf9\u6743\u91cd\u5927\u5c0f\u8fdb\u884c\u60e9\u7f5a\u9650\u5236\u3002\u5728 SGD \u573a\u666f\u4e0b\uff1a</p> \\[ \\begin{align*}     g_{n} &amp;= -\\eta\\nabla\\left(\\mathcal{L}({x};\\theta_{n-1})+\\dfrac{\\lambda}{2}|\\theta_{n-1}|^2\\right)\\\\     &amp;=-\\eta\\nabla\\mathcal{L}({x};\\theta_{n-1})-\\eta\\lambda\\theta_{n-1}\\\\     \\theta_n&amp;=\\theta_{n-1}+g_n\\\\     &amp;=(1-\\eta\\lambda)\\theta_{n-1}-\\eta\\nabla\\mathcal{L}(x;\\theta_{n-1}) \\end{align*} \\] <p>\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u4ee5\u6570\u4e58\u4ee3\u66ff\u7e41\u7410\u4e14\u8017\u65f6\u7684\u68af\u5ea6\u8ba1\u7b97\uff0c\u8fd9\u88ab\u53eb\u505a\u201c\u89e3\u8026\u7684\u6743\u91cd\u8870\u51cf\u201d\uff08Decoupled Weight Decay\uff09\u3002\u5982\u679c\u8fd8\u60f3\u89e3\u8026\u66f4\u5f7b\u5e95\u4e9b\uff0c\u53ef\u4ee5\u5199\u6210 \\((1-\\lambda)\\theta_{n-1}-\\eta\\nabla\\mathcal{L}(x;\\theta_{n-1})\\)\uff0c\u4e5f\u5c31\u662f\u751a\u81f3\u628a\u5b66\u4e60\u7387\u548c\u6b63\u5219\u5316\u53c2\u6570\u89e3\u8026\u3002\u5728\u540e\u9762\u7684\u4f18\u5316\u5668\u4e2d\uff08\u6bd4\u5982 AdamW\uff09\uff0c\u6211\u4eec\u57fa\u672c\u4e0d\u4f1a\u76f4\u63a5\u4f7f\u7528\u539f\u6559\u65e8\u4e3b\u4e49\u7684 \\(L_2\\) \u6b63\u5219\u5316\uff0c\u800c\u662f\u91c7\u7528\u8fd9\u79cd\u6743\u91cd\u8870\u51cf\u7684\u65b9\u5f0f\uff0c\u5c3d\u7ba1\u5728\u66f4\u590d\u6742\u7684\u4f18\u5316\u5668\u4e0b\uff0c\u8fd9\u4e24\u8005\u6570\u5b66\u4e0a\u5e76\u4e0d\u7b49\u6548\u3002</p>"}, {"location": "DNN/optimizer/SGD/#sgdm_1", "title": "SGDM \u7684\u4ee3\u7801\u5b9e\u73b0", "text": "<p>\u4e0b\u9762\uff0c\u8ba9\u6211\u4eec\u6765\u8d4f\u6790\u4e00\u4e0b <code>torch.optim.SGD</code> \u5bf9 SGDM \u7684\u5b9e\u73b0\u3002\u4e2d\u6587\u6ce8\u91ca\u662f\u6211\u8ba9 Gemini \u5e2e\u6211\u8bfb\u4ee3\u7801\u7ed9\u51fa\u7684\u6ce8\u89e3\u3002</p> SGDM \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_sgd(\n    params: list[Tensor],\n    grads: list[Tensor],\n    momentum_buffer_list: list[Optional[Tensor]],\n    grad_scale: Optional[Tensor],\n    found_inf: Optional[Tensor],\n    *,\n    weight_decay: float,\n    momentum: float,\n    lr: float,\n    dampening: float,\n    nesterov: bool,\n    maximize: bool,\n    has_sparse_grad: bool,\n):\n    # \u8fd9\u4e24\u4e2a\u53c2\u6570\u4e0e\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6\uff08AMP\uff09\u4e2d\u7684\u68af\u5ea6\u7f29\u653e\u6709\u5173\uff0c\u7528\u4e8e\u8df3\u8fc7\u65e0\u6548\u66f4\u65b0\u3002\n    # \u6b64\u51fd\u6570\u662f\u57fa\u7840\u5b9e\u73b0\uff0c\u4e0d\u5904\u7406\u8fd9\u4e9b\u60c5\u51b5\uff0c\u6545\u65ad\u8a00\u5b83\u4eec\u4e3a None\u3002\n    assert grad_scale is None and found_inf is None\n\n    # \u5faa\u73af\u904d\u5386\u6bcf\u4e00\u4e2a\u53c2\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u68af\u5ea6\u548c\u52a8\u91cf\u7f13\u51b2\u533a\n    for i, param in enumerate(params):\n        # \u83b7\u53d6\u5f53\u524d\u53c2\u6570\u7684\u68af\u5ea6\u3002\u5982\u679c\u76ee\u6807\u662f\u6700\u5927\u5316\uff08maximize=True\uff09\uff0c\u5219\u53cd\u8f6c\u68af\u5ea6\u65b9\u5411\u3002\n        grad = grads[i] if not maximize else -grads[i]\n\n        # --- \u6b65\u9aa4 1: \u5e94\u7528\u6743\u91cd\u8870\u51cf (Weight Decay / L2 \u6b63\u5219\u5316) ---\n        if weight_decay != 0:\n            # \u6ce8\u610f: \u8fd9\u91cc\u7684\u5b9e\u73b0\u662f\u5c06\u6743\u91cd\u8870\u51cf\u9879\u52a0\u5230\u68af\u5ea6\u4e0a\uff0c\u800c\u4e0d\u662f\u4ece\u6743\u91cd\u4e2d\u76f4\u63a5\u51cf\u53bb\uff08\u89e3\u8026\u6743\u91cd\u8870\u51cf\uff09\u3002\n            # \u8fd9\u7b49\u4ef7\u4e8e\u5728\u635f\u5931\u51fd\u6570\u4e2d\u52a0\u5165\u4e86 L2 \u6b63\u5219\u5316\u9879 0.5 * weight_decay * param^2\u3002\n            # \u66f4\u65b0\u524d\u7684\u68af\u5ea6 g' = g + w * theta\n\n            # \u4f7f\u7528\u5d4c\u5957 if \u662f\u4e3a\u4e86\u7ed5\u8fc7 TorchScript JIT \u7f16\u8bd1\u5668\u7684\u89c4\u5219\uff0c\u5e76\u5904\u7406\u53ef\u5fae\u7684 weight_decay\u3002\n            if isinstance(weight_decay, Tensor):\n                if weight_decay.requires_grad:\n                    # \u5982\u679c weight_decay \u672c\u8eab\u662f\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u7684\u5f20\u91cf\uff08\u4f8b\u5982\u5728\u5143\u5b66\u4e60\u4e2d\uff09\uff0c\n                    # \u5fc5\u987b\u514b\u9686 param \u6765\u8fdb\u884c\u4e58\u6cd5\uff0c\u4ee5\u907f\u514d\u5728\u53cd\u5411\u4f20\u64ad\u4e2d\u51fa\u73b0\u539f\u5730\u4fee\u6539\u9519\u8bef\u3002\n                    grad = grad.addcmul(param.clone(), weight_decay)\n                else:\n                    # \u5982\u679c weight_decay \u662f\u5f20\u91cf\u4f46\u65e0\u9700\u68af\u5ea6\uff0c\u5219\u4f7f\u7528\u5e38\u89c4\u7684 add \u64cd\u4f5c\u3002\n                    grad = grad.add(param, alpha=weight_decay)\n            else:\n                # \u5982\u679c weight_decay \u662f\u4e00\u4e2a\u666e\u901a\u7684\u6d6e\u70b9\u6570\uff0c\u8fd9\u662f\u6700\u5e38\u89c1\u7684\u60c5\u51b5\u3002\n                grad = grad.add(param, alpha=weight_decay)\n\n        # --- \u6b65\u9aa4 2: \u8ba1\u7b97\u52a8\u91cf\u5e76\u66f4\u65b0\u68af\u5ea6 ---\n        if momentum != 0:\n            # \u83b7\u53d6\u5f53\u524d\u53c2\u6570\u7684\u52a8\u91cf\u7f13\u51b2\u533a\uff08momentum buffer\uff09\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a M\n            buf = momentum_buffer_list[i]\n\n            if buf is None:\n                # \u5982\u679c\u662f\u7b2c\u4e00\u6b21\u66f4\u65b0\u8be5\u53c2\u6570\uff0c\u52a8\u91cf\u7f13\u51b2\u533a\u4e3a\u7a7a\u3002\n                # \u521d\u59cb\u5316\u52a8\u91cf M_0 = g' (\u5f53\u524d\u68af\u5ea6)\n                # \u4f7f\u7528 clone().detach() \u6765\u521b\u5efa\u4e00\u4e2a\u4e0d\u5e26\u68af\u5ea6\u5386\u53f2\u7684\u65b0\u5f20\u91cf\u4f5c\u4e3a\u521d\u59cb\u52a8\u91cf\u3002\n                buf = torch.clone(grad).detach()\n                momentum_buffer_list[i] = buf\n            else:\n                # \u5982\u679c\u5df2\u6709\u52a8\u91cf\uff0c\u5219\u8fdb\u884c\u66f4\u65b0\u3002\n                # \u516c\u5f0f: M_t = momentum * M_{t-1} + (1 - dampening) * g'_t\n                # momentum \u662f\u52a8\u91cf\u56e0\u5b50 (\u03b2)\uff0cdampening \u6291\u5236\u4e86\u65b0\u68af\u5ea6\u5bf9\u52a8\u91cf\u7684\u5f71\u54cd\u3002\n                # \u5f53 dampening=0 \u65f6\uff0c\u8fd9\u5c31\u662f\u6807\u51c6\u52a8\u91cf\u66f4\u65b0\u516c\u5f0f M_t = \u03b2 * M_{t-1} + g'_t\n                buf.mul_(momentum).add_(grad, alpha=1 - dampening)\n\n            if nesterov:\n                # \u5982\u679c\u4f7f\u7528 Nesterov \u52a0\u901f\u68af\u5ea6 (NAG):\n                # \u66f4\u65b0\u6240\u7528\u7684\u68af\u5ea6\u53d8\u4e3a: g''_t = g'_t + momentum * M_t\n                grad = grad.add(buf, alpha=momentum)\n            else:\n                # \u5982\u679c\u4f7f\u7528\u6807\u51c6\u52a8\u91cf:\n                # \u66f4\u65b0\u6240\u7528\u7684\u68af\u5ea6\u5c31\u662f\u52a8\u91cf\u672c\u8eab: g''_t = M_t\n                grad = buf\n\n        # --- \u6b65\u9aa4 3: \u4f7f\u7528\u6700\u7ec8\u7684\u68af\u5ea6\u66f4\u65b0\u53c2\u6570 ---\n        # \u6700\u7ec8\u66f4\u65b0\u516c\u5f0f: param_t = param_{t-1} - lr * g''_t\n\n        # \u540c\u6837\uff0c\u4f7f\u7528\u5d4c\u5957 if \u6765\u5904\u7406 lr \u53ef\u80fd\u662f\u4e00\u4e2a\u9700\u8981\u68af\u5ea6\u7684\u5f20\u91cf\u7684\u60c5\u51b5\u3002\n        if isinstance(lr, Tensor):\n            if lr.requires_grad:\n                # \u5982\u679c lr \u9700\u8981\u68af\u5ea6\uff0c\u5fc5\u987b\u4f7f\u7528 addcmul\uff0c\u5b83\u6709\u4e3a\u6240\u6709\u8f93\u5165\uff08\u5305\u62eclr\uff09\u5b9a\u4e49\u7684\u5bfc\u6570\u3002\n                # value=-1 \u5b9e\u73b0\u51cf\u6cd5\u3002\n                param.addcmul_(grad, lr, value=-1)\n            else:\n                # \u5982\u679c lr \u662f\u5f20\u91cf\u4f46\u65e0\u9700\u68af\u5ea6\uff0c\u4f7f\u7528 add_ \u548c alpha=-lr\u3002\n                param.add_(grad, alpha=-lr)\n        else:\n            # \u5982\u679c lr \u662f\u4e00\u4e2a\u666e\u901a\u7684\u6d6e\u70b9\u6570\uff08\u6700\u5e38\u89c1\u60c5\u51b5\uff09\uff0c\u4f7f\u7528\u6700\u9ad8\u6548\u7684 add_ \u64cd\u4f5c\u3002\n            param.add_(grad, alpha=-lr)\n</code></pre>"}, {"location": "DNN/optimizer/SGD/#_5", "title": "\u5176\u4ed6\u8ba8\u8bba", "text": ""}, {"location": "DNN/optimizer/SGD/#_6", "title": "\u68af\u5ea6\u4e0e\u6d77\u68ee\u77e9\u9635\u4f30\u8ba1", "text": "<p>\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u600e\u4e48\u7ed9\u4e00\u4e2a\u591a\u5143\u51fd\u6570 \\(f({x})\\) \u505a\u4e8c\u9636\u6cf0\u52d2\u5c55\u5f00\u3002</p> <p>\u5728\u4e00\u9636\u7684\u60c5\u51b5\u4e0b\uff0c\u5f88\u660e\u663e\u6709</p> \\[ f({x})\\approx f({x_0})+\\nabla f({x_0})\\cdot ({x-x_0}) \\] <p>\u7c7b\u4f3c\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6c42\u5bfc\u7b97\u5b50\u5e94\u7528\u5230\u68af\u5ea6\u4e0a\u9762\uff0c\u4e5f\u5c31\u662f\u5f97\u5230\u68af\u5ea6\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u6216\u8005\u53eb\u505a\u6d77\u68ee\u77e9\u9635\uff1a</p> \\[ H=\\left(\\frac{\\partial^2}{\\partial x_i\\partial x_j}\\right)_{1\\le i,j\\le n}=\\left( \\begin{matrix}     \\frac{\\partial^2}{\\partial x_1^2} &amp; \\frac{\\partial^2}{\\partial x_1\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial^2}{\\partial x_1\\partial x_n}\\\\     \\frac{\\partial^2}{\\partial x_2\\partial x_1} &amp; \\frac{\\partial^2}{\\partial x_2^2} &amp; \\cdots &amp; \\frac{\\partial^2}{\\partial x_2\\partial x_n}\\\\     \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\     \\frac{\\partial^2}{\\partial x_n\\partial x_1} &amp; \\frac{\\partial^2}{\\partial x_n\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial^2}{\\partial x_n^2}\\\\ \\end{matrix} \\right) \\] <p>\u90a3\u4e48\u4e8c\u9636\u7684\u6cf0\u52d2\u5c55\u5f00\u5c31\u53d8\u6210\u4e86</p> \\[ f({x})\\approx f({x_0})+\\nabla f({x_0})({x-x_0})+\\dfrac{1}{2}({x-x_0})^\\top H f({x_0})({x-x_0}) \\] <p>\u8ba9\u6211\u4eec\u7528\u719f\u6089\u7684\u8bb0\u53f7\u91cd\u5199\u4e00\u4e0b\uff1a</p> \\[ \\mathcal{L}(\\theta_n+\\Delta\\theta)\\approx \\mathcal{L}(\\theta_n)+g_n^\\top\\Delta\\theta+\\dfrac{1}{2}\\Delta\\theta^\\top H \\mathcal{L}(\\theta_n)\\Delta\\theta \\] <p>\u5728 SGD \u573a\u666f\u4e0b\uff0c\\(\\Delta\\theta=-\\eta g_n\\)\uff0c\u635f\u5931\u51fd\u6570\u7684\u6539\u53d8\u91cf\u4e3a\uff1a</p> \\[ \\mathcal{L}(\\theta_n+\\Delta\\theta)- \\mathcal{L}(\\theta_n)\\approx -\\eta g_n^\\top g_n+\\dfrac{1}{2}\\eta^2g_n^\\top H \\mathcal{L}(\\theta_n)g_n \\] <p>\u53ef\u89c1\uff0c\u5728 \\(H\\) \u8f83\u5927\uff08\u5c24\u5176\u662f\u6761\u4ef6\u6570\u8f83\u5927\uff0c\u5bf9\u5e94\u4e4b\u524d\u8bf4\u7684\u692d\u5706\u629b\u7269\u9762\uff09\u7684\u5730\u65b9\uff0cSGD \u7684\u66f4\u65b0\u662f\u76f8\u5f53\u4f4e\u6548\u7684\u3002</p> <p>\u8ba9\u6211\u4eec\u4ee5\u53e6\u5916\u4e00\u4e2a\u89c6\u89d2\u89c2\u5bdf\u524d\u9762\u7684\u5f0f\u5b50\u3002\u4e3a\u4e86\u627e\u5230\u6700\u5c0f\u503c\uff0c\u4e8b\u5b9e\u4e0a\u6211\u4eec\u662f\u5728\u5bfb\u627e\u635f\u5931\u51fd\u6570\u68af\u5ea6\u7684\u96f6\u70b9\u3002\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u632a\u7528\u6570\u503c\u5206\u6790\u91cc\u9762\u627e\u96f6\u70b9\u76f8\u5f53\u9ad8\u6548\u7684\u7b97\u6cd5\uff1a\u725b\u987f\u8fed\u4ee3\u6cd5\u3002</p> <p>\u56de\u987e\u4e00\u4e0b\u725b\u987f\u6cd5\u7684\u5185\u5bb9\uff0c\u5bf9\u4e8e\u51fd\u6570 \\(f(x)\\) \u548c\u521d\u59cb\u4f30\u8ba1 \\(x_{n-1}\\)\uff0c\u66f4\u65b0\u65b9\u5f0f\u4e3a\uff1a</p> \\[ \\Delta x = -\\dfrac{f(x_{n-1})}{f'(x_{n-1})}\\\\ x_n=x_{n-1}+\\Delta x \\] <p>\u725b\u987f\u6cd5\u7684\u7279\u5f81\u5c31\u662f\u6536\u655b\u9ad8\u6548\uff0c\u4e14\u662f\u81ea\u9002\u5e94\u7684\uff0c\u9661\u5ced\u7684\u5730\u65b9\u4e0b\u964d\u5feb\uff0c\u5e73\u7f13\u7684\u5730\u65b9\u7cbe\u5ea6\u9ad8\u3002</p> <p>\u5728\u4f18\u5316\u5668\u7684\u8bed\u5883\u91cc\u9762\uff0c\u5176\u5b9e\u5c31\u662f\u8ba9\u53c2\u6570\u66f4\u65b0\u91cf \\(\\Delta \\theta=-[H\\mathcal{L}]^{-1}\\nabla \\mathcal{L}\\)\u3002\u800c\u524d\u9762\u6240\u8ff0\u7684\u201c\u9661\u5ced\u201d\u548c\u201c\u5e73\u7f13\u201d\u6070\u5de7\u5bf9\u5e94\u7684\u5c31\u662f\u4e00\u9636\u5bfc\uff08\u68af\u5ea6\uff09\u7684\u5bfc\u6570\u4e5f\u5c31\u662f\u6d77\u68ee\u77e9\u9635\uff01</p> <p>\u7531\u4e8e\u6d77\u68ee\u77e9\u9635\uff08\u53ca\u5176\u9006\u77e9\u9635\uff09\u7684\u8ba1\u7b97\u91cf\u975e\u5e38\u4e4b\u5927\uff0c\u4e0e\u5176\u8ba1\u7b97\u5b83\u4e0d\u5982\u7528\u8fd9\u4e2a\u65f6\u95f4\u8dd1\u51e0\u8f6e\u7b97\u5f97\u5feb\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002</p> <p>\u800c SGD \u5176\u5b9e\u5c31\u662f\u53d6\u7684 \\([H\\mathcal{L}]^{-1}=\\eta I\\) \u8fd9\u4e2a\u4f30\u8ba1\uff0c\u76f8\u5f53\u4e8e\u62b9\u5e73\u5404\u4e2a\u65b9\u5411\u7684\u5dee\u5f02\u505a\u4e86\u7edf\u4e00\u7684\u66f4\u65b0\u3002</p> <p>\u5bf9\u4e8e\u6d77\u68ee\u77e9\u9635\u800c\u8a00\uff0c\u6709\u6ca1\u6709\u66f4\u597d\u7684\u4f30\u8ba1\u65b9\u5f0f\u5462\uff1f\u6709\u7684\uff01\u8981\u4e0d\u7136\u4e3a\u4ec0\u4e48\u6211\u4eec\u4f1a\u5f15\u5165\u52a8\u91cf\u5462\uff1f</p> <p>\u8ba9\u6211\u4eec\u8003\u8651\u4e00\u4e2a\u692d\u5706\u629b\u7269\u9762</p> \\[ f({x})=\\dfrac 12{x}^\\top A{x}+{b}^\\top {x} \\] <p>\u90a3\u4e48\u5728\u8fd9\u4e2a\u9762\u4e0a\u7684\u4efb\u4e00\u70b9\u6709\u68af\u5ea6 \\(\\nabla f=A{x}-{b}\\) \u4ee5\u53ca\u6d77\u68ee\u77e9\u9635 \\(Hf=A\\)\u3002</p> <p>\u4ee4\u68af\u5ea6\u7b49\u4e8e \\(0\\)\uff0c\u5b9e\u8d28\u5c31\u662f\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4 \\(H{x}={b}\\)\uff0c\u4e3a\u6b64\u6211\u4eec\u5b9a\u4e49\u6b8b\u5dee \\({r}=H{x}-{b}\\)</p> <p>\u5728\u4efb\u610f\u4e00\u672c\u6570\u503c\u5206\u6790\u6559\u6750\u91cc\u9762\u90fd\u4f1a\u8bb2\u5230\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u7684\u4e00\u767e\u4e07\u79cd\u65b9\u6cd5\uff0c\u5305\u62ec\u9ad8\u65af\u6d88\u5143\u6cd5\uff0c\u96c5\u53ef\u6bd4\u8fed\u4ee3\uff0c\u9884\u6761\u4ef6\u6cd5\u7b49\u3002\u5728\u5176\u4e2d\u548c\u5148\u524d\u6211\u4eec\u63d0\u5230\u7684\u52a8\u91cf\u6cd5\u6700\u76f8\u5173\u7684\u662f\u5171\u8f6d\u68af\u5ea6\u6cd5\u3002\u4e0b\u9762\u7b80\u8981\u4ecb\u7ecd\u4e00\u4e0b\u8fd9\u4e2a\u65b9\u6cd5\u3002</p> <p>\u5b9a\u4e49\uff1a\u82e5 \\(A\\) \u4e3a \\(n\\times n\\) \u7684\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\uff0c\\(u,v\\) \u4e3a\u4e24\u4e2a \\(n\\) \u7ef4\u7684\u5411\u91cf\uff0c\u5219\u4e24\u8005\u7684 \\(A\\)-\u5185\u79ef \u5b9a\u4e49\u4e3a\uff1a</p> \\[ \\langle u,v\\rangle _A=u^\\top Av \\] <p>\u7279\u522b\u7684\uff0c\u5982\u679c \\(\\langle u, v\\rangle _A=0\\)\uff0c\u5219\u79f0\u4e24\u4e2a\u5411\u91cf\u5173\u4e8e \\(A\\) \u5171\u8f6d\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u6709\u4e00\u4e2a\u53c2\u6570\u7684\u521d\u59cb\u4f30\u8ba1 \\(\\theta_n\\)\uff0c\u5f97\u5230\u4e86\u68af\u5ea6 \\(g_n\\) \u4e5f\u5c31\u662f\u4e4b\u524d\u63d0\u5230\u7684\u6b8b\u5dee\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u9700\u8981\u5bfb\u627e\u53c2\u6570\u66f4\u65b0\u91cf \\(M_n\\)\uff0c\u5438\u7eb3\u4e4b\u524d\u5173\u4e8e\u201c\u5171\u8f6d\u201d\u7684\u8ba8\u8bba\uff0c\u6211\u4eec\u5e0c\u671b\u5404\u4e2a \\(M\\) \u4e4b\u95f4\u7684\u4f18\u5316\u662f\u72ec\u7acb\u7684\uff0c\u4e5f\u5c31\u662f \\(\\langle M_i,M_j\\rangle _H=0\\quad(i\\ne j)\\) \u6210\u7acb\u3002</p> <p>\u611f\u89c9\u662f\u5426\u5f88\u50cf Gram-Schmidt \u6b63\u4ea4\u5316\uff1f\u662f\u7684\uff01\u5f53\u7136\u5171\u8f6d\u68af\u5ea6\u6cd5\u4f7f\u7528\u7684\u662f\u4e00\u4e2a\u7b49\u6548\u66f4\u7b80\u5355\u7684\u5f62\u5f0f\uff08\u5177\u4f53\u600e\u4e48\u4ece\u6b63\u4ea4\u5316\u7b49\u5f0f\u63a8\u5230\u8fd9\u4e2a\u7b80\u5355\u5f62\u5f0f\u6bd4\u8f83\u590d\u6742\u800c\u4e14\u4e5f\u6709\u70b9\u8dd1\u9898\u4e86\uff0c\u6211\u89c6\u60c5\u51b5\u5728\u540e\u9762\u7ed9\u4e00\u4e2a\u9644\u5f55\u8fdb\u884c\u8bc1\u660e\uff09\uff0c\u4e5f\u5c31\u662f</p> \\[ \\beta_n = \\dfrac{g_n^\\top g_n}{g_{n-1}^\\top g_{n-1}}\\\\ M_n=g_n+\\beta_nM_{n-1} \\] <p>\u5176\u5b9e\u76f4\u63a5\u7528 Gram-Schmidt \u6b63\u4ea4\u5316\u4e5f\u65e0\u53ef\u539a\u975e\uff08\u867d\u7136\u8fd9\u5c31\u6d89\u53ca\u5230\u8981\u628a \\(H\\) \u7eb3\u5165\u8ba1\u7b97\uff09\uff0c\u56e0\u4e3a\u65e0\u8bba\u5982\u4f55\u6211\u4eec\u90fd\u8981\u628a \\(\\beta_n\\) \u4f30\u8ba1\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u7684\u8d85\u53c2\u6570 \\(\\beta\\)\uff0c\u6211\u4eec\u8981\u7684\u662f\u4e0b\u9762\u90a3\u4e2a\u52a8\u91cf\u5f0f\u5b50\u7684\u7ed3\u6784\u800c\u4e0d\u662f\u53c2\u6570\u7684\u8868\u8fbe\u5f0f\uff0c\u6bd5\u7adf\u53c2\u6570\u53ef\u4ee5\u4f30\u8ba1\u3002</p> <p>\u5f53\u7136\u5171\u8f6d\u68af\u5ea6\u8fd8\u5229\u7528 \\(\\alpha_i=\\dfrac{g_n^\\top g_n}{M_n^\\top H M_n}\\) \u6765\u8ba1\u7b97\u66f4\u65b0\u6b65\u957f\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u7684\u8ba1\u7b97\u610f\u4e49\u4e0d\u5927\uff0c\u56e0\u4e3a\u6211\u4eec\u4e00\u662f\u4e0d\u77e5\u9053 \\(H\\)\uff0c\u4e8c\u662f\u5229\u7528\u7684\u56fa\u5b9a\u5b66\u4e60\u7387 \\(\\eta\\) \u6765\u8fd1\u4f3c\u66ff\u4ee3\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u628a \\(\\beta_i\\) \u4e5f\u4f30\u8ba1\u4e3a\u56fa\u5b9a\u7684\u8d85\u53c2\u6570 \\(\\beta\\)\uff0c\u90a3\u6211\u4eec\u5c31\u53ef\u4ee5\u4e0b\u8bba\u65ad\u4e86\uff1a\u52a8\u91cf\u6cd5\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u662f\u91c7\u7528\u56fa\u5b9a\u53c2\u6570\u8fd1\u4f3c\u5bf9 \\(H^{-1}\\) \u7684\u5171\u8f6d\u68af\u5ea6\u6cd5\u6c42\u89e3\u3002</p> <p>\u5bf9\u4e8e\u6d77\u68ee\u77e9\u9635\u800c\u8a00\uff0c\u6709\u6ca1\u6709\u66f4\u597d\u7684\u4f30\u8ba1\u65b9\u5f0f\u5462\uff1f\u6709\u7684\uff01\u8ba9\u6211\u4eec\u4e0d\u8981\u628a\u53c2\u6570\u56fa\u5b9a\u6b7b\uff0c\u6765\u4e00\u4e2a\u81ea\u9002\u5e94\u8c03\u8282\u3002</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 1, 2025). SGD \u7cfb\u5217\u7b97\u6cd5 [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/optimizer/SGD</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{SGD,\n    title={SGD \u7cfb\u5217\u7b97\u6cd5},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/optimizer/SGD}},\n}\n</code></pre></p>"}, {"location": "DNN/optimizer/SignGD/", "title": "\u7b26\u53f7\u68af\u5ea6\u4e0b\u964d", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 19 \u5206\u949f\u3000|\u3000\u7ea6 2029 \u5b57\u3000|\u3000\u7ea6 57 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 470 \u884c\u4ee3\u7801</p> <p>\u5982\u679c\u662f\u8fd1\u4f3c Hessian \u77e9\u9635\u662f\u4f18\u5316\u5668\u7406\u8bba\u53d1\u5c55\u7684\u4e00\u6761\u201c\u660e\u7ebf\u201d\uff0c\u90a3\u4e48\u5bf9\u68af\u5ea6\u53d6\u201c\u7b26\u53f7\u201d\u6765\u8ba1\u7b97\uff0c\u5219\u662f\u5bf9\u5e94\u7684\u4e00\u6761\u201c\u6697\u7ebf\u201d\u3002</p> <p>\u5728\u63a5\u4e0b\u6765\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u5230\u521a\u521a\u8ba8\u8bba\u7684\u90a3\u4e9b\u4f18\u5316\u5668\u662f\u5982\u4f55\u5728\u8fd9\u6761\u201c\u6697\u7ebf\u201d\u4e0b\u8d70\u5411\u7edf\u4e00\u7684\u3002\u540c\u65f6\uff0c\u8fd9\u6761\u201c\u6697\u7ebf\u201d\u4e5f\u6e10\u6e10\u8d8a\u6311\u8d8a\u660e\uff0c\u9010\u6e10\u6210\u4e3a\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4f18\u5316\u7684\u65b0\u7684\u7406\u8bba\u6307\u5bfc\u3002</p>"}, {"location": "DNN/optimizer/SignGD/#rprop", "title": "Rprop", "text": "<p>Rprop \u7684\u51fa\u73b0\u65e9\u4e8e RMSprop\uff0c\u4ece\u547d\u540d\u98ce\u683c\u5c31\u53ef\u4ee5\u770b\u51fa\u5b83\u4eec\u7684\u4e00\u8109\u76f8\u627f\u3002</p> <p>\u56de\u5fc6\u4e00\u4e0b RMSprop \u7684\u8ba1\u7b97\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u68af\u5ea6\u7f29\u653e\u7cfb\u6570 \\(\\sqrt{G_n}\\)\uff0c\u5176\u4e2d \\(G\\) \u662f\u5bf9 \\(g^2\\) \u7684\u5e73\u5747\u3002</p> <p>\u90a3\u4e48\u6700\u540e\u7684\u53c2\u6570\u66f4\u65b0\u5c31\u53d8\u6210\u4e86 \\(-\\eta\\dfrac{g}{\\sqrt{\\bar g^2}}\\)\uff0c\u5982\u679c\u6211\u4eec\u8003\u8651\u5168\u91cf\uff08Full batch\uff09\u66f4\u65b0\uff0c\u4e5f\u5c31\u662f\u8ba9 \\(\\mathcal{|B|}=n\\) \u5373 Batch size \u7b49\u4e8e\u6837\u672c\u6570\u91cf\uff0c\u90a3\u4e48\u6211\u4eec\u751a\u81f3\u53ef\u4ee5\u628a\u8fd9\u4e2a\u201c\u5e73\u5747\u68af\u5ea6\u201d\u7684\u5e73\u5747\u53bb\u6389\u3002\u8fd9\u6837\u5b9e\u9645\u7684\u66f4\u65b0\u91cf\u5c31\u662f\u68af\u5ea6\u7684\u7b26\u53f7\u51fd\u6570 \\(\\mathrm{sign}(g)\\) \u4e86\uff01</p> <p>\u8fd9\u5c31\u662f Rprop \u7684\u66f4\u65b0\u539f\u7406\u3002\u4e5f\u5c31\u662f\u6240\u6709\u7b26\u53f7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5668\u7684\u7406\u8bba\u6838\u5fc3\uff1a\u68af\u5ea6\u7684\u65b9\u5411\u76f8\u6bd4\u5176\u5728\u4e0d\u540c\u65b9\u5411\u7684\u5927\u5c0f\u66f4\u91cd\u8981\uff01</p> <p>\u56de\u5230\u6211\u4eec\u4e4b\u524d\u8ba8\u8bba\u7684\u90a3\u4e2a\u692d\u5706\u629b\u7269\u9762\uff0c\u5982\u679c\u6211\u4eec\u8fc7\u4e8e\u4f9d\u8d56\u68af\u5ea6\u5927\u5c0f\uff0c\u5c31\u4f1a\u9020\u6210\u201c\u53cd\u590d\u6a2a\u8df3\u201d\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u68af\u5ea6\u5728\u6211\u4eec\u9884\u671f\u7684\u4f18\u5316\u65b9\u5411\u7684\u5782\u76f4\u65b9\u5411\u4e0a\uff0c\u6709\u76f8\u5f53\u5927\u7684\u5927\u5c0f\uff0c\u8fd9\u5c31\u5f71\u54cd\u4e86\u4f18\u5316\u5668\u5728 Hessian \u77e9\u9635\u6761\u4ef6\u6570\u76f8\u5f53\u5927\u7684\u65f6\u5019\uff0c\u9003\u79bb\u978d\u70b9\u7684\u80fd\u529b\u3002</p> <p>\u5728\u770b\u516c\u5f0f\u4e4b\u524d\uff0c\u5148\u770b\u770b Rprop \u7684\u6548\u679c\u5427\uff1a</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u5982\u679c\u5ffd\u7565\u5168\u91cf\u68af\u5ea6\u8ba1\u7b97\u8fd9\u4e2a\uff08\u5927\uff09\u95ee\u9898\uff0cRprop \u5728\u8fd9\u4e24\u4e2a\u5730\u5f62\u7684\u6536\u655b\u80fd\u529b\u5b8c\u5168\u53ef\u4ee5\u5ab2\u7f8e Adam\uff01\u5c24\u5176\u662f\u5728 rosenbrock \u5730\u5f62\u4e0b Rprop \u6cbf\u7740\u8c37\u5e95\u79fb\u52a8\u7684\u901f\u5ea6\u662f\u76f8\u5f53\u5feb\u7684\u3002</p> <p>\u4e0b\u9762\u5219\u5c55\u793a\u4e86\u5982\u679c\u4ee5 mini-batch \u65b9\u5f0f\u8fd0\u884c Rprop \u7684\u60e8\u70c8\u6548\u679c\uff1a</p> <p></p> <p></p> <p>\u6f14\u90fd\u4e0d\u6f14\u4e86\uff0c\u6839\u672c\u6536\u655b\u4e0d\u4e86\u3002</p> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u6765\u770b\u770b Rprop \u7684\u66f4\u65b0\u516c\u5f0f\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L({x_{\\mathrm{full}}};\\theta_{n-1})}\\\\     \\hat g_n&amp;=\\mathrm{sign}(g_n)\\\\     \\theta_n&amp;=\\theta_{n-1}-\\eta\\hat g_n \\end{align*} \\] <p>\u7531\u6b64\uff0c\u5c31\u80fd\u5199\u51fa\u4ee3\u7801\u4e86\uff1a</p>  Rprop \u7684\u5b9e\u73b0 <pre><code>def _single_tensor_rprop(\n    params: list[Tensor],\n    grads: list[Tensor],\n    prevs: list[Tensor],\n    step_sizes: list[Tensor],\n    state_steps: list[Tensor],\n    *,\n    step_size_min: float,\n    step_size_max: float,\n    etaminus: float,\n    etaplus: float,\n    maximize: bool,\n    capturable: bool,\n    differentiable: bool,\n    has_complex: bool,\n):\n    # \u5faa\u73af\u5904\u7406\u6bcf\u4e2a\u53c2\u6570\n    for i, param in enumerate(params):\n        grad = grads[i]\n        grad = grad if not maximize else -grad\n        prev = prevs[i]\n        step_size = step_sizes[i]\n        step = state_steps[i]\n\n        # --- CUDA Graph \u6355\u83b7\u68c0\u67e5 ---\n        if not torch.compiler.is_compiling() and capturable:\n            capturable_supported_devices = _get_capturable_supported_devices()\n            assert (\n                param.device.type == step.device.type\n                and param.device.type in capturable_supported_devices\n            ), \"\u5982\u679c capturable=True, params \u548c state_steps \u5fc5\u987b\u5728\u652f\u6301\u7684\u8bbe\u5907\u4e0a\u3002\"\n\n        step += 1\n\n        # --- \u5904\u7406\u590d\u6570 ---\n        if torch.is_complex(param):\n            grad = torch.view_as_real(grad)\n            prev = torch.view_as_real(prev)\n            param = torch.view_as_real(param)\n            step_size = torch.view_as_real(step_size)\n\n        # --- Rprop \u6838\u5fc3\u903b\u8f91 ---\n\n        # 1. \u8ba1\u7b97\u5f53\u524d\u68af\u5ea6\u4e0e\u4e0a\u4e00\u6b65\u68af\u5ea6\u7684\u4e58\u79ef\u7684\u7b26\u53f7\n        # sign &gt; 0: \u68af\u5ea6\u7b26\u53f7\u76f8\u540c\n        # sign &lt; 0: \u68af\u5ea6\u7b26\u53f7\u76f8\u53cd\n        # sign = 0: \u5176\u4e2d\u4e00\u4e2a\u68af\u5ea6\u4e3a\u96f6\n        if differentiable:\n            # \u5728\u53ef\u5fae\u5206\u6a21\u5f0f\u4e0b\uff0c\u9700\u8981\u514b\u9686 prev \u4ee5\u9632\u539f\u5730\u64cd\u4f5c\u7834\u574f\u8ba1\u7b97\u56fe\n            sign = grad.mul(prev.clone()).sign()\n        else:\n            sign = grad.mul(prev).sign()\n\n        # 2. \u6839\u636e\u7b26\u53f7 sign \u7684\u503c\uff0c\u786e\u5b9a\u6b65\u957f\u7684\u66f4\u65b0\u56e0\u5b50\n        # \u8fd9\u91cc\u7528 sign \u5f20\u91cf\u6765\u5b58\u50a8\u66f4\u65b0\u56e0\u5b50 (etaplus, etaminus, 1)\n        if capturable:\n            # Capturable \u6a21\u5f0f\u4e0b\u4f7f\u7528 torch.where\n            sign.copy_(torch.where(sign.gt(0), etaplus, sign))   # \u7b26\u53f7\u76f8\u540c\uff0c\u66f4\u65b0\u56e0\u5b50\u4e3a etaplus\n            sign.copy_(torch.where(sign.lt(0), etaminus, sign))  # \u7b26\u53f7\u76f8\u53cd\uff0c\u66f4\u65b0\u56e0\u5b50\u4e3a etaminus\n            sign.copy_(torch.where(sign.eq(0), 1, sign))         # \u7b26\u53f7\u4e3a0\uff0c\u66f4\u65b0\u56e0\u5b50\u4e3a 1 (\u6b65\u957f\u4e0d\u53d8)\n        else:\n            # \u5e38\u89c4\u6a21\u5f0f\u4e0b\u4f7f\u7528\u7d22\u5f15\u8d4b\u503c\uff0c\u901a\u5e38\u66f4\u9ad8\u6548\n            sign[sign.gt(0)] = etaplus\n            sign[sign.lt(0)] = etaminus\n            sign[sign.eq(0)] = 1\n\n        # 3. \u66f4\u65b0\u6b65\u957f\n        # \u7528\u66f4\u65b0\u56e0\u5b50\u4e58\u4ee5\u5f53\u524d\u6b65\u957f\uff0c\u5e76\u5c06\u5176\u9650\u5236\u5728 [step_size_min, step_size_max] \u8303\u56f4\u5185\n        step_size.mul_(sign).clamp_(step_size_min, step_size_max)\n\n        # 4. \u6839\u636e Rprop \u89c4\u5219\u4fee\u6539\u5f53\u524d\u68af\u5ea6\n        # \u8fd9\u662f\u4e00\u4e2a Rprop \u7684\u53d8\u4f53\u89c4\u5219\uff1a\u5982\u679c\u68af\u5ea6\u7b26\u53f7\u53cd\u8f6c (sign.eq(etaminus))\uff0c\n        # \u5219\u672c\u6b21\u66f4\u65b0\u7684\u68af\u5ea6\u8bbe\u4e3a0\uff0c\u610f\u5473\u7740\u53c2\u6570\u5728\u8fd9\u4e00\u6b65\u4e0d\u79fb\u52a8\u3002\n        grad = grad.clone(memory_format=torch.preserve_format)\n        if capturable:\n            grad.copy_(torch.where(sign.eq(etaminus), 0, grad))\n        else:\n            grad[sign.eq(etaminus)] = 0\n\n        # 5. \u66f4\u65b0\u53c2\u6570\n        # \u53c2\u6570\u7684\u66f4\u65b0\u91cf\u53ea\u53d6\u51b3\u4e8e\u5f53\u524d\u68af\u5ea6\u7684\u7b26\u53f7\u548c\u66f4\u65b0\u540e\u7684\u6b65\u957f\n        # \u516c\u5f0f: param_t = param_{t-1} - sign(grad_t) * step_size_t\n        param.addcmul_(grad.sign(), step_size, value=-1)\n\n        # 6. \u4fdd\u5b58\u5f53\u524d\u68af\u5ea6\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u6b65\u7684 \"prev\"\n        prev.copy_(grad)\n</code></pre> <p>\u4ee3\u7801\u76f8\u5bf9\u521a\u521a\u7684\u8bb2\u89e3\u591a\u4e86\u4ebf\u70b9\u70b9\u7ec6\u8282\uff0c\u56e0\u4e3a\u5b83\u5b9e\u73b0\u7684\u662f\u540d\u53eb Rprop with weight-backtracking \u7684\u7b97\u6cd5\u3002\u8fd9\u4e2a\u6539\u8fdb\u7684\u4f5c\u7528\u4f53\u73b0\u5728\u6211\u4eec\u4e4b\u524d\u63d0\u8fc7\u65e0\u6570\u6b21\u7684\u692d\u5706\u629b\u7269\u9762\u4e0a\u9762\uff0c\u52a0\u5165 <code>sign</code> \u9879\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u68c0\u6d4b\u5230\u68af\u5ea6\u5728\u201c\u53cd\u590d\u6a2a\u8df3\u201d\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u4e0d\u5e94\u8be5\u653e\u4efb\u5b83\u8df3\uff0c\u800c\u662f\u51cf\u5c11\u6b65\u957f\u624d\u66f4\u6709\u5e0c\u671b\u843d\u5230\u4e0b\u9762\u3002</p>"}, {"location": "DNN/optimizer/SignGD/#lion", "title": "Lion", "text": "<p>Lion \u4f18\u5316\u5668\u662f Google \u56e2\u961f\u641c\u51fa\u6765\u7684\u4f18\u5316\u5668\uff0c\u5c3d\u7ba1\u4e0d\u662f\u4ece\u67d0\u4e2a\u7406\u8bba\u63a8\u5bfc\u4e0b\u6765\uff0cLion \u4f18\u5316\u5668\u4ecd\u7136\u5728\u540c\u7b49\u53c2\u6570\u91cf\u4e0b\u53d6\u5f97\u4e86\u81f3\u5c11\u548c AdamW \u6253\u5e73\u7684\u6027\u80fd\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0cLion \u4f18\u5316\u5668\u7684\u53c2\u6570\u66f4\u65b0\u89c4\u5219\u662f\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla\\mathcal{L(x;\\theta_{n-1})}\\\\     G_n&amp;=\\mathrm{sign}(\\beta_1 M_{n-1}+(1-\\beta_1)g_n)\\\\     \\theta_n&amp;=\\theta_{n-1}+\\eta(G_n+\\lambda \\theta_{n-1})\\\\     M_n &amp;= \\beta_2 M_{n-1}+(1-\\beta_2)g_n \\end{align*} \\] <p>\u53ef\u4ee5\u770b\u5230\uff0cLion \u7c7b\u4f3c\u4e8e\u5f15\u5165\u52a8\u91cf\u7684 Rprop\uff0c\u4e0d\u8fc7\u53ea\u662f\u628a\u52a8\u91cf\u7684\u66f4\u65b0\u653e\u5230\u4e86\u6700\u540e\u3002\u8fd9\u91cc\u6ca1\u6709\u4f7f\u7528\u5168\u91cf\u8ba1\u7b97\uff0c\u800c\u662f\u4f7f\u7528\u5e73\u5747\u68af\u5ea6\u6765\u89c4\u907f\u5168\u91cf\u8ba1\u7b97\u7684\u590d\u6742\u5ea6\u3002\u7531\u4e8e\u52a8\u91cf\u7684\u5f15\u5165\uff0cLion \u9700\u8981\u66f4\u5c0f\u7684\u5b66\u4e60\u7387\u3002</p> <p>\u8ba9\u6211\u4eec\u770b\u770b Lion \u7684\u6548\u679c\uff1a</p> <p></p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u89c1 Lion \u4e5f\u5728\u8fd9\u4e24\u4e2a\u5730\u5f62\u83b7\u5f97\u4e86\u4e0d\u9519\u7684\u8868\u73b0\u3002\u867d\u7136\u5728 rastrigin \u5730\u5f62\u4e0b\u9762 hyperopt \u5e76\u6ca1\u6709\u641c\u51fa\u4e00\u4e2a\u7279\u522b\u597d\u7684\u53c2\u6570\uff08\u7b2c\u4e00\u5f20\u56fe\u592a\u5c0f\u7b2c\u4e8c\u5f20\u56fe\u592a\u5927\uff09\uff0c\u4f46\u662f\u5bf9\u4e8e rosenbrock \u5730\u5f62\uff0cLion \u53d6\u5f97\u4e86\u6211\u4eec\u76ee\u524d\u6240\u89c1\u6700\u5feb\u7684\u8c37\u5e95\u884c\u8fdb\u901f\u5ea6\u3002</p> <p></p> <p></p> <p>Lion \u5728\u8fd9\u4e2a\u4efb\u52a1\u4e0b\u9762\u76f8\u5f53\u80fd\u6253\u554a\u3002\u4ec5\u9700\u8981\u7ea6 3500 \u4e2a batch \u5c31\u53ef\u4ee5\u5c06 train_loss \u964d\u5230 0.1 \u6c34\u5e73\uff0c\u7ea6 700 \u4e2a batch \u5c31\u53ef\u4ee5\u628a acc \u5237\u4e0a 0.9\u3002</p> <p>\u8ba9\u6211\u4eec\u770b\u770b <code>torch-optimizer</code> \u5e93\u7684\u5b9e\u73b0\uff1a</p>  Lion \u4f18\u5316\u5668\u7684\u5b9e\u73b0  <pre><code># \u5bfc\u5165 PyTorch \u6838\u5fc3\u5e93\nimport torch\n# \u4ece PyTorch \u4f18\u5316\u5668\u57fa\u7c7b\u4e2d\u5bfc\u5165 Optimizer\uff0c\u6240\u6709\u81ea\u5b9a\u4e49\u4f18\u5316\u5668\u90fd\u5e94\u7ee7\u627f\u5b83\nfrom torch.optim.optimizer import Optimizer\n\n# \u4ece\u672c\u5730\u7c7b\u578b\u5b9a\u4e49\u6587\u4ef6\u4e2d\u5bfc\u5165\u7c7b\u578b\u63d0\u793a\uff0c\u589e\u5f3a\u4ee3\u7801\u53ef\u8bfb\u6027\n# Betas2: \u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u6d6e\u70b9\u6570\u7684\u5143\u7ec4\uff0c\u5982 (0.9, 0.99)\n# OptFloat: \u53ef\u9009\u7684\u6d6e\u70b9\u6570\uff0c\u5373 float \u6216 None\n# OptLossClosure: \u53ef\u9009\u7684\u635f\u5931\u95ed\u5305\u51fd\u6570\n# Params: \u53ef\u8fed\u4ee3\u7684\u53c2\u6570\u6216\u5b9a\u4e49\u4e86\u53c2\u6570\u7ec4\u7684\u5b57\u5178\nfrom torch_optimizer.types import Betas2, OptFloat, OptLossClosure, Params\n\n# \u5b9a\u4e49\u5f53 `from module import *` \u65f6\uff0c\u54ea\u4e9b\u5bf9\u8c61\u4f1a\u88ab\u5bfc\u51fa\n__all__ = (\"Lion\",)\n\n\n# \u5b9a\u4e49 Lion \u4f18\u5316\u5668\u7c7b\uff0c\u5b83\u7ee7\u627f\u81ea PyTorch \u7684 Optimizer \u57fa\u7c7b\nclass Lion(Optimizer):\n    r\"\"\"\u5b9e\u73b0\u4e86 Lion \u7b97\u6cd5\u3002\n\n    \u4ee3\u7801\u6539\u7f16\u81ea Google \u7684\u5b98\u65b9\u5b9e\u73b0: https://github.com/google/automl/tree/master/lion\n\n    Lion - EvoLved SIgn MOmeNtum (\u6f14\u8fdb\u7684\u7b26\u53f7\u52a8\u91cf) \u7b97\u6cd5\u5728\n    \u8bba\u6587 https://arxiv.org/pdf/2302.06675.pdf \u4e2d\u88ab\u63d0\u51fa\u3002\n    Lion \u7684\u76ee\u6807\u662f\u901a\u8fc7\u53ea\u8ddf\u8e2a\u52a8\u91cf\u6765\u6bd4 Adam \u7b97\u6cd5\u66f4\u8282\u7701\u5185\u5b58\u3002\n\n    \u6ce8\u610f\u4e8b\u9879:\n    - \u5982\u8bba\u6587\u4e2d\u6240\u8ff0\uff0cLion \u9700\u8981\u4e00\u4e2a\u66f4\u5c0f\u7684\u5b66\u4e60\u7387 (lr)\u3002\n    - \u4e3a\u4e86\u7ef4\u6301\u6709\u6548\u7684\u6743\u91cd\u8870\u51cf\u5f3a\u5ea6\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5927\u7684\u89e3\u8026\u6743\u91cd\u8870\u51cf (decoupled weight decay) \u503c\u3002\n    - Lion \u7684\u6027\u80fd\u589e\u76ca\u4f1a\u968f\u7740\u6279\u5904\u7406\u5927\u5c0f (batch size) \u7684\u589e\u52a0\u800c\u53d8\u5927\u3002\n    - \u6b64\u5916\uff0c\u5728\u4e00\u4e9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c/\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\uff0cLion \u5e76\u672a\u88ab\u53d1\u73b0\u80fd\u8d85\u8d8a AdamW\u3002\n\n    \u53c2\u6570:\n        params: \u9700\u8981\u4f18\u5316\u7684\u3001\u53ef\u8fed\u4ee3\u7684\u53c2\u6570\uff0c\u6216\u5b9a\u4e49\u4e86\u53c2\u6570\u7ec4\u7684\u5b57\u5178\u3002\n        lr: \u5b66\u4e60\u7387 (learning rate)\uff0c\u9ed8\u8ba4\u4e3a 1e-4 (\u6ce8\u610f\uff0c\u8bba\u6587\u5efa\u8bae\u6bd4 Adam \u5c0f 3-10 \u500d)\u3002\n        betas: \u7528\u4e8e\u8ba1\u7b97\u68af\u5ea6\u53ca\u5176\u5e73\u65b9\u7684\u8fd0\u884c\u5e73\u5747\u503c\u7684\u7cfb\u6570 (\u9ed8\u8ba4: (0.9, 0.99))\u3002\n               \u5728 Lion \u4e2d\uff0cbeta1 \u7528\u4e8e\u63d2\u503c\uff0cbeta2 \u7528\u4e8e\u52a8\u91cf\u66f4\u65b0\u3002\n        weight_decay: \u6743\u91cd\u8870\u51cf (L2 \u60e9\u7f5a\u9879) (\u9ed8\u8ba4: 0)\u3002\n\n    \u793a\u4f8b:\n        &gt;&gt;&gt; import torch_optimizer as optim\n        &gt;&gt;&gt; optimizer = optim.Lion(model.parameters(), lr=0.001)\n        &gt;&gt;&gt; optimizer.zero_grad()\n        &gt;&gt;&gt; loss_fn(model(input), target).backward()\n        &gt;&gt;&gt; optimizer.step()\n    \"\"\"\n\n    # \u7c7b\u7684\u6784\u9020\u51fd\u6570\n    def __init__(\n        self,\n        params: Params,\n        lr: float = 1e-4,          # \u5b66\u4e60\u7387\n        betas: Betas2 = (0.9, 0.99), # beta \u53c2\u6570\n        weight_decay: float = 0.0, # \u6743\u91cd\u8870\u51cf\u7cfb\u6570\n    ):\n        # --- \u8f93\u5165\u53c2\u6570\u5408\u6cd5\u6027\u68c0\u67e5 ---\n        if lr &lt;= 0.0:\n            raise ValueError(\"\u65e0\u6548\u7684\u5b66\u4e60\u7387: {}\".format(lr))\n        if not 0.0 &lt;= betas[0] &lt; 1.0:\n            raise ValueError(\n                \"\u65e0\u6548\u7684 beta \u53c2\u6570 (\u7d22\u5f15 0): {}\".format(betas[0])\n            )\n        if not 0.0 &lt;= betas[1] &lt; 1.0:\n            raise ValueError(\n                \"\u65e0\u6548\u7684 beta \u53c2\u6570 (\u7d22\u5f15 1): {}\".format(betas[1])\n            )\n        if weight_decay &lt; 0:\n            raise ValueError(\n                \"\u65e0\u6548\u7684 weight_decay \u503c: {}\".format(weight_decay)\n            )\n\n        # \u5c06\u8d85\u53c2\u6570\u6253\u5305\u6210\u4e00\u4e2a\u5b57\u5178\uff0c\u4f5c\u4e3a\u9ed8\u8ba4\u914d\u7f6e\n        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n        # \u8c03\u7528\u7236\u7c7b (Optimizer) \u7684\u6784\u9020\u51fd\u6570\uff0c\u5b8c\u6210\u521d\u59cb\u5316\n        super().__init__(params, defaults)\n\n    # `@torch.no_grad()` \u662f\u4e00\u4e2a\u88c5\u9970\u5668\uff0c\u5b83\u4f1a\u7981\u7528\u6b64\u51fd\u6570\u5185\u7684\u68af\u5ea6\u8ba1\u7b97\u3002\n    # \u8fd9\u5bf9\u4e8e\u4f18\u5316\u5668\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u662f\u5728\u4fee\u6539\u53c2\u6570\u503c\uff0c\u800c\u4e0d\u662f\u5728\u8ba1\u7b97\u5173\u4e8e\u8fd9\u4e9b\u4fee\u6539\u7684\u68af\u5ea6\u3002\n    @torch.no_grad()\n    def step(self, closure: OptLossClosure = None) -&gt; OptFloat:\n        r\"\"\"\u6267\u884c\u5355\u6b65\u4f18\u5316\u3002\n\n        \u53c2\u6570:\n            closure: \u4e00\u4e2a\u53ef\u4ee5\u91cd\u65b0\u8bc4\u4f30\u6a21\u578b\u5e76\u8fd4\u56de\u635f\u5931\u7684\u95ed\u5305\u51fd\u6570 (\u53ef\u9009)\u3002\n        \"\"\"\n        loss = None\n        # \u5982\u679c\u63d0\u4f9b\u4e86\u95ed\u5305\u51fd\u6570 (closure)\uff0c\u5219\u6267\u884c\u5b83\u6765\u8ba1\u7b97\u635f\u5931\u3002\n        # \u8fd9\u5728\u67d0\u4e9b\u4f18\u5316\u7b97\u6cd5\uff08\u5982 L-BFGS\uff09\u4e2d\u5f88\u5e38\u89c1\uff0c\u53ef\u4ee5\u591a\u6b21\u8bc4\u4f30\u6a21\u578b\u3002\n        if closure is not None:\n            with torch.enable_grad(): # \u5728\u95ed\u5305\u5185\u9700\u8981\u786e\u4fdd\u68af\u5ea6\u662f\u5f00\u542f\u7684\n                loss = closure()\n\n        # \u904d\u5386\u6240\u6709\u7684\u53c2\u6570\u7ec4 (param_groups)\uff0c\u4f8b\u5982\u53ef\u4ee5\u4e3a\u6a21\u578b\u7684\u4e0d\u540c\u90e8\u5206\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\n        for group in self.param_groups:\n            # \u904d\u5386\u5f53\u524d\u53c2\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e00\u4e2a\u53c2\u6570 (p)\n            for p in group[\"params\"]:\n                # \u5982\u679c\u53c2\u6570\u6ca1\u6709\u68af\u5ea6 (\u4f8b\u5982\uff0c\u5728\u51bb\u7ed3\u5c42\u4e2d)\uff0c\u5219\u8df3\u8fc7\n                if p.grad is None:\n                    continue\n\n                # --- \u6838\u5fc3\u7b97\u6cd5\u5f00\u59cb ---\n\n                # 1. \u6267\u884c\u89e3\u8026\u6743\u91cd\u8870\u51cf (Decoupled Weight Decay)\n                # \u8fd9\u662f\u4e00\u79cd L2 \u6b63\u5219\u5316\u7684\u5f62\u5f0f\uff0c\u5b83\u76f4\u63a5\u4ece\u53c2\u6570\u4e2d\u51cf\u53bb\u4e00\u4e2a\u4e0e\u5176\u81ea\u8eab\u5927\u5c0f\u6210\u6b63\u6bd4\u7684\u503c\u3002\n                # \u6ce8\u610f\u8fd9\u91cc\u7684\u8870\u51cf\u91cf\u662f `lr * weight_decay`\uff0c\u4e0e AdamW \u4e0d\u540c (AdamW \u662f `weight_decay`)\u3002\n                p.data.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n\n                grad = p.grad\n                state = self.state[p] # \u83b7\u53d6\u8be5\u53c2\u6570\u7684\u72b6\u6001\u5b57\u5178\uff0c\u7528\u4e8e\u5b58\u50a8\u52a8\u91cf\u7b49\u4fe1\u606f\n\n                # 2. \u72b6\u6001\u521d\u59cb\u5316 (State Initialization)\n                # \u5982\u679c\u4e00\u4e2a\u53c2\u6570\u7b2c\u4e00\u6b21\u88ab\u4f18\u5316\uff0c\u5176\u72b6\u6001\u5b57\u5178 `state` \u662f\u7a7a\u7684\n                if len(state) == 0:\n                    # \u521d\u59cb\u5316\u52a8\u91cf (momentum)\uff0c\u547d\u540d\u4e3a `exp_avg` \u4ee5\u4e0e Adam \u4fdd\u6301\u4e00\u81f4\n                    # \u521b\u5efa\u4e00\u4e2a\u4e0e\u53c2\u6570 p \u5f62\u72b6\u76f8\u540c\u3001\u503c\u5168\u4e3a 0 \u7684\u5f20\u91cf\n                    state[\"exp_avg\"] = torch.zeros_like(p)\n\n                # \u83b7\u53d6\u52a8\u91cf\u548c beta \u7cfb\u6570\n                exp_avg = state[\"exp_avg\"]\n                beta1, beta2 = group[\"betas\"]\n\n                # 3. \u8ba1\u7b97\u7528\u4e8e\u66f4\u65b0\u7684\u63d2\u503c (Interpolation for update)\n                # \u8fd9\u4e00\u6b65\u662f Lion \u7b97\u6cd5\u7684\u6838\u5fc3\u4e4b\u4e00\u3002\u5b83\u4f7f\u7528 beta1 \u6765\u6df7\u5408\uff08\u63d2\u503c\uff09\u65e7\u7684\u52a8\u91cf\u548c\u5f53\u524d\u7684\u68af\u5ea6\u3002\n                # \u516c\u5f0f: c_t = \u03b2\u2081 * m_t + (1 - \u03b2\u2081) * g_t\n                update = exp_avg.mul(beta1).add(grad, alpha=1 - beta1)\n\n                # 4. \u53c2\u6570\u66f4\u65b0 (Parameter Update)\n                # \u4f7f\u7528 `update` \u7684\u7b26\u53f7 (sign) \u6765\u66f4\u65b0\u53c2\u6570\u3002\n                # `torch.sign(update)` \u4f1a\u5f97\u5230\u4e00\u4e2a\u7531 -1, 0, 1 \u7ec4\u6210\u7684\u5f20\u91cf\u3002\n                # `p.add_(..., alpha=-lr)` \u7b49\u4ef7\u4e8e `p.data = p.data - lr * torch.sign(update)`\u3002\n                # \u8fd9\u662f \"Sign Momentum\" \u540d\u79f0\u7684\u7531\u6765\u3002\n                p.add_(torch.sign(update), alpha=-group[\"lr\"])\n\n                # 5. \u66f4\u65b0\u52a8\u91cf (Momentum Update)\n                # \u8fd9\u4e00\u6b65\u4f7f\u7528 beta2 \u6765\u66f4\u65b0\u52a8\u91cf\uff0c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u505a\u51c6\u5907\u3002\n                # \u516c\u5f0f: m_{t+1} = \u03b2\u2082 * m_t + (1 - \u03b2\u2082) * g_t\n                # `exp_avg.mul_(beta2)`: \u5148\u5c06\u65e7\u52a8\u91cf\u4e58\u4ee5 beta2\n                # `.add_(grad, alpha=1 - beta2)`: \u518d\u52a0\u4e0a `(1 - beta2) * grad`\n                exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n\n        # \u8fd4\u56de\u672c\u6b21 step \u8ba1\u7b97\u7684\u635f\u5931\u503c\uff08\u5982\u679c\u63d0\u4f9b\u4e86\u95ed\u5305\uff09\n        return loss\n</code></pre>"}, {"location": "DNN/optimizer/SignGD/#muon", "title": "Muon", "text": "<p>\u6700\u540e\u8ba9\u6211\u4eec\u796d\u51fa Muon \u4f18\u5316\u5668\uff0c\u4e5f\u5c31\u662f Kimi-K2 \u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u4f18\u5316\u5668\u3002\u8fd9\u4e00\u8282\u7684\u64b0\u5199\uff0c\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53c2\u8003\u4e86\u82cf\u5251\u6797\u7684\u535a\u5ba2\u3002</p> <p>\u6211\u4eec\u8ba1\u5212\u4ece\u4e24\u6761\u8def\u7ebf\u201c\u5305\u6284\u201d\u63a8\u5bfc Muon \u4f18\u5316\u5668\u3002</p> <p>\u7b2c\u4e00\u6761\u601d\u8def\u662f Lion \u4f18\u5316\u5668\u7684\u601d\u8def\uff0c\u6216\u8005\u8bf4\u662f Rprop \u7684\u601d\u8def\u3002\u6700\u5f00\u59cb\u5bf9 Rprop \u7684\u5206\u6790\u5efa\u7acb\u5728\u53c2\u6570\u66f4\u65b0\u91cf\u662f \\(-\\eta\\dfrac{g}{\\sqrt{\\bar g^2}}\\) \u7684\u57fa\u7840\u4e0a\uff0c\u7136\u540e\u975e\u5e38\u6b66\u65ad\u5730\u8ba4\u4e3a\u5bf9\u4e8e\u77e9\u9635\u800c\u8a00 \\(\\dfrac{g}{\\sqrt{\\bar g^2}}=\\mathrm{sign}(g)\\)\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u4ece\u8868\u8fbe\u5f0f\u672c\u8eab\u51fa\u53d1\u5462\uff1f</p> <p>\u8ba9\u6211\u4eec\u56de\u5230\u68a6\u5f00\u59cb\u7684\u5730\u65b9\uff0cAdaGrad \u4f18\u5316\u5668\u7684\u521d\u8877\u662f\u8ba1\u7b97 \\(\\dfrac{g}{\\sqrt{gg^\\top}}\\)\u3002\u8003\u8651\u5355\u4e2a fc layer\uff08\u6b63\u5982\u6211\u4eec\u5728 Shampoo \u4f18\u5316\u5668\u4e2d\u505a\u7684\u90a3\u6837\uff09\uff0c\u5219 \\(g\\) \u662f\u4e00\u4e2a \\(n\\times m\\) \u7684\u77e9\u9635\u3002\u8fd9\u542f\u53d1\u6211\u4eec\u8bbe\u8ba1\u8fd9\u6837\u4e00\u4e2a\u77e9\u9635\u7b26\u53f7\u51fd\u6570\uff1a\\(\\mathrm{msign}(M)=(MM^\\top)^{-\\frac 12}M\\)\u3002</p> <p>\u4f9d\u65e7\u662f\u548c Shampoo \u4f18\u5316\u5668\u4e00\u6837\uff0c\u77e9\u9635\u7684\u9006 \\(p\\) \u6b21\u65b9\u6839\u662f\u901a\u8fc7 SVD \u8ba1\u7b97\uff08\u5f97\u5230\u63a8\u5e7f\uff09\u7684\u3002\u4e5f\u5c31\u662f\u8003\u8651 \\(M=U\\Sigma V^\\top\\) \u5219 \\(M^{-\\frac 1p}=U\\Sigma^{-\\frac 1p}V^\\top\\)\u3002</p> <p>\u5bf9 \\(M\\) \u505a SVD \u4e5f\u5c31\u662f \\(M=U\\Sigma V^\\top\\)\uff0c\u90a3\u4e48\uff1a</p> \\[ \\begin{align*}     \\mathrm{msign}(M)&amp;=(U\\Sigma V^\\top V\\Sigma U^\\top)^{-\\frac 12}(U\\Sigma V^\\top)\\\\     &amp;=(U\\Sigma^2U^\\top)^{-\\frac 12}(U\\Sigma V^\\top)\\\\     &amp;=U\\Sigma^{-1}U^\\top U\\Sigma V^\\top\\\\     &amp;=U_{[:r]}V_{[:r]}^\\top \\end{align*} \\] <p>\u5176\u4e2d \\(r\\) \u4e3a \\(M\\) \u7684\u5947\u5f02\u503c\u4e2a\u6570\u3002</p> <p>\u5229\u7528\u8fd9\u4e2a\u77e9\u9635\u7b26\u53f7\u51fd\u6570\u4ee3\u66ff Rprop \u7684\u7b26\u53f7\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u52a8\u91cf\uff08\u4f46\u662f\uff0c\u4e0d\u50cf Lion \u4e00\u6837\u628a\u52a8\u91cf\u7684\u66f4\u65b0\u653e\u5728\u6700\u540e\uff09\uff0c\u5c31\u5f97\u5230 Muon \u4f18\u5316\u5668\u7684\u66f4\u65b0\u516c\u5f0f\u4e86\uff1a</p> \\[ \\begin{align*}     g_n&amp;=\\nabla \\mathcal{L}(x;\\theta_{n-1})\\\\     M_n&amp;=\\beta M_{n-1}+g_n\\\\     \\theta_n&amp;=\\theta_{n-1}-\\eta\\mathrm{msign}(M_n+\\lambda \\theta_{n-1}) \\end{align*} \\] <p>\u8fd9\u91cc\u548c Lion \u4e0d\u4e00\u6837\u7684\u662f\u628a\u6b63\u5219\u5316\u89e3\u8026\u5230\u4e86\u7b26\u53f7\u51fd\u6570\u91cc\u9762\u3002</p> <p>\u7b2c\u4e8c\u6761\u8def\uff0c\u5982\u679c\u6211\u4eec\u91cd\u65b0\u5ba1\u89c6 Shampoo \u4f18\u5316\u5668\u5728\u4e00\u4e2a fc layer \u7684\u60c5\u51b5\uff1a</p> \\[ \\begin{align*}     L_n &amp;= \\beta L_{n-1} + g_n g_n^\\top\\\\ R_n &amp;= \\beta R_{n-1} + g_n^\\top g_n\\\\ H^{-\\frac 12}g&amp;=L^{- \\frac 14}g_nR^{- \\frac 14} \\end{align*} \\] <p>\u5728 \\(\\beta=0\\) \u7684\u65f6\u5019\uff0c\u6211\u4eec\u6709\uff1a</p> \\[ \\begin{align*}     L^{- \\frac 14}gR^{- \\frac 14}=(g_n g_n^\\top)^{- \\frac 14}g_n(g_n^\\top g_n)^{- \\frac 14} \\end{align*} \\] <p>\u5bf9 \\(g_n\\) \u505a SVD \u5373 \\(g_n=U\\Sigma V^\\top\\)\uff0c\u63a5\u7740\u63a8\u5f0f\u5b50\uff1a</p> \\[ \\begin{align*}     L^{- \\frac 14}gR^{- \\frac 14}&amp;=(g_n g_n^\\top)^{- \\frac 14}g_n(g_n^\\top g_n)^{- \\frac 14}\\\\     &amp;=(U\\Sigma V^\\top V\\Sigma U^\\top)^{- \\frac 14}(U\\Sigma V^\\top)(V\\Sigma U^\\top U\\Sigma V^\\top)\\\\     &amp;=(U\\Sigma^2 U^\\top)^{- \\frac 14}(U\\Sigma V^\\top)(V\\Sigma^2 V^\\top)^{- \\frac 14}\\\\     &amp;=U\\Sigma^{- \\frac 12}\\Sigma \\Sigma^{- \\frac 12} V^\\top\\\\     &amp;=\\mathrm{msign}(g_n) \\end{align*} \\] <p>\u8fd9\u610f\u5473\u7740 Shampoo \u4e5f\u51a5\u51a5\u4e2d\u4f7f\u7528\u4e86 \\(\\mathrm{msign}\\) \u51fd\u6570\uff01</p> <p>\u53cd\u89c2 Muon \u7684\u663e\u5b58\u5360\u7528\u548c SGDM \u4e00\u6837\uff0c\u4f46\u662f\u7406\u8bba\u4e0a\u6253\u5305\u7b97\u51fa\u4e86 \\(gg^\\top\\)\uff0c\u6548\u679c\u5e94\u8be5\u4f1a\u76f8\u5f53\u8d5e\u554a\uff01</p> <p>\u6211\u4eec\u77e5\u9053 Shampoo \u4f18\u5316\u5668\u7684\u76ee\u6807\u662f\u4f7f\u7528 Kronecker \u79ef\u9ad8\u6548\u4f18\u5316 Hessian \u8ba1\u7b97\uff0c\u6700\u7ec8\u8fd1\u4f3c \\(gg^\\top\\)\uff1b\u800c Muon \u4e00\u4e2a\u6253\u5305\u5904\u7406\uff0c\u5c31\u975e\u5e38\u9ad8\u6548\u5730\u8ba1\u7b97\u51fa\u6765\u4e86\u2026\u2026\u5417\uff1f</p> <p>\u6211\u4eec\u53ea\u662f\u5f97\u5230\u4e86\u53c2\u6570\u66f4\u65b0\u65f6\uff0c\u5982\u679c\u6bcf\u4e00\u6b21\u90fd\u8981\u8ba1\u7b97 SVD \u7684\u8bdd\uff0c\u90a3\u4ee3\u4ef7\u4ecd\u7136\u662f\u4e0d\u53ef\u627f\u62c5\u7684\u3002\u8fd9\uff0c\u4fbf\u662f Muon \u6700\u540e\u4e00\u4e2a\u5b57 N (for Newton-Schulz) \u7684\u542b\u4e49\uff01</p> <p>\u6211\u4eec\u4e0d\u4f7f\u7528 SVD\uff0c\u800c\u662f\u91c7\u7528 \\(\\mathrm{msign}(M)=(MM^\\top)^{-\\frac 12}M\\) \u6765\u8ba1\u7b97\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u8981\u8ba1\u7b97 \\((MM^\\top)^{-\\frac 12}\\)\u3002</p> <p>Muon \u7684\u4f5c\u8005\u4f7f\u7528 Newton-Schulz \u8fed\u4ee3\u6765\u8ba1\u7b97\u8fd9\u4e2a\u77e9\u9635\u3002Newton-Schulz \u8fed\u4ee3\u662f\u4e00\u79cd\u8fed\u4ee3\u6cd5\u77e9\u9635\u6c42\u9006\u7b97\u6cd5\uff0c\u4ece \\(AX=I\\) \u5f00\u59cb\u7528 Newton \u6cd5\u7c7b\u4f3c\u7684\u8fed\u4ee3\u5f0f\u5b50\u9010\u6b65\u6c42\u89e3 \\(X=A^{-1}\\)\u3002</p> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5176\u5b9e\u662f\u4ece \\(MM^\\top=I\\) \u5f00\u59cb\u8fdb\u884c\u8fed\u4ee3\u3002\u4e5f\u5c31\u662f\u5c06 \\((MM^\\top)^{-\\frac 12}\\) \u8fd1\u4f3c\u6210 \\(MM^\\top-I\\) \u7684\u591a\u9879\u5f0f\u3002\u563f\uff0c\u6211\u77e5\u9053\u4f60\u5728\u60f3\u6cf0\u52d2\u5c55\u5f00\u7684\u4e8b\u60c5\uff0c\u4f46\u662f\u60f3\u60f3\u6211\u4eec\u6700\u5c0f/\u5927\u5316\u7684\u662f\u4ec0\u4e48\uff1f\uff08\u6bd4\u5982\uff0c\u5982\u679c\u6211\u4eec\u60f3\u6700\u5927\u5316\u6b63\u5f26\u548c\u4e09\u6b21\u51fd\u6570\u7684\u76f8\u4f3c\u5ea6\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u57fa\u4e8e\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u7684\u5085\u91cc\u53f6\u7ea7\u6570\u6765\u5c55\u5f00\u800c\u4e0d\u662f\u4f7f\u7528\u6cf0\u52d2\u5c55\u5f00\u2026\u2026\uff09</p> <p>\u6240\u4ee5\u522b\u6025\u3002\u6211\u4eec\u8003\u8651\u5c55\u5f00\u5230\u4e09\u9879\uff0c\u4e5f\u5c31\u662f</p> \\[ \\mathrm{msign}(M)\\approx aM+b(MM^\\top)M+c(MM^\\top)^2M \\] <p>\u6211\u4eec\u7684\u4f18\u5316\u76ee\u6807\u662f\uff1a\u5c3d\u53ef\u80fd\u5bf9\u4e8e\u6240\u6709\u7684 \\(M\\) \u90fd\u5177\u6709\u6700\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002</p> <p>\u6211\u4eec\u5bf9 \\(M\\) \u505a\u4e00\u4e0b SVD\uff0c\u4e5f\u5c31\u662f</p> \\[ \\begin{align*}     \\mathrm{msign}(M)&amp;=aU\\Sigma V^\\top+b(U\\Sigma V^\\top V\\Sigma U^\\top)(U\\Sigma V^\\top)+c(U\\Sigma V^\\top V\\Sigma U^\\top)^2(U\\Sigma V^\\top)\\\\     &amp;=aU\\Sigma V^\\top+bU\\Sigma^3V^\\top+cU\\Sigma^5V^\\top\\\\     &amp;=U(a\\Sigma+b\\Sigma^3+c\\Sigma^5)V^\\top \\end{align*} \\] <p>\u5bf9\u4e8e\u5947\u5f02\u503c\u7684\u6bcf\u4e00\u9879 \\(\\sigma\\in(0,1]\\) \u800c\u8a00\uff0c\u6211\u4eec\u5176\u5b9e\u5e0c\u671b \\(a\\sigma+b\\sigma^3+c\\sigma^5\\) \u80fd\u591f\u5728 \\(k\\) \u6b21\u8fed\u4ee3\u4e2d\u5c3d\u91cf\u903c\u8fd1 \\(1\\)\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u5c31\u53ef\u4ee5\u8bbe\u8ba1\u95ee\u9898\u4e86\uff1a\u56fa\u5b9a\u8fed\u4ee3\u6b21\u6570 \\(k\\)\uff0c\u4ee4 \\(f(x)=ax+bx^3+cx^5(x\\in(0,1])\\)\uff0c\u7136\u540e\u635f\u5931\u51fd\u6570\u4f7f\u7528 MSE\uff1a\\(\\mathcal{L}([1-f^{(k)}(x)]^2;a,b,c)\\)\uff0c\u5bfb\u627e \\(a,b,c\\) \u4f7f\u5f97 \\(\\mathcal{L}\\) \u6700\u5c0f\u3002\u6211\u4eec\u91c7\u7528 Adam \u6765\u8dd1\u4e00\u8dd1\u3002</p>  \u4f18\u5316\u4f7f\u7528\u7684\u4ee3\u7801 <pre><code>import torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- 1. \u8bbe\u7f6e\u8d85\u53c2\u6570\u548c\u56fa\u5b9a\u503c ---\nk = 5                # \u56fa\u5b9a\u8fed\u4ee3\u6b21\u6570\nlearning_rate = 5e-5 # Adam \u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\nnum_steps = 100000     # \u4f18\u5316\u6b65\u6570\nbatch_size = 2048    # \u6bcf\u6b65\u4f18\u5316\u4e2d\u91c7\u6837\u7684 x \u7684\u6570\u91cf\n\na = torch.tensor([1.0], requires_grad=True)\nb = torch.tensor([-1.0], requires_grad=True)\nc = torch.tensor([1.0], requires_grad=True)\n\n# --- 3. \u8bbe\u7f6e\u4f18\u5316\u5668 ---\n# \u4f7f\u7528 Adam \u4f18\u5316\u5668\u6765\u66f4\u65b0 a, b, c\noptimizer = optim.Adam([a, b, c], lr=learning_rate)\n\n# \u5b58\u50a8\u5386\u53f2\u8bb0\u5f55\u4ee5\u4f9b\u53ef\u89c6\u5316\nloss_history = []\na_history, b_history, c_history = [], [], []\n\nprint(f\"\u5f00\u59cb\u4f18\u5316... k={k}, \u521d\u59cb\u503c a={a.item():.2f}, b={b.item():.2f}, c={c.item():.2f}\")\n\n# --- 4. \u4f18\u5316\u5faa\u73af ---\nfor step in range(num_steps):\n    # \u5c06\u68af\u5ea6\u6e05\u96f6\n    optimizer.zero_grad()\n\n    # \u5b9a\u4e49 f(x)\n    def f(x_in):\n        return a * x_in + b * x_in**3 + c * x_in**5\n\n    # \u5728 (0, 1] \u533a\u95f4\u968f\u673a\u91c7\u6837\u4e00\u4e2a mini-batch \u7684 x\n    # torch.rand \u751f\u6210 [0, 1) \u7684\u503c\uff0c\u5bf9\u4e8e\u6211\u4eec\u7684\u76ee\u7684\u6765\u8bf4\u8db3\u591f\u4e86\n    x = torch.rand(batch_size, 1)\n\n    # \u8ba1\u7b97 f^(k)(x)\n    y = x\n    for _ in range(k):\n        y = f(y)\n\n    # \u6700\u7ec8\u7684\u8f93\u51fa\n    f_k_x = y\n\n    # \u5b9a\u4e49\u76ee\u6807\u503c (\u5168\u4e3a 1 \u7684\u5f20\u91cf)\n    target = torch.ones_like(f_k_x)\n\n    # \u8ba1\u7b97\u635f\u5931\u51fd\u6570 (MSE)\n    loss = torch.mean((target - f_k_x)**2)\n\n    # \u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u68af\u5ea6\n    loss.backward()\n\n    # \u4f7f\u7528\u4f18\u5316\u5668\u66f4\u65b0\u53c2\u6570 a, b, c\n    optimizer.step()\n\n    # \u8bb0\u5f55\u5386\u53f2\u6570\u636e\n    loss_history.append(loss.item())\n    a_history.append(a.item())\n    b_history.append(b.item())\n    c_history.append(c.item())\n\n    # \u6bcf 1000 \u6b65\u6253\u5370\u4e00\u6b21\u8fdb\u5ea6\n    if step % 1000 == 0 or step == num_steps - 1:\n        print(f\"Step {step:&gt;{len(str(num_steps))}}: Loss = {loss.item():.8f}, \"\n              f\"a = {a.item():.4f}, b = {b.item():.4f}, c = {c.item():.4f}\")\n\n# --- 5. \u7ed3\u679c\u5c55\u793a ---\nprint(\"\\n--- \u4f18\u5316\u5b8c\u6210 ---\")\nprint(f\"\u56fa\u5b9a\u8fed\u4ee3\u6b21\u6570 k = {k}\")\nprint(f\"\u6700\u7ec8\u635f\u5931: {loss.item():.8f}\")\nprint(f\"\u4f18\u5316\u540e\u7684\u53c2\u6570: a = {a.item():.4f}, b = {b.item():.4f}, c = {c.item():.4f}\")\nprint(f\"\u53c2\u6570\u548c a+b+c = {(a+b+c).item():.4f} (\u7406\u8bba\u4e0a\u5e94\u8d8b\u8fd1\u4e8e 1)\")\n\n\n# --- 6. \u53ef\u89c6\u5316 ---\n\n# \u7ed8\u5236\u635f\u5931\u548c\u53c2\u6570\u503c\u7684\u53d8\u5316\u8fc7\u7a0b\nplt.style.use('seaborn-v0_8-whitegrid')\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n\n# \u7ed8\u5236\u635f\u5931\u51fd\u6570\nax1.plot(loss_history, label='Loss (MSE)', color='red')\nax1.set_ylabel('Loss')\nax1.set_title(f'Loss and Parameter Evolution (k={k})')\nax1.set_yscale('log') # \u4f7f\u7528\u5bf9\u6570\u5750\u6807\u8f74\u4ee5\u4fbf\u89c2\u5bdf\nax1.legend()\n\n# \u7ed8\u5236\u53c2\u6570 a, b, c\nax2.plot(a_history, label='a', linestyle='-')\nax2.plot(b_history, label='b', linestyle='--')\nax2.plot(c_history, label='c', linestyle=':')\nax2.set_xlabel('Optimization Step')\nax2.set_ylabel('Parameter Value')\nax2.legend()\nplt.tight_layout()\nplt.show()\n\n# \u7ed8\u5236\u4f18\u5316\u524d\u540e\u7684\u51fd\u6570 f(x) \u548c f^(k)(x)\nx_plot = torch.linspace(0.01, 1, 200).unsqueeze(1)\n\n# \u4f18\u5316\u540e\u7684\u51fd\u6570\ndef f_final(x_in):\n    return a.detach() * x_in + b.detach() * x_in**3 + c.detach() * x_in**5\n\n# \u521d\u59cb\u51fd\u6570\ndef f_initial(x_in):\n    return 1.0 * x_in + (-1.0) * x_in**3 + 1.0 * x_in**5\n\n# \u8ba1\u7b97 k \u6b21\u8fed\u4ee3\ny_final_k = x_plot\ny_initial_k = x_plot\nfor _ in range(k):\n    y_final_k = f_final(y_final_k)\n    y_initial_k = f_initial(y_initial_k)\n\nplt.figure(figsize=(12, 8))\nplt.plot(x_plot.numpy(), f_initial(x_plot).numpy(), 'b--', label='Initial $f(x) = x-x^3+x^5$')\nplt.plot(x_plot.numpy(), f_final(x_plot).numpy(), 'g-', label=f'Optimized $f(x)$ (k={k})')\nplt.plot(x_plot.numpy(), y_final_k.numpy(), 'r-', lw=2, label=f'Optimized $f^{{({k})}}(x)$')\nplt.plot(x_plot.numpy(), x_plot.numpy(), 'k:', label='$y=x$ (identity)')\nplt.axhline(y=1.0, color='gray', linestyle='--', label='Target y=1')\nplt.title(f'Comparison of Functions (k={k})')\nplt.xlabel('x')\nplt.ylabel('f(x) or $f^{(k)}(x)$')\nplt.legend()\nplt.ylim(-0.1, 1.5)\nplt.xlim(0, 1)\nplt.show()\n</code></pre> <p>\u8fd9\u91cc\u6211\u9009\u62e9\u7684\u521d\u59cb\u503c\u662f\u4efb\u610f\u9009\u53d6\u7684 \\(a=1,b=-1,c=1\\) \u6ee1\u8db3 \\(a+b+c=1\\)\uff0c\u4e0b\u9762\u662f\uff08\u622a\u65ad\u7684\uff09\u65e5\u5fd7\u8f93\u51fa\uff1a</p> <pre><code>\u5f00\u59cb\u4f18\u5316... k=5, \u521d\u59cb\u503c a=1.00, b=-1.00, c=1.00\nStep      0: Loss = 0.58154202, a = 1.0000, b = -0.9999, c = 1.0000\nStep   1000: Loss = 0.52524936, a = 1.0461, b = -1.0118, c = 0.9704\nStep   2000: Loss = 0.46161765, a = 1.0933, b = -1.0257, c = 0.9381\n......\nStep  99000: Loss = 0.00160778, a = 3.1010, b = -3.4233, c = 1.3183\nStep  99999: Loss = 0.00136968, a = 3.1010, b = -3.4236, c = 1.3181\n\n--- \u4f18\u5316\u5b8c\u6210 ---\n\u56fa\u5b9a\u8fed\u4ee3\u6b21\u6570 k = 5\n\u6700\u7ec8\u635f\u5931: 0.00136968\n\u4f18\u5316\u540e\u7684\u53c2\u6570: a = 3.1010, b = -3.4236, c = 1.3181\n\u53c2\u6570\u548c a+b+c = 0.9954 (\u7406\u8bba\u4e0a\u5e94\u8d8b\u8fd1\u4e8e 1)\n</code></pre> <p>MSE \u5e72\u5230\u4e86 1e-3 \u91cf\u7ea7\u3002\u4e0b\u9762\u662f\u8bad\u7ec3\u8fc7\u7a0b\u7684\u635f\u5931\u66f2\u7ebf\u3001\u53c2\u6570\u53d8\u5316\u66f2\u7ebf\u548c\u6700\u7ec8\u51fd\u6570\u7684\u62df\u5408\u56fe\u7ebf\uff1a</p> <p></p> <p></p> <p>\u5f53\u7136\u4e5f\u53ef\u4ee5\u62ff\u725b\u987f\u6cd5\u8bad\uff0c\u6bd5\u7adf\u5c31\u4e09\u4e2a\u53c2\u6570\uff0c\u4f46\u662f\u6211\u81ea\u5df1\u5b9e\u6d4b\u8bad\u7ec3\u4e0d\u5927\u7a33\u5b9a\uff0c\u65f6\u4e0d\u65f6\u5c31\u8bad\u70b8\u4e86\u3002</p> <p>\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u8fd9\u662f Muon \u4f5c\u8005\u63d0\u51fa\u7684\u53c2\u6570\u914d\u7f6e\uff1a\\(a=3.4445,b=\u22124.7750,c=2.0315\\)</p> <p></p> <p>\u8fd9\u662f Muon \u4f18\u5316\u5668\u5728\u8fd9\u4e24\u4e2a\u635f\u5931\u5730\u5f62\u4e0b\u9762\u7684\u8868\u73b0\uff1a</p> <p></p> <p></p> <p>\u4f46\u662f\uff0c\u7531\u4e8e\u5c42\u6570\u548c\u7ef4\u5ea6\u6bd4\u8f83\u4f4e\uff0c\u8fd9\u4e2a\u5730\u5f62\u6ca1\u6709\u53d1\u6325\u51fa Muon \u7684 Newton-Schulz \u8fed\u4ee3\u771f\u6b63\u7684\u6f5c\u529b\uff01</p> <p>\u6211\u4eec\u6765\u770b\u770b Muon \u5728 Fashion-MNIST \u4e0a\u9762\u7684\u6027\u80fd\uff1a</p> <p>\u4e0b\u9762\u662f\u5b98\u65b9\u53c2\u6570 \\(a,b,c=(3.4445,\u22124.7750,2.0315)\\) \u7684\u635f\u5931\u66f2\u7ebf\u3001\u51c6\u786e\u7387\u548c\u6700\u4f18\u9644\u8fd1\u7684\u635f\u5931\u5730\u5f62\u3002</p> <p></p> <p></p> <p>\u4e0b\u9762\u662f\u6211\u81ea\u5df1\u8dd1\u51fa\u6765\u7684\u53c2\u6570 \\(a,b,c=(3.1010, -3.4236, 1.3181)\\) \u7684\u635f\u5931\u66f2\u7ebf\u3001\u51c6\u786e\u7387\u548c\u6700\u4f18\u9644\u8fd1\u7684\u635f\u5931\u5730\u5f62\u3002\uff08\u751a\u81f3 Hyperopt \u641c\u51fa\u6765\u7684\u5b66\u4e60\u7387\u90fd\u4e00\u6837\uff09</p> <p></p> <p></p> <p>\u771f\u7684\u4e0d\u662f\u540c\u4e00\u5f20\u56fe\u54c8\uff0c\u53ef\u4ee5\u81ea\u884c\u653e\u5927\u5bf9\u6bd4\u4e00\u4e0b\u3002</p> <p>\u53ef\u4ee5\u770b\u5230 Newton-Shculz \u8fed\u4ee3\u9700\u8981\u7684\u8fd9\u4e2a\u53c2\u6570\u5bb9\u5dee\u8fd8\u6bd4\u8f83\u5927\uff0c\u53ea\u8981\u4e0d\u662f\u7279\u522b\u79bb\u8c31\uff0c\u6709\u7406\u6709\u636e\u641c\u7d22\u51fa\u6765\u7684\u53c2\u6570\u57fa\u672c\u4e0a\u6548\u679c\u90fd\u5dee\u4e0d\u591a\u3002</p> <p>Muon \u5728\u8fd9\u4e2a\u4efb\u52a1\u4e0a\u9762\u7684\u8868\u73b0\u5df2\u7ecf\u5230\u4e86\u9006\u5929\u7684\u6c34\u5e73\u4e86\u3002\u4e0d\u5230 2000 \u4e2a batch \u5c31\u80fd\u8ba9 train_loss \u964d\u5230 0.1 \u5de6\u53f3\uff0c\u8ba9 acc \u4e0a\u5347\u5230 0.9 \u4e5f\u53ea\u7528\u4e86\u5927\u7ea6 500 \u4e2a batch\u3002\u7b80\u76f4\u5e72\u8db4\u4e0b\u4e4b\u524d\u4e00\u4f17\u4f18\u5316\u7b97\u6cd5\u3002</p> <p>\u4e0b\u9762\uff0c\u8ba9\u6211\u4eec\u770b\u770b Muon \u7684\u4ee3\u7801\uff08\u4e3a\u5c55\u793a\u539f\u7406\u8fd9\u91cc\u53ea\u7ed9\u51fa\u5355\u8bbe\u5907\u7684\uff09\uff1a</p>  Muon \u4f18\u5316\u5668\u7684\u5b9e\u73b0  <pre><code>import torch\n# \u5bfc\u5165 PyTorch \u5206\u5e03\u5f0f\u8bad\u7ec3\u5e93\nimport torch.distributed as dist\n\n# --- \u6838\u5fc3\u6570\u5b66\u51fd\u6570 ---\ndef zeropower_via_newtonschulz5(G, steps: int):\n    \"\"\"\n    \u4f7f\u7528\u725b\u987f-\u8212\u5c14\u8328\u8fed\u4ee3\u8ba1\u7b97\u77e9\u9635 G \u7684\u96f6\u6b21\u5e42\uff0c\u5373\u5bf9 G \u8fdb\u884c\u6b63\u4ea4\u5316\u3002\n    \u6211\u4eec\u9009\u62e9\u4f7f\u7528\u4e00\u4e2a\u4e94\u6b21\u8fed\u4ee3\uff0c\u5176\u7cfb\u6570\u7ecf\u8fc7\u7cbe\u5fc3\u9009\u62e9\uff0c\u4ee5\u6700\u5927\u5316\u5728\u96f6\u70b9\u5904\u7684\u659c\u7387\u3002\n    \u4e3a\u4e86\u6700\u5c0f\u5316\u8fed\u4ee3\u6b65\u6570\uff0c\u7ecf\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u8fed\u4ee3\u5728\u533a\u95f4\u4e0a\u4e0d\u518d\u5b8c\u5168\u6536\u655b\u52301\uff0c\u6301\u7eed\u589e\u52a0\u96f6\u70b9\u5904\u7684\u659c\u7387\u4e5f\u662f\u6709\u6548\u7684\u3002\n    \u56e0\u6b64\uff0c\u8fd9\u4e2a\u8fed\u4ee3\u4e0d\u4f1a\u7cbe\u786e\u5730\u4ea7\u751f UV^T (\u5176\u4e2d U \u548c V \u662f\u6b63\u4ea4\u77e9\u9635)\uff0c\u800c\u662f\u4ea7\u751f\u7c7b\u4f3c US'V^T \u7684\u4e1c\u897f\uff0c\n    \u5176\u4e2d S' \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u5176\u5bf9\u89d2\u7ebf\u5143\u7d20 S'_{ii} \u5927\u7ea6\u5728 Uniform(0.5, 1.5) \u5206\u5e03\u3002\n    \u4e8b\u5b9e\u8bc1\u660e\uff0c\u76f8\u5bf9\u4e8e\u7cbe\u786e\u7684 UV^T\uff0c\u8fd9\u79cd\u8fd1\u4f3c\u5b8c\u5168\u4e0d\u4f1a\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u3002(\u5176\u4e2d USV^T = G \u662f G \u7684\u5947\u5f02\u503c\u5206\u89e3)\u3002\n    \"\"\"\n    # G \u7684\u7ef4\u5ea6\u5fc5\u987b\u81f3\u5c11\u4e3a 2 (\u5373\u4e00\u4e2a\u77e9\u9635)\u3002\u652f\u6301\u6279\u5904\u7406\u77e9\u9635\u3002\n    assert G.ndim &gt;= 2 \n    # \u4e94\u6b21\u8fed\u4ee3\u7684\u9884\u8ba1\u7b97\u7cfb\u6570\n    a, b, c = (3.4445, -4.7750,  2.0315)\n    # \u4e3a\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u5c06\u8f93\u5165\u77e9\u9635\u8f6c\u6362\u4e3a bfloat16 \u7c7b\u578b\n    X = G.bfloat16()\n\n    # \u5982\u679c\u77e9\u9635\u662f\u201c\u9ad8\u7626\u201d\u7684 (\u884c\u6570 &gt; \u5217\u6570)\uff0c\u5219\u8fdb\u884c\u8f6c\u7f6e\u3002\n    # \u77e9\u9635\u4e58\u6cd5\u901a\u5e38\u5728\u201c\u77ee\u80d6\u201d\u77e9\u9635\u4e0a\u66f4\u9ad8\u6548\u3002\n    if G.size(-2) &gt; G.size(-1):\n        X = X.mT\n\n    # \u5173\u952e\u6b65\u9aa4\uff1a\u786e\u4fdd\u8c31\u8303\u6570 (spectral norm) \u6700\u591a\u4e3a 1\u3002\n    # \u725b\u987f-\u8212\u5c14\u8328\u8fed\u4ee3\u7684\u6536\u655b\u6027\u8981\u6c42\u8f93\u5165\u77e9\u9635\u7684\u8c31\u8303\u6570 &lt;= 1\u3002\n    # \u8fd9\u91cc\u901a\u8fc7\u9664\u4ee5\u5176\u8c31\u8303\u6570\uff08\u77e9\u9635\u7684\u6700\u5927\u5947\u5f02\u503c\uff09\u6765\u8fdb\u884c\u5f52\u4e00\u5316\u3002\n    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n\n    # \u6267\u884c\u6307\u5b9a\u6b65\u6570\u7684\u725b\u987f-\u8212\u5c14\u8328\u8fed\u4ee3\n    for _ in range(steps):\n        A = X @ X.mT  # \u8ba1\u7b97 X * X^T\n        # \u4f7f\u7528\u4f18\u5316\u7684\u7b56\u7565\u8ba1\u7b97\u4e94\u6b21\u591a\u9879\u5f0f\uff0c\u907f\u514d\u9ad8\u6b21\u5e42\u7684\u76f4\u63a5\u8ba1\u7b97\n        B = b * A + c * A @ A \n        # \u66f4\u65b0 X\uff0c\u5f62\u5f0f\u4e3a X_{k+1} = p(X_k @ X_k^T) @ X_k\n        X = a * X + B @ X\n\n    # \u5982\u679c\u4e4b\u524d\u8f6c\u7f6e\u4e86\uff0c\u73b0\u5728\u8f6c\u7f6e\u56de\u6765\n    if G.size(-2) &gt; G.size(-1):\n        X = X.mT\n\n    # \u8fd4\u56de\u8fd1\u4f3c\u6b63\u4ea4\u5316\u7684\u77e9\u9635\n    return X\n\n\n# --- Muon \u66f4\u65b0\u89c4\u5219 ---\ndef muon_update(grad, momentum, beta=0.95, ns_steps=5, nesterov=True):\n    \"\"\"\u8ba1\u7b97\u5355\u6b65\u7684 Muon \u66f4\u65b0\u91cf\"\"\"\n    # 1. \u6807\u51c6\u7684\u52a8\u91cf\u66f4\u65b0\uff1amomentum = beta * momentum + (1 - beta) * grad\n    momentum.lerp_(grad, 1 - beta)\n\n    # 2. \u8ba1\u7b97\u66f4\u65b0\u65b9\u5411\uff1a\u5982\u679c\u4f7f\u7528 Nesterov \u52a8\u91cf\uff0c\u5219\u4e3a grad + beta * momentum\uff1b\u5426\u5219\u5c31\u662f\u66f4\u65b0\u540e\u7684\u52a8\u91cf\u3002\n    update = grad.lerp_(momentum, beta) if nesterov else momentum\n\n    # 3. \u5904\u7406\u5377\u79ef\u6838\uff1a\u5982\u679c\u66f4\u65b0\u5bf9\u8c61\u662f4D\u7684\u5377\u79ef\u6838 (out, in, h, w)\uff0c\n    #    \u5219\u5c06\u5176\u5c55\u5e73\u4e3a2D\u77e9\u9635 (out, in*h*w)\uff0c\u4ee5\u4fbf\u8fdb\u884c\u6b63\u4ea4\u5316\u3002\n    if update.ndim == 4: \n        update = update.view(len(update), -1)\n\n    # 4. \u6838\u5fc3\u6b65\u9aa4\uff1a\u5c06\u8ba1\u7b97\u51fa\u7684\u66f4\u65b0\u65b9\u5411\u8fdb\u884c\u6b63\u4ea4\u5316\u3002\n    update = zeropower_via_newtonschulz5(update, steps=ns_steps)\n\n    # 5. \u5c3a\u5bf8\u7f29\u653e\uff1a\u6839\u636e\u77e9\u9635\u7684\u5f62\u72b6\u8fdb\u884c\u7f29\u653e\uff0c\u4ee5\u4fdd\u6301\u66f4\u65b0\u7684\u8c31\u8303\u6570\u5355\u4f4d\u4e00\u81f4\u3002\n    update *= max(1, grad.size(-2) / grad.size(-1))**0.5\n    return update\n\n# --- Muon \u4f18\u5316\u5668 (\u5355\u8bbe\u5907\u7248\u672c) ---\nclass SingleDeviceMuon(torch.optim.Optimizer):\n    \"\"\"\n    \u7528\u4e8e\u975e\u5206\u5e03\u5f0f\u8bbe\u7f6e\u7684 Muon \u53d8\u4f53\u3002\n    \"\"\"\n        \"\"\"\n    Muon - \u901a\u8fc7\u725b\u987f-\u8212\u5c14\u8328\u6b63\u4ea4\u5316\u7684\u52a8\u91cf\u4f18\u5316\u5668\n\n    Muon \u5185\u90e8\u8fd0\u884c\u6807\u51c6\u7684 SGD-momentum, \u7136\u540e\u6267\u884c\u4e00\u4e2a\u6b63\u4ea4\u5316\u540e\u5904\u7406\u6b65\u9aa4\uff0c\n    \u5176\u4e2d\u6bcf\u4e2a 2D \u53c2\u6570\u7684\u66f4\u65b0\u88ab\u66ff\u6362\u4e3a\u6700\u8fd1\u7684\u6b63\u4ea4\u77e9\u9635\u3002\n    \u6211\u4eec\u4f7f\u7528\u725b\u987f-\u8212\u5c14\u8328\u8fed\u4ee3\u6765\u9ad8\u6548\u5730\u8fdb\u884c\u6b63\u4ea4\u5316\uff0c\u5176\u4f18\u70b9\u662f\u53ef\u4ee5\u5728 GPU \u4e0a\u7a33\u5b9a\u5730\u4ee5 bfloat16 \u8fd0\u884c\u3002\n\n    Muon \u53ea\u5e94\u7528\u4e8e\u9690\u85cf\u5c42\u7684\u6743\u91cd\u3002\u8f93\u5165\u5d4c\u5165\u3001\u6700\u7ec8\u8f93\u51fa\u5c42\u4ee5\u53ca\u4efb\u4f55\u5185\u90e8\u7684\u589e\u76ca\u6216\u504f\u7f6e\u9879\n    \u5e94\u4f7f\u7528\u6807\u51c6\u65b9\u6cd5\uff08\u5982 AdamW\uff09\u8fdb\u884c\u4f18\u5316\u3002\n    \u9690\u85cf\u7684\u5377\u79ef\u6743\u91cd\u53ef\u4ee5\u901a\u8fc7\u5c06\u5176\u89c6\u4e3a 2D \u5e76\u6298\u53e0\u5176\u6700\u540e3\u4e2a\u7ef4\u5ea6\u6765\u4f7f\u7528 Muon \u8fdb\u884c\u8bad\u7ec3\u3002\n\n    \u53c2\u6570:\n        lr: \u5b66\u4e60\u7387\uff0c\u5355\u4f4d\u662f\u6bcf\u6b21\u66f4\u65b0\u7684\u8c31\u8303\u6570\u3002\n        weight_decay: AdamW \u98ce\u683c\u7684\u6743\u91cd\u8870\u51cf\u3002\n        momentum: \u52a8\u91cf\u7cfb\u6570\uff0c\u901a\u5e38 0.95 \u6548\u679c\u4e0d\u9519\u3002\n    \"\"\"\n    def __init__(self, params, lr=0.02, weight_decay=0, momentum=0.95):\n        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            # \u903b\u8f91\u4e0e\u5206\u5e03\u5f0f\u7248\u672c\u76f8\u540c\uff0c\u4f46\u6ca1\u6709\u4e86\u590d\u6742\u7684\u5206\u5e03\u5f0f\u901a\u4fe1\u4ee3\u7801\n            for p in group[\"params\"]:\n                if p.grad is None:\n                    p.grad = torch.zeros_like(p)\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"momentum_buffer\"] = torch.zeros_like(p)\n                update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n\n        return loss\n\n# --- Adam \u66f4\u65b0\u89c4\u5219 (\u8f85\u52a9\u51fd\u6570) ---\ndef adam_update(grad, buf1, buf2, step, betas, eps):\n    \"\"\"\u6807\u51c6\u7684 Adam \u66f4\u65b0\u89c4\u5219\"\"\"\n    # \u66f4\u65b0\u4e00\u9636\u77e9 (\u52a8\u91cf)\n    buf1.lerp_(grad, 1 - betas[0])\n    # \u66f4\u65b0\u4e8c\u9636\u77e9 (RMSProp \u90e8\u5206)\n    buf2.lerp_(grad.square(), 1 - betas[1])\n    # \u504f\u5dee\u4fee\u6b63\n    buf1c = buf1 / (1 - betas[0]**step)\n    buf2c = buf2 / (1 - betas[1]**step)\n    # \u8ba1\u7b97\u66f4\u65b0\u91cf\n    return buf1c / (buf2c.sqrt() + eps)\n\n# --- \u6df7\u5408\u4f18\u5316\u5668 (\u5355\u8bbe\u5907\u7248\u672c) ---\nclass SingleDeviceMuonWithAuxAdam(torch.optim.Optimizer):\n    \"\"\"\n    MuonWithAuxAdam \u7684\u975e\u5206\u5e03\u5f0f\u7248\u672c\u3002\n    \"\"\"\n    def __init__(self, param_groups):\n        # \u521d\u59cb\u5316\u903b\u8f91\u4e0e\u5206\u5e03\u5f0f\u7248\u672c\u76f8\u540c\n        for group in param_groups:\n            assert \"use_muon\" in group\n            if group[\"use_muon\"]:\n                group[\"lr\"] = group.get(\"lr\", 0.02)\n                group[\"momentum\"] = group.get(\"momentum\", 0.95)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n            else:\n                group[\"lr\"] = group.get(\"lr\", 3e-4)\n                group[\"betas\"] = group.get(\"betas\", (0.9, 0.95))\n                group[\"eps\"] = group.get(\"eps\", 1e-10)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n        super().__init__(param_groups, dict())\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            if group[\"use_muon\"]:\n                # \u5355\u8bbe\u5907 Muon \u66f4\u65b0\u903b\u8f91\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        p.grad = torch.zeros_like(p)\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"momentum_buffer\"] = torch.zeros_like(p)\n                    update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n            else:\n                # \u5355\u8bbe\u5907 AdamW \u66f4\u65b0\u903b\u8f91\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        p.grad = torch.zeros_like(p)\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"exp_avg\"] = torch.zeros_like(p)\n                        state[\"exp_avg_sq\"] = torch.zeros_like(p)\n                        state[\"step\"] = 0\n                    state[\"step\"] += 1\n                    update = adam_update(p.grad, state[\"exp_avg\"], state[\"exp_avg_sq\"],\n                                         state[\"step\"], group[\"betas\"], group[\"eps\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update, alpha=-group[\"lr\"])\n\n        return loss\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 1, 2025). \u7b26\u53f7\u68af\u5ea6\u4e0b\u964d [Blog post]. Retrieved from https://dicaeopolis.github.io/DNN/optimizer/SignGD</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{SignGD,\n    title={\u7b26\u53f7\u68af\u5ea6\u4e0b\u964d},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/DNN/optimizer/SignGD}},\n}\n</code></pre></p>"}, {"location": "DNN/optimizer/misc/", "title": "\u540e\u7eed\u7684\u5199\u4f5c\u8ba1\u5212", "text": ""}, {"location": "DNN/optimizer/misc/#_2", "title": "\u975e\u68af\u5ea6\u53c2\u6570\u4f18\u5316", "text": "<p>Per aspera ad astra. \u4eb2\u7231\u7684\u8bfb\u8005\u670b\u53cb\uff0c\u606d\u559c\u60a8\u548c\u6211\u4e00\u8d77\u5ea6\u8fc7\u4e86\u8fd9\u6bb5\u96be\u5fd8\u7684\u7814\u4e60\u68af\u5ea6\u53c2\u6570\u4f18\u5316\u7684\u65c5\u7a0b\u3002\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u8c03\u8f6c\u65b9\u5411\uff0c\u770b\u770b\u522b\u5904\u7684\u98ce\u666f\u5427\u3002</p>"}, {"location": "DNN/optimizer/misc/#l-bfgs", "title": "L-BFGS", "text": ""}, {"location": "DNN/optimizer/misc/#_3", "title": "\u6a21\u62df\u9000\u706b", "text": ""}, {"location": "DNN/optimizer/misc/#_4", "title": "\u9057\u4f20\u7b97\u6cd5", "text": ""}, {"location": "DNN/optimizer/misc/#_5", "title": "\u8d85\u53c2\u6570\u4f18\u5316", "text": ""}, {"location": "DNN/optimizer/misc/#_6", "title": "\u7f51\u683c\u641c\u7d22", "text": ""}, {"location": "DNN/optimizer/misc/#_7", "title": "\u8d1d\u53f6\u65af\u641c\u7d22", "text": ""}, {"location": "DNN/optimizer/misc/#_8", "title": "\u53c2\u6570\u641c\u7d22\u6846\u67b6", "text": ""}, {"location": "DNN/optimizer/misc/#_9", "title": "\u4f18\u5316\u5668\u7684\u9006\u5411\u601d\u8003\uff08\u5bf9\u6297\u653b\u51fb\uff09", "text": ""}, {"location": "algorithm/", "title": "\u5173\u4e8e\u672c\u7c7b\u522b", "text": "<p>\u65e0\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/", "title": "STL\u7684\u4e00\u4e9b\u6027\u80fd\u6d4b\u8bd5", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 12 \u5206\u949f\u3000|\u3000\u7ea6 1262 \u5b57\u3000|\u3000\u7ea6 1 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 690 \u884c\u4ee3\u7801</p> <p>\u4f17\u6240\u5468\u77e5 <code>regex</code> \u5e93\u50cf\u9a6c\u8f66\u4e00\u6837\u6162\uff0c\u800c <code>unrodered_map</code> \u4e5f\u5e38\u5e38\u56e0\u4e3a\u5e38\u6570\u8fc7\u5927\u800c\u88ab\u8bf8\u591a\u7b97\u6cd5\u7ade\u8d5b\u9009\u624b\u6240\u6452\u5f03\u3002\u4f46 <code>STL</code> \u5e76\u975e\u94c1\u677f\u4e00\u5757\uff0c\u603b\u4f1a\u6709\u4e00\u4e9b\u597d\u7528\u4e14\u6548\u7387\u9ad8\u7684\u5bb9\u5668\u503c\u5f97\u4e00\u7528\u3002\u672c\u6587\u8bd5\u56fe\u5bf9 <code>STL</code> \u4e2d\u7684\u4e00\u4e9b\u7ecf\u5178\u5bb9\u5668\u53ca\u7b97\u6cd5\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u4e0e\u5bf9\u6bd4\uff0c\u770b\u770b\u54ea\u4e9b\u8f6e\u5b50\u662f\u597d\u7528\u7684\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/#_1", "title": "\u6d4b\u8bd5\u5e73\u53f0\u548c\u6d41\u7a0b", "text": "<p>\u672c\u6b21\u6d4b\u8bd5\u4f7f\u7528 Intel\u00ae Pentium\u00ae Gold 8505 @ 2.50GHz \u82af\u7247\uff0c\u673a\u5e26\u5185\u5b58 8GB\uff0c\u64cd\u4f5c\u7cfb\u7edf\u4e3a Windows 24H2 26100.3775 \uff0c\u7f16\u8bd1\u53ca\u8fd0\u884c\u73af\u5883\u4e3a MSYS2 \uff0c\u7f16\u8bd1\u5668\u4f7f\u7528 clang 20.1.3 \u548c gcc 13.3.0\u3002</p> <p>\u5bf9\u6bcf\u4e00\u6b21\u6d4b\u8bd5\u53d6\u4e0d\u540c\u6570\u636e\u91cf\uff0c\u6bcf\u4e2a\u6570\u636e\u91cf\u9488\u5bf9\u4e0d\u540c\u7f16\u8bd1\u5668\u6d4b\u91cf\u591a\u6b21\u540e\u53d6\u5e73\u5747\u503c\u5e76\u8ba1\u7b97\u7edd\u5bf9\u548c\u76f8\u5bf9\u4e0d\u786e\u5b9a\u5ea6\u3002</p> Warning <p></p> <p>\u4f60\u4e5f\u770b\u5230\u4e86\u7b14\u8005\u7684\u7535\u8111\u5f88\u9db8\uff0c\u5e76\u4e14 MSYS2 \u73af\u5883\u9020\u6210\u7684 I/O \u74f6\u9888\u4f1a\u5bf9\u7a0b\u5e8f\u603b\u7684\u8fd0\u884c\u65f6\u95f4\u9020\u6210\u5f88\u5927\u5f71\u54cd\uff0c\u6240\u4ee5\u672c\u6587\u4f1a\u5148\u72ec\u7acb\u8dd1\u4e00\u6b21\u7eaf\u6570\u636eI/O\u7684\u8ba1\u65f6\u6d4b\u8bd5\uff0c\u518d\u4ece\u603b\u8fd0\u884c\u65f6\u95f4\u91cc\u9762\u6263\u9664 I/O \u635f\u8017\uff0c\u5f97\u5230\u6700\u7ec8\u7ed3\u679c\u3002</p> <p></p> <p>\u6d4b\u8bd5\u6570\u636e\u7531\u968f\u673a\u7b97\u6cd5\u751f\u6210\u5e76\u4fdd\u5b58\u3002\u4f8b\u5982\uff1a</p> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;random&gt;\n#include&lt;chrono&gt;\n\nint main()\n{\n    std::ios::sync_with_stdio(false);\n    std::cin.tie(nullptr);\n    std::cout.tie(nullptr);\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n;\n    std::cin &gt;&gt; n;\n    std::cout &lt;&lt; n;\n    while(n--)\n        std::cout&lt;&lt;engine()&lt;&lt;' ';\n    return 0;\n}\n</code></pre> <p>\u6d4b\u8bd5\u8ba1\u65f6\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>\u4f7f\u7528 <code>gcc</code> \u548c <code>clang</code> \u5f00 <code>-O2</code> \u7f16\u8bd1\u5f85\u6d4b\u6e90\u7801</li> <li>\u7f16\u8bd1\u6570\u636e\u751f\u6210\u5668</li> <li>\u5f00\u542f\u4e00\u8f6e\u6d4b\u8bd5</li> <li>\u5bf9\u6bcf\u8f6e\u6d4b\u8bd5\uff0c\u5148\u8fd0\u884c\u6570\u636e\u751f\u6210\u5668\u751f\u6210\u6570\u636e\uff0c\u518d\u6253\u4e71\u53ef\u6267\u884c\u6587\u4ef6\u8fd0\u884c\u987a\u5e8f\uff0c\u6309\u6253\u4e71\u540e\u7684\u987a\u5e8f\u4f9d\u6b21\u8fd0\u884c\u5e76\u8bb0\u5f55\u7528\u65f6\uff0c\u6240\u6709 I/O \u5747\u4f7f\u7528 <code>shell</code> \u91cd\u5b9a\u5411\u7b26\u53f7\u5c06 <code>iostream</code> \u91cd\u5b9a\u5411\u5230\u6587\u4ef6 I/O\u3002</li> <li>\u56de\u5230\u6b65\u9aa4 4 \u5e76\u91cd\u590d\u82e5\u5e72\u6b21\uff0c\u8bb0\u5f55\u6bcf\u6b21\u8fd0\u884c\u7528\u65f6</li> <li>\u8ba1\u7b97\u5e73\u5747\u7528\u65f6\u548c\u4e0d\u786e\u5b9a\u5ea6\u3002</li> </ol> <p>\u4f7f\u7528\u4e0b\u9762\u7684\u811a\u672c\uff1a</p> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>import os\nimport time\nimport random\ndef calculate_uncertainties(data):\n    n = len(data)\n    if n == 0:\n        return 0.0, 0.0, 0.0\n    total = sum(data)\n    mean = total / n\n    squared_diff_sum = sum((x - mean) ** 2 for x in data)\n    absolute_uncertainty = (squared_diff_sum / (n - 1)) ** 0.5 if n &gt; 1 else 0\n    relative_uncertainty = absolute_uncertainty / mean * 100 if mean != 0 else 0\n\n    return mean, round(absolute_uncertainty, 2), round(relative_uncertainty, 3)\n\ndata_size = int(1e6)\ntest_round = 30\nsorces_filename = ['a', 'b', 'c']\ndatagen_name = 'datagen'\ntestdata_filename = 'testdata.in'\noutput_filename = 'output.out'\n\nprint('[+] Cleaning directory.')\nos.system('rm *.in *.out *.exe')\nprint('[+] Compiling data generator.')\nos.system(f'g++ -O2 .\\\\{datagen_name}.cc -o {datagen_name}.exe')\n\n#compile\ngcc_instructions = [f'g++ -O2 -lm -o {fn}_gcc.exe {fn}.cc' for fn in sorces_filename]\nclang_instructions = [f'clang++ -O2 -lm -o {fn}_clang.exe {fn}.cc' for fn in sorces_filename]\ninstructions = gcc_instructions + clang_instructions\n\nprint('[+] Compiling files.')\nfor cmd in instructions:\n    print(f'  [+] Using command: {cmd}')\n    os.system(cmd)\n\ngcc_run_cmd = [(f'.\\\\{fn}_gcc.exe &lt; {testdata_filename} &gt; {output_filename}', f'{fn}_gcc')\\\n                for fn in sorces_filename]\nclang_run_cmd = [(f'.\\\\{fn}_clang.exe &lt; {testdata_filename} &gt; {output_filename}', f'{fn}_clang')\\\n                  for fn in sorces_filename]\nrun_cmds = gcc_run_cmd + clang_run_cmd\n\ntime_data = {}\nfor cmd in run_cmds:\n    time_data[cmd[1]] = []\n\nprint('[+] Start test.')\n\n#test\nfor once_round in range(test_round):\n    random.shuffle(run_cmds)\n    print(f'[+] Test round {once_round + 1}:')\n    print('[+] Cleaning directory.')\n    os.system('rm *.in *.out')\n    test_gen = f'(.\\\\{datagen_name}.exe {data_size}) &gt; {testdata_filename}'\n    print('[+] Generating test data.')\n    os.system(test_gen)\n    for cmd in run_cmds:\n        run_cmd = cmd[0]\n        fn = cmd[1]\n        print(f'  [+] Start testing file {fn}...')\n        start_time = time.time()\n        os.system(run_cmd)\n        end_time = time.time()\n        elapsed_time_ms = int(1000 * (end_time - start_time))\n        print(f'  [-] Over. time usage: {elapsed_time_ms} ms')\n        time_data[cmd[1]].append(elapsed_time_ms)\n\nprint('[-] Time benchmark over.')\nprint()\nprint('-*- Results -*-')\nprint(f'Ran {test_round} rounds for {data_size} items.')\nfor item in time_data.items():\n    mean, u, up = calculate_uncertainties(item[1])\n    print(f'File {item[0]} average run time: {mean} \u00b1 {u} ms ({up}%).')\n</code></pre> <p>\u6240\u6709\u8f93\u5165\u8f93\u51fa\u90fd\u4f7f\u7528 <code>std::cin</code> \u548c <code>std::cout</code> \u8fdb\u884c\uff0c\u6d41\u540c\u6b65\u5df2\u7ecf\u5173\u95ed\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/#stdvector-stdarray", "title": "<code>std::vector</code>, <code>std::array</code> \u548c\u539f\u751f\u6570\u7ec4", "text": "<p>\u672c\u8f6e\u6d4b\u8bd5\u4ee5\u4e0b\u9879\u76ee\uff1a</p> <ul> <li>\u5b58\u5165\u6570\u636e\u5e76\u8f93\u51fa</li> <li>\u968f\u673a\u8bbf\u95ee\u4e0b\u6807\u5e76\u6c42\u548c</li> <li>\u4f7f\u7528 <code>std::sort</code> \u6392\u5e8f</li> </ul>"}, {"location": "algorithm/benchmark-on-stl/#_2", "title": "\u987a\u5e8f\u5b58\u50a8\u6d4b\u8bd5", "text": "\u70b9\u51fb\u67e5\u770b\u4ee3\u7801  \u4f7f\u7528 std::vector\uff1a   \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;vector&gt;\n\nint main()\n{\n    std::vector&lt;int&gt; vec;\n    int n;\n    std::cin &gt;&gt; n;\n    while (n--) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec.push_back(x);\n    }\n    long long sum = 0;\n    for(auto i : vec) {\n        std::cout &lt;&lt; i &lt;&lt; ' ';\n        sum += i;\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum &lt;&lt; '\\n';\n    for(auto it = vec.rbegin(); it != vec.rend(); ++it)\n        std::cout &lt;&lt; *it &lt;&lt; ' ';\n    return 0;\n}\n</code></pre>   \u4f7f\u7528 std::array\uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;array&gt;\nconstexpr int SIZE = int(1e8+5);\nstd::array&lt;int, SIZE&gt; arr;\n\nint main()\n{\n    int n;\n    std::cin &gt;&gt; n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        arr[i] = x;\n    }\n    long long sum = 0;\n    for(int i = 0; i &lt; n; ++i) {\n        std::cout &lt;&lt; arr[i] &lt;&lt; ' ';\n        sum += arr[i];\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum &lt;&lt; '\\n';\n    for(int i = n - 1; i &gt;= 0; --i)\n        std::cout &lt;&lt; arr[i] &lt;&lt; ' ';\n    return 0;\n}\n</code></pre>   \u4f7f\u7528\u539f\u751f\u6570\u7ec4\uff1a   \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\nconstexpr int SIZE = int(1e8+5);\nint arr[SIZE];\n\nint main()\n{\n    int n;\n    std::cin &gt;&gt; n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        arr[i] = x;\n    }\n    long long sum = 0;\n    for(int i = 0; i &lt; n; ++i) {\n        std::cout &lt;&lt; arr[i] &lt;&lt; ' ';\n        sum += arr[i];\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum &lt;&lt; '\\n';\n    for(int i = n - 1; i &gt;= 0; --i)\n        std::cout &lt;&lt; arr[i] &lt;&lt; ' ';\n    return 0;\n}\n</code></pre>"}, {"location": "algorithm/benchmark-on-stl/#_3", "title": "\u968f\u673a\u8bbf\u95ee\u6d4b\u8bd5", "text": "\u70b9\u51fb\u67e5\u770b\u4ee3\u7801   \u4f7f\u7528 std::vector\uff1a   \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;random&gt;\n\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    std::vector&lt;int&gt; vec;\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    while (n--) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec.push_back(x);\n    }\n    long long sum = 0;\n    for(int _ = 0; _ &lt; m ; ++_) {\n        auto i = vec[engine() % m];\n        sum += i;\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum;\n    return 0;\n}\n</code></pre>   \u4f7f\u7528 std::array\uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;array&gt;\n#include&lt;random&gt;\n\nconstexpr size_t SIZE = 1e6+5;\nstd::array&lt;int, SIZE&gt; vec;\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec[i] = x;\n    }\n    long long sum = 0;\n    for(int _ = 0; _ &lt; m ; ++_) {\n        auto i = vec[engine() % m];\n        sum += i;\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum;\n    return 0;\n}\n</code></pre>   \u4f7f\u7528\u539f\u751f\u6570\u7ec4\uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;array&gt;\n#include&lt;random&gt;\n\nconstexpr size_t SIZE = 1e6+5;\nint vec[SIZE];\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec[i] = x;\n    }\n    long long sum = 0;\n    for(int _ = 0; _ &lt; m ; ++_) {\n        auto i = vec[engine() % m];\n        sum += i;\n        sum %= 998244353;\n    }\n    std::cout &lt;&lt; sum;\n    return 0;\n}\n</code></pre>"}, {"location": "algorithm/benchmark-on-stl/#_4", "title": "\u6392\u5e8f\u6d4b\u8bd5", "text": "\u70b9\u51fb\u67e5\u770b\u4ee3\u7801  \u4f7f\u7528 std::vector \uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;random&gt;\n#include&lt;algorithm&gt;\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    std::vector&lt;int&gt; vec;\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    while (n--) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec.push_back(x);\n    }\n    std::sort(vec.begin(), vec.end());\n    return 0;\n}\n</code></pre>    \u4f7f\u7528 std::array\uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;array&gt;\n#include&lt;random&gt;\n#include&lt;algorithm&gt;\nconstexpr size_t SIZE = 1e6+5;\nstd::array&lt;int, SIZE&gt; vec;\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec[i] = x;\n    }\n    std::sort(vec.begin(), vec.begin() + m + 1);\n    return 0;\n}\n</code></pre>    \u4f7f\u7528\u539f\u751f\u6570\u7ec4\uff1a    \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;array&gt;\n#include&lt;random&gt;\n#include&lt;algorithm&gt;\n\nconstexpr size_t SIZE = 1e6+5;\nint vec[SIZE];\nint main()\n{\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n, m;\n    std::cin &gt;&gt; n;\n    m = n;\n    for(int i = 0; i &lt; n; ++i) {\n        int x;\n        std::cin &gt;&gt; x;\n        vec[i] = x;\n    }\n    std::sort(vec, vec + m + 1);\n    return 0;\n}\n</code></pre>"}, {"location": "algorithm/benchmark-on-stl/#_5", "title": "\u7ed3\u679c\u548c\u5206\u6790", "text": "\u70b9\u51fb\u67e5\u770b\u6d4b\u8bd5\u7ed3\u679c \u6d4b\u8bd51\uff1a <pre><code>-*- Results -*-\nRan 50 rounds for 1000 items.\nfile a_gcc average run time: 114.56 \u00b1 44.77 ms (39.083%).\nfile b_gcc average run time: 114.82 \u00b1 47.26 ms (41.157%).\nfile c_gcc average run time: 109.58 \u00b1 32.59 ms (29.745%).\nfile a_clang average run time: 63.96 \u00b1 71.77 ms (112.212%).\nfile b_clang average run time: 56.38 \u00b1 44.58 ms (79.077%).\nfile c_clang average run time: 61.92 \u00b1 49.93 ms (80.635%).\n\n-*- Results -*-\nRan 50 rounds for 100000 items.\nfile a_gcc average run time: 415.8 \u00b1 51.44 ms (12.37%).\nfile b_gcc average run time: 420.12 \u00b1 51.33 ms (12.218%).\nfile c_gcc average run time: 425.22 \u00b1 59.65 ms (14.028%).\nfile a_clang average run time: 351.1 \u00b1 52.09 ms (14.835%).\nfile b_clang average run time: 353.44 \u00b1 51.66 ms (14.615%).\nfile c_clang average run time: 352.08 \u00b1 49.55 ms (14.074%).\n\n-*- Results -*-\nRan 20 rounds for 1000000 items.\nfile a_gcc average run time: 3383.9 \u00b1 306.06 ms (9.045%).\nfile b_gcc average run time: 3349.85 \u00b1 397.41 ms (11.864%).\nfile c_gcc average run time: 3346.3 \u00b1 306.4 ms (9.156%).\nfile a_clang average run time: 3186.65 \u00b1 296.0 ms (9.289%).\nfile b_clang average run time: 3225.5 \u00b1 329.33 ms (10.21%).\nfile c_clang average run time: 3218.15 \u00b1 303.94 ms (9.445%).\n</code></pre> \u6d4b\u8bd52\uff1a <pre><code>-*- Results -*-\nRan 50 rounds for 1000 items.\nfile a_gcc average run time: 90.12 \u00b1 26.23 ms (29.107%).\nfile b_gcc average run time: 88.26 \u00b1 13.46 ms (15.254%).\nfile c_gcc average run time: 86.8 \u00b1 15.66 ms (18.044%).\nfile a_clang average run time: 32.16 \u00b1 22.44 ms (69.763%).\nfile b_clang average run time: 28.6 \u00b1 12.94 ms (45.254%).\nfile c_clang average run time: 30.24 \u00b1 14.96 ms (49.455%).\n\n-*- Results -*-\nRan 50 rounds for 100000 items.\nfile a_gcc average run time: 336.48 \u00b1 21.05 ms (6.257%).\nfile b_gcc average run time: 334.84 \u00b1 14.22 ms (4.246%).\nfile c_gcc average run time: 340.24 \u00b1 18.11 ms (5.323%).\nfile a_clang average run time: 171.8 \u00b1 16.36 ms (9.524%).\nfile b_clang average run time: 171.64 \u00b1 14.08 ms (8.202%).\nfile c_clang average run time: 171.5 \u00b1 13.84 ms (8.071%).\n\n-*- Results -*-\nRan 20 rounds for 1000000 items.\nfile a_gcc average run time: 3029.5 \u00b1 397.96 ms (13.136%).\nfile b_gcc average run time: 2998.55 \u00b1 339.45 ms (11.321%).\nfile c_gcc average run time: 2968.05 \u00b1 257.55 ms (8.677%).\nfile a_clang average run time: 1614.05 \u00b1 114.01 ms (7.064%).\nfile b_clang average run time: 1641.65 \u00b1 185.24 ms (11.284%).\nfile c_clang average run time: 1641.5 \u00b1 146.92 ms (8.95%).\n</code></pre> \u6d4b\u8bd53\uff1a <pre><code>-*- Results -*-\nRan 50 rounds for 1000 items.\nfile a_gcc average run time: 82.18 \u00b1 15.84 ms (19.279%).\nfile b_gcc average run time: 87.38 \u00b1 20.09 ms (22.997%).\nfile c_gcc average run time: 85.56 \u00b1 20.65 ms (24.14%).\nfile a_clang average run time: 22.98 \u00b1 13.12 ms (57.088%).\nfile b_clang average run time: 25.1 \u00b1 13.76 ms (54.824%).\nfile c_clang average run time: 29.16 \u00b1 22.7 ms (77.836%).\n\n-*- Results -*-\nRan 50 rounds for 100000 items.\nfile a_gcc average run time: 348.94 \u00b1 40.78 ms (11.686%).\nfile b_gcc average run time: 348.36 \u00b1 35.0 ms (10.048%).\nfile c_gcc average run time: 345.16 \u00b1 38.33 ms (11.105%).\nfile a_clang average run time: 170.74 \u00b1 19.72 ms (11.552%).\nfile b_clang average run time: 176.56 \u00b1 25.44 ms (14.411%).\nfile c_clang average run time: 174.12 \u00b1 21.54 ms (12.369%).\n\n-*- Results -*-\nRan 20 rounds for 1000000 items.\nfile a_gcc average run time: 2923.05 \u00b1 241.33 ms (8.256%).\nfile b_gcc average run time: 2978.0 \u00b1 278.09 ms (9.338%).\nfile c_gcc average run time: 2990.55 \u00b1 287.74 ms (9.622%).\nfile a_clang average run time: 1619.85 \u00b1 148.65 ms (9.177%).\nfile b_clang average run time: 1602.1 \u00b1 137.03 ms (8.553%).\nfile c_clang average run time: 1648.2 \u00b1 238.51 ms (14.471%).\n</code></pre> <p>\u6ce8\u610f\u8fd9\u91cc<code>gcc</code>\u548c<code>clang</code>\u6709\u4e00\u5b9a\u7684I/O\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46\u662f\u5bb9\u5668\u672c\u8eab\u7684\u7528\u65f6\u5dee\u8ddd\u4e0d\u5927\uff0c\u751a\u81f3\u6ca1\u6709\u56e0\u4e3a\u6027\u80fd\u6ce2\u52a8\u5bfc\u81f4\u7684\u65f6\u95f4\u5dee\u5927\u3002</p> <p>\u7ed3\u8bba\uff1a\u5bf9\u4e8e\u6240\u6709\u60c5\u5f62\uff0c\u5404\u4e2a\u5bb9\u5668\u7684\u6027\u80fd\u57fa\u672c\u6ca1\u6709\u5dee\u522b\uff0c\u56e0\u4e3a\u8fd9\u4e09\u4e2a\u5bb9\u5668\u5e95\u5c42\u90fd\u662f\u8fde\u7eed\u7684\u5185\u5b58\u5757\uff0c\u62bd\u8c61\u7684\u65f6\u95f4\u6210\u672c\u975e\u5e38\u4f4e\u3002\u4f46\u662f\u8003\u8651\u5230\u6570\u7ec4\u548c\u88f8\u6307\u9488\u7ea0\u7f20\u4e0d\u6e05\u7684\u5173\u7cfb\uff0c\u8fd8\u662f\u66f4\u63a8\u8350\u4f7f\u7528 <code>std::array</code> \u548c <code>std::vector</code> \u3002</p> <p>\u7531\u4e8e <code>std::vector</code> \u662f\u6307\u6570\u6269\u5bb9\uff0c\u5747\u644a\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(1)\\) \u3002\u4e00\u822c <code>std::vector</code> \u6269\u5bb9\u7684\u573a\u5408\u90fd\u662f\u5728\u8bfb\u5165\u9636\u6bb5\uff0c\u6240\u4ee5\u6027\u80fd\u5f00\u9500\u4e5f\u4e0d\u5927\u3002\u800c\u4e14\u5373\u4f7f <code>std::vector</code> \u7684\u6570\u636e\u662f\u7533\u8bf7\u5728\u5806\u4e0a\u9762\uff0c\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u4e5f\u4e0d\u5927\u3002</p> <p>\u5f53\u7136 <code>std::array</code> \u5c31\u662f\u539f\u751f\u6570\u7ec4\u5f88\u7ecf\u5178\u7684\u96f6\u6210\u672c\u62bd\u8c61\u4e86\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/#stdunordered_map", "title": "<code>std::unordered_map</code> \u548c\u624b\u5199\u54c8\u5e0c", "text": "<p>\u672c\u8f6e\u6d4b\u8bd5\u4f7f\u7528\u4ee5\u4e0b\u51e0\u4efd\u4ee3\u7801\uff1a</p> Warning <p>\u7531\u4e8e CRC64 \u7684\u5b9e\u73b0\u5229\u7528\u4e86\u7f16\u8bd1\u671f\u751f\u6210 CRC \u8868\uff0c\u4ee5\u53ca\u624b\u5199 unordered_map \u7684\u5b9e\u73b0\u91cc\u9762\u7528\u5230\u4e86\u4e00\u4e9b\u6bd4\u8f83\u65b0\u7684\u8bed\u8a00\u7279\u6027\uff0c\u8bf7\u786e\u4fdd\u4f60\u7684\u7f16\u8bd1\u5668\u652f\u6301 c++17\u3002\u5982\u679c\u9047\u5230\u5982\u4e0b\u9519\u8bef\uff1a</p> <pre><code>./unordered_map.cc:13:35: warning: variable declaration in a constexpr function is a C++14 extension [-Wc++14-extensions]\n   13 |         std::array&lt;uint64_t, 256&gt; table = {};\n      |                                   ^\n./unordered_map.cc:14:9: error: statement not allowed in constexpr function\n   14 |         for (int i = 0; i &lt; 256; ++i) {\n      |         ^\n./unordered_map.cc:55:9: error: 'auto' return without trailing return type; deduced return types are a C++14 extension\n   55 |         auto&amp; get_item(const key_type&amp; key)\n      |         ^\n./unordered_map.cc:60:15: error: 'auto' return without trailing return type; deduced return types are a C++14 extension\n   60 |         const auto&amp; get_item(const key_type&amp; key) const\n      |               ^\n1 warning and 3 errors generated.\n</code></pre>  \u6216\u8005\u5982\u4e0b\u9519\u8bef\uff1a  <pre><code>./unordered_map.cc:11:41: error: constexpr function never produces a constant expression [-Winvalid-constexpr]\n   11 |     constexpr std::array&lt;uint64_t, 256&gt; generate_crc64_table()\n      |                                         ^~~~~~~~~~~~~~~~~~~~\n./unordered_map.cc:18:13: note: non-constexpr function 'operator[]' cannot be used in a constant expression\n   18 |             table[i] = crc;\n      |             ^\nD:/msys64/clang64/include/c++/v1/array:268:65: note: declared here\n  268 |   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX17 reference operator[](size_type __n) _NOEXCEPT {\n      |                                                                 ^\n./unordered_map.cc:23:41: error: constexpr variable 'crc64_table' must be initialized by a constant expression\n   23 |     constexpr std::array&lt;uint64_t, 256&gt; crc64_table = generate_crc64_table();\n      |                                         ^             ~~~~~~~~~~~~~~~~~~~~~~\n./unordered_map.cc:18:13: note: non-constexpr function 'operator[]' cannot be used in a constant expression\n   18 |             table[i] = crc;\n      |             ^\n./unordered_map.cc:23:55: note: in call to 'generate_crc64_table()'\n   23 |     constexpr std::array&lt;uint64_t, 256&gt; crc64_table = generate_crc64_table();\n      |                                                       ^~~~~~~~~~~~~~~~~~~~~~\nD:/msys64/clang64/include/c++/v1/array:268:65: note: declared here\n  268 |   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX17 reference operator[](size_type __n) _NOEXCEPT {\n      |                                                                 ^\n2 errors generated.\n</code></pre> <p>\u8bf7\u786e\u4fdd\u5728\u7f16\u8bd1\u65f6\u52a0\u4e0a `-std=c++17` \u9009\u9879\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/#_6", "title": "\u6d4b\u8bd5\u4ee3\u7801", "text": "<ul> <li><code>a.cc</code> : \u539f\u751f <code>std::unordered_map</code> \u52a0 CRC64 \u54c8\u5e0c</li> </ul> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include &lt;array&gt;\n#include &lt;string&gt;\n#include &lt;iostream&gt;\n#include &lt;unordered_map&gt;\n\nconstexpr uint64_t CRC64_POLY = 0x42F0E1EBA9EA3693ULL;\n\nconstexpr std::array&lt;uint64_t, 256&gt; generate_crc64_table()\n{\n    std::array&lt;uint64_t, 256&gt; table = {};\n    for (int i = 0; i &lt; 256; ++i) {\n        uint64_t crc = i;\n        for (int j = 0; j &lt; 8; ++j)\n            crc = (crc &amp; 1) ? (crc &gt;&gt; 1) ^ CRC64_POLY : crc &gt;&gt; 1;\n        table[i] = crc;\n    }\n    return table;\n}\n\nconstexpr std::array&lt;uint64_t, 256&gt; crc64_table = generate_crc64_table();\n\nuint64_t crc64(const uint8_t *data, size_t length)\n{\n    uint64_t crc = 0xFFFFFFFFFFFFFFFFULL;\n    for (size_t i = 0; i &lt; length; i++) {\n        uint8_t index = (uint8_t)(crc ^ data[i]);\n        crc = (crc &gt;&gt; 8) ^ crc64_table[index];\n    }\n    return crc ^ 0xFFFFFFFFFFFFFFFFULL;\n}\n\nstruct my_hash {\n    uint64_t operator()(const uint64_t&amp; q) const\n    {\n        uint64_t data = q;\n        uint8_t *d = (uint8_t*)&amp;data;\n        return crc64(d, sizeof(data));\n    }\n};\n\nint main()\n{\n    int n, m;\n    std::cin&gt;&gt;n&gt;&gt;m;\n    std::unordered_map&lt;uint64_t, bool, my_hash&gt; map;\n    while(n--)\n    {\n        uint64_t s;\n        std::cin &gt;&gt; s;\n        map[s] = true;\n    }\n    while(m--)\n    {\n        uint64_t q;\n        std::cin &gt;&gt; q;\n        std::cout &lt;&lt; (map[q] ? \"hit\\n\" : \"miss\\n\");\n    }\n    return 0;\n}    \n</code></pre> <ul> <li><code>b.cc</code> : \u539f\u751f <code>std::unordered_map</code> \u52a0\u539f\u751f\u54c8\u5e0c</li> </ul> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include &lt;array&gt;\n#include &lt;string&gt;\n#include &lt;iostream&gt;\n#include &lt;unordered_map&gt;\n\nint main()\n{\n    int n, m;\n    std::cin&gt;&gt;n&gt;&gt;m;\n    std::unordered_map&lt;uint64_t, bool&gt; map;\n    while(n--)\n    {\n        uint64_t s;\n        std::cin &gt;&gt; s;\n        map[s] = true;\n    }\n    while(m--)\n    {\n        uint64_t q;\n        std::cin &gt;&gt; q;\n        std::cout &lt;&lt; (map[q] ? \"hit\\n\" : \"miss\\n\");\n    }\n    return 0;\n}    \n</code></pre> <ul> <li><code>c.cc</code> : \u539f\u751f <code>std::unordered_map</code> \u52a0 OI-Wiki \u8fd9\u4e2a\u6761\u76ee\u91cc\u9762\u4ecb\u7ecd\u7684\u54c8\u5e0c</li> </ul> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include &lt;array&gt;\n#include &lt;chrono&gt;\n#include &lt;string&gt;\n#include &lt;iostream&gt;\n#include &lt;unordered_map&gt;\n\nstruct my_hash {\n    static uint64_t splitmix64(uint64_t x) {\n        x += 0x9e3779b97f4a7c15;\n        x = (x ^ (x &gt;&gt; 30)) * 0xbf58476d1ce4e5b9;\n        x = (x ^ (x &gt;&gt; 27)) * 0x94d049bb133111eb;\n        return x ^ (x &gt;&gt; 31);\n    }\n\n    size_t operator()(uint64_t x) const {\n        static const uint64_t FIXED_RANDOM =\n            std::chrono::steady_clock::now().time_since_epoch().count();\n      return splitmix64(x + FIXED_RANDOM);\n    }\n  };\n\nint main()\n{\n    int n, m;\n    std::cin&gt;&gt;n&gt;&gt;m;\n    std::unordered_map&lt;uint64_t, bool, my_hash&gt; map;\n    while(n--)\n    {\n        uint64_t s;\n        std::cin &gt;&gt; s;\n        map[s] = true;\n    }\n    while(m--)\n    {\n        uint64_t q;\n        std::cin &gt;&gt; q;\n        std::cout &lt;&lt; (map[q] ? \"hit\\n\" : \"miss\\n\");\n    }\n    return 0;\n}\n</code></pre> <ul> <li><code>unordered_map.cc</code> : \u624b\u5199\u5b9e\u73b0\u54c8\u5e0c\u8868\u52a0 CRC64 \u54c8\u5e0c</li> </ul> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include &lt;list&gt;\n#include &lt;array&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;utility&gt;\n#include &lt;iostream&gt;\n\nnamespace crc64 {    \n    constexpr uint64_t CRC64_POLY = 0x42F0E1EBA9EA3693ULL;\n\n    constexpr std::array&lt;uint64_t, 256&gt; generate_crc64_table()\n    {\n        std::array&lt;uint64_t, 256&gt; table = {};\n        for (int i = 0; i &lt; 256; ++i) {\n            uint64_t crc = i;\n            for (int j = 0; j &lt; 8; ++j)\n                crc = (crc &amp; 1) ? (crc &gt;&gt; 1) ^ CRC64_POLY : crc &gt;&gt; 1;\n            table[i] = crc;\n        }\n        return table;\n    }\n\n    constexpr std::array&lt;uint64_t, 256&gt; crc64_table = generate_crc64_table();\n\n    uint64_t crc64(const uint8_t *data, size_t length)\n    {\n        uint64_t crc = 0xFFFFFFFFFFFFFFFFULL;\n        for (size_t i = 0; i &lt; length; i++) {\n            uint8_t index = (uint8_t)(crc ^ data[i]);\n            crc = (crc &gt;&gt; 8) ^ crc64_table[index];\n        }\n        return crc ^ 0xFFFFFFFFFFFFFFFFULL;\n    }\n}\n\n\nconstexpr size_t hash_mod = 126271;\n\ntemplate&lt;typename key_type, typename value_type&gt;\nclass unordered_map {\n    typedef std::pair&lt;key_type, value_type&gt; mapped_type;\n    private:\n        std::vector&lt;std::list&lt;mapped_type&gt;&gt; table;\n        size_t pair_cnt = 0;\n        size_t get_idx(const key_type&amp; key)\n        {\n            auto hash = crc64::crc64((uint8_t*) &amp;key, sizeof(key));\n            return static_cast&lt;size_t&gt;(hash % hash_mod);\n        }\n        const size_t get_idx(const key_type&amp; key) const\n        {\n            auto hash = crc64::crc64((uint8_t*) &amp;key, sizeof(key));\n            return static_cast&lt;size_t&gt;(hash % hash_mod);\n        }\n        auto&amp; get_item(const key_type&amp; key)\n        {\n            auto idx = get_idx(key);\n            return table[idx];\n        }\n        const auto&amp; get_item(const key_type&amp; key) const\n        {\n            auto idx = get_idx(key);\n            return table[idx];\n        }\n    public:\n        unordered_map() : table(hash_mod) {}\n        value_type&amp; operator[](const key_type&amp; key)\n        {\n            auto&amp; item = get_item(key);\n            for(auto&amp; val : item)\n                if(val.first == key)\n                    return val.second;\n            value_type val;\n            item.push_back(std::make_pair(key, val));\n            ++pair_cnt;\n            return item.back().second;\n        }\n        bool empty() const noexcept\n        {\n            return !(pair_cnt);\n        }\n        bool find(const key_type &amp;key) const noexcept\n        {\n            const auto&amp; item = get_item(key);\n            for(const auto&amp; val : item)\n                if(val.first == key)\n                    return true;\n            return false;\n        }\n        void erase(const key_type&amp; key)\n        {\n            auto&amp; item = get_item(key);\n            for(auto it = item.begin(); it != item.end(); ++it)\n                if(it-&gt;first == key) {\n                    item.erase(it);\n                    --pair_cnt;\n                    break;\n                }\n        }      \n};\n\nint main()\n{\n    int n, m;\n    std::cin&gt;&gt;n&gt;&gt;m;\n    unordered_map&lt;uint64_t, bool&gt; map;\n    while(n--)\n    {\n        uint64_t s;\n        std::cin &gt;&gt; s;\n        map[s] = true;\n    }\n    while(m--)\n    {\n        uint64_t q;\n        std::cin &gt;&gt; q;\n        std::cout &lt;&lt; (map.find(q) ? \"hit\\n\" : \"miss\\n\");\n    }\n    return 0;\n}\n</code></pre> <p>\u6d4b\u8bd5\u6570\u636e\u4f7f\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u751f\u6210\uff1a</p> \u70b9\u51fb\u67e5\u770b\u4ee3\u7801 <pre><code>#include&lt;iostream&gt;\n#include&lt;random&gt;\n#include&lt;chrono&gt;\n\nint main(int argc, char* argv[])\n{\n    std::ios::sync_with_stdio(false);\n    std::cin.tie(nullptr);\n    std::cout.tie(nullptr);\n    std::random_device device;\n    unsigned int seed = device();\n    std::mt19937 engine(seed);\n    int n = atoi(argv[1]), m = 3 * n;\n    std::cout &lt;&lt; n &lt;&lt; ' ' &lt;&lt; m &lt;&lt; ' ';\n    while(n--)\n        std::cout&lt;&lt; (engine() % 100000) * 126271 + (n % 2) &lt;&lt;' ';\n    while(m--)\n        std::cout&lt;&lt; (engine() % 100000) * 126271 + (engine()) % 100 &lt;&lt;' ';\n    return 0;\n}\n</code></pre> <p>\u672c\u6765\u8fd9\u4e2a\u6d4b\u8bd5\u6570\u636e\u662f\u51c6\u5907\u5361\u539f\u751f\u54c8\u5e0c <code>126271</code> \u7684\u6a21\u6570\u7684\uff0c\u4f46\u662f\u53ef\u80fd\u662f\u56e0\u4e3a\u7f16\u8bd1\u5668\u6bd4\u8f83\u65b0\uff08\uff1f\uff09\u8c8c\u4f3c\u6ca1\u5361\u6389\uff0c\u6240\u4ee5\u6211\u6539\u5199\u4e86\u4e00\u4e0b\u624b\u5199\u54c8\u5e0c\u8ba9\u5b83\u80fd\u88ab <code>126271</code> \u5361\u6389\u3002</p>"}, {"location": "algorithm/benchmark-on-stl/#_7", "title": "\u7ed3\u679c\u548c\u5206\u6790", "text": "\u70b9\u51fb\u67e5\u770b\u6d4b\u8bd5\u7ed3\u679c  I/O \u7528\u65f6\uff1a <pre><code>-*- Results -*-\nRan 30 rounds for 1000000 items.\nFile a_gcc average run time: 17040.7 \u00b1 82.11 ms (0.482%).\nFile b_gcc average run time: 17060.333333333332 \u00b1 132.67 ms (0.778%).\nFile c_gcc average run time: 16987.466666666667 \u00b1 179.95 ms (1.059%).\nFile unordered_map_gcc average run time: 17438.1 \u00b1 702.97 ms (4.031%).\nFile a_clang average run time: 11680.5 \u00b1 478.32 ms (4.095%).\nFile b_clang average run time: 11649.066666666668 \u00b1 265.44 ms (2.279%).\nFile c_clang average run time: 11746.3 \u00b1 497.44 ms (4.235%).\nFile unordered_map_clang average run time: 11663.466666666667 \u00b1 262.6 ms (2.251%).\n</code></pre>  \u603b\u7528\u65f6\uff1a  <pre><code>-*- Results -*-\nRan 30 rounds for 1000000 items.\nFile a_gcc average run time: 19452.466666666667 \u00b1 586.76 ms (3.016%).\nFile b_gcc average run time: 19013.066666666666 \u00b1 135.53 ms (0.713%).\nFile c_gcc average run time: 19388.8 \u00b1 535.83 ms (2.764%).\nFile unordered_map_gcc average run time: 18337.833333333332 \u00b1 683.24 ms (3.726%).\nFile a_clang average run time: 13868.1 \u00b1 262.02 ms (1.889%).\nFile b_clang average run time: 13662.266666666666 \u00b1 109.66 ms (0.803%).\nFile c_clang average run time: 13723.433333333332 \u00b1 68.47 ms (0.499%).\nFile unordered_map_clang average run time: 12740.7 \u00b1 140.08 ms (1.099%).\n</code></pre> <p>\u53ef\u89c1\u6263\u9664 I/O \u7528\u65f6\u540e\uff0c\u4f7f\u7528\u539f\u751f <code>std::unordered_map</code> \u65e0\u8bba\u91c7\u7528\u4ec0\u4e48\u54c8\u5e0c\u7b97\u6cd5\uff0c\u8fd0\u884c\u65f6\u95f4\u90fd\u5728 <code>2s</code> \u5de6\u53f3\uff0c\u800c\u4e14\u65b0\u5f15\u5165\u7684\u54c8\u5e0c\u7b97\u6cd5\u8fd8\u4f1a\u589e\u5927\u539f\u672c\u5c31\u5f88\u5927\u7684\u5e38\u6570\u3002\u624b\u5199\u7684 <code>unordered_map</code> \u5219\u53ef\u4ee5\u628a\u65f6\u95f4\u5361\u8fdb <code>1s</code> \u5de6\u53f3\u3002</p> <p>\u4e0b\u9762\u6211\u4eec\u6765\u5361\u4e00\u4e0b\u624b\u5199\u54c8\u5e0c\uff0c\u7528\u76f8\u540c\u7684\u6570\u636e\u751f\u6210\u5668\uff0c\u53ea\u4e0d\u8fc7\u628a\u624b\u5199\u54c8\u5e0c\u7684 CRC64 \u6362\u6210\u4e86\u6309\u8f93\u5165\u6570\u636e\u539f\u6837\u8fd4\u56de\uff1a</p> \u70b9\u51fb\u67e5\u770b\u6d4b\u8bd5\u7ed3\u679c  I/O \u7528\u65f6\uff1a <pre><code>-*- Results -*-\nRan 20 rounds for 100000 items.\nFile a_gcc average run time: 1911.85 \u00b1 357.35 ms (18.691%).\nFile b_gcc average run time: 1838.35 \u00b1 166.73 ms (9.069%).\nFile c_gcc average run time: 1835.6 \u00b1 153.11 ms (8.341%).\nFile unordered_map_gcc average run time: 1855.55 \u00b1 179.25 ms (9.66%).\nFile a_clang average run time: 1259.5 \u00b1 144.72 ms (11.49%).\nFile b_clang average run time: 1215.6 \u00b1 114.12 ms (9.388%).\nFile c_clang average run time: 1229.0 \u00b1 120.62 ms (9.814%).\nFile unordered_map_clang average run time: 1250.1 \u00b1 146.91 ms (11.752%).\n</code></pre>  \u603b\u7528\u65f6\uff1a <pre><code>-*- Results -*-\nRan 20 rounds for 100000 items.\nFile a_gcc averag run time: 2186.8 \u00b1 306.2 ms (14.002%).\nFile b_gcc average run time: 2183.45 \u00b1 462.09 ms (21.163%).\nFile c_gcc average run time: 2193.9 \u00b1 496.88 ms (22.648%).\nFile unordered_map_gcc average run time: 3621.0 \u00b1 416.51 ms (11.503%).\nFile a_clang average run time: 1509.0 \u00b1 278.87 ms (18.48%).\nFile b_clang avera`ge run time: 1611.0 \u00b1 418.77 ms (25.995%).\nFile c_clang average run time: 1510.6 \u00b1 292.32 ms (19.351%).\nFile unordered_map_clang average run time: 3298.75 \u00b1 1400.99 ms (42.47%).\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u5e38\u89c4\u7b97\u6cd5 <code>300ms</code> \u7ea7\u4e00\u4e0b\u5b50\u5c31\u88ab\u5361\u5230\u4e86 <code>2000ms</code> \u7ea7\u3002\u6240\u4ee5\u53ef\u4ee5\u5f97\u51fa\u7ed3\u8bba\u4e86\uff1a</p> <ul> <li>\u539f\u751f\u7684 <code>std::unordered_map</code> \u5e38\u6570\u5de8\u5927\uff0c\u968f\u4fbf\u624b\u5199\u4e00\u4e2a\u90fd\u80fd\u5feb\u4e00\u500d\u3002</li> <li>\u5361\u54c8\u5e0c\u5bf9\u7b97\u6cd5\u6027\u80fd\u5f71\u54cd\u5de8\u5927\u3002\u4e3a\u4e86\u907f\u514d\u88ab\u5361\u54c8\u5e0c\uff0c\u53ef\u4ee5\u7528\u5176\u4ed6\u5bc6\u7801\u5b66\u5b89\u5168\u7684\u54c8\u5e0c\u6216\u8005\u5229\u7528\u65f6\u95f4\u5f15\u5165\u968f\u673a\u6027\u3002</li> </ul>"}, {"location": "algorithm/benchmark-on-stl/#stdunordered_mapstdmap", "title": "<code>std::unordered_map</code>\u548c\u624b\u5199\u54c8\u5e0c\u5bf9\u6bd4<code>std::map</code>", "text": "<p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 3, 2025). STL\u7684\u4e00\u4e9b\u6027\u80fd\u6d4b\u8bd5 [Blog post]. Retrieved from https://dicaeopolis.github.io/algorithm/benchmark-on-stl</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{benchmark-on-stl,\n    title={STL\u7684\u4e00\u4e9b\u6027\u80fd\u6d4b\u8bd5},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/algorithm/benchmark-on-stl}},\n}\n</code></pre></p>"}, {"location": "algorithm/stl-wheels/", "title": "\u55ef\u9020\u8f6e\u5b50", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 4 \u5206\u949f\u3000|\u3000\u7ea6 201 \u5b57\u3000|\u3000\u7ea6 310 \u884c\u4ee3\u7801</p> <p>\u67d0\u6570\u636e\u7ed3\u6784\u8bfe\u7a0b\u4e0d\u5141\u8bb8\u7528STL\uff0c\u4f46\u6211\u53c8\u633a\u559c\u6b22\u7528STL\u7684\uff0c\u548b\u529e\uff1f</p> <p>\ud83e\uddd0\u2026\u2026\ud83e\udd13\ud83d\udca1</p> <p>\u53cd\u6b63\u6211\u4e5f\u7528\u4e0d\u4e0a\u592a\u591a\u64cd\u4f5c\uff0c\u4e0d\u59a8\u76f4\u63a5\u5c01\u88c5\u5e38\u7528\u7684\u6a21\u677f\u548c\u5e38\u7528\u7684\u64cd\u4f5c~</p> <p>\uff08\u522b\u60f3\u4e86\uff0c\u6ca1\u6709\u624b\u6495\u7ea2\u9ed1\u6811\uff09</p>"}, {"location": "algorithm/stl-wheels/#stdvector", "title": "<code>std::vector</code>", "text": "<pre><code>#include &lt;cstdlib&gt;\ntemplate &lt;typename T&gt;\nclass vector\n{\n    private:\n        T* data;\n        size_t _size;\n        size_t _capacity;\n\n        constexpr static double phi = 1.5;\n        constexpr static int initial_data_cnt = 16;\n        void memory_expand()\n        {\n            _capacity = static_cast&lt;size_t&gt;(phi * _capacity);\n            T* tmp = static_cast&lt;T*&gt;(realloc(data, _capacity * sizeof(T)));\n            if(tmp != NULL) data = tmp;\n            else std::cerr &lt;&lt; \"Un able to reacllocate memory.\\n\";\n        }\n    public:\n        vector() : _size(0), _capacity(0) { data = nullptr; }\n        vector(int size) : _size(size), _capacity(size) { data = static_cast&lt;T*&gt;(malloc(size * sizeof(T))); }\n        bool empty() { return !_size; }\n        void push_back(T new_item)\n        {\n            if(_size == 0)\n            {\n                data = static_cast&lt;T*&gt;(malloc(initial_data_cnt * sizeof(T)));\n                _capacity = initial_data_cnt;\n            }\n            else if(_size == (_capacity - 1)) // prevent end() pointing to unallocated memory.\n                memory_expand();\n            data[_size] = new_item;\n            ++_size;\n        }\n        const size_t size() { return _size; }\n        T&amp; operator[] (size_t idx) { return data[idx]; }\n        T front() { return data[0]; }\n        T back() { return data[_size - 1]; }\n        T* begin() { return data; }\n        T* end() { return data + _size; }\n};\n</code></pre>"}, {"location": "algorithm/stl-wheels/#stddequestdqueuestdstackstdlist", "title": "\u5229\u7528\u53cc\u5411\u94fe\u8868\u5b9e\u73b0\u7684<code>std::deque</code>\u3001<code>std::queue</code>\u3001<code>std::stack</code>\u548c<code>std::list</code>", "text": "<p>\u53cc\u5411\u94fe\u8868\u7ed3\u70b9\u57fa\u7840\u6a21\u677f\uff1a <pre><code>template&lt;typename T&gt;\nclass _list\n{\n    public:\n        _list&lt;T&gt;* _next;\n        _list&lt;T&gt;* _prev;\n        T _data;\n        _list() : _next(nullptr), _prev(nullptr) { }\n        _list(T data) : _data(data), _next(nullptr), _prev(nullptr) { }\n        void insert_after(T data)\n        {\n\n            _list&lt;T&gt;* node = new _list&lt;T&gt;(data);\n            node-&gt;_next = _next;\n            node-&gt;_prev = this;\n            _next-&gt;_prev = node;\n            _next = node;\n\n        }\n        void insert_before(T data)\n        {\n\n            _list&lt;T&gt;* node = new _list&lt;T&gt;(data);\n            node-&gt;_next = this;\n            node-&gt;_prev = _prev;\n            _prev-&gt;_next = node;\n            _prev = node;\n\n        }\n};\n\ntemplate&lt;typename T&gt;\nclass _deque\n{\n    public:\n        _list&lt;T&gt;* _head;\n        _list&lt;T&gt;* _tail;\n        _deque() : _head(), _tail()\n        {\n            _head = new _list&lt;T&gt;;\n            _tail = new _list&lt;T&gt;;\n            _head-&gt;_next = _tail;\n            _tail-&gt;_prev = _head;\n        }\n        bool empty() { return (_head-&gt;_next == _tail &amp;&amp; _tail-&gt;_prev == _head); }\n        void push_front(T data) { _head-&gt;insert_after(data); }\n        void push_back(T data) { _tail-&gt;insert_before(data); }\n        void pop_front()\n        {\n            if(empty()) return ;\n            _list&lt;T&gt;* next = _head-&gt;_next;\n            next-&gt;_next-&gt;_prev = _head;\n            _head-&gt;_next = next-&gt;_next;\n            delete next;\n        }\n        void pop_back()\n        {\n            if(empty()) return ;\n            _list&lt;T&gt;* prev = _tail-&gt;_prev;\n            prev-&gt;_prev-&gt;_next = _tail;\n            _tail-&gt;_prev = prev-&gt;_prev;\n            delete prev;\n        }\n};\n</code></pre></p> <p>\u6ce8\u610f\u8fd9\u91cc\u6211\u5c3d\u91cf\u4f7f\u5f97\u53cc\u5411\u94fe\u8868\u64cd\u4f5c\u5c40\u9650\u5728\u4e09\u4e2a\u8282\u70b9\u7684\u7a97\u53e3\u91cc\u9762\u3002\u5220\u9664\u8282\u70b9\u7684\u64cd\u4f5c\u9700\u8981\u6709\u4e00\u4e2a\u5934\u8282\u70b9\u6765\u9876\u4f4f\uff0c\u4e0d\u7136\u8282\u70b9\u4e00\u5220\uff0c\u5c31\u627e\u4e0d\u7740\u5317\u4e86\u3002</p>"}, {"location": "algorithm/stl-wheels/#deque", "title": "<code>deque</code>\u5b9e\u73b0", "text": "<pre><code>template&lt;typename T&gt;\nclass deque\n{\n    private:\n        _deque&lt;T&gt; _data;\n        size_t _size;\n    public:\n        deque() : _data() {  _size = 0; }\n        bool empty() { return !_size &amp;&amp; _data.empty(); }\n        T front()\n        {\n            if(_data._head-&gt;_next != nullptr &amp;&amp; _size != 0)\n                return _data._head-&gt;_next-&gt;_data;\n            std::cerr &lt;&lt; \"No front\\n\";\n            T res;\n            return res;\n        }\n        T back()\n        {\n            if(_data._tail-&gt;_prev != nullptr &amp;&amp; _size != 0)\n                return _data._tail-&gt;_prev-&gt;_data;\n            std::cerr &lt;&lt; \"No back\\n\";\n            T res;\n            return res;\n        }\n        void push_front(T data) { _data.push_front(data); ++_size; }\n        void push_back(T data) { _data.push_back(data); ++_size; }\n        void pop_front()\n        {\n            if(_size != 0)\n            {\n                _data.pop_front();\n                --_size;\n            }\n        }\n        void pop_back()\n        {\n            if(_size != 0)\n            {\n                _data.pop_back();\n                --_size;\n            }\n        }\n};\n</code></pre>"}, {"location": "algorithm/stl-wheels/#queue", "title": "<code>queue</code>\u5b9e\u73b0", "text": "<pre><code>template&lt;typename T&gt;\nclass queue\n{\n    private:\n        deque&lt;T&gt; _data;\n    public:\n        queue() : _data() {}\n        bool empty() { return _data.empty(); }\n        void push(T data) { _data.push_back(data); }\n        void pop() { _data.pop_front(); }\n        T front() { return _data.front(); }\n};\n</code></pre>"}, {"location": "algorithm/stl-wheels/#stack", "title": "<code>stack</code>\u5b9e\u73b0", "text": "<pre><code>template&lt;typename T&gt;\nclass stack\n{\n    private:\n        deque&lt;T&gt; _data;\n    public:\n        stack() : _data() {}\n        bool empty() { return _data.empty(); }\n        void push(T data) { _data.push_back(data); }\n        void pop() { _data.pop_back(); }\n        T top() { return _data.back(); }\n};\n</code></pre>"}, {"location": "algorithm/stl-wheels/#list", "title": "<code>list</code>\u5b9e\u73b0", "text": "<pre><code>template&lt;typename T&gt;\nclass list\n{\n    private:\n        _list&lt;T&gt;* _head;\n        _list&lt;T&gt;* _tail;\n    public:\n        class iterator\n        {\n            private:\n                _list&lt;T&gt;* ptr;\n            public:\n                iterator(_list&lt;T&gt; p = nullptr) : ptr(p) {}\n                iterator&amp; operator++() { ptr = ptr-&gt;_next; return *this; }\n                iterator&amp; operator--() { ptr = ptr-&gt;_prev; return *this; }\n                bool operator!=(const iterator&amp; other) { return other.ptr != ptr; }\n                T&amp; operator*() { return ptr-&gt;_data; }\n        };\n        list() : _head(), _tail()\n        {\n            _head = new _list&lt;T&gt;;\n            _tail = new _list&lt;T&gt;;\n            _head-&gt;_next = _tail;\n            _tail-&gt;_prev = _head;\n        }\n        bool empty() { return (_head-&gt;_next == _tail &amp;&amp; _tail-&gt;_prev == _head); }\n        void push_front(T data) { _head-&gt;insert_after(data); }\n        void push_back(T data) { _tail-&gt;insert_before(data); }\n        void pop_front()\n        {\n            if(empty()) return ;\n            _list&lt;T&gt;* next = _head-&gt;_next;\n            next-&gt;_next-&gt;_prev = _head;\n            _head-&gt;_next = next-&gt;_next;\n            delete next;\n        }\n        void pop_back()\n        {\n            if(empty()) return ;\n            _list&lt;T&gt;* prev = _tail-&gt;_prev;\n            prev-&gt;_prev-&gt;_next = _tail;\n            _tail-&gt;_prev = prev-&gt;_prev;\n            delete prev;\n        }\n        iterator begin() { return iterator(_head-&gt;_next); }\n        iterator end() { return iterator(_tail); }\n        void erase(iterator item)\n        {\n            _list&lt;T&gt;* node = item.ptr;\n            if(node == _head || node == _tail) return;\n            node-&gt;_prev-&gt;_next = node-&gt;_next;\n            node-&gt;_next-&gt;_prev = node-&gt;_prev;\n            delete node;\n        }\n};\n</code></pre> <p>\u8fd9\u91cc\u81ea\u5b9a\u4e49\u4e86\u8fed\u4ee3\u5668\u7c7b\uff0c\u4f9b\u987a\u5e8f\u8bbf\u95ee\u4f7f\u7528\u3002</p>"}, {"location": "algorithm/stl-wheels/#_2", "title": "\u54c8\u5e0c\u8868", "text": "<p>\u5229\u7528CRC64\u8fdb\u884c\u54c8\u5e0c\u5e76\u5728\u7f16\u8bd1\u671f\u8ba1\u7b97\u4e86\u7cfb\u6570\u8868\u3002</p> <p>\u4f9d\u8d56\u524d\u9762\u7684<code>list</code>\u548c<code>vector</code>\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u4f7f\u7528\u73b0\u6210\u7684STL\u3002</p> <pre><code>#include &lt;array&gt;\nnamespace crc64 {    \n    constexpr uint64_t CRC64_POLY = 0x42F0E1EBA9EA3693ULL;\n\n    constexpr std::array&lt;uint64_t, 256&gt; generate_crc64_table()\n    {\n        std::array&lt;uint64_t, 256&gt; table = {};\n        for (int i = 0; i &lt; 256; ++i) {\n            uint64_t crc = i;\n            for (int j = 0; j &lt; 8; ++j)\n                crc = (crc &amp; 1) ? (crc &gt;&gt; 1) ^ CRC64_POLY : crc &gt;&gt; 1;\n            table[i] = crc;\n        }\n        return table;\n    }\n\n    constexpr std::array&lt;uint64_t, 256&gt; crc64_table = generate_crc64_table();\n\n    uint64_t crc64(const uint8_t *data, size_t length)\n    {\n        uint64_t crc = 0xFFFFFFFFFFFFFFFFULL;\n        for (size_t i = 0; i &lt; length; i++) {\n            uint8_t index = (uint8_t)(crc ^ data[i]);\n            crc = (crc &gt;&gt; 8) ^ crc64_table[index];\n        }\n        return crc ^ 0xFFFFFFFFFFFFFFFFULL;\n    }\n}\n\n\nconstexpr size_t hash_mod = 126271;\n\ntemplate&lt;typename key_type, typename value_type&gt;\nclass unordered_map {\n    typedef std::pair&lt;key_type, value_type&gt; mapped_type;\n    private:\n        vector&lt;list&lt;mapped_type&gt;&gt; table;\n        size_t pair_cnt = 0;\n        size_t get_idx(const key_type&amp; key)\n        {\n            auto hash = crc64::crc64((uint8_t*) &amp;key, sizeof(key));\n            return static_cast&lt;size_t&gt;(hash % hash_mod);\n        }\n        const size_t get_idx(const key_type&amp; key) const\n        {\n            auto hash = crc64::crc64((uint8_t*) &amp;key, sizeof(key));\n            return static_cast&lt;size_t&gt;(hash % hash_mod);\n        }\n        auto&amp; get_item(const key_type&amp; key)\n        {\n            auto idx = get_idx(key);\n            return table[idx];\n        }\n        const auto&amp; get_item(const key_type&amp; key) const\n        {\n            auto idx = get_idx(key);\n            return table[idx];\n        }\n    public:\n        unordered_map() : table(hash_mod) {}\n        value_type&amp; operator[](const key_type&amp; key)\n        {\n            auto&amp; item = get_item(key);\n            for(auto&amp; val : item)\n                if(val.first == key)\n                    return val.second;\n            value_type val;\n            item.push_back(std::make_pair(key, val));\n            ++pair_cnt;\n            return item.back().second;\n        }\n        bool empty() const noexcept\n        {\n            return !(pair_cnt);\n        }\n        bool find(const key_type &amp;key) const noexcept\n        {\n            const auto&amp; item = get_item(key);\n            for(const auto&amp; val : item)\n                if(val.first == key)\n                    return true;\n            return false;\n        }\n        void erase(const key_type&amp; key)\n        {\n            auto&amp; item = get_item(key);\n            for(auto it = item.begin(); it != item.end(); ++it)\n                if(it-&gt;first == key) {\n                    item.erase(it);\n                    --pair_cnt;\n                    break;\n                }\n        }      \n};\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 3, 2025). \u55ef\u9020\u8f6e\u5b50 [Blog post]. Retrieved from https://dicaeopolis.github.io/algorithm/stl-wheels</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{stl-wheels,\n    title={\u55ef\u9020\u8f6e\u5b50},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/algorithm/stl-wheels}},\n}\n</code></pre></p>"}, {"location": "algorithm/template-on-numeric-ring/", "title": "\u6574\u6570\u73af\u53d6\u6a21\u6a21\u677f", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 2 \u5206\u949f\u3000|\u3000\u7ea6 72 \u5b57\u3000|\u3000\u7ea6 186 \u884c\u4ee3\u7801</p> <p>\u9002\u5408\u5404\u79cd\u7b97\u6cd5\u7ade\u8d5b\u7684\u5168\u5c40\u53d6\u6a21\u573a\u666f\u4f7f\u7528\u3002</p> <p>\u4e00\u4e2a\u590d\u6742\u4e00\u70b9\u7684\u7248\u672c\uff0c\u53ea\u652f\u6301\u7d20\u6570\u6a21\u6570\u4f46\u662f\u529f\u80fd\u548c\u4f18\u5316\u4f1a\u66f4\u591a\uff1a</p> <pre><code>#include&lt;limits&gt;\n#include&lt;cstdint&gt;\n#include&lt;iostream&gt;\n\n/* A Modulo-safe Template Designed for Competitive Programming. */\n/* Notes:\n *  0. Use C++ 20 or newer. (for operator &lt;=&gt;)\n *  1. Modulus `mod` must be less than Sqrt(MAX_OF_NUMTYPE), or it will overflow in multiplication.\n *  2. Modulus must be a prime.\n *  3. Use -O2 or higher optimization level.\n */\nconstexpr bool is_prime(uint64_t n)\n{\n    if (n &lt;= 1) return false;\n    for (uint64_t i = 2; i &lt;= (n / i); ++i)\n        if (n % i == 0) return false;\n    return true;\n}\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nclass Ring\n{\n    static_assert(std::is_unsigned_v&lt;NumType&gt;, \"NumType must be unsigned\");\n    static_assert(MOD &gt; 1, \"MOD must be greater than 1\");\n    static_assert(is_prime(MOD), \"MOD must be a prime\");\n    static_assert(MOD &lt;= std::numeric_limits&lt;NumType&gt;::max() / MOD, \"MOD is too large (MOD^2 exceeds NumType max)\");\n    NumType num;\n    private:\n        Ring inv() const { return Ring(pow_mod(num, MOD - 2)); }\n        static NumType pow_mod(NumType a, NumType b) {\n            NumType res = 1;\n            a %= MOD;\n            while (b) {\n                if (b &amp; 1) res = static_cast&lt;NumType&gt;((1ULL * res * a) % MOD);\n                a = static_cast&lt;NumType&gt;((1ULL * a * a) % MOD);\n                b &gt;&gt;= 1;\n            }\n            return res;\n        }\n    public:\n        Ring() { num = 0; }\n        Ring(NumType x) : num(x % MOD) { }\n        Ring operator+(const Ring&lt;NumType, MOD&gt;&amp; b) const\n        { \n            //Assert num and b.num are in [0, MOD)\n            NumType res = num + b.num;\n            if(res &gt;= MOD) return Ring(res - MOD);\n            else return Ring(res);\n        }\n        Ring operator-(const Ring&lt;NumType, MOD&gt;&amp; b) const  \n        {\n            //Assert num and b.num are in [0, MOD)\n            if(num &lt; b.num) return Ring(num + MOD - b.num);\n            else return Ring(num - b.num);\n        }\n        Ring operator*(const Ring&lt;NumType, MOD&gt;&amp; b) const\n        {\n            if constexpr (MOD &gt;= std::numeric_limits&lt;uint32_t&gt;::max())\n                return Ring(static_cast&lt;NumType&gt;((static_cast&lt;__uint128_t&gt;(num) * b.num) % MOD));\n            else\n            {\n                uint64_t product = 1ULL * num * b.num;\n                static constexpr uint64_t mu = (static_cast&lt;uint64_t&gt;(1) &lt;&lt; 63) / MOD;\n                uint64_t q = (product * mu) &gt;&gt; 63;\n                NumType res = static_cast&lt;NumType&gt;(product - q * MOD);\n                if (res &gt;= MOD) res -= MOD;\n                return Ring(res);\n            }\n        }\n        Ring operator/(const Ring&lt;NumType, MOD&gt;&amp; b) const \n        {\n            if constexpr (is_prime(MOD)) return *this * b.inv();\n            else static_assert(!(sizeof(NumType)), \"Require a prime modulus.\");\n        }\n        Ring operator%(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring(num % b.num); } // b.num &lt; MOD is ensured. This operator only cuts down size.\n        Ring operator^(const Ring&lt;NumType, MOD&gt;&amp; exp) const { return Ring(pow_mod(num, exp.num)); }\n        void operator+=(const Ring&lt;NumType, MOD&gt;&amp; b)\n        {\n            NumType res = num + b.num;\n            if(res &gt;= MOD) num = res - MOD;\n            else num = res;\n        }\n        void operator-=(const Ring&lt;NumType, MOD&gt;&amp; b)\n        {\n            if(num &lt; b.num) num = num + MOD - b.num;\n            else num -= b.num;\n        }\n        auto operator&lt;=&gt;(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num &lt;=&gt; b.num; }\n        template&lt;typename T, uint64_t M&gt;\n        friend std::istream&amp; operator&gt;&gt;(std::istream&amp; in, Ring&lt;T, M&gt;&amp; a);\n        template&lt;typename T, uint64_t M&gt;\n        friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const Ring&lt;T, M&gt;&amp; a);\n};\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nstd::istream&amp; operator&gt;&gt;(std::istream&amp; in, Ring&lt;NumType, MOD&gt;&amp; a)\n{\n    NumType tmp;\n    in &gt;&gt; tmp;\n    a.num = tmp % MOD;\n    return in;\n}\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nstd::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const Ring&lt;NumType, MOD&gt;&amp; a)\n{\n    out &lt;&lt; a.num;\n    return out;\n}\nusing u64 = unsigned long long;\nusing Z = Ring&lt;u64, 998244353&gt;;\n\nint main()\n{\n    std::ios::sync_with_stdio(false);\n    std::cin.tie(nullptr);\n    std::cout.tie(nullptr);\n    Z x, y;\n    std::cin &gt;&gt; x &gt;&gt; y;\n    std::cout &lt;&lt; \"x + y : \" &lt;&lt; x+y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x - y : \" &lt;&lt; x-y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x * y : \" &lt;&lt; x*y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x * inv y : \" &lt;&lt; x/y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x ^ y : \" &lt;&lt; (x^y) &lt;&lt; '\\n';\n    return 0;\n}\n</code></pre> <p>\u4e00\u4e2a\u66f4\u7b80\u5355\u7684\u7248\u672c\uff0c\u652f\u6301\u4efb\u610f\u6a21\u6570\uff0c\u4f46\u4e0d\u652f\u6301\u9006\u5143\u9664\u6cd5\uff1a</p> <pre><code>#include&lt;limits&gt;\n#include&lt;cstdint&gt;\n#include&lt;iostream&gt;\n\n/* A Modulo-safe Template Designed for Competitive Programming. ~Short Ver.~*/\n/* Notes:\n *  0. Use C++ 11 or newer.\n *  1. Modulus `mod` must be less than Sqrt(MAX_OF_NUMTYPE), or it will overflow in multiplication.\n *  3. Use -O2 or higher optimization level.\n */\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nclass Ring\n{\n    static_assert(MOD &lt;= std::numeric_limits&lt;NumType&gt;::max() / MOD, \"MOD is too large (MOD^2 exceeds NumType max)\");\n    NumType num;\n    private:\n    public:\n        Ring() { num = 0; }\n        Ring(NumType x) : num(x % MOD) { }\n        Ring operator+(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring((num + b.num) % MOD); }\n        Ring operator-(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring((num + MOD - b.num) % MOD); }\n        Ring operator*(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring((1ULL * num * b.num) % MOD); }\n        Ring operator/(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring(num / b.num); } // inverts are not assured.\n        Ring operator%(const Ring&lt;NumType, MOD&gt;&amp; b) const { return Ring(num % b.num); } // b.num &lt; MOD is ensured. This operator only cuts down size.\n        void operator+=(const Ring&lt;NumType, MOD&gt;&amp; b) { num = (num + b.num) % MOD; }\n        void operator-=(const Ring&lt;NumType, MOD&gt;&amp; b) { num = (num + MOD - b.num) % MOD; }\n        bool operator&lt;(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num &lt; b.num; }\n        bool operator&gt;(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num &gt; b.num; }\n        bool operator==(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num == b.num; }\n        bool operator&lt;=(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num &lt;= b.num; }\n        bool operator&gt;=(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num &gt;= b.num; }\n        bool operator!=(const Ring&lt;NumType, MOD&gt;&amp; b) const { return num != b.num; }        \n        template&lt;typename T, uint64_t M&gt;\n        friend std::istream&amp; operator&gt;&gt;(std::istream&amp; in, Ring&lt;T, M&gt;&amp; a);\n        template&lt;typename T, uint64_t M&gt;\n        friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const Ring&lt;T, M&gt;&amp; a);\n};\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nstd::istream&amp; operator&gt;&gt;(std::istream&amp; in, Ring&lt;NumType, MOD&gt;&amp; a)\n{\n    NumType tmp;\n    in &gt;&gt; tmp;\n    a.num = tmp % MOD;\n    return in;\n}\ntemplate&lt;typename NumType, uint64_t MOD&gt;\nstd::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const Ring&lt;NumType, MOD&gt;&amp; a)\n{\n    out &lt;&lt; a.num;\n    return out;\n}\nusing u64 = unsigned long long;\nusing Z = Ring&lt;u64, 998244353&gt;;\n\nint main()\n{\n    std::ios::sync_with_stdio(false);\n    std::cin.tie(nullptr);\n    std::cout.tie(nullptr);\n    Z x, y;\n    std::cin &gt;&gt; x &gt;&gt; y;\n    std::cout &lt;&lt; \"x + y : \" &lt;&lt; x+y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x - y : \" &lt;&lt; x-y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x * y : \" &lt;&lt; x*y &lt;&lt; '\\n';\n    std::cout &lt;&lt; \"x * inv y : \" &lt;&lt; x/y &lt;&lt; '\\n';\n    return 0;\n}\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 3, 2025). \u6574\u6570\u73af\u53d6\u6a21\u6a21\u677f [Blog post]. Retrieved from https://dicaeopolis.github.io/algorithm/template-on-numeric-ring</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{template-on-numeric-ring,\n    title={\u6574\u6570\u73af\u53d6\u6a21\u6a21\u677f},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/algorithm/template-on-numeric-ring}},\n}\n</code></pre></p>"}, {"location": "campus-sources/", "title": "\u5173\u4e8e\u672c\u5206\u7c7b", "text": "<p>\u8bb0\u5f55\u4e00\u4e9b\u6821\u5185\u4e13\u4e1a\u8bfe\u76f8\u5173\u7684\u7b14\u8bb0/\u9898\u89e3/\u8bbe\u8ba1\u7b49\u8d44\u6e90\u3002</p>"}, {"location": "campus-sources/Descrete_assignments/", "title": "\u300a\u79bb\u6563\u6570\u5b66\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 12 \u5206\u949f\u3000|\u3000\u7ea6 723 \u5b57\u3000|\u3000\u7ea6 87 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 5 \u884c\u4ee3\u7801</p> <p>\u4f9b\u5b58\u6863\u548c\u590d\u4e60\u7528\u3002</p>"}, {"location": "campus-sources/Descrete_assignments/#_2", "title": "\u7b2c\u4e00\u6b21\u4f5c\u4e1a", "text": "<p>\u8bb0 2 + 2 = 4 \u4e3a p\uff0c3 + 3 = 6 \u4e3a q\u3002</p> <ul> <li>(1) \\(p\\rightarrow q\\), \u771f</li> <li>(2) \\(p\\rightarrow \\neg q\\)\uff0c\u5047</li> <li>(3) \\(\\neg p\\rightarrow q\\)\uff0c\u771f</li> <li>(4) \\(\\neg p\\rightarrow \\neg q\\)\uff0c\u771f</li> <li>(5) \\(p\\leftrightarrow q\\)\uff0c\u771f</li> <li>(6) \\(p\\leftrightarrow \\neg q\\)\uff0c\u5047</li> <li>(7) \\(\\neg p\\leftrightarrow q\\)\uff0c\u5047</li> <li>(8) \\(\\neg p\\leftrightarrow \\neg q\\)\uff0c\u771f</li> </ul> <p>\u5176\u5b9e\u5c31\u662f\u8003\u5bdf\u4e24\u4e2a\u8054\u7ed3\u8bcd\u7684\u771f\u503c\u8868\u3002</p> <p></p> <ul> <li>(1) \u8bb0 \u201c2 \u662f\u5076\u6570\u201d \u4e3a p\uff0c\u8bb0 \u201c2 \u662f\u7d20\u6570\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(p\\land q\\)</li> <li>(2) \u8bb0 \u201c\u5c0f\u738b\u806a\u660e\u201d \u4e3a p\uff0c\u8bb0 \u201c\u5c0f\u738b\u7528\u529f\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(p\\land q\\)</li> <li>(3) \u8bb0 \u201c\u5929\u6c14\u5f88\u51b7\u201d \u4e3a p\uff0c\u8bb0 \u201c\u8001\u738b\u6765\u4e86\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(p\\land q\\)</li> <li>(4) \u8bb0 \u201c\u4ed6\u5403\u996d\u201d \u4e3a p\uff0c\u8bb0 \u201c\u4ed6\u770b\u7535\u89c6\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(p\\land q\\)</li> <li>(5) \u8bb0 \u201c\u4e0b\u5927\u96e8\u201d \u4e3a p\uff0c\u8bb0 \u201c\u4ed6\u4e58\u516c\u5171\u6c7d\u8f66\u4e0a\u73ed\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(p\\rightarrow q\\)</li> <li>(6) \u8bb0 \u201c\u4e0b\u5927\u96e8\u201d \u4e3a p\uff0c\u8bb0 \u201c\u4ed6\u4e58\u516c\u5171\u6c7d\u8f66\u4e0a\u73ed\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(q\\rightarrow p\\)</li> <li>(7) \u8bb0 \u201c\u4e0b\u5927\u96e8\u201d \u4e3a p\uff0c\u8bb0 \u201c\u4ed6\u4e58\u516c\u5171\u6c7d\u8f66\u4e0a\u73ed\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(q\\rightarrow p\\)</li> <li>(8) \u8bb0 \u201c\u7ecf\u4e00\u4e8b\u201d \u4e3a p\uff0c\u8bb0 \u201c\u957f\u4e00\u667a\u201d \u4e3a q\uff0c\u5219\u547d\u9898\u7b26\u53f7\u5316\u4e3a \\(q\\rightarrow p\\)</li> </ul> <p>\u4e0d\u2026\u2026\u4e0d = \u51fa\u53d1\u2026\u2026\u5426\u5219\u4e0d = \u53ea\u6709\u2026\u2026\u624d</p> <p></p> <ul> <li>(1) \\(p\\lor (q\\land r)=0\\lor (0\\land 1)=0\\)</li> <li>(2) \\((p\\leftrightarrow r)\\land (\\neg q\\lor s)=(0\\leftrightarrow 1)\\land (\\neg q\\lor s)=0\\) \u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u5229\u7528 \\(\\land\\) \u7684\u77ed\u8def\u7279\u6027</li> <li>(3) \\((p\\land (q\\lor r))\\rightarrow ((p\\lor q)\\land(r\\land s))=(0\\land (0\\lor 1))\\rightarrow ((0\\lor 0)\\land(1\\land 1))=1\\) \u540c\u6837\u662f\u5229\u7528\u8574\u542b\u7b26\u53f7\u5de6\u8fb9 \\(\\land\\) \u7684\u77ed\u8def\u7279\u6027\u5f97\u5230\u90a3\u4e00\u5768\u662f \\(0\\) \u7136\u540e\u518d\u5229\u7528\u8574\u542b\u7b26\u53f7\u672c\u8eab\u7684\u77ed\u8def\u7279\u6027\u5f97\u5230\u7ed3\u679c</li> <li>(4) \\(\\neg (p\\lor (q\\rightarrow (r\\land \\neg p)))\\rightarrow (r\\lor \\neg s)=\\neg (0\\lor (0\\rightarrow (r\\land \\neg p)))\\rightarrow (1\\lor \\neg 1)=1\\rightarrow 1=1\\)</li> </ul> <p></p> <ul> <li>(1) \\(\\neg((p \\land q) \\to p)=\\neg (\\neg (p \\land q)\\lor p)=(p \\land q)\\land \\neg p=q\\land( p\\land\\neg p)=0\\) \u4e3a\u77db\u76fe\u5f0f\u3002</li> <li>(2) \\(((p \\to q) \\land (q \\to p)) \\leftrightarrow (p \\leftrightarrow q)=(p \\leftrightarrow q)\\leftrightarrow(p \\leftrightarrow q)=1\\) \u4e3a\u91cd\u8a00\u5f0f\u3002</li> <li>(3) \\((\\neg p \\to q) \\to (q \\to \\neg p)=(\\neg(\\neg p) \\lor q)\\to (\\neg q \\lor \\neg p)\\) \\(=(p \\lor q)\\to \\neg(q \\land p)=\\neg(p \\lor q)\\lor \\neg(q \\land p)=\\neg(p \\lor q\\land q \\land p)=\\neg(p\\land q)\\) \u4e3a\u53ef\u6ee1\u8db3\u5f0f\u3002</li> </ul>"}, {"location": "campus-sources/Descrete_assignments/#_3", "title": "\u7b2c\u4e8c\u6b21\u4f5c\u4e1a", "text": "<p>(1) \u4e3b\u6790\u53d6\u8303\u5f0f\uff1a</p> \\[ \\begin{align*}     (p\\lor(q\\land r))\\to (p\\land q\\land r)&amp;\\Leftrightarrow \\neg(p\\lor(q\\land r))\\lor (p\\land q\\land r)\\\\     &amp;\\Leftrightarrow(\\neg p \\land (\\neg q\\lor \\neg r))\\lor (p\\land q\\land r)\\\\     &amp;\\Leftrightarrow(\\neg p\\neg q(r\\lor\\neg r)\\lor\\neg p\\neg r(q\\lor\\neg q))\\lor(pqr)\\\\     &amp;\\Leftrightarrow(\\neg p\\land \\neg q\\land r)\\lor(\\neg p\\land \\neg q\\land \\neg r)\\lor(\\neg p\\land q\\land \\neg r)\\lor (p\\land q\\land r) \\end{align*} \\] <p>\u7531\u6b64\u5f97\u5230\u6210\u771f\u8d4b\u503c\u548c\u6210\u5047\u8d4b\u503c\uff1a</p> \\[ pqr_{\\mathrm{\u6210\u771f\u8d4b\u503c}} = \\{000, 001, 010, 111\\}\\\\ pqr_{\\mathrm{\u6210\u5047\u8d4b\u503c}} = \\{011, 100, 101, 110\\} \\] <p>\u4e3b\u5408\u53d6\u8303\u5f0f\u53ef\u7531\u6210\u5047\u8d4b\u503c\u76f4\u63a5\u5f97\u5230\uff1a</p> \\[ (p\\lor(q\\land r))\\to (p\\land q\\land r)\\Leftrightarrow(\\neg p\\lor q\\lor r)\\land(p\\lor \\neg q\\land \\neg r)\\land(p\\lor \\neg q\\lor r)\\land (p\\lor q\\lor \\neg r) \\] <p>(2) \u4e3b\u6790\u53d6\u8303\u5f0f\uff1a</p> \\[ \\begin{align*}     (\\neg p\\to q)\\to(\\neg q\\lor p)&amp;\\Leftrightarrow\\neg(p\\lor q)\\lor(\\neg q\\lor p)\\\\     &amp;\\Leftrightarrow(\\neg p\\land \\neg q)\\lor(\\neg q\\lor p)\\\\     &amp;\\Leftrightarrow(\\neg p\\land \\neg q)\\lor(\\neg q\\land(p\\lor \\neg p)\\lor p\\land(q\\lor \\neg q))\\\\     &amp;\\Leftrightarrow(\\neg p\\land \\neg q)\\lor(p\\land \\neg q)\\lor(p\\land q) \\end{align*} \\] <p>\u7531\u6b64\u5f97\u5230\u6210\u771f\u8d4b\u503c\u548c\u6210\u5047\u8d4b\u503c\uff1a</p> \\[ pq_{\\mathrm{\u6210\u771f\u8d4b\u503c}} = \\{00,10,11\\}\\\\ pq_{\\mathrm{\u6210\u5047\u8d4b\u503c}} = \\{01\\} \\] <p>\u4e3b\u5408\u53d6\u8303\u5f0f\u53ef\u7531\u6210\u5047\u8d4b\u503c\u76f4\u63a5\u5f97\u5230\uff1a</p> \\[ (\\neg p\\to q)\\to(\\neg q\\lor p)\\Leftrightarrow p\\land\\neg q \\] <p>(3) \u4e3b\u6790\u53d6\u8303\u5f0f\uff1a</p> \\[ \\begin{align*}     \\neg (p\\to q)\\land q\\land r&amp;\\Leftrightarrow \\neg (\\neg p\\lor q)\\land q\\land r\\\\     &amp;\\Leftrightarrow(p\\land \\neg q)\\land q\\land r\\\\     &amp;\\Leftrightarrow0 \\end{align*} \\] <p>\u7531\u6b64\u5f97\u5230\u6210\u771f\u8d4b\u503c\u548c\u6210\u5047\u8d4b\u503c\uff1a</p> \\[ pq_{\\mathrm{\u6210\u771f\u8d4b\u503c}} = \\{\\}\\\\ pq_{\\mathrm{\u6210\u5047\u8d4b\u503c}} = \\{000,001,010,011,100,101,110,111\\} \\] <p>\u4e3b\u5408\u53d6\u8303\u5f0f\u53ef\u7531\u6210\u5047\u8d4b\u503c\u76f4\u63a5\u5f97\u5230\uff1a</p> \\[ \\neg (p\\to q)\\land q\\land r\\Leftrightarrow\\\\ (p \\lor q \\lor r) \\land (p \\lor q \\lor \\neg r) \\land (p \\lor \\neg q \\lor r) \\land (p \\lor \\neg q \\lor \\neg r) \\land (\\neg p \\lor q \\lor r) \\land (\\neg p \\lor q \\lor \\neg r) \\land (\\neg p \\lor \\neg q \\lor r) \\land (\\neg p \\lor \\neg q \\lor \\neg r) \\]"}, {"location": "campus-sources/Descrete_assignments/#_4", "title": "\u7b2c\u4e09\u6b21\u4f5c\u4e1a", "text": "\\[ \\begin{align*}     p\\uparrow q &amp;\\iff \\neg(p\\land q)\\\\     &amp;\\iff \\neg p \\lor \\neg q\\\\     &amp;\\iff \\neg p(q\\lor\\neg q)\\lor \\neg q(p\\lor \\neg p)\\\\     &amp;\\iff (\\neg p\\land q) \\lor (p\\land\\neg q) \\lor (\\neg p\\land\\neg q) \\end{align*} \\] \\[ \\begin{align*}     p\\downarrow q &amp;\\iff \\neg(p\\lor q)\\\\     &amp;\\iff \\neg p \\land \\neg q\\\\     &amp;\\iff \\neg p(q\\lor\\neg q)\\land \\neg q\\\\     &amp;\\iff (\\neg p\\land \\neg q) \\end{align*} \\] <p>\u56e0\u6b64\u4e0d\u7b49\u503c\u3002</p> <p></p> <p></p> <p>\u76f4\u63a5\u6c42\u6210\u771f\u8d4b\u503c\uff1a</p> <p>\u5316\u7b80\uff1a</p> <p>\u9996\u5148\u5206\u7ec4\uff0c\u7136\u540e\u8fdb\u884c\u5408\u5e76\uff1a</p> <ul> <li>0 \u4e2a 1: 0000</li> <li>1 \u4e2a 1: 1000, 0100 =&gt; -000, 0-00 =&gt; 0-00</li> <li>2 \u4e2a 1: 1010, 1100 =&gt; 10-0, -100 =&gt; 10-0, --00</li> <li>3 \u4e2a 1: 1011 =&gt; 101-</li> </ul> <p>\u8fd9\u6837\u5f97\u5230\u4e86\u4e3b\u8574\u542b\u9879\uff0c\u7136\u540e\u5217\u8986\u76d6\u8868\uff1a</p> <pre><code>     0 4 8 10 11 12\n0-00 x x\n10-0     x x  \n--00 x x x       x\n101-       x  x\n</code></pre> <p>\u53ef\u89c1 --00 + 101- \u53ef\u4ee5\u5b8c\u5168\u8986\u76d6\uff0c\u56e0\u6b64\u5316\u7b80\u5f97\u5230</p> \\[ \\begin{align*}     F=&amp;\\quad (\\neg x_1\\land\\neg x_2\\land\\neg x_3\\land\\neg x_4)\\\\     &amp;\\lor (\\neg x_1\\land x_2\\land\\neg x_3\\land\\neg x_4)\\\\     &amp;\\lor ( x_1\\land\\neg x_2\\land\\neg x_3\\land\\neg x_4)\\\\     &amp;\\lor (x_1\\land \\neg x_2\\land x_3\\land \\neg x_4)\\\\     &amp;\\lor ( x_1\\land\\neg x_2\\land x_3\\land x_4)\\\\     &amp;\\lor (x_1\\land x_2\\land\\neg x_3\\land\\neg x_4)\\\\     =&amp;\\quad (\\neg x_3\\land \\neg x_4)\\lor(x_1\\land \\neg x_2\\land x_3) \\end{align*} \\] <p></p> <p>Notation:</p> <p>\\(L\\)\uff1a\u4ed6\u662f\u7406\u79d1\u5b66\u751f\uff1b\\(S\\)\uff1a\u4ed6\u5b66\u597d\u6570\u5b66\uff1b\\(W\\)\uff1a\u4ed6\u662f\u6587\u79d1\u5b66\u751f\u3002</p> <p>\u63a8\u7406\u5373\uff1a</p> \\[ \\begin{align*}     (L\\to S)\\land(\\neg W\\to L)\\land(\\neg S)\\to(W)&amp;\\iff (\\neg L\\lor S)\\land(W\\lor L)\\land(\\neg S)\\to(W)\\\\     &amp;\\iff (\\neg L)\\land (W\\lor L)\\to W\\\\     &amp;\\iff W\\to W \\end{align*} \\] <p>\u4e3a\u91cd\u8a00\u5f0f\uff0c\u56e0\u6b64\u63a8\u7406\u6b63\u786e\u3002</p>"}, {"location": "campus-sources/Descrete_assignments/#_5", "title": "\u7b2c\u56db\u6b21\u4f5c\u4e1a", "text": "<p>Notations:</p> <p>\\(F(x):=(x+1)^2=x^2+2x+1\\)\uff0c\\(G(x):=x+2=0\\)\uff0c\\(H(x):=5x=1\\)</p> <p>(1)</p> \\[ \\forall x F(x) \\] <p>\u5728 (a), (b), \u00a9 \u4e2d\u90fd\u4e3a\u771f\u3002</p> <p>(2)</p> \\[ \\exists xG(x) \\] <p>\u5728 (a) \u4e2d\u4e3a\u5047\uff0c\u5728 (b), \u00a9 \u4e2d\u4e3a\u771f\u3002</p> <p>(3)</p> \\[ \\exists xH(x) \\] <p>\u5728 (a), (b) \u4e2d\u4e3a\u5047\uff0c\u5728 \u00a9 \u4e2d\u4e3a\u771f\u3002</p> <p></p> <p>(1)</p> <p>\u6211\u4eec\u77e5\u9053\u5047\u547d\u9898\u8574\u542b\u771f\u547d\u9898\u4e3a\u771f\u4f46\u662f\u5047\u547d\u9898\u5408\u53d6\u771f\u547d\u9898\u7ed3\u679c\u4e3a\u5047\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u6784\u9020 \\(I_1\\) \u5982\u4e0b\uff1a</p> <ul> <li>\u4e2a\u4f53\u57df\uff1a\\(\\{0\\}\\)</li> <li>\u8c13\u8bcd \\(F(0)=0, G(0)=1\\)</li> </ul> <p>\u8fd9\u6837\u4e24\u4e2a\u5f0f\u5b50\u5c31\u53d8\u6210\u4e86</p> <p>\\(F(0)\\to G(0)=1\\) \u548c \\(F(0)\\land G(0)=0\\) \u662f\u5177\u6709\u4e0d\u540c\u7684\u771f\u503c\u3002</p> <p>(2)</p> <p>\u6613\u5f97 \\(I_1\\) \u4e5f\u6ee1\u8db3 (2) \u7684\u6761\u4ef6\uff0c\u76f4\u63a5\u53ef\u4ee5\u5f53\u6210 \\(I_2\\)\uff1a</p> <ul> <li>\u4e2a\u4f53\u57df\uff1a\\(\\{0\\}\\)</li> <li>\u8c13\u8bcd \\(F(0)=0, G(0)=1\\)</li> </ul> <p>\u8fd9\u6837\u4e24\u4e2a\u5f0f\u5b50\u5c31\u53d8\u6210\u4e86</p> <p>\\(F(0)\\to G(0)=1\\) \u548c \\(F(0)\\land G(0)=0\\) \u662f\u5177\u6709\u4e0d\u540c\u7684\u771f\u503c\u3002</p> <p></p> <p>(1)</p> \\[ \\begin{align*}     \\forall xF(f(a,x),a)&amp;\\iff \\forall x(a-x &lt;a)\\\\     &amp;\\iff \\forall x(x&gt;0)\\\\     &amp;\\iff 0&gt;0\\\\     &amp;\\iff 0 \\end{align*} \\] <p>(2)</p> \\[ \\begin{align*}     \\forall xF(f(x,y),x)\\to\\exists y\\neg F(x,f(y,z))&amp;\\iff \\forall x(x-y&lt;x)\\to\\exists y\\neg (x&lt;y-z)\\\\     &amp;\\iff y&gt;0 \\to \\exists y\\neg(0&lt;y-2)\\\\     &amp;\\iff 1\\to 1\\quad (y=1)\\\\     &amp;\\iff 1 \\end{align*} \\] <p>(3)</p> \\[ \\begin{align*}     \\forall x(F(x,y)\\to\\forall y(F(y,z)\\to\\forall zF(x,z)))&amp;\\iff \\forall x((x&lt;y)\\to\\forall y((y&lt;z)\\to\\forall z(x&lt;z)))\\\\     &amp;\\iff \\forall x((x&lt;y)\\to\\forall y((y&lt;z)\\to 0))\\\\     &amp;\\iff \\forall x((x&lt;y)\\to 0)\\\\     &amp;\\iff 0 \\end{align*} \\] <p>(4)</p> \\[ \\begin{align*}     \\forall x\\exists yF(x,f(f(x,y),y))&amp;\\iff\\forall x\\exists y(x&lt;x-y-y)\\\\     &amp;\\iff\\forall x\\exists y(y&lt;0)\\\\     &amp;\\iff\\forall x 1\\\\     &amp;\\iff 1 \\end{align*} \\]"}, {"location": "campus-sources/Descrete_assignments/#_6", "title": "\u7b2c\u4e94\u6b21\u4f5c\u4e1a", "text": "<p>(1) (2) \\(B\\subset A\\)</p> <p>(3) \\(A=B\\)</p> <p>(4) \\(A=B=\\mathbb{R}\\)\uff0c\u53d6 \\(a=1,b=0,y=0\\) \u5373\u53ef\u3002</p> <p>(5) \\(B=A\\) \u56e0\u4e3a\u89e3\u662f\u6709\u7406\u6570</p> <p>(6) \\(B=\\{1,0.5\\}\\) \u56e0\u6b64 \\(B\\subset A\\)</p> <p></p> <p>(1) \\(\\{\\varnothing,\\{\\varnothing\\}\\}\\)</p> <p>(2) \\(\\{\\varnothing,1,\\{1\\},\\{1,\\{1\\}\\}\\}\\)</p> <p>(3) \\(\\{\\varnothing,P(\\{1,2\\})\\}=\\{\\varnothing,\\{\\varnothing,1,2,\\{1,2\\}\\}\\}\\)</p> <p>(4) \\(\\{\\varnothing,\\{1,1\\},\\{2,1\\},\\{1,2,1\\},\\{\\{1,1\\},\\{2,1\\}\\},\\{\\{2,1\\},\\{1,2,1\\}\\},\\{\\{1,1\\},\\{1,2,1\\}\\},\\{\\{1,1\\},\\{2,1\\},\\{1,2,1\\}\\}\\}\\)</p> <p>\u7136\u540e\u6211\u4eec\u8fdb\u884c\u540c\u4e00\u5143\u7d20\u7684\u5f52\u5e76\uff1a \\(\\{\\varnothing,\\{1\\},\\{2,1\\},\\{\\{1\\},\\{2,1\\}\\},\\{\\{1\\},\\{2,1\\}\\}\\}\\)</p> <p>(5) \\(A=\\{1,-1,2\\}\\)</p> <p>\u5e42\u96c6\u4e3a\uff1a</p> \\[ \\{\\varnothing,1,-1,2,\\{1,-1\\},\\{1,2\\},\\{-1,2\\},\\{1,-1,2\\}\\} \\]"}, {"location": "campus-sources/Descrete_assignments/#_7", "title": "\u7b2c\u516d\u6b21\u4f5c\u4e1a", "text": "<p>(1) \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u89e3\u8fd9\u4e2a\u65b9\u7a0b\u5f97\u5230\uff1a</p> x y 3 3 6 2 9 1 <p>\u5171 3 \u4e2a\u6709\u5e8f\u5bf9\u3002</p> <p>(2) \\(\\mathrm{dom}R=\\{3,6,9\\}\\)</p> <p>(3) \\(R \\upharpoonright\\{2,3,4,6\\}=\\{&lt;3,3&gt;,&lt;6,2&gt;\\}\\)</p> <p>(4) \u6ce8\u610f\u662f\u96c6\u5408\u3002 \\(\\{3\\}\\)</p> <p>(5) \u53ea\u6709 \\(3\\) \u65e2\u5728\u503c\u57df\u4e5f\u5728\u5b9a\u4e49\u57df\u91cc\u9762\uff0c\u56e0\u6b64\u5f97\u5230 \\(\\{&lt;3,3&gt;\\}\\)</p> <p></p> <p>\u5148\u628a \\(R\\) \u5199\u6210\u77e9\u9635\uff1a</p> \\[ \\left[ \\begin{matrix}     0&amp;1&amp;0&amp;0\\\\     1&amp;0&amp;1&amp;0\\\\     0&amp;0&amp;0&amp;1\\\\     0&amp;0&amp;0&amp;0\\\\ \\end{matrix} \\right] \\] <p>\u7136\u540e <code>np.matmul</code> \u5373\u53ef\u89e3\u51b3\uff1a</p> \\[ R\\circ R=\\left[ \\begin{matrix}     1&amp;0&amp;1&amp;0\\\\     0&amp;1&amp;0&amp;1\\\\     0&amp;0&amp;0&amp;0\\\\     0&amp;0&amp;0&amp;0\\\\ \\end{matrix} \\right] \\] <p>\u4ee5\u53ca</p> \\[ R\\circ R\\circ R=\\left[ \\begin{matrix}     0&amp;1&amp;0&amp;1\\\\     1&amp;0&amp;1&amp;0\\\\     0&amp;0&amp;0&amp;0\\\\     0&amp;0&amp;0&amp;0\\\\ \\end{matrix} \\right] \\] <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 26, 2025). \u300a\u79bb\u6563\u6570\u5b66\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/Descrete_assignments</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{Descrete_assignments,\n    title={\u300a\u79bb\u6563\u6570\u5b66\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/Descrete_assignments}},\n}\n</code></pre></p>"}, {"location": "campus-sources/PU_Bii_assignments/", "title": "\u300a\u5927\u5b66\u7269\u7406B\u4e0b\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 1 \u5206\u949f\u3000|\u3000\u7ea6 134 \u5b57\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u7b14\u8bb0\u76f8\u5bf9\u5c11\uff0c\u4ee5\u4f5c\u4e1a\u5f52\u6863\u5c45\u591a\u3002</p> <p>\u4f9b\u5b58\u6863\u548c\u590d\u4e60\u7528\u3002</p>"}, {"location": "campus-sources/PU_Bii_assignments/#_1", "title": "\u7b2c\u4e00\u6b21\u4f5c\u4e1a", "text": ""}, {"location": "campus-sources/PU_Bii_assignments/#_2", "title": "\u7b2c\u4e8c\u6b21\u4f5c\u4e1a", "text": ""}, {"location": "campus-sources/PU_Bii_assignments/#_3", "title": "\u7b2c\u4e09\u6b21\u4f5c\u4e1a", "text": "<p>\u4efb\u52a1\uff1a\u63a8\u5bfc\u8f7d\u6d41\u7ebf\u5708\u7684\u78c1\u77e9\u529b\u77e9\u3002</p> <p></p>"}, {"location": "campus-sources/PU_Bii_assignments/#_4", "title": "\u7b2c\u56db\u6b21\u4f5c\u4e1a", "text": ""}, {"location": "campus-sources/PU_Bii_assignments/#_5", "title": "\u8865\u5145\u4e60\u9898", "text": "<p>\u9700\u8981\u53c2\u8003\u7684\u4f8b\u9898\uff1a12.1 \u4f8b (6) \u78c1\u5076\u6781\u77e9\u524d\u9762\uff0c\u4f8b 4 \u8f7d\u6d41\u5e26\uff0c\u4f8b 5 \u8f7d\u6d41\u677f\u3002</p> <p>\u4f8b 2 \u5706\u68d2\u7ed5\u7aef\u70b9\u8f6c\u52a8\u5f62\u6210\u78c1\u77e9\uff0c\u6700\u540e\u65cb\u8f6c\u76f4\u7b52\u5185\u90e8\u78c1\u573a</p> <p>12.2 P13 \u4f8b\u9898\uff1b12.3 \u65e0\uff1b12.5 \u4f8b 2\uff08P7\uff09\u4f8b 3\uff0c\u4f8b 4\uff0c\u4f8b 5\uff0cP22 \u4f8b 4</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"}, {"location": "campus-sources/PU_Bii_assignments/#_6", "title": "\u4e60\u9898", "text": ""}, {"location": "campus-sources/PU_Bii_assignments/#_7", "title": "\u7b2c\u4e94\u6b21\u4f5c\u4e1a", "text": ""}, {"location": "campus-sources/PU_Bii_assignments/#_8", "title": "\u7b2c\u516d\u6b21\u4f5c\u4e1a", "text": "<p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 27, 2025). \u300a\u5927\u5b66\u7269\u7406B\u4e0b\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/PU_Bii_assignments</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{PU_Bii_assignments,\n    title={\u300a\u5927\u5b66\u7269\u7406B\u4e0b\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/PU_Bii_assignments}},\n}\n</code></pre></p>"}, {"location": "campus-sources/Prob_Stats_assignments/", "title": "\u300a\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 11 \u5206\u949f\u3000|\u3000\u7ea6 454 \u5b57\u3000|\u3000\u7ea6 91 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 13 \u884c\u4ee3\u7801</p> <p>\u4f9b\u5b58\u6863\u548c\u590d\u4e60\u7528\u3002</p>"}, {"location": "campus-sources/Prob_Stats_assignments/#_2", "title": "\u7b2c\u4e00\u6b21\u4f5c\u4e1a", "text": "<p>i. A, B \u4e92\u4e0d\u76f8\u5bb9\uff0c\u5373 AB \u65e0\u4ea4\u96c6\uff0c\u4e5f\u5c31\u662f A \u4e00\u5b9a\u5728 B \u7684\u8865\u96c6\u91cc\u9762\u3002\\(P(A\\bar B)=P(A)=1/2\\)</p> <p>ii. \u7531 \\(P(A)=P(AB)+P(A\\bar B)\\) \u53ef\u5f97 \\(P(A\\bar B)=3/8\\)</p> <p></p> <p>11 \u53d6 7 \u6392\u5217\uff0c\u8fd9\u4e2a 7 \u5b57\u6bcd\u8bcd\u6709\u4e24\u4e2a i \u4ee5\u53ca\u4e24\u4e2a b \u53ef\u4ee5\u4e92\u6362\u90fd\u6ee1\u8db3\u6761\u4ef6\uff0c\u6240\u4ee5</p> \\[ P=\\dfrac{2\\times2}{A^7_{11}}=\\dfrac{2\\times2}{5\\times6\\times7\\times8\\times9\\times10\\times11}=\\dfrac{1}{415800} \\] <p></p> <p>\u6211\u4eec\u5206\u6210\u56db\u4e2a\u533a\u57df</p> <p></p> \\[ P=\\dfrac{B\\cap (A\\cup \\bar B)}{A\\cup \\bar B}=\\dfrac{\\mathrm{II}}{\\mathrm{I+II+IV}}=\\dfrac{0.2}{0.5+0.2+0.1}=\\dfrac{1}{4} \\]"}, {"location": "campus-sources/Prob_Stats_assignments/#_3", "title": "\u7b2c\u4e8c\u6b21\u4f5c\u4e1a", "text": "<p>(1)</p> <p>\u7b2c\u4e00\u6b21\u53d6\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4\uff1a\u9009\u7bb1\u5b50+\u9009\u96f6\u4ef6\u3002</p> \\[ P(A)=\\dfrac{1}{2}\\times\\dfrac{10}{50}+\\dfrac{1}{2}\\times\\dfrac{18}{30}=\\dfrac{2}{5} \\] <p>(2)</p> <p>\u6839\u636e\u6761\u4ef6\u6982\u7387\u516c\u5f0f\uff1a</p> \\[ P(B|A)=\\dfrac{P(AB)}{P(A)} \\] <p>\u5176\u4e2d</p> \\[ P(AB)=\\dfrac{1}{2}\\times\\dfrac{10}{50}\\times\\dfrac{9}{49}+\\dfrac{1}{2}\\times\\dfrac{18}{30}\\times\\dfrac{17}{29}=\\dfrac{276}{1421} \\] <p>\u5219</p> \\[ P(B|A)=\\dfrac{276}{1421}\\times\\dfrac{5}{2}=\\dfrac{690}{1421} \\] <p></p> <p>(1) \u548c (2) \u5fc5\u7136\u5047\u3002 \\(P(AB)=P(A)P(B)=0\\) \u4e0e \\(P(A)&gt;0, P(B)&gt;0\\) \u77db\u76fe</p> <p>(3) \u5fc5\u7136\u5047\u3002 \u82e5 \\(B\\) \u4e0e \\(A\\) \u4e0d\u76f8\u5bb9\u5219\u5fc5\u7136 \\(P(B)&lt;1-P(A)\\)\uff0c\u8fd9\u5c31\u77db\u76fe\u3002</p> <p>(4) \u53ef\u80fd\u5bf9\u3002\u8003\u8651\u968f\u673a\u53d8\u91cf \\(x\\) \u670d\u4ece\u4e00\u4e2a \\([0,1]\\) \u4e0a\u7684\u5747\u5300\u5206\u5e03\u3002</p> <p>\u6210\u7acb\u7684\u60c5\u5f62\uff1a</p> \\[ P(A)=P(0&lt;x&lt;0.6)\\\\ P(B)=P(0.24&lt;x&lt;0.84) \\] <p>\u5219 \\(P(AB)=P(A)P(B)=0.36\\)</p> <p>\u4e0d\u6210\u7acb\u7684\u60c5\u5f62\uff1a</p> \\[ P(A)=P(0&lt;x&lt;0.6)\\\\ P(B)=P(0.4&lt;x&lt;1) \\] <p>\u5219 \\(P(AB)=0.2\\neq P(A)P(B)=0.36\\)</p> <p></p> \\[ P(B)=\\underbrace{0.8\\times(1-2\\%)^3}_{P(BA_1)}+\\underbrace{0.15\\times(1-10\\%)^3}_{P(BA_2)}+\\underbrace{0.05\\times(1-90\\%)^3}_{P(BA_3)}=0.8623536\\\\ \\] <p>\u62ff Python \u7b97\u4e86\u4e00\u4e0b\u6570\u503c\u89e3\uff1a</p> \\[ \\begin{align*}     P(A_1|B)=\\dfrac{P(BA_1)}{P(B)}&amp;=0.8731378868250795\\\\ P(A_2|B)=\\dfrac{P(BA_2)}{P(B)}&amp;=0.12680413231880752\\\\ P(A_3|B)=\\dfrac{P(BA_3)}{P(B)}&amp;=0.00005798085611285204\\\\ \\end{align*} \\] <p>\u4ec0\u4e48\u662f\u968f\u673a\u53d8\u91cf\uff1a\u5982\u679c\u4e00\u4e2a\u53d8\u91cf \\(x\\) \u5728\u6bcf\u4e00\u6b21\u89c2\u6d4b\u65f6\u7684\u503c\u4e0d\u80fd\u88ab\u5b8c\u5168\u5148\u9a8c\u5730\u786e\u5b9a\u5219\u79f0\u5176\u4e3a\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\u3002</p>"}, {"location": "campus-sources/Prob_Stats_assignments/#_4", "title": "\u7b2c\u4e09\u6b21\u4f5c\u4e1a", "text": "<p>(1)</p> \\[ X\\sim Ge(p)\\Leftrightarrow P(X=n)=p(1-p)^{n-1} \\] <p>\u4e5f\u5c31\u662f\u5728\u524d \\(n-1\\) \u6b21\u5c1d\u8bd5\u90fd\u5931\u8d25\u4e86\uff0c\u6700\u540e\u4e00\u6b21\u6210\u529f\u5c31\u6536\u624b\u3002</p> <p>(2)</p> \\[ P(X=n)=C_{n-1}^{r-1} p^r(1-p)^{n-r} \\] <p>\u6700\u540e\u4e00\u6b21\u5c1d\u8bd5\u5fc5\u987b\u6210\u529f\u7136\u540e\u6536\u624b\uff0c\u524d\u9762\u7684 \\(n-1\\) \u6b21\u5c1d\u8bd5\u91cc\u9762\u53ef\u4ee5\u4efb\u610f\u5b89\u6392 \\(r-1\\) \u6b21\u6210\u529f\u5c1d\u8bd5\u7684\u4f4d\u7f6e\u3002</p> <p>(3)</p> <p>\u548c (1) \u4e00\u6837\u7684\u51e0\u4f55\u5206\u5e03\u3002</p> \\[ P(X=n) = p(1-p)^{n-1} \\] <p>\u7531\u6b64</p> \\[ \\begin{align*}     P(x\\in\\mathrm{Even.})&amp;=\\sum_{i=1}^\\infty P(X=2i)\\\\     &amp;=p[(1-p)^1+(1-p)^3+\\cdots]\\\\     &amp;=p\\times\\dfrac{1-p}{1-(1-p)^2}\\\\     &amp;=\\dfrac{1-p}{2-p} \\end{align*} \\] <p>\u5e26\u5165\u5373\u53ef\u5f97\u5230\u503c\u4e3a \\(0.3548387096774194\\)</p> <p></p> <p>\u9898\u76ee\u662f\u8981\u8ba9\u6211\u4eec\u7528\u6cca\u677e\u5206\u5e03\u8fd1\u4f3c\u4e8c\u9879\u5206\u5e03\u3002\u51fa\u4e8b\u6545\u7684\u8f66\u8f86\u6570 \\(X\\) \u6ee1\u8db3\uff1a</p> \\[ X\\sim B(1000,0.0001) \\] <p>\u8fd1\u4f3c\u5373</p> \\[ X\\sim Po(0.1) \\] <p>\u7531\u6cca\u677e\u5206\u5e03\u516c\u5f0f\uff1a\\(P(x=k) =\\dfrac{\\lambda^k\\mathrm{e}^{-\\lambda}}{k!}\\) \u53ef\u5f97\uff1a</p> \\[ \\begin{align*}     P(X\\ge 2)&amp;=1-P(x=1)-P(x=0)\\\\     &amp;=1-\\dfrac{0.1^1\\exp(-0.1)}{1!}-\\dfrac{0.1^0\\exp(-0.1)}{0!}\\\\     &amp;=1-1.1\\exp(-0.1)\\\\     &amp;=0.00467884016044440 \\end{align*} \\] <p></p> <p>(1)</p> <p>\u6839\u636e\u5b9a\u4e49\uff1a</p> \\[ \\begin{align*}     P(x&lt;2)&amp;=F(2)=\\ln 2\\\\     P(0&lt;x\\le 3)&amp;=F(3)-F(0)=1\\\\     P(2&lt;x&lt;5/2)&amp;=F(5/2)-F(2)=\\ln 5-2\\ln 2 \\end{align*} \\] <p>(2)</p> <p>\u76f4\u63a5\u6c42\u5bfc\u5373\u53ef\uff1a</p> \\[ f(x)= \\begin{cases}     0,&amp;x&lt;1,x\\ge \\mathrm{e}\\\\     \\dfrac{1}{x},&amp;1\\le x&lt;\\mathrm{e}\\\\ \\end{cases} \\] <p></p> <p>\u51e0\u4f55\u6982\u578b\u3002\u6210\u7acb\u7684\u4e8b\u4ef6\u57df\u4e3a\uff1a</p> \\[ \\begin{align*}     (4K)^2-4\\times4\\times(K+2)\\ge 0&amp;\\iff K^2-K-2\\ge 0\\\\     &amp;\\iff (K-2)(K+1)\\ge 0\\\\     &amp;\\iff K\\in (2,5) \\end{align*} \\] <p>\u56e0\u6b64 \\(P=3/5\\)</p>"}, {"location": "campus-sources/Prob_Stats_assignments/#_5", "title": "\u7b2c\u56db\u6b21\u4f5c\u4e1a", "text": "<p>\u6211\u4eec\u76f4\u63a5\u5199\u7a0b\u5e8f\u8ba1\u7b97\u5373\u53ef\uff1a</p> <pre><code>from scipy import stats\n\n# X~N(a,b^2) P(X in (M, N))\ndef Gaussian_prob(a, b, M, N):\n    return stats.norm(loc=a, scale=b).cdf(N) - stats.norm(loc=a, scale=b).cdf(M)\n\nprint(stats.norm(loc=110, scale=12).cdf(105))\nprint(Gaussian_prob(110, 12, 100, 120))\n\ndef f(x):\n    return 0.05 - (1-stats.norm(loc=110, scale=12).cdf(x))\n\nfrom scipy.optimize import brentq\nprint(brentq(f, 70, 150))\n</code></pre> <p>\u8ba1\u7b97\u5f97</p> \\[ \\begin{align*}     P(X\\le 105)&amp;=0.33846111951068963\\\\     P(100&lt;X\\le 120)&amp;=0.5953432380727137\\\\     X&amp;=129.73824352341765 \\end{align*} \\] <p></p> <p>\u6211\u4eec\u76f4\u63a5\u5199\u7a0b\u5e8f\u8ba1\u7b97\u5373\u53ef\uff1a</p> <pre><code>p1=1-Gaussian_prob(120, 2, 118, 122)\np=(1-p1)**3 * p1**2 * 10\nprint(p)\n</code></pre> <p>\u5f97\u5230</p> \\[ P = 0.3203602052597432 \\] <p></p> <p>(1)</p> <p>\u6982\u7387\u5bc6\u5ea6\u79ef\u5206 \\(F(X)=X,X\\in (0,1)\\)\uff0c\u7531 \\(X=\\ln Y\\) \u53ef\u5f97 \\(F(Y)=\\ln Y,Y\\in (1,e)\\)\uff0c\u6c42\u5bfc\u53ef\u5f97\u5bc6\u5ea6\uff1a</p> \\[ P(Y)= \\begin{cases}     \\dfrac{1}{Y},&amp;Y\\in(1,e)\\\\     0,&amp;\\mathrm{otherwise} \\end{cases} \\] <p>(2)</p> <p>\u6982\u7387\u5bc6\u5ea6\u79ef\u5206 \\(F(X)=X,X\\in (0,1)\\)\uff0c\u7531 \\(X=\\exp(-\\dfrac 12 Y)\\) \u53ef\u5f97 \\(F(Y)=\\exp(-\\dfrac 12 Y),Y\\in (0,+\\infty)\\)\uff0c\u6c42\u5bfc\u53ef\u5f97\u5bc6\u5ea6\uff1a</p> \\[ P(Y)= \\begin{cases}     \\dfrac 12\\exp(-\\dfrac 12 Y),&amp;Y\\in(0,+\\infty)\\\\     0,&amp;\\mathrm{otherwise} \\end{cases} \\]"}, {"location": "campus-sources/Prob_Stats_assignments/#_6", "title": "\u7b2c\u4e94\u6b21\u4f5c\u4e1a", "text": "<p>(1)</p> \\[ C_7^4=35 \\] <p>\u53ef\u5217\u5206\u5e03\u5f8b\u5982\u4e0b\uff1a</p> X=0 X=1 X=2 X=3 Y=0 \\(0\\) \\(0\\) \\(\\frac{3}{35}\\) \\(\\frac{2}{35}\\) Y=1 \\(0\\) \\(\\frac{6}{35}\\) \\(\\frac{12}{35}\\) \\(\\frac{2}{35}\\) Y=2 \\(\\frac{1}{35}\\) \\(\\frac{6}{35}\\) \\(\\frac{3}{35}\\) \\(0\\) <p>(2)</p> \\[ \\begin{align*}     P(X&gt;Y)&amp;=\\dfrac{1}{35}(3+2+12+2)=\\dfrac{19}{35}\\\\     P(Y=2X)&amp;=\\dfrac{6}{35}\\\\     P(X+Y=3)&amp;=\\dfrac{1}{35}(6+12+2)=\\dfrac{20}{35}\\\\     P(X&lt;3-Y)&amp;=\\dfrac{1}{35}(3+6+1)=\\dfrac{10}{35} \\end{align*} \\] <p></p> \\[ 6-x-y=0\\implies x+y=6 \\] <p>\u5219\u9700\u8981\u5f52\u4e00\u5316\u6761\u4ef6\uff1a</p> \\[ \\begin{align*}     \\iint_{\\mathbb{R}^2}f(x,y)\\mathrm{d}x\\mathrm{d}y&amp;=k\\int_0^2\\int_2^4(6-x-y)\\mathrm{d}y\\mathrm{d}x\\\\     &amp;=k\\int_0^2 2(6-x)-6\\mathrm{d}x\\\\     &amp;=8k\\\\     &amp;=1\\\\     &amp;\\implies k = \\dfrac{1}{8} \\end{align*} \\] \\[ \\begin{align*}     P(X&lt;1,Y&lt;3)&amp;=k\\int_0^1\\int_2^3(6-x-y)\\mathrm{d}y\\mathrm{d}x\\\\     &amp;=3k\\\\     &amp;=\\dfrac{3}{8} \\end{align*} \\] \\[ \\begin{align*}     P(X&lt;1.5)&amp;=k\\int_0^\\frac{3}{2}\\int_2^4(6-x-y)\\mathrm{d}y\\mathrm{d}x\\\\     &amp;=\\dfrac{27}{4}k\\\\     &amp;=\\dfrac{27}{32} \\end{align*} \\] \\[ \\begin{align*}     P(X+Y\\le 4)&amp;=k\\int_0^2\\int_2^{4-x}(6-x-y)\\mathrm{d}y\\mathrm{d}x\\\\     &amp;=(\\dfrac{8}{6}+4)k\\\\     &amp;=\\dfrac{2}{3} \\end{align*} \\] <p></p> <p>\u679a\u4e3e\u7ed3\u679c\u5e76\u8ba1\u6570\u5373\u53ef\u3002</p> X=0 X=1 X=2 Y=0 \\(\\frac{1}{8}\\) \\(0\\) \\(0\\) Y=1 \\(\\frac{1}{8}\\) \\(\\frac{1}{4}\\) \\(0\\) Y=2 \\(0\\) \\(\\frac{1}{4}\\) \\(\\frac{1}{8}\\) Y=3 \\(0\\) \\(0\\) \\(\\frac{1}{8}\\) X=0 X=1 X=2 P \\(\\frac{1}{4}\\) \\(\\frac{1}{2}\\) \\(\\frac{1}{4}\\) Y=0 Y=1 Y=2 Y=3 P \\(\\frac{1}{8}\\) \\(\\frac{3}{8}\\) \\(\\frac{3}{8}\\) \\(\\frac{1}{8}\\) <p></p> \\[ \\begin{align*}     \\iint_{\\mathbb{R}^2}f(x,y)\\mathrm{d}x\\mathrm{d}y&amp;=c\\int_{-1}^1\\int^1_{x^2}x^2y\\mathrm{d}y\\mathrm{d}x\\\\     &amp;=c\\int_{-1}^1 \\frac{1}{2}x^2(1-x^4)\\mathrm{d}x\\\\     &amp;=\\dfrac{4}{21}c\\\\     &amp;=1\\\\     &amp;\\implies c = \\dfrac{21}{4} \\end{align*} \\] \\[ \\begin{align*}     P(x)&amp;=c\\int_{x^2}^1x^2y\\mathrm{d}y=c\\frac{1}{2}x^2(1-x^4)\\\\     \\implies P(x)&amp;=\\         \\begin{cases}             \\frac{21}{8}x^2(1-x^4),&amp;x\\in[-1,1]\\\\             0,&amp;\\mathrm{otherwise}         \\end{cases} \\end{align*} \\] \\[ \\begin{align*}     P(y)&amp;=c\\int_{-\\sqrt y}^{\\sqrt{y}}x^2y\\mathrm{d}y=c\\frac{2}{3}y^{\\frac{5}{2}}\\\\     \\implies P(y)&amp;=\\         \\begin{cases}             \\frac{7}{2}y^{\\frac{5}{2}},&amp;y\\in[0,1]\\\\             0,&amp;\\mathrm{otherwise}         \\end{cases} \\end{align*} \\] <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 20, 2025). \u300a\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/Prob_Stats_assignments</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{Prob_Stats_assignments,\n    title={\u300a\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\u300b\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/Prob_Stats_assignments}},\n}\n</code></pre></p>"}, {"location": "campus-sources/SDC_assignments/", "title": "\u300a\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u300b\u7406\u8bba\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 10 \u5206\u949f\u3000|\u3000\u7ea6 1230 \u5b57\u3000|\u3000\u7ea6 17 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 346 \u884c\u4ee3\u7801</p> <p>\u4f9b\u5b58\u6863\u548c\u590d\u4e60\u7528\u3002</p>"}, {"location": "campus-sources/SDC_assignments/#_2", "title": "\u7b2c\u4e00\u6b21\u4f5c\u4e1a", "text": ""}, {"location": "campus-sources/SDC_assignments/#_3", "title": "\u7b2c\u4e8c\u6b21\u4f5c\u4e1a", "text": "<p>\u8fd9\u4e2a\u9898\u5e76\u4e0d\u9700\u8981\u6211\u4eec\u8fdb\u884c\u5177\u4f53\u7684\u8fd0\u7b97\u3002\u53ea\u9700\u8981\u6309\u89c4\u5219\u8bd1\u7801\u5373\u53ef\u3002</p> <p>(1) \u65e0\u7b26\u53f7\u6574\u6570\uff0c\u76f4\u63a5\u539f\u7801\u8bd1\u7801\uff1a \\(R_1: 108B_{16}=4235_{10}\\)\uff0c\\(R_2: 8080108B_{16}=2155876491_{10}\\)</p> <p>(2) \u6709\u7b26\u53f7\u6574\u6570\uff0c\u6309\u8865\u7801\u8bd1\u7801\uff1a \\(R_1: 108B_{16}=4235_{10}\\)\uff0c\\(R_2\\) \u76f4\u63a5\u6a21\u8fd0\u7b97\uff1a \\(2155876491-4294967296=-2139090805\\)</p> <p>(3) FP32: S1E8M23, FP64: S1E11M52\uff0c\u9996\u5148\u5199\u6210\u4e8c\u8fdb\u5236\u5e76\u4e14\u628a\u7b26\u53f7\u4f4d\uff0c\u9636\u7801\uff0c\u5c3e\u6570\u65ad\u5f00\uff1a</p> <pre><code>R1: 0000 0000 0000 0000 0001 0000 1000 1011\n  = 0 00000000 00000000001000010001011 \u662f\u4e00\u4e2a\u975e\u89c4\u683c\u5316\u6d6e\u70b9\u6570\u3002\n  = (-1)^0 * 2^(0-126) * 0.00000000001000010001011\n\nR2: 1000 0000 1000 0000 0001 0000 1000 1011\n  = 1 00000001 00000000001000010001011\n  = (-1)^1 * 2^(1-127) * 1.00000000001000010001011\n</code></pre> <p>\u5f97\u5230\uff1a</p> \\[ R_1 = 0.00000000001000010001011_2 \\times 2^{-126}\\\\ R_2 = -1.00000000001000010001011_2 \\times 2^{-126} \\] <p></p> <p>\u4e3a\u7b80\u4fbf\uff0c\u4f7f\u7528\u5341\u516d\u8fdb\u5236\u8868\u8bb0\u3002</p> \u5173\u7cfb\u8868\u8fbe\u5f0f \u8fd0\u7b97\u7c7b\u578b \u7ed3\u679c \u8bf4\u660e 0==0U \u65e0\u7b26\u53f7\u6574\u6570 1 0000 0000H = 0000 0000H -1 &lt; 0 \u5e26\u7b26\u53f7\u6574\u6570 1 FFFF FFFFH(-1) &lt; 0000 0000H(0) -1 &lt; 0U \u65e0\u7b26\u53f7\u6574\u6570 0 11\u20261B\uff082\u00b3\u00b2-1\uff09&gt;00\u20260B\uff080\uff09 2147483647 &gt; -2147483647 - 1 \u5e26\u7b26\u53f7\u6574\u6570 1 011\u20261B\uff082\u00b3\u00b9-1\uff09&gt;100\u20260B\uff08-2\u00b3\u00b9\uff09 2147483647U &gt; -2147483647 - 1 \u65e0\u7b26\u53f7\u6574\u6570 0 7FFF FFFFH(2\u00b3\u00b9-1) &lt; 8000 0000H (2\u00b3\u00b9) 2147483647 &gt; (int)2147483648U \u5e26\u7b26\u53f7\u6574\u6570 1 7FFF FFFFH &gt; 8000 0000H (-2\u00b3\u00b9) -1 &gt; -2 \u5e26\u7b26\u53f7\u6574\u6570 1 FFFF FFFF(-1) &gt; FFFF FFFE(-2) (unsigned)-1 &gt; -2 \u65e0\u7b26\u53f7\u6574\u6570 1 FFFF FFFF(2\u00b3\u00b2-1) &gt; FFFF FFFE(2\u00b3\u00b2-2) <p></p> <pre><code>(1)\nx = -FFFAH = -65530\n\n(2)\ny = -2004H = -8196\n\n(3)\nz = 4294967296 - 6 = 4294967290\n\n(4)\nc = 2*16+10 = 42 = '*'\n\n(5)\na = 1100 0100 0100 1000 0000 0000 0000 0000\n  = -1 * (10001000) * 1.10010000000000000000000\n  = -1 * 2^9 * (1 + 2^-1 + 2^-4)\n  = -1 * (512 + 256 + 32)\n  = -800\n\n(6)\nb = 1100 0000 0010 0100 1000 0000 .... 0000\n  = -1 * (100 0000 0010) * 1.01001\n  = -1 * 2^3 * (1 + 2^-2 + 2^-5)\n  = -1 * (8 + 2 + 0.25)\n  = -10.25\n</code></pre> <p></p> <p>\u6211\u4eec\u9996\u5148\u5f97\u5230\u6570\u636e\u7684\u5b57\u8282\u578b\u8868\u793a\uff1a</p> <pre><code>x = -0.125 = -1 * 2^(-3) * 1.0 = -1 * 2^(124-127) * 1.0\n  = 1 0111 1100 0000 .... 0000\n  = 1011 1110 0000 0000 .... 0000\n  = BF 00 00 00\ny = 7.5 = 1 * 2^(2) * 1.111\n  = 0 1000 0001 1110 0000 .... 0000\n  = 0100 0000 1111 0000 0000 .... 0000\n  = 40 F0 00 00\ni = 100 = 64 + 32 + 4 = 0000 0000 0110 0100 = 00 64\n</code></pre> <p>\u5728\u5c0f\u7aef\u5e8f\u673a\u5668\u4e0a\u9762\uff1a</p> <pre><code>  00 00 00 BF ** ** ** ** 00 00 F0 40 64 00\n |     x     |           |     y     |  i  |\n 100         104         108         112   \n</code></pre> <p>\u5728\u5927\u7aef\u5e8f\u673a\u5668\u4e0a\u9762\uff1a</p> <pre><code>  BF 00 00 00 ** ** ** ** 40 F0 00 00 00 64\n |     x     |           |     y     |  i  |\n 100         104         108         112  \n</code></pre>"}, {"location": "campus-sources/SDC_assignments/#_4", "title": "\u7b2c\u4e09\u6b21\u4f5c\u4e1a", "text": "w func1(w) func2(w) \u673a\u5668\u6570 \u503c \u673a\u5668\u6570 \u503c \u673a\u5668\u6570 \u503c 0000 007F 127 0000 007F 127 0000 007F 127 0000 0080 128 0000 0080 128 FFFF FF80 -128 0000 00FF 255 0000 00FF 255 FFFF FFFF -1 0000 0100 256 0000 0000 0 0000 0000 0 <p>\u5173\u952e\u70b9\u662f\u903b\u8f91\u79fb\u4f4d\u4e0d\u8865\u96f6\uff0c\u7b97\u672f\u79fb\u4f4d\u8865\u96f6\uff0c\u4ee5\u53ca\u6574\u6570\u79fb\u4f4d\u7684\u622a\u65ad\u3002</p> <p></p> <p></p> \u8868\u793a X x Y y X+Y x+y OF SF CF X-Y x-y OF SF CF \u65e0\u7b26\u53f7 0xB0 176 0x8C 140 0x3C 316 1 0 1 0x24 36 0 0 0 \u5e26\u7b26\u53f7 0xB0 -80 0x8C -116 0x3C -196 1 0 1 0x24 36 0 0 0 <p>\u4ece\u786c\u4ef6\u89d2\u5ea6\u7406\u89e3\uff0c\\(OF = C_{out} \\oplus C_{n-1}\\), \\(SF = F_{n}\\), \\(CF = C_{out} \\oplus Sub\\)\u3002</p> <p>\u52a0\u6cd5\u65f6\uff0c\\(C_{out}=1,C_{n-1}=0,F_{n}=0,Sub=0\\)\uff0c\u6839\u636e\u4e0a\u8ff0\u8ba1\u7b97\u89c4\u5219\u53ef\u5f97\u5404\u6807\u5fd7\u4f4d\u503c\u3002</p> <p>\u51cf\u6cd5\u65f6\uff0c\\(C_{out}=1,C_{n-1}=1,F_{n}=0,Sub=1\\)\uff0c\u6839\u636e\u4e0a\u8ff0\u8ba1\u7b97\u89c4\u5219\u53ef\u5f97\u5404\u6807\u5fd7\u4f4d\u503c\u3002</p> <p>\u4ece\u610f\u4e49\u4e0a\u7406\u89e3\uff0c\u52a0\u6cd5\u65f6\u7ed3\u679c\u4e3a\u6b63\u6570\uff0c\u51fa\u73b0\u6ea2\u51fa\u4e14\u6700\u9ad8\u4f4d\u4ea7\u751f\u8fdb\u4f4d\uff1b\u51cf\u6cd5\u65f6\u7ed3\u679c\u4e5f\u4e3a\u6b63\u6570\uff0c\u672a\u51fa\u73b0\u6ea2\u51fa\u6216\u4ea7\u751f\u6700\u9ad8\u4f4d\u7684\u8fdb\u4f4d\u3002</p> <p></p> <pre><code>(1)\n\u8865\u7801\uff1a\n x=001010\n y=111010\n-y=000110\nx+y = 000100 = 4\nx-y = 010000 = 16\n\n(2)\n\u539f\u7801\uff1a\u7b26\u53f7\u4f4d 1\nx=001010\ny=000110\n\n       001010\n    x  000110\n---------------\n      001010\n     001010\n---------------\n  00000111100\nx*y = 111100 = 28\n\n(3)\n y=111010\n-y=000110\n\nQ      A      Q_{0}Q_{-1}\n000000 001010 00\n000000 000101\n000110 000101 10\n000011 000010\n111101 000010 01\n111110 100001\n000100 100001 10\n000010 010000\n111100 010000 01\n111110 001000\n111111 000100 00\n\nx*y = -60\n\n(4)\n\u539f\u7801\uff1a\u7b26\u53f7\u4f4d 1\n x=001010\n y=000110\n-y=111010\nS R      Q\n0 000000 001010\n0 000000 01010_\n1 000110 01010_\n1 000110 010100\n1 001100 10100_\n1 000110 10100_\n1 000110 101000\n1 001011 01000_\n1 000101 01000_\n1 000101 010000\n1 001010 10000_\n1 000100 10000_\n1 000100 100000\n1 000111 00000_\n1 000001 00000_\n1 000001 000000\n1 000010 00000_\n0 000100 00000_\n0 000100 000001\nR = 4, Q = -1\n</code></pre> <p></p> <p>\u5982\u679c\u79fb\u52a8 n \u4f4d\u9700\u8981 n \u4e2aclk:</p> <p>55 = 56 - 1, 56 = 7 * 8 = (8 - 1) * 8\uff0c\u7531\u6b64\u53ef\u4ee5\u6784\u9020\uff1a</p> <pre><code>55 * x == (((x &lt;&lt; 3) - x) &lt;&lt; 3) - x\n</code></pre> <p>\u4ec5\u9700 3 + 1 + 3 + 1 = 8 \u4e2a clk.</p> <p>\u5982\u679c\u79fb\u4f4d\u64cd\u4f5c\u53ea\u9700\u8981\u4e00\u4e2a clk:</p> <pre><code>55 * x = (x &lt;&lt; 4) - (x &lt;&lt; 3) - x\n</code></pre> <p>\u4ec5\u9700\u8981 3 \u4e2a clk.</p> <p></p> <p>(1) \u6c38\u771f\u3002int \u8f6c double \u4e0d\u4f1a\u51fa\u73b0 INF \u6216\u8005 NaN\uff0c\u56e0\u6b64\u65e0\u8bba\u5982\u4f55\u90fd\u662f\u5927\u4e8e\u96f6\u7684\u3002</p> <p>(2) float \u5728 x \u63a5\u8fd1 INT_MAX \u7684\u65f6\u5019\uff0c\u7c92\u5ea6\u4f1a\u53d8\u7a00\u5230\u5c0f\u4e8e 1\uff08\u56e0\u4e3a\u5c3e\u6570\u53ea\u6709 23 bits\uff0c\u65e0\u8bba\u5982\u4f55\u4e0d\u80fd\u8986\u76d6 32 bits \u7684 int\uff09\u3002\u56e0\u6b64\u5f53 x = 2146483647 \u65f6\u4e3a\u5047\u3002</p> <p>(3) \u663e\u7136 x+y \u6ea2\u51fa\u65f6\u4e24\u8005\u4e0d\u7b49\u3002\u53d6 x = 2146483647, y = 1 \u5373\u53ef\u3002</p> <p>(4) \u6c38\u771f\u3002\u8fd9\u91cc\u6ca1\u6709\u5927\u6570\u5403\u5c0f\u6570\u7684\u95ee\u9898\uff0c\u56e0\u4e3a double \u5728 int \u7684\u7c92\u5ea6\u8db3\u591f\u3002</p> <p>(5) \u6c38\u771f\uff0c\u7406\u7531\u540c\u4e0a\u3002</p> <p>(6) \u53d6 x = 0, y = 1\uff0c\u8fd9\u6837 dx/dx = -nan\u3002</p> <p></p> <p>E4M6\uff0c\u89c4\u683c\u5316\u7684\u6d6e\u70b9\u6570\u6307\u6570\u8303\u56f4\u662f -7 ~ 7\u3002</p> <p>(1)</p> <pre><code>15/16 * 2^7 = 0.1111 * 2^7 = 1.111000 * 2^6\n2/16 * 2^5 = 4 = 1.000000 * 2^2\n\u5bf9\u9636\uff1a\n1.000000 * 2^2 = 0.000100 * 2^6\n\u76f8\u52a0\uff1a\n= 1.111100 * 2^6\n\u7ed3\u679c\u662f\u89c4\u683c\u5316\u6570\u4e14\u4e0d\u5b58\u5728\u7cbe\u5ea6\u8bef\u5dee\uff0c\u56e0\u6b64\u65e0\u9700\u91cd\u65b0\u89c4\u683c\u5316\uff0c\u6dfb\u52a0\u4fdd\u62a4\u4f4d\u7684\u7ed3\u679c\u4e0d\u53d8\u3002\n= 1.111100 * 2^6 = 0 1110 111100\n</code></pre> <p>(2)</p> <pre><code>15/16 * 2^7 = 0.1111 * 2^7 = 1.111000 * 2^6\n-2/16 * 2^5 = -4 = 11 1.000000 * 2^2\n\u5bf9\u9636\uff1a\n1.000000 * 2^2 = 1.111100 * 2^6\n\u76f8\u51cf\uff08\u8865\u7801\u76f8\u52a0\uff09\uff1a\n= 00 1.110100 * 2^6\n\u7ed3\u679c\u662f\u89c4\u683c\u5316\u6570\u4e14\u4e0d\u5b58\u5728\u7cbe\u5ea6\u8bef\u5dee\uff0c\u56e0\u6b64\u65e0\u9700\u91cd\u65b0\u89c4\u683c\u5316\uff0c\u6dfb\u52a0\u4fdd\u62a4\u4f4d\u7684\u7ed3\u679c\u4e0d\u53d8\u3002\n= 1.110100 * 2^6 = 0 1110 110100\n</code></pre> <p>(3)</p> <pre><code>15/16 * 2^5 = 0.1111 * 2^5 = 00 1.111000 * 2^4\n2/16 * 2^7 = 16 = 00 1.000000 * 2^4\n\u5bf9\u9636\uff1a\n\u5df2\u7ecf\u5bf9\u597d\u3002\n\u76f8\u52a0\uff1a\n= 00 10.111000 * 2^4\n\u7531\u4e8e\u6700\u540e\u4e00\u4f4d\u662f0\u6240\u4ee5\u662f\u5426\u6dfb\u52a0\u4fdd\u62a4\u4f4d\u90fd\u4e0d\u4f1a\u5f71\u54cd\u7ed3\u679c\u3002\n\u53f3\u89c4\uff1a\n= 1.011100 * 2^5 = 0 1101 011100\n</code></pre> <p>(4)</p> <pre><code>15/16 * 2^5 = 0.1111 * 2^5 = 00 1.111000 * 2^4\n-2/16 * 2^7 = -16 = 11 1.000000 * 2^4\n\u5bf9\u9636\uff1a\n\u5df2\u7ecf\u5bf9\u597d\u3002\n\u76f8\u51cf\uff08\u8865\u7801\u76f8\u52a0\uff09\uff1a\n= 00 0.111000 * 2^4\n\u7531\u4e8e\u6ca1\u6709\u8fdb\u884c\u53f3\u89c4\u6240\u4ee5\u662f\u5426\u6dfb\u52a0\u4fdd\u62a4\u4f4d\u90fd\u4e0d\u4f1a\u5f71\u54cd\u7ed3\u679c\u3002\n\u5de6\u89c4\uff1a\n= 1.110000 * 2^3 = 0 1011 110000\n</code></pre> <p></p> <p>FP32: S1E8M23</p> <p>(1)</p> <pre><code>0.75 = 3/4 = 0.11 = 1.1 * 2^-1\nS = 0\nE = 0111 1111\nM = 1000 0000 .... 0000\n\n65.25 = 64 + 1 + 0.25 = 1000001.01 = 1.00000101 * 2^6\n-65.25:\nS = 1\nE = 1000 0110\nM = 1111 1011 0000 .... 0000\n\n\u5bf9\u9636:\n1.1 * 2^-1 = 0.0000 0011 * 2^6\n\n\u76f8\u52a0\uff1a\nS = 1\nE = 1000 0110\nM = 1111 1110 0000 .... 0000\n = -1.0000 0010 * 2^6\n\u4e5f\u5c31\u662f -64.5\n</code></pre> <p>(2)</p> <pre><code>0.75 = 3/4 = 0.11 = 1.1 * 2^-1\nS = 0\nE = 0111 1111\nM = 1000 0000 .... 0000\n\n65.25 = 64 + 1 + 0.25 = 1000001.01 = 1.00000101 * 2^6\n\u51cf\u53bb\u8d1f\u6570\u5c31\u662f\u52a0\u4e0a\u8865\u7801\u7684\u8865\u7801\u4e5f\u5c31\u662f\u52a0\u4e0a\u6b63\u6570\u3002\n65.25:\nS = 0\nE = 1000 0110\nM = 0000 0101 0000 .... 0000\n\n\u5bf9\u9636:\n1.1 * 2^-1 = 0.0000 0011 * 2^6\n\n\u76f8\u52a0\uff1a\nS = 0\nE = 1000 0110\nM = 0000 1000 0000 .... 0000\n = 1.0000 1000 * 2^6\n\u4e5f\u5c31\u662f 66\n</code></pre>"}, {"location": "campus-sources/SDC_assignments/#_5", "title": "\u7b2c\u56db\u6b21\u4f5c\u4e1a", "text": "<p>\u96f6\u5730\u5740\u6307\u4ee4\u3001\u5355\u5730\u5740\u6307\u4ee4\u548c\u4e8c\u5730\u5740\u6307\u4ee4\u6ee1\u8db3</p> \\[ k_0+2^6 k_1+2^{12}k_2=2^{16} \\] <p>\u6211\u4eec\u6ca1\u6709\u5fc5\u8981\u50cf\u8bfe\u4ef6\u90a3\u6837\u8003\u8651\u600e\u4e48\u5206\u914d\u524d\u7f00\u624d\u80fd\u4f7f\u5f97\u7f16\u7801\u4e0d\u6df7\u6dc6\uff0c\u56e0\u4e3a\u53ea\u8981\u6ee1\u8db3\u4e0a\u9762\u7684\u7b49\u5f0f\uff0c\u5c31\u5fc5\u7136\u80fd\u591f\u4e0d\u91cd\u4e0d\u6f0f\u5730\u4e3a\u8fd9\u4e09\u79cd\u7f16\u7801\u5206\u914d\u7f16\u7801\u7a7a\u95f4\u3002\u4e8e\u662f</p> \\[ k_1=2^{10}-2^6k_2-\\dfrac{k_0}{2^6} \\] <p></p> <p>(1) OP \u5360 12 \u5230 15 \u4f4d\uff0c\u4e00\u5171 4 bits\uff0c\u652f\u6301 \\(2^4=16\\) \u6761\u6307\u4ee4\uff1b\u5355\u4e2a\u64cd\u4f5c\u6570 6 bits\uff0c\u5176\u4e2d\u524d 3 bits \u62ff\u6765\u5b9a\u4e49\u5bfb\u5740\u65b9\u5f0f\uff0c\u540e 3 bits \u5c31\u5e94\u8be5\u662f\u5bc4\u5b58\u5668\u7f16\u53f7\uff0c\u652f\u6301 \\(2^3=8\\) \u4e2a\u901a\u7528\u5bc4\u5b58\u5668\u3002\u7531\u4e8e\u4e3b\u5b58 128KiB\uff0c\u4e5f\u5c31\u662f \\(2^{16}\\) \u4e2a\u5b57\u957f\uff081 word = 2 bytes\uff09\uff0c\u56e0\u6b64\u9700\u8981 16 bits \u7684\u5730\u5740\u5bc4\u5b58\u5668 MAR\uff0c\u7531\u4e8e\u673a\u5668\u5b57\u957f 16 bits\uff0c\u56e0\u6b64\u9700\u8981 16 bits \u7684\u6570\u636e\u5bc4\u5b58\u5668 MDR\u3002</p> <p>(2) \u8f6c\u79fb\u91c7\u7528\u8865\u7801\u4e5f\u5c31\u662f \\([PC-32767,PC+32768]\\)\u3002</p> <p>(3) \u673a\u5668\u7801\u5982\u4e0b\uff1a</p> <pre><code>0010 001 100 010 101\n ADD  ()  R4 ()+  R5\n0010 0011 0001 0101B = 0x2315\n</code></pre> <p>\u6309\u6307\u4ee4\u6267\u884c\uff0c\u53d6 R4 \u5185\u5bb9 1234H \u6307\u5411\u7684\u5730\u5740\u5185\u5bb9 5678H\uff0c\u53d6 R5 \u5185\u5bb9 5678H \u6307\u5411\u7684\u5730\u5740\u5185\u5bb9 1234H\uff0c\u76f8\u52a0\u4e4b\u540e\u5c06\u7ed3\u679c 68ACH \u5b58\u5230\u5730\u5740 5678H \u5185\uff08\u7b2c\u4e00\u5904\u6539\u53d8\uff09\uff0c\u7136\u540e R5 \u5bc4\u5b58\u5668\u81ea\u589e 1 \u5c31\u662f 5679H\uff08\u7b2c\u4e8c\u5904\u6539\u53d8\uff09\u3002</p> <p></p> <p>\u8fd9\u91cc\u7684\u5173\u952e\u662f A_lower_12 \u8fdb\u884c\u7b26\u53f7\u6269\u5c55\u4e4b\u540e\uff0c\u5982\u679c A_lower_12 \u7684\u6700\u9ad8\u4f4d\u662f 1 \u5c31\u4f1a\u51fa\u95ee\u9898\uff0c\u6269\u5c55\u4e4b\u540e\u9ad8 20 \u4f4d\u5168\u90e8\u90fd\u53d8\u6210 1 \u4e86\uff0c\u56e0\u6b64\u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u8981\u5728\u9ad820\u4f4d\u6700\u540e\u4e00\u4f4d\u591a\u52a0\u4e00\u4e2a 1\uff0c\u5c31\u80fd\u628a\u521a\u521a\u7684\u7b26\u53f7\u6269\u5c55\u201c\u7ffb\u56de\u6765\u201d\u3002\u5373\uff1a</p> <pre><code>A_upper20_adjusted = A_upper20 + A_lower12[11]\n</code></pre> <p></p> <p>\u9996\u5148\u9700\u8981\u6307\u51fa\u9898\u76ee\u8bbe\u8ba1\u7684\u8fd9\u4e2a\u7b97\u6cd5\u7684 Bug\uff0c\u5982\u679c a0 \u548c a1 \u4e2d\u95f4\u6ca1\u6709 0\uff0c\u90a3\u8fd9\u4e2a\u7b97\u6cd5\u5c31\u4f1a\u8d8a\u754c\u8bbf\u95ee\u5185\u5b58\u3002</p> <pre><code>        addi    t0, zero, 0     ;\u521d\u59cb\u5316 t0 &lt;- 0\nloop:   lw      t1, 0(a0)       ;t1 \u5b58\u653e a0 \u5185\u5bb9\n\n        sw      t1, 0(a1)       ;\u5c06 t1 \u7684\u503c\uff08a0\u7684\u5185\u5bb9\uff09\u5b58\u5728 a1 \u91cc\u9762\uff0c\u4e5f\u5c31\u662f\u62f7\u8d1d\n        addi    a0, a0, 4       ;a0 \u5f80\u540e\u632a 1 \u4e2a int\n        addi    a1, a1, 4       ;a1 \u5f80\u540e\u632a 1 \u4e2a int \n        beq     t1, zero, loop  ;\u82e5 t1 = 0 \u5219\u8df3\u56de loop\n        mv      a0, t0          ;\u628a t0 \u653e\u5230 a0\n</code></pre> <p>\u9996\u5148\u6211\u4eec\u53ef\u4ee5\u5927\u4f53\u4e0a\u77e5\u9053\u8fd9\u4e2a\u4ee3\u7801\u60f3\u5e72\u4ec0\u4e48\u4f46\u662f\u5931\u8d25\u4e86\uff0c\u6211\u628a\u8fd9\u4e2a\u610f\u56fe\u7528 C \u8bed\u8a00\u7b80\u5355\u5199\u4e00\u4e0b\uff1a</p> <pre><code>int memcpy_0(void* src, void* dst)// a0 -&gt; src, a1 -&gt; dst\n{\n  int cnt = 0; //t0 &lt;- 0\n  //loop:\n  while(*src != 0)\n  //lw t1, 0(a0); t1 = *src\n  //beq t1, zero, ret; *src !=0 then loop otherwise jump to ret\n  {\n    *dst = *src;//sw t1, 0(a1)\n    ++src;//addi a0, a0, 4\n    ++dst;//addi a1, a1, 4\n    ++cnt;//addi t0, t0, 1\n    //j loop\n  }\n  //ret: mv a0, t0\n  return cnt;\n}\n</code></pre> <p>\u7ffb\u8bd1\u6210\u6c47\u7f16\u5982\u4e0b\uff1a</p> <pre><code>      addi  t0, zero, 0\nloop: lw    t1, 0(a0)\n      beq   t1, zero, ret\n      sw    t1, 0(a1)\n      addi  a0, a0, 4\n      addi  a1, a1, 4\n      addi  t0, t0, 1\n      j     loop\nret:  mv    a0, t0\n</code></pre> <p></p> <p></p> <p>(1) 8\u4f4d\u6216\u8005\u8bf4\u4e00\u4e2a\u5b57\u8282\uff0c\u6570\u7ec4\u6bcf\u4e2a\u5143\u7d20 4 \u5b57\u8282\u3002\u56e0\u4e3a\u7b2c\u4e00\u884c R[t1] = i * 4 \u8bf4\u660e\u4e00\u4e2a int \u5360 4 \u5b57\u8282\uff0c\u8fd9\u6837\u5c31\u80fd\u6b63\u786e\u7b97\u51fa\u57fa\u4e8e\u5b57\u8282\u5730\u5740\u7684\u504f\u79fb\u91cf\u3002</p> <p>(2) i \u653e\u5728 s3 \u91cc\u9762\uff0c\u5de6\u79fb\u4e24\u4f4d\u5c31\u662f i * 4\uff0c\u7136\u540e\u653e\u8fdb t1 \u5907\u7528\u3002</p> <p>(3) R \u578b\u6307\u4ee4\u5bf9\u5e94\u4e09\u4e2a\u64cd\u4f5c\u6570\u7684\u52a0\u51cf\u4f4d\u8fd0\u7b97\uff0copcode = 0110011B = 51\uff0c\u4e5f\u5c31\u662f\u7b2c\u4e8c\u6761\u4f4d\u4e8e\u5185\u5b58 40004 \u5904\u7684\u6307\u4ee4\u3002</p> <p>I \u578b\u6307\u4ee4\u5bf9\u5e94\u7acb\u5373\u6570\u548c\u4e24\u4e2a\u64cd\u4f5c\u6570\u7684\u52a0\u51cf\u4f4d\u8fd0\u7b97\uff0copcode = 0010011B = 19\uff0c\u4e5f\u5c31\u662f\u7b2c\u4e00\u6761\u4f4d\u4e8e\u5185\u5b58 40000 \u5904\u7684\u6307\u4ee4\u548c\u7b2c\u4e94\u6761\u4f4d\u4e8e\u5185\u5b58 40016 \u5904\u7684\u6307\u4ee4\uff0c\u4ee5\u53ca lw \u6307\u4ee4\uff0copcode = 0000011B = 3 \u4e5f\u5c31\u662f\u7b2c\u4e09\u6761\u4f4d\u4e8e\u5185\u5b58 40008 \u5904\u7684\u6307\u4ee4\u3002</p> <p>B \u578b\u6307\u4ee4\u5c31\u662f\u4ee5 B \u6253\u5934\u7684\u6307\u4ee4\u4e5f\u5c31\u662f\u7b2c\u56db\u6761\u4f4d\u4e8e\u5185\u5b58 40012 \u5904\u7684\u6307\u4ee4\u3002</p> <p>J \u578b\u6307\u4ee4\u4e3a\u6700\u540e\u4e00\u6761\u4f4d\u4e8e\u5185\u5b58 40020 \u5904\u7684\u6307\u4ee4\u3002</p> <p>(4) \u7531 lw t0, 0(t1) \u5bf9\u5e94\u7684\u673a\u5668\u7801\u53ef\u77e5 t0 \u7684\u7f16\u53f7\u662f 5\uff0c\u7531 add t1, t1, s6 \u5bf9\u5e94\u7684\u673a\u5668\u7801\u53ef\u77e5 s6 \u7684\u7f16\u53f7\u662f 22\u3002</p> <p>(5) jal x0, loop\u3002\u64cd\u4f5c\u7801\u4e3a 1101111</p> <p>(6) \u5982\u4e0b\uff1a</p> <pre><code>0=0000000 = 0 | 000000\n12=01100 = 0110 | 0\noffset = 0 0 0000 0110 0 = 12\nexit = PC + offset = 40024\n</code></pre> <p>(7) \u6309\u7406\u8bf4\u5e94\u8be5\u662f 40000 \u4e5f\u5c31\u662f\u5e26 loop \u6807\u53f7\u7684\u5185\u5b58\u5730\u5740\u7684\uff0c\u6309\u673a\u5668\u7801\u5982\u4e0b\uff1a</p> <pre><code>\u504f\u79fb\u91cf -20 bytes =&gt; \u6700\u540e imm = -10\n-10 = 1 11111111 1 1111110110\n\u91cd\u7ec4: 1 1111110110 11111111 1\n11111110110111111111 = 1043967\uff08???\uff09\n</code></pre> <p>\u6211\u6000\u7591\u672c\u9898\u6570\u636e\u6709 typo\uff0c\u5e94\u8be5\u662f 1043967\uff0c\u8bc1\u636e\u5982\u4e0b\uff1a</p> <p></p> <p></p> <p></p> <p>\u9996\u5148\u5904\u7406 <code>compare</code> \u51fd\u6570\uff0c\u8fd9\u662f\u4e00\u4e2a\u53f6\u5b50\u51fd\u6570\u6240\u4ee5\u53ef\u4ee5\u4e0d\u7528\u7279\u610f\u5206\u914d\u6808\u5e27\uff1a</p> <pre><code>int compare(int a, int b)\n// a0 &lt;- a, a1 &lt;- b, ret -&gt; a0\n{\n  //blt a1, a0, ret1\n  if (a &gt; b)\n    return 1; // ret1 :addi a0, zero, 1; ret\n  else\n    return 0; // addi a0, zero, 0; ret\n}\n</code></pre> <p>\u7ec4\u7ec7\u4e00\u4e0b\uff1a</p> <pre><code>compare:\n  blt a1, a0, ret1\n  addi a0, zero 0\n  ret\n\nret1:\n  addi a0, zero, 1\n  ret\n</code></pre> <p>\u7136\u540e\u770b\u4e00\u4e0b <code>sum_array</code>\uff1a</p> <pre><code>int sum = 0; //t0 &lt;- sum\nint sum_array ( int array[], int num )\n// a0 &lt;- array, a1 &lt;- num\n{\n    // Registers needed to save: s0 for array, s1 for num, s2 for i. We also need to save ra. We will also call `compare` so \n    /*\n    Prologue:\n    addi sp, sp, -20\n    sw ra, 16(sp)\n    sw s0, 12(sp)\n    sw s1, 8(sp)\n    sw s2, 4(sp)\n    ...\n    Epilogue:\n    lw s2, 4(sp)\n    lw s1, 8(sp)\n    lw s0, 12(sp)\n    lw ra, 16(sp)\n    addi sp, sp, 20\n    */\n    int i;\n    /*\n    Initialization:\n    save parameters:\n    addi s0, a0, 0\n    addi s1, a1, 0\n    num = 0: addi t0, zero, 0\n    i = 0:   addi s2, zero, 0\n    */\n    for (i = 0; i &lt; num; i++)\n    //if i &gt;= num, jump to ret: bge s2, s1, ret\n    //loop:\n    /*\n    Now we will call `compare`.\n    `compare` take num(s1) as a0, i+1(s2) as a1\n    so we generate arguments:\n    addi a0, s1, 0\n    addi a1, s2, 1\n    also, we need to save t0\n    sw t0, 0(sp)\n    then call compare.\n    now resume t0: lw t0, 0(sp)\n    now a0 = compare (num, i+1)\n    if a0 = 0 we just skip sum += array[i]: beq a0, zero, skip\n    */\n        if compare (num, i+1) sum += array[i];\n    /*\n    now we calculate sum += array[i].\n    firstly we get the address array + i:\n    slli t1, s2, 2\n    addi t1, s0, t1\n    then we load array[i] = *(array + i):\n    lw t2, 0(t1)\n    finally we add it to sum:\n    addi t0, t0, t2\n    */\n    //skip: addi s2, s2, 1\n    //j loop\n    //ret: addi a0, t0, 0\n    return sum;\n}\n</code></pre> <pre><code>sum_array:\n    ;Prologue\n    addi sp, sp, -20\n    sw ra, 16(sp)\n    sw s0, 12(sp)\n    sw s1, 8(sp)\n    sw s2, 4(sp)\n\n    ;Initialization\n    addi s0, a0, 0\n    addi s1, a1, 0\n    addi t0, zero, 0\n    addi s2, zero, 0\n\nloop:\n    bge s2, s1, ret\n\n    addi a0, s1, 0\n    addi a1, s2, 1\n\n    sw t0, 0(sp)\n\n    jal compare\n\n    lw t0, 0(sp)\n\n    beq a0, zero, skip\n\n    slli t1, s2, 2\n    add t1, s0, t1\n    lw t2, 0(t1)\n    add t0, t0, t2\nskip:\n    addi s2, s2, 1\n    j loop\n\nret:\n    addi a0, t0, 0\n    ;Epilogue\n    lw s2, 4(sp)\n    lw s1, 8(sp)\n    lw s0, 12(sp)\n    lw ra, 16(sp)\n    addi sp, sp, 20\n\n    ret\n</code></pre> <p>\u56e0\u6b64\u8c03\u7528 sum_array \u524d\uff0c\u5176\u6808\u7a7a\u95f4\u91cc\u9762\u6ca1\u6709\u4e1c\u897f\uff1a</p> <pre><code>\u9ad8\u5730\u5740-&gt;\u4f4e\u5730\u5740\uff0c\u6bcf\u4e00\u683c 4 bytes\u3002\n----+----+\n... |    |\n----+----+\n      \u2191sp\n</code></pre> <p>\u8c03\u7528 sum_array \u540e\uff0c\u8c03\u7528 compare \u524d\u540e\uff1a</p> <pre><code>\u9ad8\u5730\u5740-&gt;\u4f4e\u5730\u5740\uff0c\u6bcf\u4e00\u683c 4 bytes\u3002\n----+----+----+----+----+----+\n... | ra | s0 | s1 | s2 | t0 |\n----+----+----+----+----+----+\n                          \u2191sp\n</code></pre> <p>\u56e0\u4e3a compare \u7279\u522b\u7b80\u5355\u4e0d\u6d89\u53ca\u6808\u4e0a\u64cd\u4f5c\uff0c\u56e0\u6b64\u6808\u72b6\u6001\u4e0d\u53d8\u3002</p> <p>\u8c03\u7528 sum_array \u540e\uff0c\u91ca\u653e\u6808\u7a7a\u95f4\uff1a</p> <pre><code>\u9ad8\u5730\u5740-&gt;\u4f4e\u5730\u5740\uff0c\u6bcf\u4e00\u683c 4 bytes\u3002\n----+----+\n... |    |\n----+----+\n      \u2191sp\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Oct. 26, 2025). \u300a\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u300b\u7406\u8bba\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/SDC_assignments</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{SDC_assignments,\n    title={\u300a\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u300b\u7406\u8bba\u8bfe\u7a0b\u4f5c\u4e1a\u4e0e\u7b14\u8bb0\u5f52\u6863},\n    author={Yan Li},\n    year={2025},\n    month={Oct},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/SDC_assignments}},\n}\n</code></pre></p>"}, {"location": "campus-sources/autosignin/", "title": "\u81ea\u52a8\u7b7e\u5230\u811a\u672c", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 1 \u5206\u949f\u3000|\u3000\u7ea6 82 \u5b57\u3000|\u3000\u7ea6 75 \u884c\u4ee3\u7801</p> <p>\u653e\u5728\u4f60\u7684git\u4ed3\u5e93\u4e0b\u9762\u3002</p> <p>\u4f7f\u7528\u524d\uff0c\u5148Ctrl-F\u627e\u5230\u6240\u6709\u5e26\"Replace\"\u6ce8\u91ca\u7684\u884c\uff0c\u7136\u540e\u6839\u636e\u63d0\u793a\u5185\u5bb9\u6362\u6210\u4f60\u81ea\u5df1\u7684\u8d26\u53f7\u3001\u4ed3\u5e93\u3001\u53e3\u4ee4\u7b49\u3002</p> <p>\u5982\u679c\u4e0d\u60f3\u6bcf\u4e00\u6b21push\u90fd\u9274\u6743\uff0c\u4f7f\u7528\u4e0b\u9762\u7684\u547d\u4ee4\u5b58\u50a8\u7528\u6237\u540d\u548c\u53e3\u4ee4\uff1a</p> <pre><code>git config --global credential.helper store\n</code></pre> <p>\u5927\u5bb6\u5c0f\u5b66\u671f\u7b7e\u5230\u6109\u5feb\uff01</p> <pre><code>import datetime\n\nprint(\"Automatic Sign-in Script created by Dicaeopolis\")\n\naccount = \"xxxxxxx\" # Replace it with your repository name.\nnum = 2024123451234 # Replace it with your student number.\npassword = input(\"[+] Enter the password given today: \")\nroom = 123          # Replace it with your classroom number.\n\ncurrent_date = datetime.date.today()\n\nformatted_date = current_date.strftime(\"%Y-%m-%d\")\n\nfile_creation = f\"echo -n \\\"{num}{password}{room}\\\" | md5sum | cut -d ' ' -f1 &gt; {formatted_date}\"\n\nsave_cmd = f\"git add {formatted_date}\"\n\ncommit_cmd = f\"git commit -m \\\"{formatted_date}\\\"\"\n\npush_cmd = f\"git push origin {account}\"\n\nprint(\"[+] All commands are ready to be executed. Please check the commands below:\")\nprint(f\"    {file_creation}\")\nprint(f\"    {save_cmd}\")\nprint(f\"    {commit_cmd}\")\nprint(f\"    {push_cmd}\")\n\nprint(\"[/] Execute now? [y/N]: \", end=\"\")\n\nexecute = input().strip().lower()\n\nif execute == 'y':\n    import os\n    os.system(file_creation)\n    os.system(save_cmd)\n    os.system(commit_cmd)\n    os.system(push_cmd)\n    print(\"[+] All commands executed successfully.\")\n    print(\"[+] Checking the repository for the latest changes.\")\n    import requests\n    from bs4 import BeautifulSoup\n\n    LOGIN_URL = \"https://se.jisuanke.com/users/sign_in\"\n    TARGET_URL = f\"https://se.jisuanke.com/whu2025/{room}/-/raw/{account}/{formatted_date}\"\n    session = requests.Session()\n\n    response = session.get(LOGIN_URL)\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    csrf_token = None\n    try:\n        csrf_token = soup.find('meta', {'name': 'csrf-token'})['content']\n    except (TypeError, KeyError):\n        print(\"[-] CSRF token not found. Please check the login page structure.\")\n        exit(1)\n\n    login_data = {\n        \"user[login]\": \"xxx\",                   # Replace with your username\n        \"user[password]\": \"xxxxxxxxxxxxxxx\",    # Replace with your password\n        \"authenticity_token\": csrf_token,\n        \"user[remember_me]\": \"1\"                # Remember me option, if needed\n    }\n\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n        \"Referer\": LOGIN_URL\n    }\n\n    response = session.post(LOGIN_URL, data=login_data, headers=headers)\n\n    if response.status_code == 200:\n        print(\"[+] Login successfully!\")\n\n        cookies = session.cookies.get_dict()\n        print(\"[+] Cookies after login:\")\n        for key, value in cookies.items():\n            print(f\"{key}: {value}\")\n\n        response = session.get(TARGET_URL, headers=headers)\n        if response.status_code == 200:\n            print(\"[+] Successfully accessed the target page!\")\n            import hashlib\n            md5sum_str = response.text.strip()\n            print(f\"[+] Retrieved MD5 checksum: {md5sum_str}\")\n            print(f\"[+] Expected MD5 checksum: {hashlib.md5(f'{num}{password}{room}'.encode()).hexdigest()}\")\n            if md5sum_str == hashlib.md5(f\"{num}{password}{room}\".encode()).hexdigest():\n                print(\"[+] Latest file retrieved successfully. MD5 checksum matches.\")\n            else:\n                print(\"[-] MD5 checksum does not match. Please check the password or the repository.\")\n        else:\n            print(f\"[-] Failed to visit target page with error code: {response.status_code}\")\n    else:\n        print(f\"[-] Failed to login with error code : {response.status_code}\")\nelse:\n    print(\"[+] Execution cancelled. No changes made.\")\n</code></pre> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 3, 2025). \u81ea\u52a8\u7b7e\u5230\u811a\u672c [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/autosignin</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{autosignin,\n    title={\u81ea\u52a8\u7b7e\u5230\u811a\u672c},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/autosignin}},\n}\n</code></pre></p>"}, {"location": "campus-sources/binmul/", "title": "<i class=\"fas fa-calculator\"></i> \u4e8c\u8fdb\u5236\u4e58\u6cd5\u53ef\u89c6\u5316\u5de5\u5177", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 7 \u5206\u949f\u3000|\u3000\u7ea6 1393 \u5b57\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> \u4e8c\u8fdb\u5236\u4e58\u6cd5\u53ef\u89c6\u5316\u5de5\u5177  \u4e8c\u8fdb\u5236\u4e58\u6cd5\u53ef\u89c6\u5316\u5de5\u5177 <p>\u652f\u6301\u65e0\u7b26\u53f7\u4e58\u6cd5\u3001\u539f\u7801\u4e58\u6cd5\u4e0e Booth\uff08\u8865\u7801\uff09\u4e58\u6cd5\u3002\u652f\u6301\u5355\u6b65\u3001\u56de\u9000\u4e0e\u81ea\u52a8\u64ad\u653e\u3002</p>  \u53c2\u6570\u8bbe\u7f6e  \u4e58\u6cd5\u7c7b\u578b: \u65e0\u7b26\u53f7\u4e58\u6cd5 \u539f\u7801\u4e58\u6cd5 \u8865\u7801\u4e58\u6cd5 (Booth \u7b97\u6cd5)  \u4f4d\u6570: 4\u4f4d 8\u4f4d 16\u4f4d  \u88ab\u4e58\u6570 (\u5341\u8fdb\u5236):  \u4e58\u6570 (\u5341\u8fdb\u5236):  \u521d\u59cb\u5316\u8ba1\u7b97  \u4e0a\u4e00\u6b65  \u4e0b\u4e00\u6b65  \u81ea\u52a8\u64ad\u653e  \u91cd\u7f6e  \u52a8\u753b\u901f\u5ea6: \u6162 \u4e2d \u5feb  \u8ba1\u7b97\u8fc7\u7a0b <p> \u70b9\u51fb\u201c\u521d\u59cb\u5316\u8ba1\u7b97\u201d\u5f00\u59cb\u3002\u4f7f\u7528\u201c\u4e0b\u4e00\u6b65/\u4e0a\u4e00\u6b65\u201d\u9010\u6b65\u67e5\u770b\u3002\u53f3\u4fa7\u53ea\u663e\u793a\u5f53\u524d\u4e00\u6b65\u7684\u8bf4\u660e\u3002</p>  \u5bc4\u5b58\u5668\u72b6\u6001  \u6b65\u9aa4\u8bf4\u660e\uff08\u4ec5\u5f53\u524d\u4e00\u6b65\uff09 <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 25, 2025).  \u4e8c\u8fdb\u5236\u4e58\u6cd5\u53ef\u89c6\u5316\u5de5\u5177 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/binmul</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{binmul,\n    title={&lt;i class=\"fas fa-calculator\"&gt;&lt;/i&gt; \u4e8c\u8fdb\u5236\u4e58\u6cd5\u53ef\u89c6\u5316\u5de5\u5177},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/binmul}},\n}\n</code></pre></p>"}, {"location": "campus-sources/ds-keynote/", "title": "\u300a\u6570\u636e\u7ed3\u6784\u300b\u5212\u91cd\u70b9\u7b14\u8bb0", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 112 \u5206\u949f\u3000|\u3000\u7ea6 17269 \u5b57\u3000\u26a0\ufe0f \u4e07\u5b57\u957f\u6587\uff0c\u8bf7\u6162\u6162\u9605\u8bfb\u3000|\u3000\u7ea6 267 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 27 \u884c\u4ee3\u7801</p> <p>\u521b\u4f5c\u58f0\u660e\uff1a\u672c\u6587\u5927\u90e8\u5206\u6587\u5b57\u7531\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u521b\u4f5c\uff0c\u4f46\u5df2\u7ecf\u8fc7\u68c0\u67e5\u548c\u4fee\u8ba2\u3002\u4f5c\u8005\u4e3a\u672c\u6587\u5185\u5bb9\u6b63\u786e\u6027\u8d1f\u8d23\u3002</p>"}, {"location": "campus-sources/ds-keynote/#_2", "title": "\u4ec0\u4e48\u662f\u6563\u5217\u8868\uff1f\u6709\u54ea\u4e9b\u91cd\u8981\u7684\u89e3\u51b3\u51b2\u7a81\u7684\u65b9\u6cd5\uff1f\u4ec0\u4e48\u662f\u88c5\u586b\u56e0\u5b50\uff1f\u5b83\u5bf9\u6563\u5217\u8868\u7684\u641c\u7d22\u6548\u7387\u6709\u4ec0\u4e48\u5f71\u54cd\uff1f\u5982\u4f55\u8ba1\u7b97\u5728\u6563\u5217\u8868\u4e0a\u641c\u7d22\u6210\u529f\u6216\u641c\u7d22\u5931\u8d25\u65f6\u7684\u5e73\u5747\u641c\u7d22\u957f\u5ea6\uff1f\uff08\u6807\u7ea2\uff09", "text": "<ul> <li> <p>\u4f4d\u7f6e\uff1a\u6559\u6750 9.4</p> </li> <li> <p>\u6563\u5217\u8868\u5373\u54c8\u5e0c\u8868\u3002\u7528\u4e8e\u5c06\u4efb\u610f\u6570\u636e\u6620\u5c04\u5230\u8fde\u7eed\u5185\u5b58\u7a7a\u95f4\u91cc\u9762\uff0c\u5177\u4f53\u800c\u8a00\uff1a\u5229\u7528\u54c8\u5e0c\u51fd\u6570 \\(h(k_i)\\) \u5c06\u6570\u636e \\(k_i\\) \u6620\u5c04\u4e3a\u5185\u5b58\u5355\u5143\u7684\u4e0b\u6807\uff0c\u7531\u6b64\u6784\u9020\u7684\u7ebf\u6027\u8868\u7ed3\u6784\u5373\u4e3a\u6563\u5217\u8868\u3002</p> </li> <li> <p>\u89e3\u51b3\u51b2\u7a81\u7684\u65b9\u6cd5\u6709\u591a\u79cd\uff1a</p> <ul> <li>\u7ebf\u6027\u63a2\u6d4b\u6cd5\uff1a\u5f53\u51fa\u73b0\u54c8\u5e0c\u51b2\u7a81\u65f6\uff0c\u4e00\u76f4\u5f80\u540e\u627e\uff0c\u76f4\u5230\u627e\u5230\u7a7a\u95f2\u7684\u5185\u5b58\u7a7a\u95f4\u3002\uff08\u9047\u5230\u672b\u5c3e\u5219\u4ece\u5934\u5f00\u59cb\uff09\u4f18\u70b9\uff1a\u5b9e\u73b0\u7b80\u5355\uff1b\u7f3a\u70b9\uff1a\u6570\u636e\u5bb9\u6613\u5806\u79ef\uff0c\u4e5f\u5c31\u662f\u54c8\u5e0c\u503c\u4e0d\u540c\u7684\u4e24\u4e2a\u6570\u636e\u8981\u4e89\u593a\u540c\u4e00\u4e2a\u5185\u5b58\u7a7a\u95f4\u3002</li> <li>\u5e73\u65b9\u63a2\u6d4b\u6cd5\uff1a\u53ea\u63a2\u6d4b\u524d\u9762\u548c\u540e\u9762\u7684 \\(i^2\\) \u7684\u4f4d\u7f6e\uff0c\u53ef\u4ee5\u89e3\u51b3\u5806\u79ef\u95ee\u9898\u4f46\u662f\u4e0d\u4e00\u5b9a\u53ef\u4ee5\u63a2\u6d4b\u5230\u6240\u6709\u5355\u5143\u3002</li> <li>\u5176\u4ed6\u5f00\u653e\u5b9a\u5740\u6cd5\uff0c\u5982\u4f2a\u968f\u673a\u5e8f\u5217\u6cd5\uff0c\u62c9\u94fe\u6cd5\u3002</li> <li>\u62c9\u94fe\u6cd5\uff1a\u5c06\u5177\u6709\u76f8\u540c\u54c8\u5e0c\u503c\u7684\u5143\u7d20\u62c9\u6210\u4e00\u4e2a\u94fe\u8868\uff0c\u800c\u539f\u6765\u7684\u5185\u5b58\u7a7a\u95f4\u5b58\u653e\u8fd9\u4e2a\u94fe\u8868\u7684\u5934\u7ed3\u70b9\u3002</li> </ul> </li> <li> <p>\u88c5\u586b\u56e0\u5b50 \\(\\alpha\\) \uff1a\u6307\u54c8\u5e0c\u8868\u88c5\u5165\u5143\u7d20\u6570\u4e0e\u539f\u6765\u5185\u5b58\u7a7a\u95f4\u5927\u5c0f\u7684\u6bd4\u503c\u3002</p> </li> <li> <p>\u88c5\u586b\u56e0\u5b50\u592a\u5c0f\uff0c\u5373\u54c8\u5e0c\u8868\u7a7a\u95f4\u672a\u80fd\u5145\u5206\u5229\u7528\uff1b\u592a\u5927\uff0c\u5219\u5bb9\u6613\u4ea7\u751f\u51b2\u7a81\u3002</p> </li> <li> <p>\u8ba1\u7b97\u5e73\u5747\u641c\u7d22\u957f\u5ea6\uff1a\u3010\u53c2\u8003\u6559\u6750\u4f8b 9.11\u3011\u5bf9\u4e8e\u5f00\u653e\u5b9a\u5740\u6cd5\u800c\u8a00\uff1a\u5982\u679c\u641c\u7d22\u6210\u529f\uff0c\u53d6\u6bcf\u4e00\u4e2a\u5173\u952e\u5b57\uff0c\u5728\u6784\u5efa\u7684\u54c8\u5e0c\u8868\u91cc\u9762\u6a21\u62df\u4e00\u4e0b\u63a2\u6d4b\u8fc7\u7a0b\uff0c\u6700\u540e\u628a\u6bd4\u8f83\u6b21\u6570\u53d6\u4e00\u4e0b\u5e73\u5747\uff1b\u5982\u679c\u641c\u7d22\u5931\u8d25\uff0c\u53d6\u6bcf\u4e00\u4e2a\u54c8\u5e0c\u503c\uff0c\u7136\u540e\u6309\u7167\u63a2\u6d4b\u65b9\u6cd5\u76f4\u5230\u63a2\u6d4b\u5230\u7a7a\u4f4d\u7f6e\uff0c\u8bb0\u5f55\u63a2\u6d4b\u6b21\u6570\u53d6\u5e73\u5747\u503c\u5373\u53ef\u3002</p> </li> </ul> <p>\u672c\u77e5\u8bc6\u70b9\u6613\u8003\u5bdf\u7efc\u5408\u9898\u3001\u586b\u7a7a\u9898\u548c\u9009\u62e9\u9898\uff0c\u8003\u70b9\u4e3a\u8ba1\u7b97\u5e73\u5747\u641c\u7d22\u957f\u5ea6\u3002</p>"}, {"location": "campus-sources/ds-keynote/#_3", "title": "\u4ec0\u4e48\u662f\u7ebf\u6027\u8868\uff1f\u5b83\u7684\u6700\u4e3b\u8981\u7684\u6027\u8d28\u662f\u4ec0\u4e48\uff1f", "text": "<ul> <li> <p>\u7ebf\u6027\u8868\u662f\u5177\u6709\u76f8\u540c\u7279\u6027\u7684\u6570\u636e\u5143\u7d20\u7684\u4e00\u4e2a\u6709\u9650\u5e8f\u5217\u3002</p> </li> <li> <p>\u6027\u8d28\uff1a\u5e8f\u5217\u6027\uff0c\u5b58\u5728\u5f00\u59cb\u548c\u7ec8\u7aef\uff0c\u5e76\u4e14\u6bcf\u4e00\u4e2a\u5143\u7d20\u90fd\u6709\u552f\u4e00\u7684\u524d\u9a71\u548c\u540e\u7ee7\u5143\u7d20\u3002</p> </li> </ul> <p>\u672c\u77e5\u8bc6\u70b9\u6613\u8003\u5bdf\u987a\u5e8f\u8868\u548c\u94fe\u8868\u8fdb\u884c\u63d2\u5165\u3001\u5220\u9664\u7b49\u64cd\u4f5c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u533a\u522b\u3002\u4e5f\u53ef\u80fd\u51fa\u5224\u65ad\u9898\u8fa8\u6790\u7ebf\u6027\u8868\u3001\u987a\u5e8f\u8868\u548c\u94fe\u8868\u662f\u4e0a\u4e0b\u4f4d\u6982\u5ff5\u5173\u7cfb</p>"}, {"location": "campus-sources/ds-keynote/#_4", "title": "\u4ec0\u4e48\u662f\u903b\u8f91\u7ed3\u6784\uff1f\u4ec0\u4e48\u662f\u6570\u636e\u5143\u7d20\uff1f\u4ec0\u4e48\u662f\u6570\u636e\u9879\uff1f\u4ec0\u4e48\u662f\u6570\u636e\u7c7b\u578b\uff1f\u5b83\u4eec\u6709\u4ec0\u4e48\u8054\u7cfb\uff1f", "text": "<ul> <li> <p>\u903b\u8f91\u7ed3\u6784\u662f\u6307\u6570\u636e\u4e4b\u95f4\u5728\u903b\u8f91\u4e0a\u7684\u7ec4\u7ec7\u65b9\u5f0f\uff0c\u4e0d\u6d89\u53ca\u5177\u4f53\u7684\u7269\u7406\u5b58\u50a8\u7ec6\u8282\u3002</p> </li> <li> <p>\u6570\u636e\u5143\u7d20\u662f\u57fa\u672c\u7684\u6570\u636e\u5355\u4f4d\uff0c\u662f\u80fd\u88ab\u8bc6\u522b\u548c\u5904\u7406\u7684\u6700\u5c0f\u6570\u636e\u7ec4\u7ec7\u5355\u4f4d\u3002\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u6761\u201c\u8bb0\u5f55\u201d\u6216\u4e00\u4e2a\u201c\u5b9e\u4f53\u201d\u3002</p> </li> <li> <p>\u6570\u636e\u9879\u662f\u6570\u636e\u5143\u7d20\u7684\u4e0d\u53ef\u518d\u5206\u7684\u6700\u5c0f\u5355\u4f4d\uff0c\u662f\u6784\u6210\u6570\u636e\u5143\u7d20\u7684\u5177\u4f53\u5c5e\u6027\u3002</p> </li> <li> <p>\u6570\u636e\u7c7b\u578b\u662f\u5bf9\u6570\u636e\u9879\u7684\u503c\u53ca\u5176\u64cd\u4f5c\u7684\u96c6\u5408\u7684\u5b9a\u4e49\uff0c\u6307\u5b9a\u4e86\u8be5\u6570\u636e\u7684\u5b58\u50a8\u683c\u5f0f\u548c\u53ef\u8fdb\u884c\u7684\u64cd\u4f5c\u3002</p> </li> <li> <p>\u4f8b\u5982\uff1a <pre><code>struct student\n{\n    std::string name;\n    int age;\n};\nstudent group[4];\n</code></pre> \u91cc\u9762\u7684\u6570\u7ec4\u53ef\u4ee5\u7406\u89e3\u4e3a\u7ebf\u6027\u903b\u8f91\u7ed3\u6784\u7684\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\uff0c\u6570\u7ec4\u91cc\u9762\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u5c31\u662f\u6570\u636e\u5143\u7d20\uff0c\u8fd9\u6bcf\u4e00\u4e2a\u5143\u7d20\u91cc\u9762\u7684 <code>name</code> \u548c <code>age</code> \u9879\u5c31\u662f\u6570\u636e\u9879\uff0c\u800c <code>student</code> \u5c31\u662f\u6570\u636e\u7c7b\u578b\u3002</p> </li> </ul> <p>\u672c\u77e5\u8bc6\u70b9\u6613\u8003\u5224\u65ad\u9898\u8fdb\u884c\u6982\u5ff5\u8fa8\u6790\uff0c\u6216\u8005\u51fa\u9001\u5206\u9898\u3002</p>"}, {"location": "campus-sources/ds-keynote/#_5", "title": "\u4ec0\u4e48\u662f\u987a\u5e8f\u5b58\u50a8\u7ed3\u6784\uff1f\u4ec0\u4e48\u662f\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\uff1f\u8fd8\u6709\u54ea\u4e9b\u5176\u4ed6\u5b58\u50a8\u7ed3\u6784\uff1f", "text": "<ul> <li>\u987a\u5e8f\u5b58\u50a8\u7ed3\u6784\uff1a\u6570\u636e\u5b58\u653e\u5728\u8fde\u7eed\u7684\u5185\u5b58\u7a7a\u95f4\u91cc\u9762\uff0c\u968f\u673a\u8bbf\u95ee\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(1)\\)\uff0c\u63d2\u5165\u548c\u5220\u9664\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(n)\\)\u3002</li> <li>\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\uff1a\u6570\u636e\u5b58\u653e\u5728\u7ed3\u70b9\u91cc\u9762\uff0c\u6bcf\u4e2a\u7ed3\u70b9\u4e0d\u4ec5\u5b58\u653e\u6570\u636e\uff0c\u8fd8\u5b58\u653e\u6307\u9488\uff0c\u7528\u6765\u5b58\u50a8\u8be5\u7ed3\u70b9\u7684\u5355\u4e2a\u524d\u9a71\u548c/\u6216\u540e\u7ee7\uff0c\u968f\u673a\u8bbf\u95ee\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(n)\\)\uff0c\u63d2\u5165\u548c\u5220\u9664\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(1)\\)\u3002</li> <li>\u8fd8\u6709\u6808\u7ed3\u6784\u3001\u961f\u5217\u7ed3\u6784\u3001\u6811\u7ed3\u6784\u3001\u56fe\u7ed3\u6784\u548c\u7d22\u5f15\u7ed3\u6784\u7b49\u3002</li> </ul>"}, {"location": "campus-sources/ds-keynote/#_6", "title": "\u4ec0\u4e48\u662f\u5355\u94fe\u8868\uff1f\u4ec0\u4e48\u662f\u53cc\u5411\u94fe\u8868\uff1f\u4ec0\u4e48\u662f\u5faa\u73af\u94fe\u8868\uff1f\u600e\u6837\u5728\u94fe\u8868\u4e0a\u8fdb\u884c\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\uff1f", "text": "<ul> <li>\u5355\u94fe\u8868\uff1a\u53ea\u6709\u4e00\u4e2a\u6307\u5411\u540e\u7ee7\u7684\u6307\u9488\u57df\u7684\u94fe\u8868\u3002</li> <li>\u53cc\u5411\u94fe\u8868\uff1a \u6307\u9488\u57df\u65e2\u6307\u5411\u540e\u7ee7\u53c8\u6307\u5411\u524d\u9a71\u7684\u94fe\u8868\u3002</li> <li>\u5faa\u73af\u94fe\u8868\uff1a\u5934\u5c3e\u8282\u70b9\u5b58\u5728\u6307\u9488\u57df\u5173\u8054\u5f62\u6210\u5faa\u73af\u7684\u94fe\u8868\u3002</li> <li>\u63d2\u5165\u7684\u65b9\u6cd5\uff1a\u5148\u53d6\u5f85\u63d2\u5165\u7ed3\u70b9\uff0c\u8c03\u6574\u5176\u6307\u9488\u57df\uff0c\u7136\u540e\u8c03\u6574\u539f\u94fe\u8868\u91cc\u9762\u548c\u8be5\u7ed3\u70b9\u76f8\u8fde\u7684\u7ed3\u70b9\u7684\u6307\u9488\u57df\u3002</li> <li>\u5220\u9664\u7684\u65b9\u6cd5\u540c\u7406\u3002</li> </ul> <p>\u6613\u8003\u70b9\uff1a\u54ea\u4e00\u4e2a\u9009\u9879\u7684\u4ee3\u7801\u6b63\u786e\u6267\u884c\u4e86\u63d2\u5165/\u5220\u9664\u64cd\u4f5c\uff1b\u6216\u63d2\u5165/\u5220\u9664\u64cd\u4f5c\u5171\u9700\u8981\u8c03\u6574\u51e0\u4e2a\u6307\u9488\u57df\u3002</p>"}, {"location": "campus-sources/ds-keynote/#_7", "title": "\u4ec0\u4e48\u662f\u6808\uff1f\u7ed9\u5b9a\u4e00\u4e2a\u5165\u6808\u5e8f\u5217\uff0c\u5982\u4f55\u5224\u65ad\u4e00\u4e2a\u51fa\u6808\u5e8f\u5217\u662f\u5426\u53ef\u80fd\uff1f\u4ec0\u4e48\u662f\u94fe\u5f0f\u6808\uff1f\u8ddf\u987a\u5e8f\u6808\u76f8\u6bd4\uff0c\u5b83\u6709\u4ec0\u4e48\u4f18\u7f3a\u70b9\uff1f", "text": "<ul> <li>\u6808\uff1a\u540e\u8fdb\u5148\u51fa\u7684\u6570\u636e\u7ed3\u6784\u3002</li> <li>\u5224\u5b9a\u6807\u51c6\uff1a\u5bf9\u51fa\u6808\u5e8f\u5217\u8fdb\u884c\u6a21\u62df\uff0c\u5224\u65ad\u6709\u65e0\u975e\u6808\u9876\u7684\u5143\u7d20\u63d0\u524d\u51fa\u6808\u3002</li> <li>\u94fe\u6808\u5373\u5e95\u5c42\u4f7f\u7528\u94fe\u8868\u5b9e\u73b0\u7684\u6808\u3002\u4f18\u70b9\u662f\u65e0\u9700\u62c5\u5fc3\u6808\u5bb9\u91cf\u95ee\u9898\uff0c\u4e0d\u4f1a\u6d6a\u8d39\u7a7a\u95f4\uff1b\u7f3a\u70b9\u662f\u5220\u9664\u548c\u63d2\u5165\u5143\u7d20\u7684\u5e38\u6570\u7565\u5927\u3002</li> </ul>"}, {"location": "campus-sources/ds-keynote/#_8", "title": "\u5df2\u77e5\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u5e8f\u5217\u548c\u540e\u5e8f\u5e8f\u5217\u53ef\u4ee5\u6062\u590d\u4e00\u68f5\u4e8c\u53c9\u6811\u5417\uff1f\u9700\u8981\u6ee1\u8db3\u4ec0\u4e48\u6761\u4ef6\u624d\u53ef\u4ee5\u5462\uff1f\u5982\u4f55\u7531\u7ed9\u5b9a\u7684\u6761\u4ef6\u6062\u590d\u4e8c\u53c9\u6811\uff08\u5305\u62ec\u6240\u6709\u53ef\u80fd\u7684\u5f62\u72b6\uff09\uff1f\uff08\u6807\u7ea2\uff09", "text": "<ul> <li>\u4e0d\u4e00\u5b9a\u53ef\u4ee5\u3002\u524d\u5e8f\u5e8f\u5217ULR\uff0c\u540e\u5e8f\u5e8f\u5217LRU\uff0c\u627e\u5230\u6839\u8282\u70b9\u4e4b\u540e\uff0c\u96be\u4ee5\u5212\u5206\u51fa\u5de6\u53f3\u5b50\u6811\u3002</li> <li>\u4f55\u65f6\u53ef\u4ee5\uff1f\u5373\u53ef\u4ee5\u5212\u5206\u51fa\u5de6\u53f3\u5b50\u6811\u65f6\uff0c\u5982\u679c\u6bcf\u4e2a\u8282\u70b9\u7684\u5de6\u53f3\u5b50\u6811\u5927\u5c0f\u90fd\u76f8\u7b49\uff0c\u90a3\u4e48\u6211\u4eec\u53ea\u9700\u8981\u627e\u5b50\u5217\u7684\u4e2d\u70b9\uff0c\u5c31\u53ef\u4ee5\u5206\u5f00\u4e86\uff0c\u6b64\u65f6\u5bf9\u5e94\u7684\u662f\u6ee1\u4e8c\u53c9\u6811\u3002</li> <li>\u5982\u4f55\u6062\u590d\uff1f\u904d\u5386\u6240\u6709\u53ef\u80fd\u7684\u5de6\u53f3\u5b50\u6811\u5206\u754c\u70b9\uff0c\u9012\u5f52\u68c0\u67e5\u5de6\u53f3\u5b50\u6811\u662f\u5426\u5408\u6cd5\u3002\u5177\u4f53\u800c\u8a00\uff1a\u4ece\u7b2c\u4e00\u4e2a\u7ed3\u70b9\u5230\u5012\u6570\u7b2c\u4e8c\u4e2a\u7ed3\u70b9\uff0c\u904d\u5386\u4e0b\u6807 \\(i\\) \uff0c\u5047\u5b9a\u5176\u662f\u524d\u5e8f\u5e8f\u5217\u91cc\u9762\u6839\u8282\u70b9\u5de6\u5b50\u6811\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5728\u540e\u5e8f\u5e8f\u5217\u91cc\u9762\u627e\u5230\u5b83\uff0c\u5c31\u5206\u51fa\u6765\u5de6\u53f3\u5b50\u6811\uff0c\u5bf9\u8fd9\u4e24\u4e2a\u5b50\u6811\u9012\u5f52\u5730\u8fdb\u884c\u8fd9\u4e00\u64cd\u4f5c\uff0c\u5982\u679c\u6700\u7ec8\u5f97\u5230\u4e86\u5408\u6cd5\u7684\u5e8f\u5217\uff0c\u6210\u529f\u6062\u590d\u4e86\u4e00\u79cd\u53ef\u80fd\u7684\u4e8c\u53c9\u6811\u3002</li> </ul>"}, {"location": "campus-sources/ds-keynote/#-", "title": "\u6811\u4e0e\u4e8c\u53c9\u6811\u6709\u54ea\u4e9b\u8868\u793a\u65b9\u6cd5\uff08\u5982\u51f9\u5165\u8868\u793a\u3001\u6587\u6c0f\u56fe\u3001\u5e7f\u4e49\u8868\u7b49\uff09\uff1f\u6811\u672c\u8eab\u8fd8\u6709\u5b69\u5b50-\u5144\u5f1f\u94fe\u8868\u793a\u6cd5\u3002\u5982\u4f55\u5728\u7279\u5b9a\u8868\u793a\u6cd5\u4e0b\u76f4\u63a5\u6c42\u53d6\u6811\u6216\u4e8c\u53c9\u6811\u7684\u67d0\u4e9b\u7279\u6027\uff08\u5982\u6811\u9ad8\u7b49\uff09\uff1f\uff08\u6807\u7ea2\uff09", "text": "<ul> <li>\u8868\u793a\u65b9\u6cd5\uff1a<ul> <li>\u51f9\u5165\u8868\u793a\uff1a\u6bd4\u5982 Linux \u91cc\u9762 <code>tree</code> \u547d\u4ee4\u7684\u8f93\u51fa\uff1a <pre><code>.\n\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 assets\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ds-t6.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 js\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 init-highlight.js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 benchmark-on-stl.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 codehilite.css\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ds-keynote.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ds-t6.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ds-write-up.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 index.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 stl-wheels.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 template-on-numeric-ring.md\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test.md\n\u251c\u2500\u2500 mkdocs.yml\n\u2514\u2500\u2500 themes\n    \u2514\u2500\u2500 js\n        \u251c\u2500\u2500 katex.js\n        \u2514\u2500\u2500 mathjax.js\n</code></pre></li> <li>\u6587\u6c0f\u56fe\uff1a\u5229\u7528\u5706\u5708\u7684\u5305\u542b\u548c\u5e76\u5217\u8868\u793a\u6811\u5f62\u5c42\u7ea7\u3002</li> <li>\u5e7f\u4e49\u8868\uff1a\u5229\u7528\u62ec\u53f7\u7684\u5d4c\u5957\u8868\u793a\u5c42\u7ea7\u3002\u5982 A(B(C,D),E)</li> <li>\u7ebf\u8fde\u56fe\uff1a\u7528\u7ebf\u8fde\u63a5\u7ed3\u70b9\u4ee5\u76f4\u89c2\u8868\u793a\u6811\u5f62\u7ed3\u6784\u3002</li> <li>\u987a\u5e8f\u8868\u793a\uff1a\u5229\u7528 \\(2*i\\) \u548c \\(2*i+ 1\\) \u6765\u8868\u793a\u4e0b\u6807 \\(i\\) \u7ed3\u70b9\u7684\u5b50\u8282\u70b9\uff0c\u7528\u4e8e\u8868\u793a\u5b8c\u5168\u4e8c\u53c9\u6811\uff0c\u4f8b\u5982\u5806\u3002</li> <li>\u5b69\u5b50-\u5144\u5f1f\u94fe\u8868\u793a\uff1a\u5229\u7528\u5de6\u5b69\u5b50\u53f3\u5144\u5f1f\u65b9\u6cd5\u5c06\u68ee\u6797\u548c\u4e8c\u53c9\u6811\u4e92\u76f8\u8f6c\u5316\u3002</li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#dfsbfsdfsbfs", "title": "\u4ec0\u4e48\u662f\u6df1\u5ea6\u4f18\u5148\u904d\u5386DFS\uff1f\u4ec0\u4e48\u662f\u5e7f\u5ea6\u4f18\u5148\u904d\u5386BFS\uff1f\u9488\u5bf9\u7279\u5b9a\u7684\u95ee\u9898\uff0c\u5982\u4f55\u9009\u62e9\u4f7f\u7528DFS\u8fd8\u662fBFS\uff1f", "text": "<ul> <li> <p>\u6df1\u5ea6\u4f18\u5148\u904d\u5386\u662f\u4e00\u79cd\u7528\u4e8e\u904d\u5386\u6216\u641c\u7d22\u6811\u6216\u56fe\u7684\u7b97\u6cd5\u3002\u5b83\u4ece\u6839\uff08\u6216\u4efb\u610f\u6307\u5b9a\u8282\u70b9\uff09\u5f00\u59cb\uff0c\u6cbf\u7740\u4e00\u6761\u8def\u5f84 \u5c3d\u53ef\u80fd\u6df1\u5730 \u63a2\u7d22\u6bcf\u4e2a\u5206\u652f\uff0c\u76f4\u5230\u5230\u8fbe\u53f6\u5b50\u8282\u70b9\u6216\u4e0d\u80fd\u518d\u6df1\u5165\u4e3a\u6b62\u3002\u7136\u540e\uff0c\u5b83\u56de\u6eaf\uff08\u64a4\u9500\uff09\u5230\u524d\u4e00\u4e2a\u672a\u5b8c\u5168\u63a2\u7d22\u7684\u8282\u70b9\uff0c\u5e76\u63a2\u7d22\u53e6\u4e00\u6761\u8def\u5f84\u3002</p> </li> <li> <p>\u5de5\u4f5c\u539f\u7406\uff08\u901a\u5e38\u4f7f\u7528 \u9012\u5f52 \u6216\u6808 \u5b9e\u73b0\uff09\uff1a</p> <ol> <li>\u8bbf\u95ee\u8d77\u59cb\u8282\u70b9\u3002</li> <li>\u5c06\u8d77\u59cb\u8282\u70b9\u6807\u8bb0\u4e3a\u5df2\u8bbf\u95ee\u3002</li> <li>\u5bf9\u4e8e\u5f53\u524d\u8282\u70b9\uff0c\u9009\u62e9\u4e00\u4e2a\u672a\u8bbf\u95ee\u7684\u90bb\u5c45\u8282\u70b9\u3002</li> <li>\u5982\u679c\u5b58\u5728\u672a\u8bbf\u95ee\u7684\u90bb\u5c45\u8282\u70b9\uff0c\u5219\u5bf9\u8be5\u90bb\u5c45\u8282\u70b9\u9012\u5f52\u8c03\u7528DFS\u3002</li> <li>\u5982\u679c\u6ca1\u6709\u672a\u8bbf\u95ee\u7684\u90bb\u5c45\u8282\u70b9\uff0c\u5219\u56de\u6eaf\u5230\u524d\u4e00\u4e2a\u8282\u70b9\u3002</li> <li>\u91cd\u590d\u6b64\u8fc7\u7a0b\uff0c\u76f4\u5230\u6240\u6709\u53ef\u8fbe\u8282\u70b9\u90fd\u88ab\u8bbf\u95ee\u3002</li> </ol> </li> <li> <p>\u7279\u70b9\uff1a</p> <ol> <li>\u6808\uff08Stack\uff09 \u7684\u6570\u636e\u7ed3\u6784\u7279\u6027\uff1a\u540e\u8fdb\u5148\u51fa\uff08LIFO\uff09\u3002</li> <li>\u975e\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\u3002</li> <li>\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a\u5bf9\u4e8e\u56fe\u6765\u8bf4\uff0c\u6700\u574f\u60c5\u51b5\u4e0b\u53ef\u80fd\u662f \\(O(V+E)\\)\uff0c\u5176\u4e2d \\(V\\) \u662f\u9876\u70b9\u6570\uff0c\\(E\\) \u662f\u8fb9\u6570\uff1b\u5bf9\u4e8e\u6811\u6765\u8bf4\uff0c\u53d6\u51b3\u4e8e\u6811\u7684\u6df1\u5ea6\u3002</li> <li>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a\\(O(V+E)\\)\u3002</li> </ol> </li> <li> <p>\u5e7f\u5ea6\u4f18\u5148\u904d\u5386\u4e5f\u662f\u4e00\u79cd\u7528\u4e8e\u904d\u5386\u6216\u641c\u7d22\u6811\u6216\u56fe\u7684\u7b97\u6cd5\u3002\u5b83\u4ece\u6839\uff08\u6216\u4efb\u610f\u6307\u5b9a\u8282\u70b9\uff09\u5f00\u59cb\uff0c\u9996\u5148\u8bbf\u95ee\u5176\u6240\u6709\u76f4\u63a5\u90bb\u5c45\uff0c\u7136\u540e\u8bbf\u95ee\u8fd9\u4e9b\u90bb\u5c45\u7684\u6240\u6709\u672a\u8bbf\u95ee\u90bb\u5c45\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002\u5b83\u4ee5 \u201c\u5c42\u201d \u7684\u65b9\u5f0f\u5411\u5916\u6269\u5c55\u3002</p> </li> <li> <p>\u5de5\u4f5c\u539f\u7406\uff08\u901a\u5e38\u4f7f\u7528 \u961f\u5217 \u5b9e\u73b0\uff09\uff1a</p> <ol> <li>\u8bbf\u95ee\u8d77\u59cb\u8282\u70b9\u3002</li> <li>\u5c06\u8d77\u59cb\u8282\u70b9\u6807\u8bb0\u4e3a\u5df2\u8bbf\u95ee\uff0c\u5e76\u5c06\u5176\u6dfb\u52a0\u5230\u961f\u5217\u4e2d\u3002</li> <li>\u5f53\u961f\u5217\u4e0d\u4e3a\u7a7a\u65f6\uff0c\u6267\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a<ul> <li>\u4ece\u961f\u5217\u4e2d\u53d6\u51fa\uff08\u51fa\u961f\uff09\u4e00\u4e2a\u8282\u70b9\u3002</li> <li>\u8bbf\u95ee\u8be5\u8282\u70b9\u7684\u6240\u6709\u672a\u8bbf\u95ee\u7684\u90bb\u5c45\u8282\u70b9\u3002</li> <li>\u5c06\u8fd9\u4e9b\u672a\u8bbf\u95ee\u7684\u90bb\u5c45\u8282\u70b9\u6807\u8bb0\u4e3a\u5df2\u8bbf\u95ee\uff0c\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230\u961f\u5217\u4e2d\u3002</li> </ul> </li> <li>\u91cd\u590d\u6b64\u8fc7\u7a0b\uff0c\u76f4\u5230\u961f\u5217\u4e3a\u7a7a\u3002</li> </ol> </li> <li> <p>\u7279\u70b9\uff1a</p> </li> <li>\u961f\u5217\uff08Queue\uff09 \u7684\u6570\u636e\u7ed3\u6784\u7279\u6027\uff1a\u5148\u8fdb\u5148\u51fa\uff08FIFO\uff09\u3002</li> <li>\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\uff1a\u5728\u65e0\u6743\u56fe\u4e2d\uff0cBFS\u80fd\u591f\u627e\u5230\u4ece\u8d77\u59cb\u8282\u70b9\u5230\u6240\u6709\u5176\u4ed6\u53ef\u8fbe\u8282\u70b9\u7684\u6700\u77ed\u8def\u5f84\uff08\u6309\u8fb9\u6570\u8ba1\u7b97\uff09\u3002</li> <li>\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a\\(O(V+E)\\)\uff0c\u6700\u574f\u60c5\u51b5\u4e0b\u9700\u8981\u5b58\u50a8\u6240\u6709\u8282\u70b9\u548c\u8fb9\u3002</li> <li> <p>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a\\(O(V+E)\\)\u3002</p> </li> <li> <p>\u5982\u4f55\u9009\u62e9\u4f7f\u7528DFS\u8fd8\u662fBFS\uff1f</p> <ul> <li> <p>\u9009\u62e9DFS\u7684\u573a\u666f\uff1a</p> <ol> <li>\u67e5\u627e\u6240\u6709\u53ef\u80fd\u7684\u8def\u5f84/\u89e3\uff1a \u5f53\u4f60\u9700\u8981\u904d\u5386\u6240\u6709\u53ef\u80fd\u7684\u8def\u5f84\u6216\u627e\u5230\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684\u89e3\u65f6\uff0cDFS\u975e\u5e38\u9002\u5408\u3002\u4f8b\u5982\uff0c\u56de\u6eaf\u95ee\u9898\uff08\u5982N\u7687\u540e\u95ee\u9898\u3001\u7ec4\u5408\u603b\u548c\uff09\u901a\u5e38\u4f7f\u7528DFS\u3002</li> <li>\u5224\u65ad\u56fe\u4e2d\u662f\u5426\u5b58\u5728\u73af\uff1a DFS\u53ef\u4ee5\u6709\u6548\u5730\u68c0\u6d4b\u56fe\u4e2d\u7684\u73af\u3002\u5f53\u4f60\u5728DFS\u904d\u5386\u8fc7\u7a0b\u4e2d\u9047\u5230\u4e00\u4e2a\u5df2\u7ecf\u8bbf\u95ee\u8fc7\u4f46\u4ecd\u5728\u5f53\u524dDFS\u8def\u5f84\u4e0a\u7684\u8282\u70b9\u65f6\uff0c\u5c31\u8868\u793a\u5b58\u5728\u73af\u3002</li> <li>\u62d3\u6251\u6392\u5e8f\uff1a \u5bf9\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u62d3\u6251\u6392\u5e8f\uff0cDFS\u662f\u4e00\u4e2a\u5e38\u7528\u7684\u65b9\u6cd5\u3002</li> <li>\u8fde\u901a\u5206\u91cf\uff1a \u67e5\u627e\u56fe\u4e2d\u7684\u8fde\u901a\u5206\u91cf\u6216\u5f3a\u8fde\u901a\u5206\u91cf\u3002</li> <li>\u5185\u5b58\u9650\u5236\uff1a \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u56fe\u975e\u5e38\u5bbd\u4f46\u6df1\u5ea6\u6709\u9650\uff0cDFS\u53ef\u80fd\u4f1a\u6bd4BFS\u5360\u7528\u66f4\u5c11\u7684\u5185\u5b58\uff0c\u56e0\u4e3a\u5b83\u53ea\u9700\u8981\u5b58\u50a8\u5f53\u524d\u8def\u5f84\u4e0a\u7684\u8282\u70b9\u3002</li> <li>\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7684\u7279\u6027\uff1a \u5982\u679c\u4f60\u60f3\u8981\u627e\u5230\u4e00\u4e2a\u201c\u6df1\u5c42\u201d\u7684\u89e3\uff0c\u6216\u8005\u5bf9\u8def\u5f84\u7684\u6df1\u5ea6\u66f4\u611f\u5174\u8da3\uff0cDFS\u662f\u81ea\u7136\u7684\u9009\u62e9\u3002</li> </ol> </li> <li> <p>\u9009\u62e9BFS\u7684\u573a\u666f\uff1a</p> <ol> <li>\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff08\u65e0\u6743\u56fe\uff09\uff1a \u5f53\u4f60\u9700\u8981\u627e\u5230\u4ece\u4e00\u4e2a\u8282\u70b9\u5230\u53e6\u4e00\u4e2a\u8282\u70b9\u7684\u6700\u77ed\u8def\u5f84\uff08\u4ee5\u8fb9\u6570\u8861\u91cf\uff09\u65f6\uff0cBFS\u662f\u9996\u9009\u3002\u4f8b\u5982\uff0c\u5728\u4e00\u4e2a\u8ff7\u5bab\u4e2d\u627e\u5230\u6700\u77ed\u7684\u9003\u751f\u8def\u5f84\u3002</li> <li>\u5c42\u5e8f\u904d\u5386\uff1a \u5982\u679c\u4f60\u9700\u8981\u6309\u5c42\u7ea7\u987a\u5e8f\u8bbf\u95ee\u8282\u70b9\uff0c\u4f8b\u5982\u5728\u6811\u4e2d\u6309\u5c42\u7ea7\u6253\u5370\u8282\u70b9\u3002</li> <li>\u67e5\u627e\u4efb\u610f\u4e00\u4e2a\u89e3\uff0c\u4e14\u89e3\u53ef\u80fd\u4f4d\u4e8e\u56fe\u7684\u6d45\u5c42\uff1a \u5982\u679c\u4f60\u77e5\u9053\u67d0\u4e2a\u95ee\u9898\u7684\u89e3\u53ef\u80fd\u5728\u79bb\u8d77\u59cb\u8282\u70b9\u4e0d\u8fdc\u7684\u5c42\u7ea7\u4e0a\uff0cBFS\u53ef\u80fd\u4f1a\u66f4\u5feb\u5730\u627e\u5230\u5b83\u3002</li> </ol> </li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_9", "title": "\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u3001\u53f6\u5b50\u7ed3\u70b9\u6570\u548c\u9ad8\u5ea6\u4e4b\u95f4\u6ee1\u8db3\u600e\u6837\u7684\u5173\u7cfb\uff1f\u5982\u4f55\u7ed9\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u70b9\u7f16\u53f7\uff1f", "text": "<ul> <li> <p>\u5b8c\u5168\u4e8c\u53c9\u6811\u53ef\u4ee5\u770b\u4f5c\u662f\u6700\u540e\u4e00\u5c42\u6240\u6709\u8282\u70b9\u96c6\u4e2d\u5728\u5de6\u4fa7\uff0c\u5176\u4ed6\u5c42\u6784\u6210\u6ee1\u4e8c\u53c9\u6811\u7684\u4e00\u9897\u4e8c\u53c9\u6811\u3002</p> </li> <li> <p>\u5df2\u77e5\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\uff0c\u53ef\u4ee5\u53cd\u63a8\u9ad8\u5ea6\uff1a\u9ad8\u5ea6 \\(h\\) \u7684\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u4ecb\u4e8e \\(2^{h - 1}\\) \u548c \\(2 ^{h} - 1\\) \u4e4b\u95f4\u3002\u53cd\u4e4b\u4e0d\u7136\u3002</p> </li> <li> <p>\u5df2\u77e5\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\uff0c\u53ef\u4ee5\u53cd\u63a8\u5176\u53f6\u5b50\u7ed3\u70b9\u6570\u76ee\uff1a\u5df2\u77e5\u7ed3\u70b9\u6570 \\(n\\)\uff0c\u9996\u5148\u53cd\u63a8\u5176\u9ad8\u5ea6 \\(h = \\lfloor \\log_2 n\\rfloor + 1\\)\uff0c\u7136\u540e\u53ef\u4ee5\u7b97\u51fa\u4ece\u7b2c\u4e00\u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u5f97\u5230\u7684\u6ee1\u4e8c\u53c9\u6811\u7684\u8282\u70b9\u6570 \\(n' = 2^{h - 1} - 1\\)\uff0c\u4e8e\u662f\u5f97\u5230\u5e95\u5c42\u8282\u70b9\u6570\u4e3a \\(n_{\\text{bottom}} = n - n'\\)\u3002\u8fd9\u4e9b\u8282\u70b9\u90fd\u662f\u53f6\u5b50\u8282\u70b9\u3002\u7136\u540e\u8003\u8651\u5012\u6570\u7b2c\u4e8c\u5c42\u7684\u7ed3\u70b9\uff0c\u91cc\u9762\u6709\u4e9b\u7ed3\u70b9\u662f\u5e95\u5c42\u7ed3\u70b9\u7684\u7236\u8282\u70b9\uff0c\u5c06\u5012\u6570\u7b2c\u4e8c\u5c42\u7684\u7ed3\u70b9\u6263\u9664\u8fd9\u4e00\u90e8\u5206\uff0c\u518d\u52a0\u4e0a\u5e95\u5c42\u8282\u70b9\u5373\u53ef\u5f97\u5230\u53f6\u5b50\u8282\u70b9\u6570\uff1a\\(n_{\\text{leaf}} = 2^{h - 1} - \\lfloor\\dfrac{n_{\\text{bottom}} + 1}{2}\\rfloor + n_{\\text{bottom}}\\)</p> </li> <li> <p>\u7f16\u53f7\u95ee\u9898\uff0c\u53ef\u4ee5\u53c2\u8003\u6570\u7ec4\u4e0a\u5efa\u5806\u7684\u65b9\u6cd5\uff0c\u5373\u5bf9\u4e8e\u4e0b\u6807 \\(i\\) \u7684\u7ed3\u70b9\uff0c\u5176\u5b50\u8282\u70b9\u7684\u4e0b\u6807\u4e3a \\(2 \\times i + 1\\) \u548c \\(2\\times i + 2\\)\u3002</p> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_10", "title": "\u4ec0\u4e48\u662f\u4e8c\u53c9\u6392\u5e8f\u6811\uff1f\u5f62\u6210\u4e8c\u53c9\u6392\u5e8f\u6811\u7684\u5145\u5206\u5fc5\u8981\u6761\u4ef6\u662f\u4ec0\u4e48\uff1f\u5982\u4f55\u6784\u9020\u4e00\u68f5\u4e8c\u53c9\u6392\u5e8f\u6811\uff1f\uff08\u6807\u7ea2\uff09", "text": "<ul> <li> <p>BST \u662f\u6ee1\u8db3\u7ed3\u70b9\u504f\u5e8f\u5173\u7cfb\u7684\u4e8c\u53c9\u6811\u3002\u5373\u4e00\u9897\u4e8c\u53c9\u6811\uff0c\u5b83\u7684\u6240\u6709\u7ed3\u70b9\u90fd\u6ee1\u8db3\u5de6\u513f\u5b50\u5c0f\u4e8e\u53f3\u513f\u5b50\uff0c\u90a3\u4e48\u5c31\u662f\u4e00\u9897 BST\u3002</p> </li> <li> <p>\u6784\u9020\u65b9\u6cd5\uff1a\u5931\u8d25\u67e5\u627e\u6cd5\uff0c\u5373\u9996\u5148\u5bf9\u65b0\u7684\u8282\u70b9\u503c\u8fdb\u884c\u67e5\u627e\uff0c\u627e\u5230\u67e5\u627e\u5931\u8d25\u65f6\u7684\u7a7a\u6307\u9488\uff0c\u518d\u76f4\u63a5\u5728\u8fd9\u4e2a\u7a7a\u6307\u9488\u4f4d\u7f6e\u63d2\u5165\u6570\u636e\u3002</p> </li> <li> <p>\u5982\u4f55\u8ba1\u7b97\u7ed9\u5b9a BST \u7684\u5e73\u5747\u67e5\u627e\u6b21\u6570\uff1f\u5bf9\u4e8e\u6210\u529f\u800c\u8a00\uff0c\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7ed3\u70b9\u5230\u6839\u8282\u70b9\u8def\u5f84\u957f\u5ea6\u7684\u5747\u503c\uff1b\u5bf9\u4e8e\u5931\u8d25\u800c\u8a00\uff0c\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u7a7a\u6307\u9488\u5230\u6839\u8282\u70b9\u8def\u5f84\u957f\u5ea6\u7684\u5747\u503c\u3002</p> </li> <li> <p>\u8fd9\u79cd\u63d2\u5165\u65b9\u6cd5\u6709\u53ef\u80fd\u5bfc\u81f4 BST \u9000\u5316\u6210\u94fe\u8868\uff0c\u6216\u8005\u8bf4\u5de6\u53f3\u5b50\u6811\u9ad8\u5ea6\u4e25\u91cd\u4e0d\u5bf9\u79f0\uff0c\u56e0\u6b64\u5f15\u5165\u4e86\u5404\u79cd\u64cd\u4f5c\u6765\u8c03\u6574\u6811\u9ad8\uff0c\u4f7f\u5176\u7ef4\u6301\u5728 \\(\\log n\\) \u7684\u6570\u91cf\u7ea7\u3002</p> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#b-b-bb-b", "title": "\u4ec0\u4e48\u662fB-\u6811\uff1f\u600e\u6837\u6784\u9020B-\u6811\uff1f\u4ec0\u4e48\u662fB+\u6811\uff1fB-\u6811\u4e0eB+\u6811\u7684\u5dee\u522b\u5728\u54ea\u91cc\uff1f", "text": "<ul> <li> <p>B-\u6811\u662f\u6ee1\u8db3\u4ee5\u4e0b\u7279\u70b9\u7684\u6811\uff1a</p> <ul> <li>\u591a\u8def\u5206\u652f\uff1a\u6bcf\u4e2a\u8282\u70b9\u53ef\u4ee5\u6709\u591a\u4e2a\u5b50\u8282\u70b9\uff08\u901a\u5e38\u4e3am\u4e2a\uff0cm\u79f0\u4e3aB\u6811\u7684\u9636\uff09\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4e8c\u53c9\u6811\u7684\u4e24\u4e2a\u5b50\u8282\u70b9\u3002\u8fd9\u4f7f\u5f97B\u6811\u7684\u9ad8\u5ea6\u8fdc\u4f4e\u4e8e\u4e8c\u53c9\u6811\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u78c1\u76d8\u8bfb\u5199\u6b21\u6570\u3002</li> <li>\u5e73\u8861\u6027\uff1a\u6240\u6709\u7684\u53f6\u5b50\u8282\u70b9\u90fd\u4f4d\u4e8e\u540c\u4e00\u5c42\uff0c\u4ece\u6839\u8282\u70b9\u5230\u4efb\u4f55\u53f6\u5b50\u8282\u70b9\u7684\u8def\u5f84\u957f\u5ea6\u90fd\u76f8\u540c\u3002\u8fd9\u4fdd\u8bc1\u4e86\u67e5\u627e\u3001\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u59cb\u7ec8\u4e3a\\(O(\\log_m N)\\)\uff0c\u5176\u4e2d\\(N\\)\u662f\u6570\u636e\u603b\u91cf\uff0c\\(m\\)\u662f\u9636\u6570\u3002</li> <li>\u8282\u70b9\u7ed3\u6784\uff1a\u4e00\u4e2aB\u6811\u8282\u70b9\u901a\u5e38\u5305\u542b\\(k-1\\)\u4e2a\u5173\u952e\u5b57\u548c\\(k\\)\u4e2a\u5b50\u6307\u9488\uff08\u5176\u4e2d\\(k \\le m\\)\uff09\u3002\u8fd9\u4e9b\u5173\u952e\u5b57\u5c06\u8282\u70b9\u5185\u7684\u952e\u503c\u7a7a\u95f4\u5212\u5206\u4e3a\\(k\\)\u4e2a\u5b50\u533a\u95f4\uff0c\u6bcf\u4e2a\u5b50\u6307\u9488\u6307\u5411\u5bf9\u5e94\u5b50\u533a\u95f4\u7684\u6570\u636e\u6216\u5b50\u6811\u3002</li> <li>\u5173\u952e\u5b57\u6709\u5e8f\uff1a\u8282\u70b9\u5185\u7684\u5173\u952e\u5b57\u662f\u6309\u5347\u5e8f\u6392\u5217\u7684\u3002</li> </ul> </li> <li> <p>\u4e00\u4e2am\u9636B-\u6811\u7684\u5c5e\u6027\u901a\u5e38\u5b9a\u4e49\u4e3a</p> <ol> <li>\u6bcf\u4e2a\u8282\u70b9\u6700\u591a\u6709m\u4e2a\u5b50\u8282\u70b9\u3002</li> <li>\u6bcf\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\uff08\u9664\u6839\u8282\u70b9\uff09\u6700\u5c11\u6709\\(\\lceil m/2 \\rceil\\)\u4e2a\u5b50\u8282\u70b9\u3002</li> <li>\u5982\u679c\u6839\u8282\u70b9\u4e0d\u662f\u53f6\u5b50\u8282\u70b9\uff0c\u90a3\u4e48\u5b83\u81f3\u5c11\u6709\u4e24\u4e2a\u5b50\u8282\u70b9\u3002</li> <li>\u6709\\(k\\)\u4e2a\u5b50\u8282\u70b9\u7684\u975e\u53f6\u5b50\u8282\u70b9\u62e5\u6709\\(k-1\\)\u4e2a\u5173\u952e\u5b57\u3002</li> <li>\u6240\u6709\u7684\u53f6\u5b50\u8282\u70b9\u90fd\u5728\u540c\u4e00\u5c42\u3002</li> </ol> </li> <li> <p>B-\u6811\u7684\u63d2\u5165\u64cd\u4f5c</p> <ol> <li>\u67e5\u627e\u63d2\u5165\u4f4d\u7f6e\uff1a\u9996\u5148\uff0c\u4ece\u6839\u8282\u70b9\u5f00\u59cb\uff0c\u6839\u636e\u8981\u63d2\u5165\u7684\u5173\u952e\u5b57\uff0c\u627e\u5230\u5b83\u5e94\u8be5\u63d2\u5165\u7684\u53f6\u5b50\u8282\u70b9\u3002</li> <li>\u63d2\u5165\u5173\u952e\u5b57\uff1a\u5c06\u5173\u952e\u5b57\u63d2\u5165\u5230\u8be5\u53f6\u5b50\u8282\u70b9\u4e2d\uff0c\u5e76\u4fdd\u6301\u8282\u70b9\u5185\u5173\u952e\u5b57\u7684\u6709\u5e8f\u6027\u3002</li> <li>\u5904\u7406\u8282\u70b9\u4e0a\u6ea2\uff08\u5206\u88c2\uff09\uff1a\u5982\u679c\u63d2\u5165\u540e\uff0c\u5f53\u524d\u8282\u70b9\u7684\u5173\u952e\u5b57\u6570\u91cf\u8d85\u8fc7\u4e86\u5141\u8bb8\u7684\u6700\u5927\u503c\uff08m-1\u4e2a\uff09\uff0c\u5219\u53d1\u751f\u4e0a\u6ea2\u3002<ul> <li>\u5206\u88c2\uff1a\u5c06\u8be5\u8282\u70b9\u5206\u88c2\u4e3a\u4e24\u4e2a\u65b0\u8282\u70b9\u3002\u901a\u5e38\u662f\u5c06\u4e2d\u95f4\u7684\u5173\u952e\u5b57\u63d0\u5347\u5230\u7236\u8282\u70b9\u4e2d\uff0c\u5e76\u5c06\u4e24\u4fa7\u7684\u5173\u952e\u5b57\u5206\u522b\u653e\u5165\u4e24\u4e2a\u65b0\u8282\u70b9\u3002</li> <li>\u5411\u4e0a\u9012\u5f52\uff1a\u5982\u679c\u7236\u8282\u70b9\u56e0\u4e3a\u63d0\u5347\u7684\u5173\u952e\u5b57\u4e5f\u53d1\u751f\u4e0a\u6ea2\uff0c\u5219\u91cd\u590d\u5206\u88c2\u64cd\u4f5c\uff0c\u76f4\u5230\u6839\u8282\u70b9\u6216\u8005\u627e\u5230\u4e00\u4e2a\u6ca1\u6709\u4e0a\u6ea2\u7684\u8282\u70b9\u3002\u5982\u679c\u6839\u8282\u70b9\u4e0a\u6ea2\uff0c\u5219\u6811\u7684\u9ad8\u5ea6\u589e\u52a0\u4e00\u5c42\u3002</li> </ul> </li> </ol> </li> <li> <p>B-\u6811\u7684\u5220\u9664\u64cd\u4f5c\uff1a</p> <ul> <li>\u53d6\u51b3\u4e8e\u5220\u9664\u540e\u662f\u5426\u5bfc\u81f4\u8282\u70b9\u5173\u952e\u5b57\u6570\u91cf\u4f4e\u4e8e\u6700\u5c0f\u503c\uff0c\u5373\u4e0b\u6ea2\u3002</li> <li>\u5982\u679c\u4e0d\u51fa\u73b0\u4e0b\u6ea2\uff0c\u5219\u76f4\u63a5\u5220\u9664\u3002</li> <li>\u5982\u679c\u51fa\u73b0\u4e0b\u6ea2\uff0c\u901a\u5e38\u901a\u8fc7\u5408\u5e76\u6216\u501f\u7528\u5144\u5f1f\u8282\u70b9\u7684\u5173\u952e\u5b57\u6765\u89e3\u51b3\u3002</li> <li>\u5408\u5e76\uff1a\u5982\u679c\u4e00\u4e2a\u8282\u70b9\u4e0b\u6ea2\uff0c\u5e76\u4e14\u5176\u5144\u5f1f\u8282\u70b9\u4e5f\u6ca1\u6709\u591a\u4f59\u7684\u5173\u952e\u5b57\u53ef\u4ee5\u501f\u7528\uff0c\u90a3\u4e48\u5b83\u4f1a\u4e0e\u5144\u5f1f\u8282\u70b9\u5408\u5e76\uff0c\u5e76\u5c06\u7236\u8282\u70b9\u4e2d\u5206\u9694\u5b83\u4eec\u7684\u5173\u952e\u5b57\u4e0b\u79fb\u3002</li> <li>\u501f\u7528\uff1a\u5982\u679c\u4e00\u4e2a\u8282\u70b9\u4e0b\u6ea2\uff0c\u4f46\u5176\u5144\u5f1f\u8282\u70b9\u6709\u591a\u4f59\u7684\u5173\u952e\u5b57\uff0c\u5219\u53ef\u4ee5\u4ece\u5144\u5f1f\u8282\u70b9\u501f\u7528\u4e00\u4e2a\u5173\u952e\u5b57\uff0c\u5e76\u76f8\u5e94\u5730\u8c03\u6574\u7236\u8282\u70b9\u4e2d\u7684\u5173\u952e\u5b57\u3002</li> </ul> </li> <li> <p>B+\u6811\uff1a\u662fB-\u6811\u7684\u4e00\u79cd\u53d8\u4f53\uff0c\u901a\u5e38\u5728\u6570\u636e\u5e93\u548c\u6587\u4ef6\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u3002\u5b83\u5728B-\u6811\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u4e00\u4e9b\u4f18\u5316\uff0c\u4f7f\u5176\u66f4\u9002\u5408\u8303\u56f4\u67e5\u8be2\u548c\u78c1\u76d8I/O\u3002</p> </li> <li> <p>B+\u6811\u7684\u4e3b\u8981\u7279\u70b9\u662f\uff1a</p> <ul> <li>\u6240\u6709\u5173\u952e\u5b57\u90fd\u51fa\u73b0\u5728\u53f6\u5b50\u8282\u70b9\uff1a\u975e\u53f6\u5b50\u8282\u70b9\u53ea\u5b58\u50a8\u7d22\u5f15\u4fe1\u606f\uff08\u5173\u952e\u5b57\uff09\uff0c\u4e0d\u5b58\u50a8\u5b9e\u9645\u7684\u6570\u636e\u8bb0\u5f55\u3002\u6240\u6709\u7684\u5b9e\u9645\u6570\u636e\u8bb0\u5f55\u90fd\u5b58\u50a8\u5728\u53f6\u5b50\u8282\u70b9\u4e2d\u3002</li> <li>\u53f6\u5b50\u8282\u70b9\u5f62\u6210\u6709\u5e8f\u94fe\u8868\uff1a\u6240\u6709\u7684\u53f6\u5b50\u8282\u70b9\u5305\u542b\u5168\u90e8\u5173\u952e\u5b57\u4fe1\u606f\uff0c\u5e76\u4e14\u5b83\u4eec\u4e4b\u95f4\u901a\u8fc7\u6307\u9488\u8fde\u63a5\u6210\u4e00\u4e2a\u6709\u5e8f\u7684\u94fe\u8868\u3002\u8fd9\u4f7f\u5f97\u8303\u56f4\u67e5\u8be2\u975e\u5e38\u9ad8\u6548\uff0c\u53ea\u9700\u904d\u5386\u53f6\u5b50\u8282\u70b9\u94fe\u8868\u5373\u53ef\u3002</li> <li>\u975e\u53f6\u5b50\u8282\u70b9\u53ea\u4f5c\u4e3a\u7d22\u5f15\uff1a\u975e\u53f6\u5b50\u8282\u70b9\uff08\u5185\u90e8\u8282\u70b9\uff09\u53ea\u5b58\u50a8\u5173\u952e\u5b57\u7684\u62f7\u8d1d\uff0c\u4f5c\u4e3a\u6307\u5411\u5b50\u8282\u70b9\u7684\u7d22\u5f15\uff0c\u4e0d\u5b58\u50a8\u5b9e\u9645\u7684\u6570\u636e\u6307\u9488\u3002</li> </ul> </li> <li> <p>B-\u6811\u4e0eB+\u6811\u7684\u5dee\u522b\uff1a</p> <ol> <li>\u53ea\u9700\u8981\u8bb0\u4f4f\u76f8\u6bd4\u4e8eB-\u6811\uff0cB+\u6811\u662f\u7d22\u5f15\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u4e14\u53f6\u5b50\u8282\u70b9\u4e4b\u95f4\u8fd8\u6709\u94fe\u8868\u76f8\u8fde\u5373\u53ef\u3002\u4e0b\u9762\u7684\u5bf9\u6bd4\u90fd\u662f\u56f4\u7ed5\u8fd9\u4e2a\u533a\u522b\u5c55\u5f00\u3002</li> <li> <p>\u6570\u636e\u5b58\u50a8\u65b9\u5f0f\uff1a</p> <ul> <li>B-\u6811\uff1a\u6bcf\u4e2a\u8282\u70b9\uff08\u5305\u62ec\u975e\u53f6\u5b50\u8282\u70b9\u548c\u53f6\u5b50\u8282\u70b9\uff09\u90fd\u53ef\u80fd\u5b58\u50a8\u5173\u952e\u5b57\u548c\u6307\u5411\u6570\u636e\u8bb0\u5f55\u7684\u6307\u9488\u3002\u8fd9\u610f\u5473\u7740\u6570\u636e\u53ef\u80fd\u5206\u6563\u5728\u6811\u7684\u5404\u4e2a\u5c42\u7ea7\u3002</li> <li>B+\u6811\uff1a\u6240\u6709\u7684\u6570\u636e\u8bb0\u5f55\u90fd\u5b58\u50a8\u5728\u53f6\u5b50\u8282\u70b9\u4e2d\u3002\u975e\u53f6\u5b50\u8282\u70b9\u53ea\u5b58\u50a8\u5173\u952e\u5b57\uff08\u7d22\u5f15\uff09\u548c\u6307\u5411\u5b50\u8282\u70b9\u7684\u6307\u9488\uff0c\u4e0d\u5b58\u50a8\u5b9e\u9645\u6570\u636e\u3002</li> </ul> </li> <li> <p>\u8303\u56f4\u67e5\u8be2\uff1a</p> <ul> <li>B-\u6811\uff1a\u8fdb\u884c\u8303\u56f4\u67e5\u8be2\u65f6\uff0c\u53ef\u80fd\u9700\u8981\u591a\u6b21\u4ece\u6839\u8282\u70b9\u5f00\u59cb\u904d\u5386\uff0c\u6548\u7387\u76f8\u5bf9\u8f83\u4f4e\u3002</li> <li>B+\u6811\uff1a\u7531\u4e8e\u53f6\u5b50\u8282\u70b9\u5f62\u6210\u4e86\u4e00\u4e2a\u6709\u5e8f\u94fe\u8868\uff0c\u8303\u56f4\u67e5\u8be2\u53ef\u4ee5\u76f4\u63a5\u5728\u53f6\u5b50\u8282\u70b9\u94fe\u8868\u4e0a\u8fdb\u884c\u904d\u5386\uff0c\u6548\u7387\u975e\u5e38\u9ad8\u3002\u8fd9\u662fB+\u6811\u5728\u6570\u636e\u5e93\u7d22\u5f15\u4e2d\u88ab\u5e7f\u6cdb\u5e94\u7528\u7684\u91cd\u8981\u539f\u56e0\u3002</li> </ul> </li> <li> <p>\u9002\u7528\u573a\u666f\uff1a</p> <ul> <li>B-\u6811\uff1a\u9002\u7528\u4e8e\u5185\u5b58\u4e2d\u7684\u6570\u636e\u7ed3\u6784\uff0c\u6216\u8005\u5bf9\u968f\u673a\u67e5\u627e\u6027\u80fd\u8981\u6c42\u8f83\u9ad8\uff0c\u4e14\u5bf9\u8303\u56f4\u67e5\u8be2\u6ca1\u6709\u7279\u522b\u8981\u6c42\u7684\u573a\u666f\u3002</li> <li>B+\u6811\uff1a\u66f4\u9002\u5408\u5916\u90e8\u5b58\u50a8\uff08\u5982\u78c1\u76d8\uff09\u4e2d\u7684\u6570\u636e\u7ed3\u6784\uff0c\u5c24\u5176\u5728\u6570\u636e\u5e93\u548c\u6587\u4ef6\u7cfb\u7edf\u4e2d\u4f5c\u4e3a\u7d22\u5f15\u7ed3\u6784\u3002\u5b83\u4f18\u5316\u4e86\u78c1\u76d8I/O\u548c\u8303\u56f4\u67e5\u8be2\u3002</li> </ul> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_11", "title": "\u4ec0\u4e48\u662f\u54c8\u592b\u66fc\u7f16\u7801\uff1f\u54c8\u592b\u66fc\u7f16\u7801\u662f\u5982\u4f55\u5f62\u6210\u7684\uff1f\u54c8\u592b\u66fc\u7f16\u7801\u6709\u54ea\u4e9b\u6027\u8d28\uff1f\uff08\u6807\u7ea2\uff09", "text": "<ul> <li> <p>Huffman \u7f16\u7801\u662f\u57fa\u4e8e\u54c8\u592b\u66fc\u6811\u7684\u7f16\u7801\u65b9\u5f0f\uff0c\u5b83\u65e2\u662f\u4e00\u4e2a\u524d\u7f00\u7f16\u7801\uff08\u5373\u4e0d\u4f1a\u6709\u4e00\u4e2a\u7f16\u7801\u662f\u53e6\u5916\u4e00\u4e2a\u7f16\u7801\u7684\u524d\u7f00\uff09\uff0c\u4e5f\u662f\u4fe1\u606f\u5bc6\u5ea6\u6700\u9ad8\u7684\u7f16\u7801\u3002\u4e0b\u9762\u8bb2\u54c8\u592b\u66fc\u6811\u3002</p> </li> <li> <p>\u54c8\u592b\u66fc\u6811\u662f\u53f6\u5b50\u8282\u70b9\u5177\u6709\u6700\u77ed\u5e26\u6743\u8def\u5f84\u957f\u5ea6 (WPL) \u7684\u6811\u3002\u6784\u9020\u65b9\u5f0f\u4e3a\uff1a\u9996\u5148\u5c06\u6240\u6709\u6570\u636e\u7684\u9891\u6570\u4ece\u4f4e\u5230\u9ad8\u6392\u597d\uff0c\u7136\u540e\u53d6\u51fa\u6700\u524d\u9762\u7684\u4e24\u4e2a\u6570\u636e\uff0c\u5c06\u9891\u6570\u76f8\u52a0\uff0c\u5f97\u5230\u8fd9\u4e24\u4e2a\u7ed3\u70b9\u7684\u6839\u8282\u70b9\uff0c\u7136\u540e\u628a\u8fd9\u4e2a\u548c\u653e\u5165\u6709\u5e8f\u6570\u5217\u4e2d\uff0c\u7ef4\u6301\u6570\u5217\u4f4e\u5230\u9ad8\u7684\u6709\u5e8f\u6027\uff0c\u7136\u540e\u4e0d\u65ad\u53d6\u51fa\u6700\u524d\u9762\u4e24\u4e2a\u6570\u636e\uff0c\u76f4\u5230\u5e8f\u5217\u4e3a\u7a7a\u3002</p> </li> <li> <p>\u6784\u9020\u597d\u54c8\u592b\u66fc\u6811\u4e4b\u540e\uff0c\u6240\u6709\u53f6\u5b50\u8282\u70b9\u90fd\u662f\u539f\u6765\u7684\u6570\u636e\u8282\u70b9\u3002\u6211\u4eec\u4e3a\u6bcf\u4e00\u4e2a\u53f6\u5b50\u6307\u6d3e\u4e00\u4e2a\u7f16\u7801\uff0c\u6307\u6d3e\u89c4\u5219\u4e3a\uff1a\u4ece\u6839\u7ed3\u70b9\u51fa\u53d1\uff0c\u5411\u5de6\u8d70\uff0c\u5c31\u5f80\u540e\u9762\u6dfb\u4e0a\u4e00\u4e2a<code>0</code>\uff0c\u5411\u53f3\u8d70\uff0c\u5c31\u6dfb\u4e0a\u4e00\u4e2a<code>1</code>\uff0c\u6307\u6d3e\u4e00\u4e2a</p> </li> <li> <p>\u4e3a\u4ec0\u4e48 Huffman \u7f16\u7801\u662f\u524d\u7f00\u7f16\u7801\uff1f\u56e0\u4e3a\u6240\u6709\u7f16\u7801\u7684\u8282\u70b9\u90fd\u662f\u53f6\u5b50\u8282\u70b9\u3002</p> </li> <li> <p>\u4e3a\u4ec0\u4e48\u4fe1\u606f\u5bc6\u5ea6\u9ad8\uff1f\u56e0\u4e3a WPL \u6700\u77ed\u3002\u6570\u636e\u5728\u67d0\u4e2a\u7f16\u7801\u4e0b\u6240\u5360\u7684\u7a7a\u95f4 = \u7f16\u7801\u957f\u5ea6 * \u9891\u6570 = \u53f6\u5b50\u8282\u70b9\u7684 WPL \u4e4b\u548c\uff0c\u800c Huffman \u6811\u6070\u597d\u662f\u8ba9\u8fd9\u4e2a\u4e1c\u897f\u6700\u5c0f\u7684\u6811\u3002</p> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_12", "title": "\u4ec0\u4e48\u662f\u56fe\u7684\u90bb\u63a5\u8868\u3001\u9006\u90bb\u63a5\u8868\u3001\u5341\u5b57\u94fe\u8868\u3001\u90bb\u63a5\u8868\u591a\u91cd\u8868\uff1f", "text": "<ul> <li> <p>\u90bb\u63a5\u8868\uff1a\u56fe\u7684\u4e00\u79cd\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\uff0c\u5b83\u4e3a\u56fe\u4e2d\u7684\u6bcf\u4e2a\u9876\u70b9\u521b\u5efa\u4e00\u4e2a\u94fe\u8868\uff0c\u94fe\u8868\u4e2d\u5b58\u50a8\u4e0e\u8be5\u9876\u70b9\u76f8\u90bb\u7684\u6240\u6709\u9876\u70b9\u3002</p> </li> <li> <p>\u90bb\u63a5\u8868\u7684\u7ed3\u6784\uff1a</p> <ul> <li>\u9876\u70b9\u6570\u7ec4\uff1a \u4e00\u4e2a\u5305\u542b\u6240\u6709\u9876\u70b9\u7684\u6570\u7ec4\uff08\u6216\u94fe\u8868\uff09\uff0c\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u9876\u70b9\u3002</li> <li>\u8fb9\u94fe\u8868\uff1a \u5bf9\u4e8e\u6bcf\u4e2a\u9876\u70b9 \\(V_i\\)\uff0c\u6709\u4e00\u4e2a\u94fe\u8868\u5b58\u50a8\u6240\u6709\u4ece \\(V_i\\) \u51fa\u53d1\u7684\u8fb9\u3002\u94fe\u8868\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\u901a\u5e38\u5305\u542b\uff1a<ul> <li>\u90bb\u63a5\u9876\u70b9\u7d22\u5f15\uff1a \u8fb9\u7684\u53e6\u4e00\u7aef\u9876\u70b9\u7684\u7d22\u5f15\u3002</li> <li>\u6743\u503c\uff08\u53ef\u9009\uff09\uff1a \u5982\u679c\u662f\u5e26\u6743\u56fe\uff0c\u5219\u5b58\u50a8\u8fb9\u7684\u6743\u503c\u3002</li> <li>\u4e0b\u4e00\u6761\u8fb9\u6307\u9488\uff1a \u6307\u5411\u8be5\u94fe\u8868\u4e2d\u4e0b\u4e00\u6761\u8fb9\u7684\u6307\u9488\u3002</li> </ul> </li> </ul> </li> <li> <p>\u9006\u90bb\u63a5\u8868\uff1a\u4e0e\u90bb\u63a5\u8868\u7c7b\u4f3c\uff0c\u4f46\u5b83\u5b58\u50a8\u7684\u662f\u6307\u5411\u5f53\u524d\u9876\u70b9\u7684\u8fb9\u3002\u5bf9\u4e8e\u6709\u5411\u56fe\u6765\u8bf4\uff0c\u90bb\u63a5\u8868\u5b58\u50a8\u7684\u662f\u51fa\u8fb9\uff0c\u9006\u90bb\u63a5\u8868\u5b58\u50a8\u7684\u662f\u5165\u8fb9\u3002\u5bf9\u4e8e\u65e0\u5411\u56fe\uff0c\u90bb\u63a5\u8868\u548c\u9006\u90bb\u63a5\u8868\u662f\u7b49\u4ef7\u7684\u3002\u5b83\u7684\u7ed3\u6784\u548c\u90bb\u63a5\u8868\u4e00\u81f4\u3002</p> </li> <li> <p>\u5341\u5b57\u94fe\u8868\uff1a\u9488\u5bf9\u6709\u5411\u56fe\u7684\u4e00\u79cd\u66f4\u590d\u6742\u7684\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\uff0c\u5b83\u7ed3\u5408\u4e86\u90bb\u63a5\u8868\u548c\u9006\u90bb\u63a5\u8868\u7684\u601d\u60f3\uff0c\u4f7f\u5f97\u67e5\u627e\u67d0\u4e2a\u9876\u70b9\u7684\u51fa\u8fb9\u548c\u5165\u8fb9\u90fd\u975e\u5e38\u65b9\u4fbf\u3002\u6bcf\u4e2a\u8fb9\u8282\u70b9\u90fd\u540c\u65f6\u5b58\u5728\u4e8e\u5176\u8d77\u59cb\u9876\u70b9\u7684\u51fa\u8fb9\u94fe\u8868\u548c\u7ec8\u6b62\u9876\u70b9\u7684\u5165\u8fb9\u94fe\u8868\u4e2d\u3002</p> </li> <li> <p>\u90bb\u63a5\u591a\u91cd\u8868\uff1a\u9488\u5bf9\u65e0\u5411\u56fe\u7684\u4e00\u79cd\u5b58\u50a8\u7ed3\u6784\uff0c\u5b83\u4e3b\u8981\u89e3\u51b3\u7684\u662f\u5728\u90bb\u63a5\u8868\u4e2d\uff0c\u6bcf\u6761\u65e0\u5411\u8fb9 \\((V_i, V_j)\\) \u4f1a\u5b58\u50a8\u4e24\u6b21\u7684\u95ee\u9898\uff08\u4e00\u6b21\u5728 \\(V_i\\) \u7684\u94fe\u8868\u4e2d\uff0c\u4e00\u6b21\u5728 \\(V_j\\) \u7684\u94fe\u8868\u4e2d\uff09\u3002\u90bb\u63a5\u591a\u91cd\u8868\u53ea\u5b58\u50a8\u6bcf\u6761\u8fb9\u4e00\u6b21\uff0c\u4f46\u901a\u8fc7\u6307\u9488\u5c06\u5176\u8fde\u63a5\u5230\u76f8\u5173\u8054\u7684\u4e24\u4e2a\u9876\u70b9\u7684\u94fe\u8868\u4e2d\u3002</p> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#rearfront", "title": "\u4ec0\u4e48\u662f\u5faa\u73af\u961f\u5217\uff1frear\u548cfront\u6307\u9488\u901a\u5e38\u4ee3\u8868\u4ec0\u4e48\uff1f\u5faa\u73af\u961f\u5217\u4e3a\u6ee1\u7684\u6761\u4ef6\u4e0e\u5faa\u73af\u961f\u5217\u4e3a\u7a7a\u7684\u6761\u4ef6\u4e4b\u95f4\u6709\u4ec0\u4e48\u5173\u7cfb\uff1f\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\u6761\u4ef6\u80fd\u63a8\u5bfc\u51fa\u53e6\u4e00\u4e2a\u6761\u4ef6\u5417\uff1f", "text": "<ul> <li> <p>\u5faa\u73af\u961f\u5217\uff08Circular Queue\uff09\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u961f\u5217\uff0c\u5b83\u5c06\u6570\u7ec4\u7684\u5934\u5c3e\u8fde\u63a5\u8d77\u6765\uff0c\u5f62\u6210\u4e00\u4e2a\u73af\u72b6\u7ed3\u6784\u3002\u8fd9\u6837\u505a\u7684\u597d\u5904\u662f\uff0c\u5f53\u961f\u5217\u7684\u672b\u5c3e\u8fbe\u5230\u6570\u7ec4\u7684\u672b\u7aef\u65f6\uff0c\u53ef\u4ee5\u4ece\u6570\u7ec4\u7684\u5f00\u5934\u7ee7\u7eed\u5b58\u50a8\u6570\u636e\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5229\u7528\u5b58\u50a8\u7a7a\u95f4\uff0c\u907f\u514d\u4e86\u666e\u901a\u961f\u5217\u5728\u961f\u5934\u5143\u7d20\u51fa\u961f\u540e\uff0c\u9700\u8981\u5c06\u6240\u6709\u5143\u7d20\u5411\u524d\u79fb\u52a8\u7684\u5f00\u9500\u3002</p> </li> <li> <p>\u6839\u636e\u6559\u6750\u7684\u8bf4\u6cd5\uff0c\u53ea\u6709\u5229\u7528\u6570\u7ec4\u505a\u5e95\u5c42\u5b58\u50a8\u7ed3\u6784\u7684\u961f\u5217\u624d\u80fd\u53eb\u5faa\u73af\u961f\u5217\u3002\u7528\u5404\u79cd\u94fe\u8868\u505a\u5e95\u5c42\u5b58\u50a8\u7ed3\u6784\u7684\u961f\u5217\u53eb\u505a\u94fe\u961f\u3002</p> </li> <li> <p>\u5728\u5faa\u73af\u961f\u5217\u4e2d\uff0c\u901a\u5e38\u4f7f\u7528\u4e24\u4e2a\u6307\u9488\uff1a</p> <ul> <li>front\uff08\u6216head\uff09\u6307\u9488\uff1a\u6307\u5411\u961f\u5217\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u524d\u4e00\u4e2a\u4f4d\u7f6e\uff08\u961f\u5934\uff09\u3002\u5f53\u5143\u7d20\u51fa\u961f\u65f6\uff0cfront\u6307\u9488\u5411\u524d\u79fb\u52a8\u3002</li> <li>rear\uff08\u6216tail\uff09\u6307\u9488\uff1a\u6307\u5411\u961f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff08\u961f\u5c3e\uff09\u3002\u5f53\u5143\u7d20\u5165\u961f\u65f6\uff0crear\u6307\u9488\u5411\u524d\u79fb\u52a8\u3002</li> </ul> </li> <li> <p>\u5faa\u73af\u961f\u5217\u4e3a\u6ee1\u7684\u6761\u4ef6\u4e0e\u5faa\u73af\u961f\u5217\u4e3a\u7a7a\u7684\u6761\u4ef6\u4e4b\u95f4\u6709\u4ec0\u4e48\u5173\u7cfb\uff1f</p> </li> <li> <p>\u5047\u8bbe\u5faa\u73af\u961f\u5217\u7684\u5e95\u5c42\u6570\u7ec4\u5927\u5c0f\u4e3a<code>Capacity</code>\u3002</p> <ul> <li>1. \u5faa\u73af\u961f\u5217\u4e3a\u7a7a\u7684\u6761\u4ef6\uff1a</li> <li>\u5f53 <code>front == rear</code> \u65f6\uff0c\u8868\u793a\u961f\u5217\u4e3a\u7a7a\u3002\u8fd9\u610f\u5473\u7740\u961f\u5934\u6307\u9488\u548c\u961f\u5c3e\u6307\u9488\u6307\u5411\u4e86\u540c\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u961f\u5217\u4e2d\u6ca1\u6709\u5143\u7d20\u3002 2. \u5faa\u73af\u961f\u5217\u4e3a\u6ee1\u7684\u6761\u4ef6\uff1a</li> <li> <p>\u4e3a\u4e86\u533a\u5206\u961f\u5217\u4e3a\u7a7a\u548c\u961f\u5217\u4e3a\u6ee1\u7684\u60c5\u51b5\uff0c\u901a\u5e38\u6709\u4ee5\u4e0b\u51e0\u79cd\u5904\u7406\u65b9\u5f0f\uff1a</p> <ul> <li> <p>\u65b9\u6cd5\u4e00\uff1a\u727a\u7272\u4e00\u4e2a\u5b58\u50a8\u5355\u5143</p> <ul> <li> <p>\u8fd9\u662f\u6700\u5e38\u7528\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u7ea6\u5b9a\uff0c\u5f53\u961f\u5217\u4e3a\u6ee1\u65f6\uff0c<code>front</code> \u6307\u5411\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\u662f <code>rear</code>\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5f53 <code>(rear + 1) % Capacity == front</code> \u65f6\uff0c\u8868\u793a\u961f\u5217\u5df2\u6ee1\u3002</p> </li> <li> <p>\u5728\u8fd9\u79cd\u7ea6\u5b9a\u4e0b\uff0c\u5b9e\u9645\u53ef\u5b58\u50a8\u7684\u5143\u7d20\u6570\u91cf\u662f <code>Capacity - 1</code>\uff0c\u6709\u4e00\u4e2a\u4f4d\u7f6e\u662f\u59cb\u7ec8\u7a7a\u7740\u7684\uff0c\u7528\u6765\u533a\u5206\u7a7a\u548c\u6ee1\u3002</p> </li> </ul> </li> <li> <p>\u65b9\u6cd5\u4e8c\uff1a\u4f7f\u7528\u4e00\u4e2a\u8ba1\u6570\u5668\uff08count\uff09</p> <ul> <li>\u9664\u4e86 <code>front</code> \u548c <code>rear</code> \u6307\u9488\u5916\uff0c\u518d\u7ef4\u62a4\u4e00\u4e2a <code>count</code> \u53d8\u91cf\u6765\u8bb0\u5f55\u961f\u5217\u4e2d\u5143\u7d20\u7684\u6570\u91cf\u3002</li> <li>\u5f53 <code>count == 0</code> \u65f6\uff0c\u961f\u5217\u4e3a\u7a7a\u3002</li> <li>\u5f53 <code>count == Capacity</code> \u65f6\uff0c\u961f\u5217\u4e3a\u6ee1\u3002</li> <li>\u8fd9\u79cd\u65b9\u6cd5\u7684\u597d\u5904\u662f\u4e0d\u727a\u7272\u5b58\u50a8\u7a7a\u95f4\uff0c\u4f46\u9700\u8981\u989d\u5916\u7ef4\u62a4\u4e00\u4e2a\u8ba1\u6570\u5668\u3002</li> </ul> </li> </ul> </li> <li> <p>\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\u6761\u4ef6\u80fd\u63a8\u5bfc\u51fa\u53e6\u4e00\u4e2a\u6761\u4ef6\u5417\uff1f</p> </li> <li>\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u5728\u4e0d\u5f15\u5165\u989d\u5916\u4fe1\u606f\uff08\u5982\u8ba1\u6570\u5668\u6216\u6807\u5fd7\u4f4d\uff09\u7684\u524d\u63d0\u4e0b\uff0c\u4ec5\u4ec5\u901a\u8fc7\u6539\u53d8\u4e00\u4e2a\u6761\u4ef6\uff08\u4f8b\u5982\uff0c\u6539\u53d8\u5224\u65ad\u6ee1\u7684\u6761\u4ef6\uff09\uff0c\u5f88\u96be\u76f4\u63a5\u63a8\u5bfc\u51fa\u53e6\u4e00\u4e2a\u6761\u4ef6\uff08\u7a7a\u7684\u6761\u4ef6\uff09\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u6307\u9488\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3002\u5982\u679c\u6211\u4eec\u7b80\u5355\u5730\u628a\u6ee1\u7684\u6761\u4ef6\u4e5f\u8bbe\u4e3a <code>front == rear</code>\uff0c\u90a3\u4e48\u5c31\u4f1a\u5bfc\u81f4\u6b67\u4e49\uff1a\u6211\u4eec\u65e0\u6cd5\u533a\u5206\u961f\u5217\u662f\u7a7a\u7684\u8fd8\u662f\u6ee1\u7684\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u901a\u5e38\u9700\u8981\u727a\u7272\u4e00\u4e2a\u5b58\u50a8\u5355\u5143\u6216\u8005\u5f15\u5165\u8ba1\u6570\u5668/\u6807\u5fd7\u4f4d\u7684\u539f\u56e0\u3002</li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_13", "title": "\u4ec0\u4e48\u662f\u5206\u5757\u67e5\u627e\uff1f\u5982\u4f55\u8fdb\u884c\u5206\u5757\u67e5\u627e\uff1f\u5982\u4f55\u8ba1\u7b97\u5206\u5757\u67e5\u627e\u7684\u6548\u7387\uff1f", "text": "<ul> <li> <p>\u5206\u5757\u67e5\u627e\u662f\u4e00\u79cd\u7ed3\u5408\u4e86\u987a\u5e8f\u67e5\u627e\u548c\u4e8c\u5206\u67e5\u627e\u4f18\u70b9\u7684\u67e5\u627e\u65b9\u6cd5\u3002\u5b83\u9002\u7528\u4e8e\u90a3\u4e9b\u6570\u636e\u91cf\u8f83\u5927\uff0c\u4e14\u6570\u636e\u672c\u8eab\u4e0d\u9700\u8981\u4e25\u683c\u6709\u5e8f\uff0c\u4f46\u53c8\u5e0c\u671b\u6bd4\u7eaf\u987a\u5e8f\u67e5\u627e\u6548\u7387\u66f4\u9ad8\u7684\u60c5\u51b5\u3002</p> </li> <li> <p>\u5206\u5757\u67e5\u627e\u7684\u57fa\u672c\u601d\u60f3\u662f\u5c06\u6570\u636e\u96c6\u5408\u5206\u6210\u82e5\u5e72\u4e2a\u5757\uff0c\u6bcf\u4e2a\u5757\u5185\u7684\u5143\u7d20\u53ef\u4ee5\u65e0\u5e8f\uff0c\u4f46\u5757\u4e0e\u5757\u4e4b\u95f4\u662f\u6709\u5e8f\u7684\uff08\u5373\u524d\u4e00\u4e2a\u5757\u4e2d\u7684\u6700\u5927\u503c\u5c0f\u4e8e\u6216\u7b49\u4e8e\u540e\u4e00\u4e2a\u5757\u4e2d\u7684\u6700\u5c0f\u503c\uff0c\u6216\u8005\u6bcf\u4e2a\u5757\u7684\u7d22\u5f15\u9879\u662f\u5757\u5185\u67d0\u4e2a\u5143\u7d20\u7684\u5173\u952e\u5b57\uff09\u3002\u4e3a\u4e86\u52a0\u901f\u67e5\u627e\uff0c\u901a\u5e38\u4f1a\u4e3a\u6bcf\u4e2a\u5757\u5efa\u7acb\u4e00\u4e2a\u7d22\u5f15\u8868\uff0c\u7d22\u5f15\u8868\u8bb0\u5f55\u4e86\u6bcf\u4e2a\u5757\u7684\u6700\u5927\uff08\u6216\u6700\u5c0f\uff09\u5173\u952e\u5b57\u4ee5\u53ca\u8be5\u5757\u7684\u8d77\u59cb\u5730\u5740\u3002</p> </li> <li> <p>\u5206\u5757\u67e5\u627e\u901a\u5e38\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4\uff1a</p> <ul> <li> <ol> <li>\u786e\u5b9a\u76ee\u6807\u5757\uff1a</li> <li>\u9996\u5148\uff0c\u5728\u7d22\u5f15\u8868\u4e2d\u8fdb\u884c\u67e5\u627e\u3002\u7531\u4e8e\u7d22\u5f15\u8868\u4e2d\u7684\u5173\u952e\u5b57\u662f\u5757\u7684\u4ee3\u8868\uff0c\u5e76\u4e14\u7d22\u5f15\u8868\u672c\u8eab\u662f\u6309\u5173\u952e\u5b57\u6709\u5e8f\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u5728\u7d22\u5f15\u8868\u4e2d\u8fdb\u884c\u987a\u5e8f\u67e5\u627e\u6216\u4e8c\u5206\u67e5\u627e\u6765\u786e\u5b9a\u76ee\u6807\u5143\u7d20\u53ef\u80fd\u5b58\u5728\u7684\u5757\u3002</li> <li>\u901a\u5e38\uff0c\u4e3a\u4e86\u63d0\u9ad8\u6548\u7387\uff0c\u7d22\u5f15\u8868\u4f1a\u9009\u62e9\u4f7f\u7528\u4e8c\u5206\u67e5\u627e\u3002\u901a\u8fc7\u6bd4\u8f83\u5f85\u67e5\u627e\u5173\u952e\u5b57\u4e0e\u7d22\u5f15\u8868\u4e2d\u6bcf\u4e2a\u5757\u7684\u6700\u5927\uff08\u6216\u6700\u5c0f\uff09\u5173\u952e\u5b57\uff0c\u627e\u5230\u7b2c\u4e00\u4e2a\u5757\u7684\u6700\u5927\uff08\u6216\u6700\u5c0f\uff09\u5173\u952e\u5b57\u5927\u4e8e\u6216\u7b49\u4e8e\u5f85\u67e5\u627e\u5173\u952e\u5b57\u7684\u5757\u3002</li> </ol> </li> <li>\u5728\u76ee\u6807\u5757\u5185\u67e5\u627e\uff1a<ul> <li>\u4e00\u65e6\u786e\u5b9a\u4e86\u76ee\u6807\u5757\uff0c\u5c31\u6839\u636e\u7d22\u5f15\u8868\u4e2d\u8bb0\u5f55\u7684\u8be5\u5757\u7684\u8d77\u59cb\u5730\u5740\uff0c\u8fdb\u5165\u8be5\u5757\u8fdb\u884c\u987a\u5e8f\u67e5\u627e\u3002\u56e0\u4e3a\u5757\u5185\u7684\u5143\u7d20\u53ef\u4ee5\u662f\u65e0\u5e8f\u7684\uff0c\u6240\u4ee5\u53ea\u80fd\u8fdb\u884c\u987a\u5e8f\u67e5\u627e\u3002</li> </ul> </li> </ul> </li> <li>\u5206\u5757\u67e5\u627e\u7684\u6548\u7387\u901a\u5e38\u7528\u5e73\u5747\u67e5\u627e\u957f\u5ea6\uff08Average Search Length, ASL\uff09\u6765\u8861\u91cf\u3002\u5e73\u5747\u67e5\u627e\u957f\u5ea6\u662f\u6307\u5728\u67e5\u627e\u8fc7\u7a0b\u4e2d\uff0c\u5e73\u5747\u9700\u8981\u6bd4\u8f83\u7684\u6b21\u6570\u3002</li> <li>\u5047\u8bbe\uff1a</li> <li>\u6570\u636e\u5143\u7d20\u603b\u6570\u4e3a \\(N\\)\u3002</li> <li>\u5c06\u6570\u636e\u5206\u6210 \\(m\\) \u4e2a\u5757\uff0c\u6bcf\u4e2a\u5757\u5305\u542b \\(s\\) \u4e2a\u5143\u7d20\uff08\\(N = m \\times s\\)\uff09\u3002</li> <li>\u7d22\u5f15\u8868\u4e2d\u8fdb\u884c\u7684\u662f\u4e8c\u5206\u67e5\u627e\u3002</li> <li>\u5757\u5185\u8fdb\u884c\u7684\u662f\u987a\u5e8f\u67e5\u627e\u3002</li> <li> <p>\u5e73\u5747\u67e5\u627e\u957f\u5ea6 \\(ASL\\) \u53ef\u4ee5\u5206\u4e3a\u4e24\u90e8\u5206\uff1a</p> <ol> <li>\u67e5\u627e\u7d22\u5f15\u8868\u7684\u6bd4\u8f83\u6b21\u6570\uff1a<ul> <li>\u5982\u679c\u5728\u7d22\u5f15\u8868\u4e2d\u8fdb\u884c\u4e8c\u5206\u67e5\u627e\uff0c\u6700\u574f\u60c5\u51b5\u662f \\(\\log_2 m\\) \u6b21\u6bd4\u8f83\u3002\u5e73\u5747\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u8fd1\u4f3c\u4e3a \\(\\log_2 m\\) \u6b21\u3002</li> <li>\u5982\u679c\u5728\u7d22\u5f15\u8868\u4e2d\u8fdb\u884c\u987a\u5e8f\u67e5\u627e\uff0c\u5e73\u5747\u6bd4\u8f83\u6b21\u6570\u4e3a \\((m+1)/2\\) \u6b21\u3002</li> </ul> </li> <li>\u5728\u76ee\u6807\u5757\u5185\u67e5\u627e\u7684\u6bd4\u8f83\u6b21\u6570\uff1a<ul> <li>\u7531\u4e8e\u5757\u5185\u662f\u987a\u5e8f\u67e5\u627e\uff0c\u5e73\u5747\u9700\u8981\u6bd4\u8f83 \\((s+1)/2\\) \u6b21\u3002</li> </ul> </li> </ol> </li> <li> <p>\u56e0\u6b64\uff0c\u5206\u5757\u67e5\u627e\u7684\u5e73\u5747\u67e5\u627e\u957f\u5ea6\uff08ASL\uff09\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a</p> <ul> <li> <p>\u5f53\u7d22\u5f15\u8868\u91c7\u7528\u987a\u5e8f\u67e5\u627e\u65f6\uff1a \\(ASL = \\frac{m+1}{2} + \\frac{s+1}{2}\\)   \u5c06 \\(m = N/s\\) \u4ee3\u5165\uff0c\u5f97\u5230\uff1a   \\(ASL = \\frac{N/s+1}{2} + \\frac{s+1}{2}\\)1   \u4e3a\u4e86\u4f7f \\(ASL\\) \u6700\u5c0f\uff0c\u53ef\u4ee5\u5bf9 \\(ASL\\) \u5173\u4e8e \\(s\\) \u6c42\u5bfc\u5e76\u4ee4\u5176\u4e3a0\uff0c\u53ef\u4ee5\u8fd1\u4f3c\u5730\u5f97\u5230\u5f53 \\(s \\approx \\sqrt{N}\\) \u65f6\uff0cASL \u6700\u5c0f\u3002\u6b64\u65f6\uff0cASL \u5927\u7ea6\u4e3a \\(\\sqrt{N}\\)\u3002</p> </li> <li> <p>\u5f53\u7d22\u5f15\u8868\u91c7\u7528\u4e8c\u5206\u67e5\u627e\u65f6\uff1a \\(ASL = \\log_2 m + \\frac{s+1}{2}\\)   \u5c06 \\(m = N/s\\) \u4ee3\u5165\uff0c\u5f97\u5230\uff1a   \\(ASL = \\log_2 (N/s) + \\frac{s+1}{2}\\)</p> </li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#aovaov", "title": "\u4ec0\u4e48\u662fAOV\u7f51\uff1f\u5728AOV\u7f51\u4e0a\u7684\u7ecf\u5178\u95ee\u9898\u548c\u7b97\u6cd5\u662f\u4ec0\u4e48\uff1f\u600e\u6837\u8fdb\u884c\u62d3\u6251\u6392\u5e8f\uff1f", "text": "<ul> <li>AOV\u7f51\u5168\u79f0\u662fActivity On Vertex Network\uff08\u9876\u70b9\u6d3b\u52a8\u7f51\uff09\uff0c\u5b83\u662f\u4e00\u79cd\u6709\u5411\u65e0\u73af\u56fe\uff08Directed Acyclic Graph, DAG\uff09\u3002\u5728AOV\u7f51\u4e2d\uff0c\u56fe\u7684\u9876\u70b9\u8868\u793a\u6d3b\u52a8\uff08\u6216\u4e8b\u4ef6\uff09\uff0c\u800c\u6709\u5411\u8fb9\u8868\u793a\u6d3b\u52a8\u4e4b\u95f4\u7684\u4f18\u5148\u5173\u7cfb\u6216\u987a\u5e8f\u5173\u7cfb\u3002\u4f8b\u5982\uff0c\u5982\u679c\u5b58\u5728\u4e00\u6761\u4ece\u9876\u70b9A\u5230\u9876\u70b9B\u7684\u8fb9\uff0c\u5219\u8868\u793a\u6d3b\u52a8A\u5fc5\u987b\u5728\u6d3b\u52a8B\u4e4b\u524d\u5b8c\u6210\u3002\u7531\u4e8eAOV\u7f51\u8868\u793a\u7684\u662f\u6d3b\u52a8\u4e4b\u95f4\u7684\u987a\u5e8f\uff0c\u6240\u4ee5\u5b83\u5fc5\u987b\u662f\u65e0\u73af\u7684\uff0c\u5426\u5219\u4f1a\u9677\u5165\u65e0\u9650\u7684\u4f9d\u8d56\u5faa\u73af\u3002</li> <li>AOV\u7f51\u5e38\u7528\u4e8e\u63cf\u8ff0\u4e00\u4e2a\u5de5\u7a0b\u6216\u9879\u76ee\uff0c\u5176\u4e2d\u5404\u4e2a\u4efb\u52a1\u4e4b\u95f4\u5b58\u5728\u4f9d\u8d56\u5173\u7cfb\uff0c\u6211\u4eec\u9700\u8981\u786e\u5b9a\u4e00\u4e2a\u5408\u7406\u7684\u6267\u884c\u987a\u5e8f\u3002</li> <li>AOV\u7f51\u6700\u7ecf\u5178\u7684\u7684\u5e94\u7528\u5c31\u662f\u62d3\u6251\u6392\u5e8f\u3002</li> <li>\u62d3\u6251\u6392\u5e8f\u662f\u5bf9AOV\u7f51\u7684\u9876\u70b9\u8fdb\u884c\u7ebf\u6027\u6392\u5e8f\uff0c\u4f7f\u5f97\u5bf9\u4e8e\u56fe\u4e2d\u7684\u4efb\u610f\u4e00\u6761\u6709\u5411\u8fb9 \\((u, v)\\)\uff0c\u9876\u70b9 \\(u\\) \u5728\u6392\u5e8f\u7ed3\u679c\u4e2d\u603b\u662f\u5728\u9876\u70b9 \\(v\\) \u4e4b\u524d\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u62d3\u6251\u6392\u5e8f\u5c31\u662f\u627e\u51fa\u6240\u6709\u6d3b\u52a8\u7684\u4e00\u4e2a\u5408\u6cd5\u6267\u884c\u5e8f\u5217\u3002</li> <li>\u5229\u7528Kahn\u7b97\u6cd5\u8fdb\u884c\u62d3\u6251\u6392\u5e8f\u7684\u6b65\u9aa4\u5982\u4e0b\uff1a<ol> <li>\u8ba1\u7b97\u6240\u6709\u9876\u70b9\u7684\u5165\u5ea6\uff1a \u904d\u5386\u56fe\u4e2d\u7684\u6240\u6709\u9876\u70b9\uff0c\u7edf\u8ba1\u6bcf\u4e2a\u9876\u70b9\u7684\u5165\u5ea6\u3002</li> <li>\u521d\u59cb\u5316\u961f\u5217\uff1a \u5c06\u6240\u6709\u5165\u5ea6\u4e3a0\u7684\u9876\u70b9\u653e\u5165\u4e00\u4e2a\u961f\u5217\u4e2d\u3002\u8fd9\u4e9b\u9876\u70b9\u662f\u5f53\u524d\u53ef\u4ee5\u5f00\u59cb\u6267\u884c\u7684\u6d3b\u52a8\u3002</li> <li>\u5faa\u73af\u5904\u7406\u961f\u5217\uff1a<ul> <li>\u4ece\u961f\u5217\u4e2d\u53d6\u51fa\u4e00\u4e2a\u9876\u70b9 \\(u\\)\uff0c\u5e76\u5c06\u5176\u52a0\u5165\u5230\u62d3\u6251\u6392\u5e8f\u7ed3\u679c\u5217\u8868\u3002</li> <li>\u904d\u5386\u6240\u6709\u4ece\u9876\u70b9 \\(u\\) \u51fa\u53d1\u7684\u8fb9\uff0c\u5bf9\u4e8e\u6bcf\u6761\u8fb9 \\((u, v)\\)\uff1a<ul> <li>\u5c06\u9876\u70b9 \\(v\\) \u7684\u5165\u5ea6\u51cf1\u3002</li> <li>\u5982\u679c\u9876\u70b9 \\(v\\) \u7684\u5165\u5ea6\u53d8\u4e3a0\uff0c\u5219\u5c06 \\(v\\) \u52a0\u5165\u961f\u5217\u3002</li> </ul> </li> </ul> </li> <li>\u68c0\u67e5\u73af\uff1a \u91cd\u590d\u6b65\u9aa43\uff0c\u76f4\u5230\u961f\u5217\u4e3a\u7a7a\u3002<ul> <li>\u5982\u679c\u6700\u7ec8\u62d3\u6251\u6392\u5e8f\u7ed3\u679c\u5217\u8868\u4e2d\u7684\u9876\u70b9\u6570\u91cf\u7b49\u4e8e\u56fe\u4e2d\u9876\u70b9\u7684\u603b\u6570\u91cf\uff0c\u8bf4\u660e\u56fe\u662f\u65e0\u73af\u7684\uff0c\u62d3\u6251\u6392\u5e8f\u6210\u529f\u3002</li> <li>\u5982\u679c\u62d3\u6251\u6392\u5e8f\u7ed3\u679c\u5217\u8868\u4e2d\u7684\u9876\u70b9\u6570\u91cf\u5c11\u4e8e\u56fe\u4e2d\u9876\u70b9\u7684\u603b\u6570\u91cf\uff0c\u8bf4\u660e\u56fe\u4e2d\u5b58\u5728\u73af\uff0c\u56e0\u6b64\u65e0\u6cd5\u8fdb\u884c\u62d3\u6251\u6392\u5e8f\u3002</li> </ul> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_14", "title": "\u4ec0\u4e48\u662f\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\uff1f\u7b97\u6cd5\u590d\u6742\u5ea6\u662f\u4ec0\u4e48\uff1f\u6709\u4ec0\u4e48\u7279\u70b9\uff1f", "text": "<ul> <li> <p>\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\uff08Two-way Merge Sort\uff09\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6392\u5e8f\u7b97\u6cd5\uff0c\u5b83\u57fa\u4e8e\u201c\u5206\u800c\u6cbb\u4e4b\u201d\uff08Divide and Conquer\uff09\u7684\u601d\u60f3\u3002</p> </li> <li> <p>\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5c06\u4e00\u4e2a\u5f85\u6392\u5e8f\u7684\u5e8f\u5217\u9012\u5f52\u5730\u5206\u6210\u4e24\u4e2a\u5b50\u5e8f\u5217\uff0c\u76f4\u5230\u6bcf\u4e2a\u5b50\u5e8f\u5217\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\uff08\u6b64\u65f6\u8ba4\u4e3a\u8fd9\u4e9b\u5b50\u5e8f\u5217\u5df2\u7ecf\u6709\u5e8f\uff09\u3002\u7136\u540e\uff0c\u5c06\u8fd9\u4e9b\u6709\u5e8f\u7684\u5b50\u5e8f\u5217\u4e24\u4e24\u5408\u5e76\uff08\u5f52\u5e76\uff09\uff0c\u751f\u6210\u66f4\u5927\u7684\u6709\u5e8f\u5b50\u5e8f\u5217\uff0c\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\u76f4\u5230\u6240\u6709\u7684\u5b50\u5e8f\u5217\u5408\u5e76\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u6709\u5e8f\u5e8f\u5217\u3002</p> </li> <li> <p>\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ul> <li>\u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u6570\u7ec4\uff0c\u7528\u4e8e\u5b58\u653e\u5408\u5e76\u540e\u7684\u7ed3\u679c\u3002</li> <li>\u8bbe\u5b9a\u4e24\u4e2a\u6307\u9488\uff0c\u5206\u522b\u6307\u5411\u4e24\u4e2a\u5f85\u5408\u5e76\u5b50\u5e8f\u5217\u7684\u8d77\u59cb\u4f4d\u7f6e\u3002</li> <li>\u6bd4\u8f83\u4e24\u4e2a\u6307\u9488\u6240\u6307\u5411\u7684\u5143\u7d20\uff0c\u5c06\u8f83\u5c0f\u7684\u5143\u7d20\u653e\u5165\u4e34\u65f6\u6570\u7ec4\uff0c\u5e76\u79fb\u52a8\u76f8\u5e94\u6307\u9488\u3002</li> <li>\u91cd\u590d\u6b64\u6b65\u9aa4\uff0c\u76f4\u5230\u5176\u4e2d\u4e00\u4e2a\u5b50\u5e8f\u5217\u7684\u6240\u6709\u5143\u7d20\u90fd\u88ab\u653e\u5165\u4e34\u65f6\u6570\u7ec4\u3002</li> <li>\u5c06\u53e6\u4e00\u4e2a\u5b50\u5e8f\u5217\u4e2d\u5269\u4f59\u7684\u6240\u6709\u5143\u7d20\u76f4\u63a5\u590d\u5236\u5230\u4e34\u65f6\u6570\u7ec4\u7684\u672b\u5c3e\u3002</li> <li>\u6700\u540e\uff0c\u5c06\u4e34\u65f6\u6570\u7ec4\u4e2d\u7684\u6709\u5e8f\u5143\u7d20\u590d\u5236\u56de\u539f\u59cb\u6570\u7ec4\u5bf9\u5e94\u7684\u4f4d\u7f6e\u3002</li> </ul> </li> <li> <p>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\u6700\u597d\u3001\u6700\u574f\u548c\u5e73\u5747\u60c5\u51b5\u90fd\u662f \\(O(N \\log N)\\)\u3002</li> <li>\u5206\u6790\uff1a<ul> <li>\u5206\u89e3\u9636\u6bb5\uff1a\u6bcf\u6b21\u5c06\u5e8f\u5217\u4e00\u5206\u4e3a\u4e8c\uff0c\u76f4\u5230\u6bcf\u4e2a\u5b50\u5e8f\u5217\u53ea\u5269\u4e00\u4e2a\u5143\u7d20\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u8fdb\u884c \\(\\log N\\) \u5c42\u3002</li> <li>\u5408\u5e76\u9636\u6bb5\uff1a\u5728\u6bcf\u4e00\u5c42\u4e2d\uff0c\u5408\u5e76\u4e24\u4e2a\u5b50\u5e8f\u5217\u9700\u8981\u7ebf\u6027\u65f6\u95f4\uff0c\u5373 \\(O(N)\\)\uff08\u56e0\u4e3a\u8981\u904d\u5386\u6240\u6709\u5143\u7d20\uff09\u3002</li> <li>\u56e0\u6b64\uff0c\u603b\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(N \\log N)\\)\u3002</li> </ul> </li> </ul> </li> <li> <p>\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\\(O(N)\\)\u3002</li> <li>\u5206\u6790\uff1a\u5f52\u5e76\u6392\u5e8f\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u8f85\u52a9\u6570\u7ec4\u6765\u5b58\u50a8\u5408\u5e76\u540e\u7684\u7ed3\u679c\uff0c\u8fd9\u4e2a\u8f85\u52a9\u6570\u7ec4\u7684\u5927\u5c0f\u4e0e\u539f\u59cb\u5e8f\u5217\u7684\u5927\u5c0f\u76f8\u540c\uff0c\u56e0\u6b64\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(N)\\)\u3002</li> </ul> </li> <li> <p>\u6709\u4ec0\u4e48\u7279\u70b9\uff1f</p> <ol> <li>\u7a33\u5b9a\u6027\uff1a\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\u662f\u4e00\u79cd\u7a33\u5b9a\u7684\u6392\u5e8f\u7b97\u6cd5\u3002\u8fd9\u610f\u5473\u7740\u5982\u679c\u5e8f\u5217\u4e2d\u6709\u4e24\u4e2a\u76f8\u540c\u503c\u7684\u5143\u7d20\uff0c\u5728\u6392\u5e8f\u524d\u540e\u5b83\u4eec\u7684\u76f8\u5bf9\u4f4d\u7f6e\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u662f\u56e0\u4e3a\u5728\u5408\u5e76\u8fc7\u7a0b\u4e2d\uff0c\u5f53\u4e24\u4e2a\u5b50\u5e8f\u5217\u4e2d\u7684\u5143\u7d20\u76f8\u7b49\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f18\u5148\u9009\u62e9\u5de6\u8fb9\u5b50\u5e8f\u5217\u7684\u5143\u7d20\u653e\u5165\u4e34\u65f6\u6570\u7ec4\uff0c\u4ece\u800c\u4fdd\u6301\u5b83\u4eec\u7684\u539f\u59cb\u76f8\u5bf9\u987a\u5e8f\u3002</li> <li>\u65f6\u95f4\u590d\u6742\u5ea6\u7a33\u5b9a\uff1a\u65e0\u8bba\u8f93\u5165\u6570\u636e\u7684\u521d\u59cb\u987a\u5e8f\u5982\u4f55\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u59cb\u7ec8\u4e3a \\(O(N \\log N)\\)\uff0c\u8fd9\u4f7f\u5176\u5728\u5404\u79cd\u60c5\u51b5\u4e0b\u90fd\u8868\u73b0\u826f\u597d\u3002</li> <li>\u975e\u539f\u5730\u6392\u5e8f\uff1a\u7531\u4e8e\u9700\u8981\u989d\u5916\u7684\u8f85\u52a9\u7a7a\u95f4\u8fdb\u884c\u5408\u5e76\u64cd\u4f5c\uff0c\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\u662f\u4e00\u79cd\u975e\u539f\u5730\u6392\u5e8f\u7b97\u6cd5\u3002</li> <li>\u9002\u7528\u4e8e\u5916\u90e8\u6392\u5e8f\uff1a\u7531\u4e8e\u5176\u5206\u6cbb\u7684\u601d\u60f3\uff0c\u5f52\u5e76\u6392\u5e8f\u975e\u5e38\u9002\u5408\u5904\u7406\u5927\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u65e0\u6cd5\u4e00\u6b21\u6027\u5168\u90e8\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\uff08\u79f0\u4e3a\u5916\u90e8\u6392\u5e8f\uff09\u3002\u53ef\u4ee5\u5c06\u5927\u6587\u4ef6\u5206\u6210\u5c0f\u5757\u8fdb\u884c\u5185\u90e8\u6392\u5e8f\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6709\u5e8f\u7684\u5c0f\u5757\u8fdb\u884c\u591a\u8def\u5f52\u5e76\u3002</li> <li>\u9012\u5f52\u5b9e\u73b0\u6216\u8fed\u4ee3\u5b9e\u73b0\uff1a\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\u65e2\u53ef\u4ee5\u901a\u8fc7\u9012\u5f52\u65b9\u5f0f\u5b9e\u73b0\uff08\u81ea\u9876\u5411\u4e0b\uff09\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u5b9e\u73b0\uff08\u81ea\u5e95\u5411\u4e0a\uff09\u3002</li> <li>\u5e76\u884c\u6027\uff1a\u5f52\u5e76\u6392\u5e8f\u7684\u5206\u89e3\u548c\u5408\u5e76\u6b65\u9aa4\u5177\u6709\u4e00\u5b9a\u7684\u5e76\u884c\u6027\uff0c\u53ef\u4ee5\u5229\u7528\u591a\u6838\u5904\u7406\u5668\u8fdb\u884c\u4f18\u5316\u3002</li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_15", "title": "\u4ec0\u4e48\u662f\u56fe\u7684\u5355\u6e90\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff1f\u89e3\u51b3\u8be5\u95ee\u9898\u7684\u5e38\u89c1\u65b9\u6cd5\u6709\u54ea\u4e9b\uff1f", "text": "<ul> <li> <p>\u56fe\u7684\u5355\u6e90\u6700\u77ed\u8def\u5f84\u95ee\u9898\u662f\u6307\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u5e26\u6743\u6709\u5411\u56fe\u6216\u65e0\u5411\u56fe \\(G = (V, E)\\)\uff0c\u5176\u4e2d \\(V\\) \u662f\u9876\u70b9\u7684\u96c6\u5408\uff0c\\(E\\) \u662f\u8fb9\u7684\u96c6\u5408\uff0c\u6bcf\u6761\u8fb9 \\((u, v) \\in E\\) \u90fd\u6709\u4e00\u4e2a\u975e\u8d1f\u7684\u6743\u91cd \\(w(u, v)\\)\u3002\u7ed9\u5b9a\u4e00\u4e2a\u6e90\u70b9 \\(s \\in V\\)\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230\u4ece\u6e90\u70b9 \\(s\\) \u5230\u56fe\u4e2d\u6240\u6709\u5176\u4ed6\u9876\u70b9 \\(v \\in V\\) \u7684\u6700\u77ed\u8def\u5f84\u3002\u6700\u77ed\u8def\u5f84\u662f\u6307\u8def\u5f84\u4e0a\u6240\u6709\u8fb9\u7684\u6743\u91cd\u4e4b\u548c\u6700\u5c0f\u7684\u8def\u5f84\u3002</p> </li> <li> <p>\u89e3\u51b3\u8be5\u95ee\u9898\u7684\u5e38\u89c1\u65b9\u6cd5\u6709\uff1a</p> <ol> <li> <p>\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22 (BFS)     \u867d\u7136 BFS \u901a\u5e38\u7528\u4e8e\u65e0\u6743\u56fe\u7684\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff0c\u4f46\u5b83\u4e5f\u53ef\u4ee5\u7528\u4e8e\u89e3\u51b3\u8fb9\u6743\u90fd\u4e3a 1 \u7684\u7279\u6b8a\u5355\u6e90\u6700\u77ed\u8def\u5f84\u95ee\u9898\u3002\u5176\u6838\u5fc3\u601d\u60f3\u662f\uff0c\u4ece\u6e90\u70b9 \\(s\\) \u5f00\u59cb\uff0c\u9010\u5c42\u5411\u5916\u6269\u5c55\uff0c\u9996\u5148\u8bbf\u95ee\u8ddd\u79bb \\(s\\) \u4e3a 1 \u7684\u6240\u6709\u9876\u70b9\uff0c\u7136\u540e\u662f\u8ddd\u79bb \\(s\\) \u4e3a 2 \u7684\u6240\u6709\u9876\u70b9\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002</p> <ul> <li>\u7b97\u6cd5\u6d41\u7a0b\uff1a<ol> <li>\u521d\u59cb\u5316\u6240\u6709\u9876\u70b9\u7684\u8ddd\u79bb\u4e3a\u65e0\u7a77\u5927\uff0c\u6e90\u70b9 \\(s\\) \u7684\u8ddd\u79bb\u4e3a 0\u3002</li> <li>\u521b\u5efa\u4e00\u4e2a\u961f\u5217\uff0c\u5e76\u5c06\u6e90\u70b9 \\(s\\) \u52a0\u5165\u961f\u5217\u3002</li> <li>\u5f53\u961f\u5217\u4e0d\u4e3a\u7a7a\u65f6\uff0c\u53d6\u51fa\u961f\u5934\u9876\u70b9 \\(u\\)\u3002</li> <li>\u904d\u5386 \\(u\\) \u7684\u6240\u6709\u90bb\u5c45 \\(v\\)\u3002\u5982\u679c \\(v\\) \u5c1a\u672a\u88ab\u8bbf\u95ee\uff08\u6216\u8005\u8bf4 \\(v\\) \u7684\u8ddd\u79bb\u4ecd\u7136\u662f\u65e0\u7a77\u5927\uff09\uff0c\u5219\u5c06 \\(v\\) \u7684\u8ddd\u79bb\u8bbe\u7f6e\u4e3a \\(u\\) \u7684\u8ddd\u79bb\u52a0 1\uff0c\u5e76\u5c06 \\(v\\) \u52a0\u5165\u961f\u5217\u3002</li> <li>\u91cd\u590d\u6b65\u9aa4 3 \u548c 4\uff0c\u76f4\u5230\u961f\u5217\u4e3a\u7a7a\u3002</li> </ol> </li> </ul> </li> <li> <p>Dijkstra \u7b97\u6cd5     Dijkstra \u7b97\u6cd5\u662f\u89e3\u51b3\u5e26\u6709\u975e\u8d1f\u6743\u91cd\u7684\u5355\u6e90\u6700\u77ed\u8def\u5f84\u95ee\u9898\u7684\u5e38\u7528\u7b97\u6cd5\u3002\u5b83\u91c7\u7528\u8d2a\u5fc3\u7b56\u7565\uff0c\u9010\u6b65\u6269\u5c55\u6700\u77ed\u8def\u5f84\u6811\u3002</p> <ul> <li>\u7b97\u6cd5\u6d41\u7a0b\uff1a<ol> <li>\u521d\u59cb\u5316\u6240\u6709\u9876\u70b9\u7684\u8ddd\u79bb\u4e3a\u65e0\u7a77\u5927\uff0c\u6e90\u70b9 \\(s\\) \u7684\u8ddd\u79bb\u4e3a 0\u3002</li> <li>\u521b\u5efa\u4e00\u4e2a\u4f18\u5148\u961f\u5217\uff08\u6216\u79f0\u4e3a\u5c0f\u9876\u5806\uff09\uff0c\u5e76\u5c06\u6240\u6709\u9876\u70b9\u53ca\u5176\u5f53\u524d\u8ddd\u79bb\u52a0\u5165\u961f\u5217\u3002</li> <li>\u5f53\u4f18\u5148\u961f\u5217\u4e0d\u4e3a\u7a7a\u65f6\uff0c\u53d6\u51fa\u8ddd\u79bb\u6700\u5c0f\u7684\u9876\u70b9 \\(u\\)\u3002</li> <li>\u5982\u679c \\(u\\) \u5df2\u7ecf\u88ab\u786e\u5b9a\u4e3a\u6700\u77ed\u8def\u5f84\uff08\u5373\u5df2\u7ecf\u4ece\u4f18\u5148\u961f\u5217\u4e2d\u53d6\u51fa\u8fc7\uff09\uff0c\u5219\u8df3\u8fc7\u3002</li> <li>\u5bf9\u4e8e \\(u\\) \u7684\u6bcf\u4e00\u4e2a\u90bb\u5c45 \\(v\\)\uff0c\u8ba1\u7b97\u4ece\u6e90\u70b9 \\(s\\) \u7ecf\u8fc7 \\(u\\) \u5230 \\(v\\) \u7684\u65b0\u8ddd\u79bb\uff1a\\(dist(u) + w(u, v)\\)\u3002</li> <li>\u5982\u679c\u8fd9\u4e2a\u65b0\u8ddd\u79bb\u5c0f\u4e8e\u5f53\u524d \\(v\\) \u7684\u8ddd\u79bb \\(dist(v)\\)\uff0c\u5219\u66f4\u65b0 \\(dist(v)\\)\uff0c\u5e76\u5c06 \\(v\\) \u53ca\u5176\u65b0\u8ddd\u79bb\u91cd\u65b0\u52a0\u5165\uff08\u6216\u66f4\u65b0\u5176\u5728\uff09\u4f18\u5148\u961f\u5217\u4e2d\u3002</li> <li>\u91cd\u590d\u6b65\u9aa4 3 \u5230 6\uff0c\u76f4\u5230\u4f18\u5148\u961f\u5217\u4e3a\u7a7a\uff0c\u6216\u8005\u6240\u6709\u53ef\u8fbe\u9876\u70b9\u7684\u6700\u77ed\u8def\u5f84\u90fd\u5df2\u786e\u5b9a\u3002</li> </ol> </li> </ul> </li> <li> <p>Floyd-Warshall \u7b97\u6cd5     Floyd-Warshall \u7b97\u6cd5\u662f\u89e3\u51b3\u6240\u6709\u9876\u70b9\u5bf9\u6700\u77ed\u8def\u5f84\u95ee\u9898\u7684\u7b97\u6cd5\uff0c\u4f46\u5b83\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5c06\u5176\u5e94\u7528\u4e8e\u5355\u4e2a\u6e90\u70b9\u6765\u89e3\u51b3\u5355\u6e90\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff08\u5c3d\u7ba1\u6548\u7387\u4e0d\u5982 Dijkstra \u7b97\u6cd5\uff09\u3002\u5b83\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u601d\u60f3\uff0c\u901a\u8fc7\u8003\u8651\u6240\u6709\u53ef\u80fd\u7684\u4e2d\u95f4\u9876\u70b9\u6765\u9010\u6b65\u8ba1\u7b97\u6700\u77ed\u8def\u5f84\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cFloyd-Warshall \u7b97\u6cd5\u53ef\u4ee5\u5904\u7406\u8d1f\u6743\u8fb9\uff0c\u4f46\u4e0d\u80fd\u5904\u7406\u8d1f\u6743\u73af\u3002</p> <ul> <li>\u7b97\u6cd5\u6d41\u7a0b\uff1a<ol> <li>\u521d\u59cb\u5316\u4e00\u4e2a\u8ddd\u79bb\u77e9\u9635 \\(D\\)\uff0c\u5176\u4e2d \\(D[i][j]\\) \u8868\u793a\u4ece\u9876\u70b9 \\(i\\) \u5230\u9876\u70b9 \\(j\\) \u7684\u76f4\u63a5\u8fb9\u6743\u91cd\u3002\u5982\u679c\u4e0d\u5b58\u5728\u76f4\u63a5\u8fb9\uff0c\u5219\u8bbe\u7f6e\u4e3a\u65e0\u7a77\u5927\u3002\u5982\u679c \\(i=j\\)\uff0c\u5219 \\(D[i][j]=0\\)\u3002</li> <li>\u5bf9\u4e8e\u56fe\u4e2d\u7684\u6bcf\u4e00\u4e2a\u9876\u70b9 \\(k\\) (\u4f5c\u4e3a\u4e2d\u95f4\u9876\u70b9)\uff0c\u904d\u5386\u6240\u6709\u9876\u70b9\u5bf9 \\((i, j)\\)\u3002</li> <li>\u66f4\u65b0 \\(D[i][j]\\) \u7684\u503c\uff1a\\(D[i][j] = \\min(D[i][j], D[i][k] + D[k][j])\\)\u3002\u8fd9\u610f\u5473\u7740\u4ece \\(i\\) \u5230 \\(j\\) \u7684\u6700\u77ed\u8def\u5f84\u8981\u4e48\u662f\u76f4\u63a5\u8def\u5f84\uff0c\u8981\u4e48\u662f\u7ecf\u8fc7 \\(k\\) \u7684\u8def\u5f84\u3002</li> <li>\u91cd\u590d\u6b65\u9aa4 2 \u548c 3\uff0c\u76f4\u5230\u6240\u6709\u9876\u70b9 \\(k\\) \u90fd\u4f5c\u4e3a\u4e2d\u95f4\u9876\u70b9\u88ab\u8003\u8651\u8fc7\u3002</li> <li>\u6700\u7ec8\uff0c\u77e9\u9635 \\(D\\) \u4e2d\u7684 \\(D[s][v]\\) \u5c31\u662f\u4ece\u6e90\u70b9 \\(s\\) \u5230\u9876\u70b9 \\(v\\) \u7684\u6700\u77ed\u8def\u5f84\u3002</li> </ol> </li> </ul> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_16", "title": "\u4ec0\u4e48\u662f\u5feb\u901f\u6392\u5e8f\uff1f\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u7b97\u6cd5\u590d\u6742\u5ea6\u662f\u4ec0\u4e48\uff1f", "text": "<ul> <li> <p>\u5feb\u901f\u6392\u5e8f\u7684\u57fa\u672c\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u6311\u9009\u57fa\u51c6\u503c\uff08Pivot\uff09\uff1a\u4ece\u6570\u5217\u4e2d\u6311\u51fa\u4e00\u4e2a\u5143\u7d20\uff0c\u79f0\u4e3a\u201c\u57fa\u51c6\u201d\uff08pivot\uff09\u3002\u8fd9\u4e2a\u57fa\u51c6\u503c\u7684\u9009\u62e9\u5bf9\u7b97\u6cd5\u7684\u6027\u80fd\u6709\u5f88\u5927\u5f71\u54cd\u3002</li> <li>\u5206\u5272\uff08Partition\uff09\uff1a\u91cd\u65b0\u6392\u5e8f\u6570\u5217\uff0c\u6240\u6709\u6bd4\u57fa\u51c6\u503c\u5c0f\u7684\u5143\u7d20\u6446\u653e\u5728\u57fa\u51c6\u524d\u9762\uff0c\u6240\u6709\u6bd4\u57fa\u51c6\u503c\u5927\u7684\u5143\u7d20\u6446\u5728\u57fa\u51c6\u540e\u9762\uff08\u4e0e\u57fa\u51c6\u503c\u76f8\u7b49\u7684\u6570\u53ef\u4ee5\u5230\u4efb\u4f55\u4e00\u8fb9\uff09\u3002\u5728\u8fd9\u4e2a\u5206\u5272\u7ed3\u675f\u4e4b\u540e\uff0c\u57fa\u51c6\u503c\u5c31\u5904\u4e8e\u5176\u6700\u7ec8\u7684\u6392\u5e8f\u4f4d\u7f6e\u3002</li> <li>\u9012\u5f52\u6392\u5e8f\u5b50\u5e8f\u5217\uff1a\u9012\u5f52\u5730\u5c06\u5c0f\u4e8e\u57fa\u51c6\u503c\u5143\u7d20\u7684\u5b50\u5e8f\u5217\u548c\u5927\u4e8e\u57fa\u51c6\u503c\u5143\u7d20\u7684\u5b50\u5e8f\u5217\u6392\u5e8f\u3002</li> </ol> </li> <li> <p>\u7b97\u6cd5\u590d\u6742\u5ea6</p> <ol> <li> <p>\u6700\u597d\u60c5\u51b5\uff08Best Case\uff09\uff1a</p> <ul> <li>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a\\(O(N \\log N)\\)</li> <li>\u5f53\u6bcf\u6b21\u9009\u62e9\u7684\u57fa\u51c6\u503c\u90fd\u80fd\u5c06\u6570\u7ec4\u5747\u5300\u5730\u5206\u6210\u4e24\u4e2a\u5927\u81f4\u76f8\u7b49\uff08\u6216\u63a5\u8fd1\u76f8\u7b49\uff09\u7684\u5b50\u6570\u7ec4\u65f6\uff0c\u5c31\u4f1a\u51fa\u73b0\u6700\u597d\u60c5\u51b5\u3002\u4f8b\u5982\uff0c\u6bcf\u6b21\u57fa\u51c6\u503c\u90fd\u6070\u597d\u662f\u5f53\u524d\u5b50\u6570\u7ec4\u7684\u4e2d\u4f4d\u6570\u3002</li> <li>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9012\u5f52\u7684\u6df1\u5ea6\u5927\u7ea6\u4e3a \\(\\log N\\)\uff0c\u6bcf\u5c42\u64cd\u4f5c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(N)\\)\uff08\u56e0\u4e3a\u9700\u8981\u904d\u5386\u5143\u7d20\u8fdb\u884c\u5206\u5272\uff09\uff0c\u6240\u4ee5\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(N \\log N)\\)\u3002</li> </ul> </li> <li> <p>\u5e73\u5747\u60c5\u51b5\uff08Average Case\uff09\uff1a</p> <ul> <li>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a\\(O(N \\log N)\\)</li> <li>\u5728\u5927\u591a\u6570\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5982\u679c\u57fa\u51c6\u503c\u662f\u968f\u673a\u9009\u62e9\u7684\uff0c\u6216\u8005\u901a\u8fc7\u4e00\u4e9b\u7b56\u7565\uff08\u5982\u201c\u4e09\u6570\u53d6\u4e2d\u201d\u6cd5\uff09\u6765\u9009\u62e9\u57fa\u51c6\u503c\uff0c\u5feb\u901f\u6392\u5e8f\u7684\u6027\u80fd\u901a\u5e38\u4f1a\u8d8b\u5411\u4e8e\u5e73\u5747\u60c5\u51b5\u3002</li> <li>\u867d\u7136\u6bcf\u6b21\u5206\u5272\u4e0d\u4e00\u5b9a\u90fd\u975e\u5e38\u5747\u5300\uff0c\u4f46\u4ece\u6982\u7387\u4e0a\u8bb2\uff0c\u6bcf\u6b21\u5206\u5272\u90fd\u80fd\u6709\u6548\u5730\u51cf\u5c11\u95ee\u9898\u89c4\u6a21\uff0c\u56e0\u6b64\u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6\u4e5f\u8fd1\u4f3c\u4e8e \\(O(N \\log N)\\)\u3002</li> </ul> </li> <li> <p>\u6700\u574f\u60c5\u51b5\uff08Worst Case\uff09\uff1a</p> <ul> <li>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a\\(O(N^2)\\)</li> <li>\u5f53\u6bcf\u6b21\u9009\u62e9\u7684\u57fa\u51c6\u503c\u90fd\u6070\u597d\u662f\u5f53\u524d\u5b50\u6570\u7ec4\u7684\u6700\u5c0f\u503c\u6216\u6700\u5927\u503c\u65f6\uff0c\u5c31\u4f1a\u51fa\u73b0\u6700\u574f\u60c5\u51b5\u3002</li> <li>\u4f8b\u5982\uff0c\u5982\u679c\u6570\u7ec4\u5df2\u7ecf\u5b8c\u5168\u6709\u5e8f\uff08\u5347\u5e8f\u6216\u964d\u5e8f\uff09\uff0c\u5e76\u4e14\u6bcf\u6b21\u90fd\u9009\u62e9\u7b2c\u4e00\u4e2a\u6216\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u4f5c\u4e3a\u57fa\u51c6\u503c\uff0c\u90a3\u4e48\u6bcf\u6b21\u5206\u5272\u64cd\u4f5c\u90fd\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u5b50\u6570\u7ec4\u4e3a\u7a7a\uff0c\u800c\u53e6\u4e00\u4e2a\u5b50\u6570\u7ec4\u5305\u542b\u9664\u4e86\u57fa\u51c6\u503c\u4e4b\u5916\u7684\u6240\u6709\u5143\u7d20\u3002</li> <li>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9012\u5f52\u7684\u6df1\u5ea6\u5c06\u8fbe\u5230 \\(N\\)\uff0c\u6bcf\u5c42\u64cd\u4f5c\u4ecd\u7136\u662f \\(O(N)\\)\uff0c\u6240\u4ee5\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(N^2)\\)\u3002</li> <li>\u4e3a\u4e86\u907f\u514d\u6700\u574f\u60c5\u51b5\u7684\u53d1\u751f\uff0c\u901a\u5e38\u4f1a\u91c7\u7528\u4e00\u4e9b\u4f18\u5316\u7b56\u7565\uff0c\u4f8b\u5982\uff1a<ul> <li>\u968f\u673a\u9009\u62e9\u57fa\u51c6\u503c\uff1a\u968f\u673a\u9009\u62e9\u6570\u7ec4\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20\u4f5c\u4e3a\u57fa\u51c6\uff0c\u53ef\u4ee5\u5927\u5927\u964d\u4f4e\u9047\u5230\u6700\u574f\u60c5\u51b5\u7684\u6982\u7387\u3002</li> <li>\u4e09\u6570\u53d6\u4e2d\u6cd5\uff1a\u9009\u62e9\u6570\u7ec4\u7684\u7b2c\u4e00\u4e2a\u3001\u4e2d\u95f4\u548c\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u7136\u540e\u53d6\u8fd9\u4e09\u4e2a\u6570\u7684\u4e2d\u4f4d\u6570\u4f5c\u4e3a\u57fa\u51c6\u503c\uff0c\u8fd9\u6709\u52a9\u4e8e\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u907f\u514d\u6781\u7aef\u60c5\u51b5\u3002</li> </ul> </li> </ul> </li> </ol> </li> <li> <p>\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\u5feb\u901f\u6392\u5e8f\u662f\u539f\u5730\u6392\u5e8f\uff08In-place sorting\uff09\u7b97\u6cd5\uff0c\u4f46\u7531\u4e8e\u5176\u9012\u5f52\u7684\u7279\u6027\uff0c\u9700\u8981\u989d\u5916\u7684\u6808\u7a7a\u95f4\u6765\u5b58\u50a8\u9012\u5f52\u8c03\u7528\u7684\u4fe1\u606f\u3002</li> <li>\u6700\u597d\u548c\u5e73\u5747\u60c5\u51b5\uff1a\\(O(\\log N)\\)\uff0c\u5bf9\u5e94\u4e8e\u9012\u5f52\u6df1\u5ea6\u3002</li> <li>\u6700\u574f\u60c5\u51b5\uff1a\\(O(N)\\)\uff0c\u5bf9\u5e94\u4e8e\u9012\u5f52\u6df1\u5ea6\u8fbe\u5230 \\(N\\)\u3002</li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#aoe", "title": "\u4ec0\u4e48\u662fAOE\u7f51\u7edc\uff1f\u7ed3\u70b9\u548c\u8fb9\u5206\u522b\u4ee3\u8868\u4ec0\u4e48\uff1f\u4ec0\u4e48\u662f\u5173\u952e\u6d3b\u52a8\uff1f\u600e\u6837\u6c42\u5173\u952e\u8def\u5f84\uff1f", "text": "<ul> <li> <p>AOE\u7f51\u7edc\uff08Activity On Edge Network\uff09\uff0c\u5373\u8fb9\u6d3b\u52a8\u7f51\u7edc\uff0c\u662f\u4e00\u79cd\u7528\u4e8e\u9879\u76ee\u7ba1\u7406\u548c\u8c03\u5ea6\u3001\u4f30\u7b97\u5de5\u7a0b\u5b8c\u6210\u65f6\u95f4\u7684\u5e26\u6743\u6709\u5411\u65e0\u73af\u56fe\u3002\u5b83\u5f3a\u8c03\u7684\u662f\u6d3b\u52a8\u5728\u8fb9\u4e0a\u3002</p> <ul> <li>\u7ed3\u70b9\uff08Vertex/Node\uff09\uff1a\u5728AOE\u7f51\u7edc\u4e2d\uff0c\u7ed3\u70b9\u4ee3\u8868\u4e8b\u4ef6\uff08Event\uff09\u3002\u4e8b\u4ef6\u8868\u793a\u67d0\u4e2a\u6d3b\u52a8\u7684\u5f00\u59cb\u6216\u7ed3\u675f\u7684\u72b6\u6001\uff0c\u5b83\u672c\u8eab\u4e0d\u8017\u8d39\u65f6\u95f4\uff0c\u4f46\u4ee3\u8868\u7740\u4e00\u4e2a\u7279\u5b9a\u65f6\u523b\u3002\u4f8b\u5982\uff0c\"\u5b8c\u6210\u5730\u57fa\"\u3001\"\u5f00\u59cb\u88c5\u4fee\"\u7b49\u3002</li> <li>\u8fb9\uff08Edge/Arc\uff09\uff1a\u8fb9\u4ee3\u8868\u6d3b\u52a8\uff08Activity\uff09\u3002\u6bcf\u6761\u8fb9\u8868\u793a\u4e00\u4e2a\u9700\u8981\u8017\u8d39\u65f6\u95f4\u548c\u8d44\u6e90\u7684\u5177\u4f53\u4efb\u52a1\u6216\u5de5\u4f5c\u3002\u8fb9\u7684\u6743\u91cd\u901a\u5e38\u8868\u793a\u8be5\u6d3b\u52a8\u6240\u9700\u7684\u6301\u7eed\u65f6\u95f4\u3002\u4f8b\u5982\uff0c\"\u5efa\u9020\u5899\u58c1\"\u3001\"\u94fa\u8bbe\u7535\u7f06\"\u7b49\u3002\u6709\u5411\u6027\u8868\u793a\u6d3b\u52a8\u7684\u5148\u540e\u987a\u5e8f\u548c\u4f9d\u8d56\u5173\u7cfb\u3002</li> </ul> </li> <li> <p>\u5173\u952e\u6d3b\u52a8\uff08Critical Activity\uff09 \u6307\u5728AOE\u7f51\u7edc\u4e2d\uff0c\u4efb\u4f55\u4e00\u70b9\u5ef6\u8fdf\u90fd\u4f1a\u5bfc\u81f4\u6574\u4e2a\u9879\u76ee\u5b8c\u6210\u65f6\u95f4\u5ef6\u8fdf\u7684\u6d3b\u52a8\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5b83\u4eec\u7684\u6d6e\u52a8\u65f6\u95f4\uff08Slack Time\uff09\u4e3a\u96f6\u3002\u5982\u679c\u5173\u952e\u6d3b\u52a8\u88ab\u5ef6\u8bef\uff0c\u9879\u76ee\u7684\u603b\u5de5\u671f\u5c31\u4f1a\u589e\u52a0\u3002</p> </li> <li> <p>\u5982\u4f55\u6c42\u5173\u952e\u8def\u5f84\uff08Critical Path\uff09\uff1a \u5173\u952e\u8def\u5f84\u662fAOE\u7f51\u7edc\u4e2d\u4ece\u8d77\u70b9\u5230\u7ec8\u70b9\u7684\u6240\u6709\u8def\u5f84\u4e2d\uff0c\u8def\u5f84\u957f\u5ea6\u6700\u957f\u7684\u90a3\u6761\u8def\u5f84\u3002\u8fd9\u6761\u8def\u5f84\u4e0a\u7684\u6240\u6709\u6d3b\u52a8\u90fd\u662f\u5173\u952e\u6d3b\u52a8\uff0c\u5b83\u7684\u957f\u5ea6\u51b3\u5b9a\u4e86\u6574\u4e2a\u9879\u76ee\u5b8c\u6210\u6240\u9700\u7684\u6700\u77ed\u65f6\u95f4\u3002\u6c42\u5173\u952e\u8def\u5f84\u901a\u5e38\u91c7\u7528\u201c\u524d\u5411\u8ba1\u7b97\u201d\u548c\u201c\u540e\u5411\u8ba1\u7b97\u201d\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff1a</p> <ol> <li> <p>\u786e\u5b9a\u6700\u65e9\u5f00\u59cb\u65f6\u95f4 (Earliest Start Time, ES) \u548c \u6700\u65e9\u5b8c\u6210\u65f6\u95f4 (Earliest Finish Time, EF)\uff1a</p> <ul> <li>\u4e8b\u4ef6\u7684\u6700\u65e9\u53d1\u751f\u65f6\u95f4 (Earliest Event Time, EE)\uff1a\u4ece\u6e90\u70b9\uff08\u8d77\u59cb\u4e8b\u4ef6\uff09\u5f00\u59cb\uff0c\u6309\u62d3\u6251\u987a\u5e8f\u8ba1\u7b97\u6bcf\u4e2a\u4e8b\u4ef6\u53ef\u80fd\u53d1\u751f\u7684\u6700\u65e9\u65f6\u95f4\u3002<ul> <li>\u6e90\u70b9\uff08\u8d77\u59cb\u4e8b\u4ef6\uff09\u7684EE\u4e3a0\u3002</li> <li>\u5bf9\u4e8e\u4efb\u4f55\u4e8b\u4ef6 \\(j\\)\uff0c\u5176 \\(EE(j)\\) \u7b49\u4e8e\u6240\u6709\u6307\u5411 \\(j\\) \u7684\u6d3b\u52a8 \\(i \\to j\\) \u7684\u6700\u65e9\u5b8c\u6210\u65f6\u95f4\u7684\u6700\u5927\u503c\u3002\u5373 \\(EE(j) = \\max \\{ EE(i) + Duration(i \\to j) \\}\\)\u3002</li> </ul> </li> <li>\u6d3b\u52a8\u7684\u6700\u65e9\u5f00\u59cb\u65f6\u95f4 (Earliest Start Time, ES)\uff1a\u4e00\u4e2a\u6d3b\u52a8\u7684ES\u7b49\u4e8e\u5176\u524d\u7f6e\u4e8b\u4ef6\u7684\u6700\u65e9\u53d1\u751f\u65f6\u95f4\u3002<ul> <li>\u5bf9\u4e8e\u6d3b\u52a8 \\(i \\to j\\)\uff0c\u5176 \\(ES(i \\to j) = EE(i)\\)\u3002</li> </ul> </li> <li>\u6d3b\u52a8\u7684\u6700\u65e9\u5b8c\u6210\u65f6\u95f4 (Earliest Finish Time, EF)\uff1a\u4e00\u4e2a\u6d3b\u52a8\u7684EF\u7b49\u4e8e\u5176\u6700\u65e9\u5f00\u59cb\u65f6\u95f4\u52a0\u4e0a\u5176\u6301\u7eed\u65f6\u95f4\u3002<ul> <li>\u5bf9\u4e8e\u6d3b\u52a8 \\(i \\to j\\)\uff0c\u5176 \\(EF(i \\to j) = ES(i \\to j) + Duration(i \\to j)\\)\u3002</li> </ul> </li> <li>\u6574\u4e2a\u9879\u76ee\u7684\u6700\u65e9\u5b8c\u6210\u65f6\u95f4\u5c31\u662f\u6c47\u70b9\uff08\u7ec8\u70b9\u4e8b\u4ef6\uff09\u7684EE\u3002</li> </ul> </li> <li> <p>\u786e\u5b9a\u6700\u8fdf\u5f00\u59cb\u65f6\u95f4 (Latest Start Time, LS) \u548c \u6700\u8fdf\u5b8c\u6210\u65f6\u95f4 (Latest Finish Time, LF)\uff1a</p> <ul> <li>\u4e8b\u4ef6\u7684\u6700\u8fdf\u53d1\u751f\u65f6\u95f4 (Latest Event Time, LE)\uff1a\u4ece\u6c47\u70b9\uff08\u7ec8\u70b9\u4e8b\u4ef6\uff09\u5f00\u59cb\uff0c\u6309\u9006\u62d3\u6251\u987a\u5e8f\u8ba1\u7b97\u6bcf\u4e2a\u4e8b\u4ef6\u5141\u8bb8\u53d1\u751f\u7684\u6700\u8fdf\u65f6\u95f4\uff0c\u800c\u4e0d\u5f71\u54cd\u6574\u4e2a\u9879\u76ee\u7684\u5b8c\u6210\u65f6\u95f4\u3002<ul> <li>\u6c47\u70b9\uff08\u7ec8\u70b9\u4e8b\u4ef6\uff09\u7684LE\u7b49\u4e8e\u5176EE\uff08\u5373\u9879\u76ee\u7684\u6700\u65e9\u5b8c\u6210\u65f6\u95f4\uff09\u3002</li> <li>\u5bf9\u4e8e\u4efb\u4f55\u4e8b\u4ef6 \\(i\\)\uff0c\u5176 \\(LE(i)\\) \u7b49\u4e8e\u6240\u6709\u4ece \\(i\\) \u53d1\u51fa\u7684\u6d3b\u52a8 \\(i \\to j\\) \u7684\u6700\u8fdf\u5f00\u59cb\u65f6\u95f4\u7684\u6700\u5c0f\u503c\u3002\u5373 \\(LE(i) = \\min \\{ LE(j) - Duration(i \\to j) \\}\\)\u3002</li> </ul> </li> <li>\u6d3b\u52a8\u7684\u6700\u8fdf\u5b8c\u6210\u65f6\u95f4 (Latest Finish Time, LF)\uff1a\u4e00\u4e2a\u6d3b\u52a8\u7684LF\u7b49\u4e8e\u5176\u540e\u7ee7\u4e8b\u4ef6\u7684\u6700\u8fdf\u53d1\u751f\u65f6\u95f4\u3002<ul> <li>\u5bf9\u4e8e\u6d3b\u52a8 \\(i \\to j\\)\uff0c\u5176 \\(LF(i \\to j) = LE(j)\\)\u3002</li> </ul> </li> <li>\u6d3b\u52a8\u7684\u6700\u8fdf\u5f00\u59cb\u65f6\u95f4 (Latest Start Time, LS)\uff1a\u4e00\u4e2a\u6d3b\u52a8\u7684LS\u7b49\u4e8e\u5176\u6700\u8fdf\u5b8c\u6210\u65f6\u95f4\u51cf\u53bb\u5176\u6301\u7eed\u65f6\u95f4\u3002<ul> <li>\u5bf9\u4e8e\u6d3b\u52a8 \\(i \\to j\\)\uff0c\u5176 \\(LS(i \\to j) = LF(i \\to j) - Duration(i \\to j)\\)\u3002</li> </ul> </li> </ul> </li> <li> <p>\u8ba1\u7b97\u6d3b\u52a8\u7684\u6d6e\u52a8\u65f6\u95f4 (Slack Time)\uff1a</p> <ul> <li>\u6d6e\u52a8\u65f6\u95f4\u662f\u6307\u4e00\u4e2a\u6d3b\u52a8\u5728\u4e0d\u5f71\u54cd\u9879\u76ee\u603b\u5de5\u671f\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5ef6\u8fdf\u7684\u65f6\u95f4\u3002</li> <li>\u5bf9\u4e8e\u6d3b\u52a8 \\(i \\to j\\)\uff0c\u5176\u6d6e\u52a8\u65f6\u95f4 \\(Slack(i \\to j) = LS(i \\to j) - ES(i \\to j)\\) \u6216 \\(Slack(i \\to j) = LF(i \\to j) - EF(i \\to j)\\)\u3002</li> </ul> </li> <li> <p>\u786e\u5b9a\u5173\u952e\u8def\u5f84\uff1a</p> <ul> <li>\u6240\u6709\u6d6e\u52a8\u65f6\u95f4\u4e3a\u96f6\u7684\u6d3b\u52a8\u90fd\u662f\u5173\u952e\u6d3b\u52a8\u3002</li> <li>\u8fde\u63a5\u6240\u6709\u5173\u952e\u6d3b\u52a8\u7684\u8def\u5f84\uff0c\u5c31\u662f\u5173\u952e\u8def\u5f84\u3002\u901a\u5e38\uff0c\u53ef\u80fd\u5b58\u5728\u591a\u6761\u5173\u952e\u8def\u5f84\u3002</li> </ul> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_17", "title": "\u4ec0\u4e48\u662f\u591a\u5173\u952e\u5b57\u6392\u5e8f\uff1f\u4ec0\u4e48\u662f\u57fa\u6570\u6392\u5e8f\u7b97\u6cd5\uff1f\u7b97\u6cd5\u590d\u6742\u5ea6\u5982\u4f55\uff1f", "text": "<ul> <li> <p>\u591a\u5173\u952e\u5b57\u6392\u5e8f\uff08Multi-key Sort\uff09\uff0c\u4e5f\u79f0\u4e3a\u591a\u7ea7\u6392\u5e8f\u6216\u591a\u7ef4\u5ea6\u6392\u5e8f\uff0c\u662f\u6307\u5bf9\u4e00\u7ec4\u6570\u636e\u8fdb\u884c\u6392\u5e8f\u65f6\uff0c\u4e0d\u4ec5\u4ec5\u4f9d\u636e\u4e00\u4e2a\u5173\u952e\u5b57\u8fdb\u884c\u6392\u5e8f\uff0c\u800c\u662f\u4f9d\u636e\u591a\u4e2a\u5173\u952e\u5b57\u7684\u4f18\u5148\u7ea7\u987a\u5e8f\u8fdb\u884c\u6392\u5e8f\u3002</p> </li> <li> <p>\u5f53\u6570\u636e\u5305\u542b\u591a\u4e2a\u5c5e\u6027\uff08\u6216\u5b57\u6bb5\uff09\u65f6\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\u6839\u636e\u8fd9\u4e9b\u5c5e\u6027\u7684\u7ec4\u5408\u6765\u786e\u5b9a\u6570\u636e\u7684\u6700\u7ec8\u987a\u5e8f\u3002</p> <ol> <li>\u786e\u5b9a\u4e3b\u5173\u952e\u5b57\uff1a \u9996\u5148\u9009\u62e9\u4e00\u4e2a\u6700\u4e3b\u8981\u7684\u5173\u952e\u5b57\u4f5c\u4e3a\u6392\u5e8f\u7684\u7b2c\u4e00\u4f18\u5148\u7ea7\u3002</li> <li>\u6b21\u8981\u5173\u952e\u5b57\u53ca\u5176\u4f18\u5148\u7ea7\uff1a \u63a5\u7740\u786e\u5b9a\u6b21\u8981\u5173\u952e\u5b57\uff0c\u5982\u679c\u4e3b\u5173\u952e\u5b57\u7684\u503c\u76f8\u540c\uff0c\u5219\u6309\u7167\u6b21\u8981\u5173\u952e\u5b57\u8fdb\u884c\u6392\u5e8f\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002</li> <li>\u9010\u7ea7\u6bd4\u8f83\uff1a \u6392\u5e8f\u7b97\u6cd5\u4f1a\u5148\u6839\u636e\u4e3b\u5173\u952e\u5b57\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5217\u3002\u5982\u679c\u9047\u5230\u4e3b\u5173\u952e\u5b57\u76f8\u540c\u7684\u6570\u636e\u9879\uff0c\u5b83\u4f1a\u8fdb\u4e00\u6b65\u6bd4\u8f83\u5b83\u4eec\u7684\u6b21\u8981\u5173\u952e\u5b57\uff0c\u76f4\u5230\u627e\u5230\u4e00\u4e2a\u4e0d\u540c\u7684\u5173\u952e\u5b57\uff0c\u6216\u8005\u6240\u6709\u5173\u952e\u5b57\u90fd\u6bd4\u8f83\u5b8c\u6bd5\u3002</li> </ol> </li> <li> <p>\u5b9e\u73b0\u591a\u5173\u952e\u5b57\u6392\u5e8f\u901a\u5e38\u6709\u4ee5\u4e0b\u4e24\u79cd\u65b9\u6cd5\uff1a</p> <ul> <li>\u591a\u8d9f\u6392\u5e8f\uff08Multi-pass Sort\uff09\uff1a \u4f7f\u7528\u4e00\u4e2a\u7a33\u5b9a\u7684\u6392\u5e8f\u7b97\u6cd5\uff08\u5982\u5f52\u5e76\u6392\u5e8f\u6216\u63d2\u5165\u6392\u5e8f\uff09\u5bf9\u6570\u636e\u8fdb\u884c\u591a\u8d9f\u6392\u5e8f\u3002\u4ece\u6700\u4f4e\u4f18\u5148\u7ea7\u7684\u5173\u952e\u5b57\u5f00\u59cb\uff0c\u9010\u7ea7\u5bf9\u6bcf\u4e2a\u5173\u952e\u5b57\u8fdb\u884c\u6392\u5e8f\u3002\u7531\u4e8e\u6bcf\u8d9f\u6392\u5e8f\u90fd\u662f\u7a33\u5b9a\u7684\uff0c\u56e0\u6b64\u524d\u9762\u5df2\u7ecf\u6392\u597d\u7684\u4f4e\u4f18\u5148\u7ea7\u5173\u952e\u5b57\u7684\u76f8\u5bf9\u987a\u5e8f\u4e0d\u4f1a\u88ab\u7834\u574f\u3002</li> <li>\u5355\u4e00\u6bd4\u8f83\u51fd\u6570\uff08Single Comparison Function\uff09\uff1a \u8bb8\u591a\u6392\u5e8f\u7b97\u6cd5\uff08\u5982\u5feb\u901f\u6392\u5e8f\u3001\u5f52\u5e76\u6392\u5e8f\uff09\u5141\u8bb8\u81ea\u5b9a\u4e49\u6bd4\u8f83\u51fd\u6570\u3002\u5728\u8fd9\u4e2a\u6bd4\u8f83\u51fd\u6570\u4e2d\uff0c\u4f60\u53ef\u4ee5\u5b9a\u4e49\u591a\u4e2a\u5173\u952e\u5b57\u7684\u6bd4\u8f83\u903b\u8f91\uff0c\u6309\u7167\u4f18\u5148\u7ea7\u987a\u5e8f\u8fdb\u884c\u5224\u65ad\u3002</li> </ul> </li> <li> <p>\u57fa\u6570\u6392\u5e8f\uff08Radix Sort\uff09\u662f\u4e00\u79cd\u975e\u6bd4\u8f83\u578b\u6574\u6570\u6392\u5e8f\u7b97\u6cd5\uff0c\u5176\u539f\u7406\u662f\u5c06\u6574\u6570\u6309\u4f4d\u6570\u5207\u5272\u6210\u4e0d\u540c\u7684\u6570\u5b57\uff0c\u7136\u540e\u6309\u6bcf\u4e2a\u4f4d\u6570\u5206\u522b\u8fdb\u884c\u6392\u5e8f\u3002\u5b83\u4e0d\u901a\u8fc7\u6bd4\u8f83\u5143\u7d20\u7684\u5927\u5c0f\u6765\u6392\u5e8f\uff0c\u800c\u662f\u901a\u8fc7\u5206\u914d\u548c\u6536\u96c6\u7684\u8fc7\u7a0b\u6765\u5b8c\u6210\u6392\u5e8f\u3002</p> <ol> <li> <p>\u6700\u4f4e\u6709\u6548\u4f4d\u4f18\u5148\uff08LSD Radix Sort\uff09\uff1a</p> <ul> <li>\u4ece\u5f85\u6392\u5e8f\u6570\u5b57\u7684\u6700\u4f4e\u4f4d\uff08\u4e2a\u4f4d\uff09\u5f00\u59cb\uff0c\u5bf9\u6240\u6709\u6570\u5b57\u6839\u636e\u8be5\u4f4d\u4e0a\u7684\u503c\u8fdb\u884c\u201c\u5206\u914d\u201d\u3002\u901a\u5e38\u4f1a\u4f7f\u7528\u6876\uff08Bucket\uff09\u6216\u961f\u5217\u6765\u5b58\u50a8\u76f8\u540c\u4f4d\u503c\u7684\u6570\u5b57\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u521b\u5efa0-9\u768410\u4e2a\u6876\uff0c\u5c06\u4e2a\u4f4d\u662f0\u7684\u6570\u5b57\u653e\u51650\u53f7\u6876\uff0c\u4e2a\u4f4d\u662f1\u7684\u6570\u5b57\u653e\u51651\u53f7\u6876\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002</li> <li>\u5206\u914d\u5b8c\u6210\u540e\uff0c\u6309\u7167\u6876\u7684\u987a\u5e8f\uff08\u4ece0\u52309\uff09\u4f9d\u6b21\u5c06\u6876\u4e2d\u7684\u6570\u5b57\u201c\u6536\u96c6\u201d\u8d77\u6765\uff0c\u5f62\u6210\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217\u3002</li> <li>\u91cd\u590d\u4e0a\u8ff0\u5206\u914d\u548c\u6536\u96c6\u8fc7\u7a0b\uff0c\u4f9d\u6b21\u5bf9\u6570\u5b57\u7684\u66f4\u9ad8\u4f4d\uff08\u5341\u4f4d\u3001\u767e\u4f4d\u7b49\uff09\u8fdb\u884c\u6392\u5e8f\uff0c\u76f4\u5230\u6700\u9ad8\u4f4d\u3002</li> <li>\u7531\u4e8e\u6bcf\u4e00\u6b65\u6392\u5e8f\u90fd\u662f\u7a33\u5b9a\u7684\uff0c\u6240\u4ee5\u7ecf\u8fc7\u6240\u6709\u4f4d\u7684\u6392\u5e8f\u540e\uff0c\u6574\u4e2a\u5e8f\u5217\u5c31\u662f\u6709\u5e8f\u7684\u3002</li> </ul> </li> <li> <p>\u6700\u9ad8\u6709\u6548\u4f4d\u4f18\u5148\uff08MSD Radix Sort\uff09\uff1a</p> <ul> <li>\u4ece\u5f85\u6392\u5e8f\u6570\u5b57\u7684\u6700\u9ad8\u4f4d\u5f00\u59cb\uff0c\u5bf9\u6240\u6709\u6570\u5b57\u6839\u636e\u8be5\u4f4d\u4e0a\u7684\u503c\u8fdb\u884c\u5206\u914d\u3002</li> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u6876\u4e2d\u7684\u5b50\u5e8f\u5217\uff0c\u9012\u5f52\u5730\u5e94\u7528\u57fa\u6570\u6392\u5e8f\uff0c\u5904\u7406\u4e0b\u4e00\u4f4d\u3002</li> <li>\u5f53\u67d0\u4e2a\u6876\u4e2d\u7684\u5b50\u5e8f\u5217\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u6216\u6240\u6709\u5143\u7d20\u7684\u5f53\u524d\u4f4d\u90fd\u76f8\u540c\uff08\u6216\u8005\u8fbe\u5230\u6700\u4f4e\u4f4d\uff09\u65f6\uff0c\u505c\u6b62\u9012\u5f52\u3002</li> <li>\u6700\u540e\u5c06\u6240\u6709\u6876\u4e2d\u7684\u6709\u5e8f\u5b50\u5e8f\u5217\u8fde\u63a5\u8d77\u6765\u3002</li> </ul> </li> <li> <p>\u57fa\u6570\u6392\u5e8f\u9002\u7528\u4e8e\u6574\u6570\uff0c\u4e5f\u53ef\u4ee5\u6269\u5c55\u5230\u5b57\u7b26\u4e32\u548c\u7279\u5b9a\u683c\u5f0f\u7684\u6d6e\u70b9\u6570\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u88ab\u8868\u793a\u4e3a\u4e00\u7cfb\u5217\u7684\u201c\u4f4d\u201d\u6216\u201c\u5b57\u7b26\u201d\u3002</p> </li> </ol> </li> <li> <p>\u7b97\u6cd5\u590d\u6742\u5ea6</p> <ul> <li> <p>\u57fa\u6570\u6392\u5e8f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\u57fa\u6570\u6392\u5e8f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(d \\cdot (n + k))\\)\uff0c\u5176\u4e2d\uff1a<ul> <li>\\(n\\) \u662f\u5f85\u6392\u5e8f\u5143\u7d20\u7684\u6570\u91cf\u3002</li> <li>\\(d\\) \u662f\u6570\u5b57\u7684\u6700\u5927\u4f4d\u6570\uff08\u6216\u8005\u8bf4\uff0c\u9700\u8981\u8fdb\u884c\u591a\u5c11\u8f6e\u6392\u5e8f\uff09\u3002</li> <li>\\(k\\) \u662f\u57fa\u6570\uff08radix\uff09\uff0c\u901a\u5e38\u662f\u6bcf\u4e2a\u4f4d\u4e0a\u53ef\u80fd\u51fa\u73b0\u7684\u4e0d\u540c\u503c\u7684\u6570\u91cf\uff0c\u4f8b\u5982\uff0c\u5bf9\u4e8e\u5341\u8fdb\u5236\u6570\u5b57\uff0c \\(k=10\\)\uff1b\u5bf9\u4e8e\u4e8c\u8fdb\u5236\u6570\u5b57\uff0c \\(k=2\\)\u3002</li> </ul> </li> <li>\u6bcf\u8d9f\u6392\u5e8f\uff08\u5bf9\u4e00\u4f4d\u8fdb\u884c\u5206\u914d\u548c\u6536\u96c6\uff09\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(n + k)\\)\u3002\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u904d\u5386\u6240\u6709 \\(n\\) \u4e2a\u6570\u5b57\u8fdb\u884c\u5206\u914d\uff0c\u7136\u540e\u904d\u5386 \\(k\\) \u4e2a\u6876\u5e76\u5c06\u6240\u6709\u6570\u5b57\u6536\u96c6\u8d77\u6765\u3002</li> <li>\u603b\u5171\u6709 \\(d\\) \u8d9f\u6392\u5e8f\uff0c\u6240\u4ee5\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(d \\cdot (n + k))\\)\u3002</li> </ul> </li> <li> <p>\u57fa\u6570\u6392\u5e8f\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\u57fa\u6570\u6392\u5e8f\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(n + k)\\)\u3002</li> <li>\\(O(k)\\) \u7528\u4e8e\u5b58\u50a8 \\(k\\) \u4e2a\u6876\u3002</li> <li>\\(O(n)\\) \u7528\u4e8e\u5728\u5206\u914d\u8fc7\u7a0b\u4e2d\u4e34\u65f6\u5b58\u50a8\u6570\u5b57\uff0c\u6216\u8005\u7528\u4e8e\u6536\u96c6\u65f6\u7684\u65b0\u5e8f\u5217\u3002</li> </ul> </li> </ul> </li> <li> <p>\u4e0e\u6bd4\u8f83\u6392\u5e8f\u7684\u6bd4\u8f83\uff1a</p> <ul> <li>\u57fa\u6570\u6392\u5e8f\u662f\u975e\u6bd4\u8f83\u578b\u6392\u5e8f\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u53ef\u4ee5\u8fbe\u5230\u7ebf\u6027\u7ea7\u522b\uff0c\u5373 \\(O(n)\\)\uff0c\u5f53 \\(d\\) \u548c \\(k\\) \u76f8\u5bf9\u4e8e \\(n\\) \u8f83\u5c0f\u65f6\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6240\u6709\u6570\u5b57\u7684\u4f4d\u6570 \\(d\\) \u8f83\u5c0f\uff0c\u5e76\u4e14\u57fa\u6570 \\(k\\) \u4e5f\u8f83\u5c0f\uff08\u5e38\u6570\uff09\uff0c\u90a3\u4e48\u57fa\u6570\u6392\u5e8f\u4f1a\u6bd4\u4efb\u4f55\u57fa\u4e8e\u6bd4\u8f83\u7684\u6392\u5e8f\u7b97\u6cd5\uff08\u5982\u5feb\u901f\u6392\u5e8f\u3001\u5f52\u5e76\u6392\u5e8f\u7b49\uff0c\u5b83\u4eec\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u901a\u5e38\u4e3a \\(O(n \\log n)\\)\uff09\u66f4\u5feb\u3002</li> <li>\u7136\u800c\uff0c\u57fa\u6570\u6392\u5e8f\u5bf9\u6570\u636e\u7c7b\u578b\u6709\u4e25\u683c\u8981\u6c42\uff08\u901a\u5e38\u662f\u6574\u6570\u6216\u53ef\u8f6c\u6362\u4e3a\u6574\u6570\u7684\u7c7b\u578b\uff09\uff0c\u5e76\u4e14\u9700\u8981\u989d\u5916\u7684\u7a7a\u95f4\u6765\u5b58\u50a8\u6876\u3002\u800c\u6bd4\u8f83\u6392\u5e8f\u5219\u66f4\u901a\u7528\uff0c\u53ef\u4ee5\u9002\u7528\u4e8e\u5404\u79cd\u7c7b\u578b\u7684\u6570\u636e\u3002</li> </ul> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#kmpnext", "title": "\u4ec0\u4e48\u662fKMP\u7b97\u6cd5\uff1f\u4ec0\u4e48\u662f\u76ee\u6807\u4e32\uff1f\u4ec0\u4e48\u662f\u6a21\u5f0f\u4e32\uff1fnext\u6570\u7ec4\u8d77\u5230\u4ec0\u4e48\u4f5c\u7528\uff1f", "text": "<ul> <li> <p>KMP (Knuth-Morris-Pratt) \u7b97\u6cd5\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5b57\u7b26\u4e32\u641c\u7d22\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u4e00\u4e2a\u8f83\u957f\u7684\u76ee\u6807\u4e32\uff08\u6216\u79f0\u4e3b\u4e32\u3001\u6587\u672c\u4e32\uff09\u4e2d\u67e5\u627e\u4e00\u4e2a\u8f83\u77ed\u7684\u6a21\u5f0f\u4e32\uff08\u6216\u79f0\u5b50\u4e32\u3001\u5173\u952e\u5b57\uff09\u7684\u6240\u6709\u51fa\u73b0\u4f4d\u7f6e\u3002\u4e0e\u6734\u7d20\u7684\u5b57\u7b26\u4e32\u5339\u914d\u7b97\u6cd5\u4e0d\u540c\uff0cKMP \u7b97\u6cd5\u901a\u8fc7\u9884\u5904\u7406\u6a21\u5f0f\u4e32\uff0c\u907f\u514d\u4e86\u5728\u53d1\u751f\u4e0d\u5339\u914d\u65f6\uff0c\u76ee\u6807\u4e32\u6307\u9488\u4e0d\u5fc5\u8981\u7684\u201c\u56de\u6eaf\u201d\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u7ebf\u6027\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002</p> </li> <li> <p>KMP \u7b97\u6cd5\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff0c\u5f53\u6a21\u5f0f\u4e32\u4e0e\u76ee\u6807\u4e32\u53d1\u751f\u4e0d\u5339\u914d\u65f6\uff0c\u5b83\u4e0d\u4f1a\u7b80\u5355\u5730\u5c06\u6a21\u5f0f\u4e32\u5411\u53f3\u79fb\u52a8\u4e00\u4f4d\u5e76\u4ece\u5934\u5f00\u59cb\u6bd4\u8f83\u3002\u76f8\u53cd\uff0c\u5b83\u4f1a\u5229\u7528\u5df2\u7ecf\u5339\u914d\u7684\u90e8\u5206\u4fe1\u606f\uff0c\u5373\u6a21\u5f0f\u4e32\u81ea\u8eab\u7684\u7ed3\u6784\u7279\u70b9\uff0c\u6765\u51b3\u5b9a\u6a21\u5f0f\u4e32\u5e94\u8be5\u201c\u8df3\u8dc3\u201d\u5230\u54ea\u4e2a\u4f4d\u7f6e\u7ee7\u7eed\u6bd4\u8f83\u3002\u8fd9\u79cd\u201c\u8df3\u8dc3\u201d\u662f\u57fa\u4e8e\u6a21\u5f0f\u4e32\u7684\u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u4fe1\u606f\u3002</p> </li> <li> <p>\u5177\u4f53\u6765\u8bf4\uff0cKMP \u7b97\u6cd5\u5206\u4e3a\u4e24\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a</p> <ol> <li> <p>\u6a21\u5f0f\u4e32\u9884\u5904\u7406\uff08\u6784\u5efa next \u6570\u7ec4\uff09\uff1a</p> <p>\u8fd9\u4e2a\u9636\u6bb5\u662f KMP \u7b97\u6cd5\u7684\u5173\u952e\uff0c\u5b83\u5728\u5339\u914d\u5f00\u59cb\u4e4b\u524d\u5bf9\u6a21\u5f0f\u4e32\u8fdb\u884c\u5206\u6790\uff0c\u751f\u6210\u4e00\u4e2a\u88ab\u79f0\u4e3a <code>next</code> \u6570\u7ec4\uff08\u6216\u79f0 <code>LPS</code> \u6570\u7ec4\uff0c\u5373\u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u6570\u7ec4\uff09\u3002<code>next[i]</code> \u7684\u503c\u8868\u793a\u6a21\u5f0f\u4e32 <code>P</code> \u7684\u524d <code>i</code> \u4e2a\u5b57\u7b26\u6784\u6210\u7684\u5b50\u4e32 <code>P[0...i-1]</code> \u4e2d\uff0c\u6700\u957f\u7684\u516c\u5171\u524d\u7f00\uff08\u540c\u65f6\u4e5f\u662f\u540e\u7f00\uff09\u7684\u957f\u5ea6\u3002</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u6a21\u5f0f\u4e32\u4e3a \"ababa\"\uff0c\u90a3\u4e48\uff1a * <code>P[0]</code> (\"a\"): \u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u957f\u5ea6\u4e3a 0\u3002 * <code>P[0...1]</code> (\"ab\"): \u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u957f\u5ea6\u4e3a 0\u3002 * <code>P[0...2]</code> (\"aba\"): \u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u957f\u5ea6\u4e3a 1 (\"a\")\u3002 * <code>P[0...3]</code> (\"abab\"): \u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u957f\u5ea6\u4e3a 2 (\"ab\")\u3002 * <code>P[0...4]</code> (\"ababa\"): \u6700\u957f\u516c\u5171\u524d\u7f00\u540e\u7f00\u957f\u5ea6\u4e3a 3 (\"aba\")\u3002</p> <p>\u8fd9\u4e2a <code>next</code> \u6570\u7ec4\u5728\u5339\u914d\u8fc7\u7a0b\u4e2d\u8d77\u5230\u4e86\u6307\u5bfc\u6a21\u5f0f\u4e32\u5982\u4f55\u201c\u8df3\u8dc3\u201d\u7684\u4f5c\u7528\u3002</p> </li> <li> <p>\u6a21\u5f0f\u4e32\u4e0e\u76ee\u6807\u4e32\u7684\u5339\u914d\uff1a</p> <p>\u5728\u5339\u914d\u9636\u6bb5\uff0c\u7b97\u6cd5\u4f7f\u7528\u4e24\u4e2a\u6307\u9488\uff0c\u4e00\u4e2a\u6307\u5411\u76ee\u6807\u4e32\uff08\u901a\u5e38\u8bb0\u4e3a <code>i</code>\uff09\uff0c\u4e00\u4e2a\u6307\u5411\u6a21\u5f0f\u4e32\uff08\u901a\u5e38\u8bb0\u4e3a <code>j</code>\uff09\u3002</p> <ul> <li>\u5339\u914d\u6210\u529f\u65f6\uff1a \u5982\u679c <code>\u76ee\u6807\u4e32[i]</code> \u548c <code>\u6a21\u5f0f\u4e32[j]</code> \u76f8\u7b49\uff0c\u5219 <code>i</code> \u548c <code>j</code> \u90fd\u5411\u540e\u79fb\u52a8\u4e00\u4f4d\uff0c\u7ee7\u7eed\u6bd4\u8f83\u4e0b\u4e00\u4e2a\u5b57\u7b26\u3002</li> <li>\u5339\u914d\u5931\u8d25\u65f6\uff1a \u5982\u679c <code>\u76ee\u6807\u4e32[i]</code> \u548c <code>\u6a21\u5f0f\u4e32[j]</code> \u4e0d\u7b49\uff0c\u6b64\u65f6 KMP \u7b97\u6cd5\u5c31\u5229\u7528 <code>next</code> \u6570\u7ec4\u6765\u786e\u5b9a\u6a21\u5f0f\u4e32\u7684\u65b0\u4f4d\u7f6e\u3002<ul> <li>\u5982\u679c <code>j &gt; 0</code> (\u5373\u6a21\u5f0f\u4e32\u5df2\u7ecf\u5339\u914d\u4e86\u4e00\u90e8\u5206)\uff0c\u90a3\u4e48 <code>j</code> \u4f1a\u88ab\u66f4\u65b0\u4e3a <code>next[j-1]</code>\u3002\u8fd9\u610f\u5473\u7740\u6a21\u5f0f\u4e32\u4f1a\u201c\u56de\u9000\u201d\u5230 <code>next[j-1]</code> \u6240\u6307\u793a\u7684\u957f\u5ea6\u4f4d\u7f6e\uff0c\u56e0\u4e3a\u6a21\u5f0f\u4e32\u7684\u524d <code>next[j-1]</code> \u4e2a\u5b57\u7b26\u5df2\u77e5\u662f\u5f53\u524d\u5df2\u5339\u914d\u90e8\u5206\u7684\u540e\u7f00\uff0c\u4ece\u800c\u907f\u514d\u4e86\u91cd\u590d\u6bd4\u8f83\u3002</li> <li>\u5982\u679c <code>j == 0</code> (\u5373\u6a21\u5f0f\u4e32\u7684\u7b2c\u4e00\u4e2a\u5b57\u7b26\u5c31\u672a\u5339\u914d\u6210\u529f)\uff0c\u5219\u76ee\u6807\u4e32\u6307\u9488 <code>i</code> \u5411\u540e\u79fb\u52a8\u4e00\u4f4d\uff0c\u6a21\u5f0f\u4e32\u6307\u9488 <code>j</code> \u4fdd\u6301\u5728 0\uff0c\u4ece\u6a21\u5f0f\u4e32\u7684\u5f00\u5934\u91cd\u65b0\u5f00\u59cb\u6bd4\u8f83\u3002</li> </ul> </li> </ul> <p>\u8fd9\u4e2a\u8fc7\u7a0b\u6301\u7eed\u8fdb\u884c\uff0c\u76f4\u5230\u6a21\u5f0f\u4e32\u5b8c\u5168\u5339\u914d\u6210\u529f\uff08<code>j</code> \u8fbe\u5230\u6a21\u5f0f\u4e32\u7684\u957f\u5ea6\uff09\uff0c\u6216\u8005\u76ee\u6807\u4e32\u5df2\u7ecf\u904d\u5386\u5b8c\u6bd5\u3002</p> </li> </ol> </li> <li> <p>\u76ee\u6807\u4e32\uff08Target String\uff09\uff0c\u4e5f\u79f0\u4e3a\u4e3b\u4e32\u6216\u6587\u672c\u4e32\uff08Text String\uff09\uff0c\u662f\u6307\u6211\u4eec\u8981\u5728\u5176\u4e2d\u8fdb\u884c\u641c\u7d22\u7684\u3001\u8f83\u957f\u7684\u5b57\u7b26\u4e32\u3002KMP \u7b97\u6cd5\u7684\u76ee\u7684\u5c31\u662f\u5728\u76ee\u6807\u4e32\u4e2d\u627e\u5230\u6a21\u5f0f\u4e32\u7684\u51fa\u73b0\u4f4d\u7f6e\u3002</p> </li> <li> <p>\u6a21\u5f0f\u4e32\uff08Pattern String\uff09\uff0c\u4e5f\u79f0\u4e3a\u5b50\u4e32\u6216\u5173\u952e\u5b57\uff0c\u662f\u6307\u6211\u4eec\u60f3\u8981\u5728\u76ee\u6807\u4e32\u4e2d\u67e5\u627e\u7684\u3001\u8f83\u77ed\u7684\u5b57\u7b26\u4e32\u3002KMP \u7b97\u6cd5\u4f1a\u5c1d\u8bd5\u5c06\u6a21\u5f0f\u4e32\u7684\u5404\u4e2a\u4f4d\u7f6e\u4e0e\u76ee\u6807\u4e32\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u786e\u5b9a\u6a21\u5f0f\u4e32\u662f\u5426\u5b58\u5728\u4e8e\u76ee\u6807\u4e32\u4e2d\uff0c\u4ee5\u53ca\u5b58\u5728\u7684\u4f4d\u7f6e\u3002</p> </li> <li> <p><code>next</code> \u6570\u7ec4\uff08\u4e5f\u5e38\u88ab\u79f0\u4e3a <code>LPS</code> \u6570\u7ec4\uff0c\u5373 Longest Proper Prefix which is also a Suffix \u7684\u7f29\u5199\uff09\u662f KMP \u7b97\u6cd5\u7684\u6838\u5fc3\u8f85\u52a9\u6570\u636e\u7ed3\u6784\u3002\u5b83\u7684\u4f5c\u7528\u53ef\u4ee5\u6982\u62ec\u4e3a\uff1a</p> <ol> <li> <p>\u5b58\u50a8\u6a21\u5f0f\u4e32\u81ea\u8eab\u7684\u7ed3\u6784\u4fe1\u606f\uff1a <code>next[i]</code> \u7684\u503c\u8bb0\u5f55\u4e86\u6a21\u5f0f\u4e32 <code>P</code> \u7684\u524d <code>i</code> \u4e2a\u5b57\u7b26\u6240\u7ec4\u6210\u7684\u5b50\u4e32 <code>P[0...i-1]</code> \u4e2d\uff0c\u6700\u957f\u7684\u3001\u975e\u81ea\u8eab\u7684\u3001\u65e2\u662f\u524d\u7f00\u53c8\u662f\u540e\u7f00\u7684\u5b50\u4e32\u7684\u957f\u5ea6\u3002</p> </li> <li> <p>\u907f\u514d\u76ee\u6807\u4e32\u6307\u9488\u7684\u56de\u6eaf\uff1a \u5f53\u6a21\u5f0f\u4e32\u548c\u76ee\u6807\u4e32\u5728\u67d0\u4e2a\u4f4d\u7f6e\u53d1\u751f\u4e0d\u5339\u914d\u65f6\uff0c<code>next</code> \u6570\u7ec4\u4f1a\u6307\u5bfc\u6a21\u5f0f\u4e32\u5982\u4f55\u201c\u9ad8\u6548\u5730\u201d\u5411\u53f3\u79fb\u52a8\uff0c\u800c\u4e0d\u9700\u8981\u5c06\u76ee\u6807\u4e32\u7684\u6307\u9488\u56de\u6eaf\u5230\u4e4b\u524d\u7684\u4f4d\u7f6e\u3002\u5b83\u544a\u8bc9\u6211\u4eec\uff0c\u5f53\u524d\u6a21\u5f0f\u4e32\u5df2\u5339\u914d\u7684\u90e8\u5206\u4e2d\uff0c\u6709\u4e00\u4e2a\u957f\u5ea6\u4e3a <code>next[j-1]</code> \u7684\u524d\u7f00\uff08<code>P[0...next[j-1]-1]</code>\uff09\u4e0e\u5df2\u5339\u914d\u90e8\u5206\u7684\u540e\u7f00\uff08<code>P[j-next[j-1]...j-1]</code>\uff09\u662f\u76f8\u540c\u7684\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u6a21\u5f0f\u4e32\u5411\u53f3\u79fb\u52a8\uff0c\u4f7f\u5f97\u6a21\u5f0f\u4e32\u7684 <code>next[j-1]</code> \u4f4d\u7f6e\u7684\u5b57\u7b26\u5bf9\u9f50\u5230\u76ee\u6807\u4e32\u5f53\u524d\u4e0d\u5339\u914d\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u7ee7\u7eed\u4ece <code>\u6a21\u5f0f\u4e32[next[j-1]]</code> \u5904\u5f00\u59cb\u6bd4\u8f83\u3002</p> </li> <li> <p>\u63d0\u9ad8\u5339\u914d\u6548\u7387\uff1a \u901a\u8fc7\u5229\u7528 <code>next</code> \u6570\u7ec4\uff0cKMP \u7b97\u6cd5\u5728\u53d1\u751f\u4e0d\u5339\u914d\u65f6\uff0c\u80fd\u591f\u201c\u8df3\u8fc7\u201d\u90a3\u4e9b\u4e0d\u53ef\u80fd\u5339\u914d\u7684\u4f4d\u7f6e\uff0c\u4ece\u800c\u5927\u5927\u51cf\u5c11\u4e86\u5b57\u7b26\u6bd4\u8f83\u7684\u6b21\u6570\uff0c\u4f7f\u5f97\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u8fbe\u5230\u7ebf\u6027\uff0c\u5373 \\(O(N+M)\\)\uff0c\u5176\u4e2d \\(N\\) \u662f\u76ee\u6807\u4e32\u7684\u957f\u5ea6\uff0c\\(M\\) \u662f\u6a21\u5f0f\u4e32\u7684\u957f\u5ea6\u3002\u5982\u679c\u6ca1\u6709 <code>next</code> \u6570\u7ec4\uff0c\u6734\u7d20\u7684\u5b57\u7b26\u4e32\u5339\u914d\u7b97\u6cd5\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u53ef\u80fd\u8fbe\u5230 \\(O(N \\cdot M)\\) \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002</p> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_18", "title": "\u5e38\u7528\u7684\u6392\u5e8f\u7b97\u6cd5\u6709\u54ea\u4e9b\uff1f\u54ea\u4e9b\u6392\u5e8f\u7b97\u6cd5\u662f\u7a33\u5b9a\u7684\uff0c\u54ea\u4e9b\u662f\u4e0d\u7a33\u5b9a\u7684\uff1f\u8fd9\u4e9b\u6392\u5e8f\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u5982\u4f55\uff1f\u5355\u8d9f\u6392\u5e8f\u80fd\u51b3\u5b9a\u67d0\u4e2a\uff08\u4e9b\uff09\u5143\u7d20\u7684\u6700\u7ec8\u4f4d\u7f6e\u7684\u6392\u5e8f\u7b97\u6cd5\u6709\u54ea\u4e9b\uff1f", "text": "<ul> <li>\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u7684\u6392\u5e8f\u7b97\u6cd5\uff1a<ol> <li>\u5192\u6ce1\u6392\u5e8f (Bubble Sort)</li> <li>\u9009\u62e9\u6392\u5e8f (Selection Sort)</li> <li>\u63d2\u5165\u6392\u5e8f (Insertion Sort)</li> <li>\u5feb\u901f\u6392\u5e8f (Quick Sort)</li> <li>\u5f52\u5e76\u6392\u5e8f (Merge Sort)</li> <li>\u5806\u6392\u5e8f (Heap Sort)</li> <li>\u8ba1\u6570\u6392\u5e8f (Counting Sort)</li> <li>\u6876\u6392\u5e8f (Bucket Sort)</li> <li>\u57fa\u6570\u6392\u5e8f (Radix Sort)</li> </ol> </li> <li>\u7b97\u6cd5\u7684\u5177\u4f53\u5185\u5bb9\u548c\u539f\u7406\uff0c\u8bf7\u7ed3\u5408\u6559\u6750\u81ea\u884c\u590d\u4e60\u3002</li> <li> <p>\u6392\u5e8f\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u662f\u6307\u5f53\u5f85\u6392\u5e8f\u5e8f\u5217\u4e2d\u5b58\u5728\u503c\u76f8\u7b49\u7684\u5143\u7d20\u65f6\uff0c\u7ecf\u8fc7\u6392\u5e8f\u4e4b\u540e\uff0c\u8fd9\u4e9b\u76f8\u7b49\u5143\u7d20\u7684\u76f8\u5bf9\u6b21\u5e8f\u4fdd\u6301\u4e0d\u53d8\u3002</p> <ul> <li> <p>\u7a33\u5b9a\u7684\u6392\u5e8f\u7b97\u6cd5\uff1a</p> <ul> <li>\u5192\u6ce1\u6392\u5e8f</li> <li>\u76f4\u63a5\u63d2\u5165\u6392\u5e8f</li> <li>\u5f52\u5e76\u6392\u5e8f</li> <li>\u8ba1\u6570\u6392\u5e8f</li> <li>\u6876\u6392\u5e8f</li> <li>\u57fa\u6570\u6392\u5e8f</li> </ul> </li> <li> <p>\u4e0d\u7a33\u5b9a\u7684\u6392\u5e8f\u7b97\u6cd5\uff1a</p> <ul> <li>\u9009\u62e9\u6392\u5e8f</li> <li>\u5feb\u901f\u6392\u5e8f</li> <li>\u5806\u6392\u5e8f</li> <li>\u5e0c\u5c14\u6392\u5e8f</li> </ul> </li> </ul> </li> <li> <p>\u6392\u5e8f\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6</p> </li> </ul> \u6392\u5e8f\u7b97\u6cd5 \u6700\u597d\u65f6\u95f4\u590d\u6742\u5ea6 \u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6 \u6700\u574f\u65f6\u95f4\u590d\u6742\u5ea6 \u7a7a\u95f4\u590d\u6742\u5ea6 \u7a33\u5b9a\u6027 \u5192\u6ce1\u6392\u5e8f \\(O(n)\\) \\(O(n^2)\\) \\(O(n^2)\\) \\(O(1)\\) \u7a33\u5b9a \u9009\u62e9\u6392\u5e8f \\(O(n^2)\\) \\(O(n^2)\\) \\(O(n^2)\\) \\(O(1)\\) \u4e0d\u7a33\u5b9a \u63d2\u5165\u6392\u5e8f \\(O(n)\\) \\(O(n^2)\\) \\(O(n^2)\\) \\(O(1)\\) \u7a33\u5b9a \u5feb\u901f\u6392\u5e8f \\(O(n \\log n)\\) \\(O(n \\log n)\\) \\(O(n^2)\\) \\(O(\\log n)\\) \u5230 \\(O(n)\\) \u4e0d\u7a33\u5b9a \u5f52\u5e76\u6392\u5e8f \\(O(n \\log n)\\) \\(O(n \\log n)\\) \\(O(n \\log n)\\) \\(O(n)\\) \u7a33\u5b9a \u5806\u6392\u5e8f \\(O(n \\log n)\\) \\(O(n \\log n)\\) \\(O(n \\log n)\\) \\(O(1)\\) \u4e0d\u7a33\u5b9a \u8ba1\u6570\u6392\u5e8f \\(O(n+k)\\) \\(O(n+k)\\) \\(O(n+k)\\) \\(O(k)\\) \u7a33\u5b9a \u6876\u6392\u5e8f \\(O(n+k)\\) \\(O(n+k)\\) \\(O(n^2)\\) \\(O(n+k)\\) \u7a33\u5b9a \u57fa\u6570\u6392\u5e8f \\(O(nk)\\) \\(O(nk)\\) \\(O(nk)\\) \\(O(n+k)\\) \u7a33\u5b9a <p>\u89e3\u91ca\uff1a</p> <ul> <li>\\(n\\): \u5f85\u6392\u5e8f\u5143\u7d20\u7684\u6570\u91cf</li> <li>\\(k\\): \u8ba1\u6570\u6392\u5e8f\u4e2d\uff0c\u5f85\u6392\u5e8f\u5143\u7d20\u7684\u6700\u5927\u503c\u4e0e\u6700\u5c0f\u503c\u4e4b\u5dee\u52a0\u4e00\uff1b\u6876\u6392\u5e8f\u4e2d\uff0c\u6876\u7684\u6570\u91cf\uff1b\u57fa\u6570\u6392\u5e8f\u4e2d\uff0c\u6700\u5927\u6570\u7684\u4f4d\u6570\u3002</li> <li>\\(O(1)\\): \u5e38\u6570\u7a7a\u95f4\uff0c\u8868\u793a\u53ea\u4f7f\u7528\u4e86\u5c11\u91cf\u989d\u5916\u7a7a\u95f4\u3002</li> <li>\\(O(\\log n)\\): \u5bf9\u6570\u7a7a\u95f4\uff0c\u901a\u5e38\u662f\u9012\u5f52\u8c03\u7528\u6808\u7684\u7a7a\u95f4\u3002</li> <li> <p>\\(O(n)\\): \u7ebf\u6027\u7a7a\u95f4\uff0c\u8868\u793a\u989d\u5916\u7a7a\u95f4\u4e0e\u8f93\u5165\u89c4\u6a21\u6210\u6b63\u6bd4\u3002</p> </li> <li> <p>\u4ee5\u4e0b\u6392\u5e8f\u7b97\u6cd5\u5728\u5355\u8d9f\uff08\u6216\u4e00\u6b21\u8fed\u4ee3\uff09\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u591f\u786e\u5b9a\u81f3\u5c11\u4e00\u4e2a\uff08\u6216\u67d0\u4e9b\uff09\u5143\u7d20\u7684\u6700\u7ec8\u6392\u5e8f\u4f4d\u7f6e\uff08\u4e5f\u5c31\u662f\u8bf4\uff0c\u5f62\u6210\u7684\u6709\u5e8f\u533a\u662f\u5168\u5c40\u7684\uff09\uff1a</p> <ol> <li> <p>\u9009\u62e9\u6392\u5e8f: \u6bcf\u8d9f\u9009\u62e9\u672a\u6392\u5e8f\u90e8\u5206\u4e2d\u7684\u6700\u5c0f\uff08\u6216\u6700\u5927\uff09\u5143\u7d20\uff0c\u5e76\u5c06\u5176\u653e\u5230\u5df2\u6392\u5e8f\u90e8\u5206\u7684\u672b\u5c3e\u3002\u56e0\u6b64\uff0c\u6bcf\u8d9f\u90fd\u80fd\u786e\u5b9a\u4e00\u4e2a\u5143\u7d20\u7684\u6700\u7ec8\u4f4d\u7f6e\u3002</p> </li> <li> <p>\u5feb\u901f\u6392\u5e8f: \u5728\u6bcf\u4e00\u8d9f\u5206\u533a\uff08partition\uff09\u64cd\u4f5c\u4e2d\uff0c\u57fa\u51c6\u5143\u7d20\uff08pivot\uff09\u4f1a\u88ab\u653e\u7f6e\u5230\u5176\u6700\u7ec8\u7684\u6392\u5e8f\u4f4d\u7f6e\u4e0a\u3002</p> </li> <li> <p>\u5806\u6392\u5e8f (Heap Sort): \u5728\u6784\u5efa\u5b8c\u5927\u9876\u5806\uff08\u6216\u5c0f\u9876\u5806\uff09\u540e\uff0c\u6bcf\u6b21\u53d6\u51fa\u5806\u9876\u5143\u7d20\uff08\u6700\u5927\u6216\u6700\u5c0f\uff09\u5e76\u5c06\u5176\u653e\u5230\u6570\u7ec4\u7684\u672b\u5c3e\uff0c\u8fd9\u4e2a\u5143\u7d20\u5c31\u786e\u5b9a\u4e86\u5176\u6700\u7ec8\u4f4d\u7f6e\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u91cd\u590d \\(n-1\\) \u6b21\uff0c\u6bcf\u6b21\u786e\u5b9a\u4e00\u4e2a\u5143\u7d20\u3002</p> </li> <li> <p>\u5192\u6ce1\u6392\u5e8f (Bubble Sort): \u6bcf\u8d9f\u5192\u6ce1\u6392\u5e8f\u4f1a\u628a\u5f53\u524d\u672a\u6392\u5e8f\u90e8\u5206\u7684\u6700\u5927\uff08\u6216\u6700\u5c0f\uff09\u5143\u7d20\u201c\u5192\u6ce1\u201d\u5230\u5176\u6700\u7ec8\u4f4d\u7f6e\u3002\u4f8b\u5982\uff0c\u4e00\u8d9f\u5192\u6ce1\u540e\uff0c\u6700\u5927\u7684\u5143\u7d20\u4f1a\u4f4d\u4e8e\u6570\u7ec4\u7684\u672b\u5c3e\u3002</p> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#_19", "title": "\u4ec0\u4e48\u662f\u5bf9\u534a\u641c\u7d22\u7b97\u6cd5\uff1f\u9002\u7528\u6761\u4ef6\u662f\u4ec0\u4e48\uff1f\u7b97\u6cd5\u590d\u6742\u5ea6\u5982\u4f55\uff1f\u4ec0\u4e48\u662f\u4e8c\u53c9\u5224\u5b9a\u6811\uff0c\u600e\u6837\u5229\u7528\u4e8c\u53c9\u5224\u5b9a\u6811\u8ba1\u7b97\u5e73\u5747\u641c\u7d22\u957f\u5ea6\uff1f", "text": "<ul> <li> <p>\u5bf9\u534a\u641c\u7d22\u7b97\u6cd5\uff0c\u4e5f\u79f0\u4e3a\u4e8c\u5206\u67e5\u627e\uff08Binary Search\uff09\uff0c\u662f\u4e00\u79cd\u5728\u6709\u5e8f\u6570\u7ec4\u4e2d\u67e5\u627e\u7279\u5b9a\u5143\u7d20\u7684\u641c\u7d22\u7b97\u6cd5\u3002\u5b83\u7684\u57fa\u672c\u601d\u60f3\u662f\uff1a\u6bcf\u6b21\u6bd4\u8f83\u6570\u7ec4\u4e2d\u95f4\u7684\u5143\u7d20\u4e0e\u76ee\u6807\u503c\uff0c\u5982\u679c\u76ee\u6807\u503c\u4e0e\u8be5\u5143\u7d20\u5339\u914d\uff0c\u5219\u67e5\u627e\u6210\u529f\uff1b\u5982\u679c\u76ee\u6807\u503c\u5c0f\u4e8e\u8be5\u5143\u7d20\uff0c\u5219\u5728\u6570\u7ec4\u8f83\u5c0f\u7684\u90a3\u4e00\u534a\u4e2d\u7ee7\u7eed\u67e5\u627e\uff1b\u5982\u679c\u76ee\u6807\u503c\u5927\u4e8e\u8be5\u5143\u7d20\uff0c\u5219\u5728\u6570\u7ec4\u8f83\u5927\u7684\u90a3\u4e00\u534a\u4e2d\u7ee7\u7eed\u67e5\u627e\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u80fd\u5c06\u641c\u7d22\u8303\u56f4\u7f29\u5c0f\u4e00\u534a\u3002</p> </li> <li> <p>\u9002\u7528\u6761\u4ef6\uff1a</p> <ul> <li>\u6570\u636e\u5fc5\u987b\u662f\u6709\u5e8f\u7684\uff1a \u8fd9\u662f\u4e8c\u5206\u67e5\u627e\u6700\u6838\u5fc3\u7684\u6761\u4ef6\u3002\u65e0\u8bba\u662f\u5347\u5e8f\u8fd8\u662f\u964d\u5e8f\u6392\u5217\uff0c\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\u90fd\u5fc5\u987b\u6309\u7167\u67d0\u79cd\u987a\u5e8f\u6392\u5217\u3002\u5982\u679c\u6570\u636e\u65e0\u5e8f\uff0c\u5219\u65e0\u6cd5\u4f7f\u7528\u4e8c\u5206\u67e5\u627e\u3002</li> <li>\u6570\u636e\u5b58\u50a8\u5728\u968f\u673a\u8bbf\u95ee\u7684\u6570\u636e\u7ed3\u6784\u4e2d\uff1a \u901a\u5e38\u662f\u6570\u7ec4\u3002\u56e0\u4e3a\u4e8c\u5206\u67e5\u627e\u9700\u8981\u901a\u8fc7\u7d22\u5f15\u76f4\u63a5\u8bbf\u95ee\u4e2d\u95f4\u5143\u7d20\uff0c\u94fe\u8868\u7b49\u987a\u5e8f\u8bbf\u95ee\u7684\u6570\u636e\u7ed3\u6784\u4e0d\u9002\u5408\u3002</li> </ul> </li> <li> <p>\u7b97\u6cd5\u590d\u6742\u5ea6\uff1a</p> <ul> <li>\u65f6\u95f4\u590d\u6742\u5ea6\uff1a \\(O(\\log n)\\)\u3002<ul> <li>\u5728\u6bcf\u6b21\u6bd4\u8f83\u540e\uff0c\u641c\u7d22\u8303\u56f4\u90fd\u4f1a\u51cf\u534a\u3002\u8fd9\u610f\u5473\u7740\u5728\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u67e5\u627e\u6240\u9700\u7684\u64cd\u4f5c\u6b21\u6570\u4e0e\u6570\u7ec4\u5927\u5c0f\u7684\u5bf9\u6570\u6210\u6b63\u6bd4\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u5305\u542b \\(n\\) \u4e2a\u5143\u7d20\u7684\u6570\u7ec4\uff0c\u6700\u591a\u9700\u8981 \\(\\log_2 n\\) \u6b21\u6bd4\u8f83\u3002</li> </ul> </li> <li>\u7a7a\u95f4\u590d\u6742\u5ea6\uff1a \\(O(1)\\) (\u8fed\u4ee3\u5b9e\u73b0) \u6216 \\(O(\\log n)\\) (\u9012\u5f52\u5b9e\u73b0)\u3002<ul> <li>\u8fed\u4ee3\u5b9e\u73b0\u53ea\u9700\u8981\u5e38\u6570\u7ea7\u522b\u7684\u989d\u5916\u7a7a\u95f4\u6765\u5b58\u50a8\u7d22\u5f15\u53d8\u91cf\u3002</li> <li>\u9012\u5f52\u5b9e\u73b0\u4f1a\u56e0\u4e3a\u51fd\u6570\u8c03\u7528\u7684\u6808\u5e27\u800c\u6d88\u8017\u4e0e\u9012\u5f52\u6df1\u5ea6\u6210\u6b63\u6bd4\u7684\u7a7a\u95f4\uff0c\u5373 \\(O(\\log n)\\)\u3002</li> </ul> </li> </ul> </li> <li> <p>\u4e8c\u53c9\u5224\u5b9a\u6811\uff08Binary Search Tree\uff0c\u7b80\u79f0BST\uff09 \u662f\u4e00\u79cd\u7279\u6b8a\u7684\u4e8c\u53c9\u6811\u6570\u636e\u7ed3\u6784\uff0c\u5b83\u6ee1\u8db3\u4ee5\u4e0b\u6027\u8d28\uff1a</p> <ol> <li>\u5de6\u5b50\u6811\u7684\u952e\u503c\u90fd\u5c0f\u4e8e\u6839\u8282\u70b9\u7684\u952e\u503c\u3002</li> <li>\u53f3\u5b50\u6811\u7684\u952e\u503c\u90fd\u5927\u4e8e\u6839\u8282\u70b9\u7684\u952e\u503c\u3002</li> <li>\u5de6\u53f3\u5b50\u6811\u4e5f\u90fd\u662f\u4e8c\u53c9\u5224\u5b9a\u6811\u3002 \u8fd9\u4e2a\u5b9a\u4e49\u786e\u4fdd\u4e86\u6811\u4e2d\u7684\u6240\u6709\u8282\u70b9\u90fd\u6309\u7167\u7279\u5b9a\u7684\u987a\u5e8f\u6392\u5217\uff0c\u4ece\u800c\u5141\u8bb8\u9ad8\u6548\u5730\u8fdb\u884c\u67e5\u627e\u3001\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\u3002\u663e\u7136\u8fd9\u91cc\u7684 BST \u548c\u90a3\u4e2a\u53eb\u505a\u4e8c\u53c9\u6392\u5e8f\u6811/\u4e8c\u53c9\u641c\u7d22\u6811\u7684 BST \u662f\u4e00\u4e2a\u4e1c\u897f\uff0c\u6240\u4ee5\u76f8\u5173\u7684\u8ba1\u7b97\u4e5f\u662f\u4e00\u81f4\u7684\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u4e8c\u53c9\u5224\u5b9a\u6811\u7684\u9ad8\u5ea6\u76f8\u5bf9\u8f83\u4f4e\uff0c\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u662f\u4e00\u4e2a\u76f8\u5bf9\u6bd4\u8f83\u5e73\u8861\u7684 BST\u3002</li> </ol> </li> <li> <p>\u600e\u6837\u5229\u7528\u4e8c\u53c9\u5224\u5b9a\u6811\u8ba1\u7b97\u5e73\u5747\u641c\u7d22\u957f\u5ea6\uff1a \u5728\u4e8c\u53c9\u5224\u5b9a\u6811\u4e2d\u8ba1\u7b97\u5e73\u5747\u641c\u7d22\u957f\u5ea6\u901a\u5e38\u6307\u7684\u662f\u5e73\u5747\u67e5\u627e\u6210\u529f\u957f\u5ea6\u548c\u5e73\u5747\u67e5\u627e\u5931\u8d25\u957f\u5ea6\u3002</p> <ol> <li> <p>\u67e5\u627e\u6210\u529f\u957f\u5ea6\uff1a</p> <ul> <li>\u5bf9\u4e8e\u6811\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\uff0c\u5b83\u7684\u67e5\u627e\u6210\u529f\u957f\u5ea6\u662f\u4ece\u6839\u8282\u70b9\u5230\u8be5\u8282\u70b9\u7684\u8def\u5f84\u957f\u5ea6\u52a01\uff08\u5982\u679c\u6839\u8282\u70b9\u6df1\u5ea6\u4e3a0\uff0c\u5219\u52a01\uff09\u3002</li> <li>\u8ba1\u7b97\u5e73\u5747\u67e5\u627e\u6210\u529f\u957f\u5ea6\uff1a \u5c06\u6240\u6709\u8282\u70b9\u7684\u67e5\u627e\u6210\u529f\u957f\u5ea6\u4e4b\u548c\u9664\u4ee5\u8282\u70b9\u603b\u6570\u3002</li> <li>\u4f8b\u5982\uff0c\u5982\u679c\u8282\u70b9A\u5728\u6df1\u5ea60\uff0c\u67e5\u627e\u6210\u529f\u957f\u5ea6\u662f1\uff1b\u8282\u70b9B\u5728\u6df1\u5ea61\uff0c\u67e5\u627e\u6210\u529f\u957f\u5ea6\u662f2\u3002</li> </ul> </li> <li> <p>\u67e5\u627e\u5931\u8d25\u957f\u5ea6\uff1a</p> <ul> <li>\u67e5\u627e\u5931\u8d25\u53d1\u751f\u5728\u641c\u7d22\u8def\u5f84\u5230\u8fbe\u4e00\u4e2a\u7a7a\u6307\u9488\uff08\u6216\u7a7a\u5b50\u6811\uff09\u65f6\u3002</li> <li>\u5728\u4e8c\u53c9\u5224\u5b9a\u6811\u4e2d\uff0c\u6bcf\u4e2a\u53ef\u80fd\u7684\u67e5\u627e\u5931\u8d25\u4f4d\u7f6e\u5bf9\u5e94\u4e8e\u4e00\u4e2a\u201c\u5916\u90e8\u8282\u70b9\u201d\u6216\u201c\u53f6\u5b50\u8282\u70b9\u201d\u7684\u7a7a\u5b50\u6811\u3002\u8fd9\u4e9b\u4f4d\u7f6e\u901a\u5e38\u88ab\u79f0\u4e3a\u865a\u62df\u8282\u70b9\u6216\u7a7a\u8282\u70b9\u3002</li> <li>\u67e5\u627e\u5931\u8d25\u957f\u5ea6\u662f\u4ece\u6839\u8282\u70b9\u5230\u67e5\u627e\u5931\u8d25\u4f4d\u7f6e\u7684\u8def\u5f84\u957f\u5ea6\u3002</li> <li>\u8ba1\u7b97\u5e73\u5747\u67e5\u627e\u5931\u8d25\u957f\u5ea6\uff1a \u5c06\u6240\u6709\u53ef\u80fd\u7684\u67e5\u627e\u5931\u8d25\u8def\u5f84\u957f\u5ea6\u4e4b\u548c\u9664\u4ee5\u53ef\u80fd\u7684\u67e5\u627e\u5931\u8d25\u4f4d\u7f6e\u7684\u6570\u91cf\u3002</li> </ul> </li> </ol> </li> </ul> <p>\u5047\u8bbe\u4e8c\u53c9\u5224\u5b9a\u6811\u4e2d\u5305\u542b \\(n\\) \u4e2a\u8282\u70b9\uff0c\u5e76\u4e14\u6240\u6709\u8282\u70b9\u7684\u67e5\u627e\u6982\u7387\u662f\u76f8\u540c\u7684\u3002</p> <ul> <li> <p>\u8ba1\u7b97\u67e5\u627e\u6210\u529f\u957f\u5ea6\uff1a</p> <ol> <li>\u904d\u5386\u4e8c\u53c9\u5224\u5b9a\u6811\uff0c\u8bb0\u5f55\u6bcf\u4e2a\u8282\u70b9\u7684\u6df1\u5ea6\uff08\u6839\u8282\u70b9\u6df1\u5ea6\u4e3a0\uff09\u3002</li> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u8282\u70b9 \\(i\\)\uff0c\u5176\u67e5\u627e\u6210\u529f\u957f\u5ea6 \\(L_i = \\text{depth}(i) + 1\\)\u3002</li> <li>\u5e73\u5747\u67e5\u627e\u6210\u529f\u957f\u5ea6 \\(ASL_{\u6210\u529f} = \\frac{\\sum_{i=1}^{n} L_i}{n}\\)\u3002</li> </ol> </li> <li> <p>\u8ba1\u7b97\u67e5\u627e\u5931\u8d25\u957f\u5ea6\uff1a</p> <ol> <li>\u627e\u5230\u6240\u6709\u53ef\u80fd\u7684\u67e5\u627e\u5931\u8d25\u4f4d\u7f6e\uff08\u5373\u7a7a\u5b50\u6811\uff09\u3002\u5728\u4e00\u4e2a\u6709 \\(n\\) \u4e2a\u8282\u70b9\u7684\u4e8c\u53c9\u6811\u4e2d\uff0c\u603b\u5171\u6709 \\(n+1\\) \u4e2a\u7a7a\u5b50\u6811\u3002</li> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u7a7a\u5b50\u6811\uff08\u67e5\u627e\u5931\u8d25\u4f4d\u7f6e\uff09\uff0c\u5176\u67e5\u627e\u5931\u8d25\u957f\u5ea6\u662f\u4ece\u6839\u8282\u70b9\u5230\u8be5\u7a7a\u5b50\u6811\u7684\u8def\u5f84\u957f\u5ea6\u3002</li> <li>\u5e73\u5747\u67e5\u627e\u5931\u8d25\u957f\u5ea6 \\(ASL_{\u5931\u8d25} = \\frac{\\sum_{j=1}^{n+1} \\text{PathLength}(\u7a7a\u5b50\u6811_j)}{n+1}\\)\u3002</li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#dagdagdag", "title": "\u4ec0\u4e48\u662f\u6709\u5411\u65e0\u73af\u56feDAG\uff1f\u5b83\u6709\u600e\u6837\u7684\u7279\u70b9\uff1fDAG\u6709\u4ec0\u4e48\u6027\u8d28\uff1fDAG\u53ef\u4ee5\u7528\u6765\u89e3\u51b3\u54ea\u4e9b\u95ee\u9898\uff1f", "text": "<ul> <li>\u6709\u5411\u65e0\u73af\u56fe\uff08Directed Acyclic Graph, \u7b80\u79f0 DAG\uff09\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6709\u5411\u56fe\u3002\u5b83\u7531\u9876\u70b9\uff08vertex\uff09\u548c\u6709\u5411\u8fb9\uff08directed edge\uff09\u7ec4\u6210\uff0c\u5e76\u4e14\u4e0d\u5305\u542b\u4efb\u4f55\u6709\u5411\u73af\u3002\u7279\u70b9\uff1a</li> <li>\u6709\u5411\u6027\uff08Directed\uff09: \u6240\u6709\u7684\u8fb9\u90fd\u6709\u660e\u786e\u7684\u65b9\u5411\uff0c\u4ece\u4e00\u4e2a\u9876\u70b9\u6307\u5411\u53e6\u4e00\u4e2a\u9876\u70b9\u3002\u8fd9\u610f\u5473\u7740\u5982\u679c\u4f60\u6709\u4e00\u6761\u4ece A \u5230 B \u7684\u8fb9\uff0c\u4f60\u4e0d\u80fd\u6cbf\u7740\u8fd9\u6761\u8fb9\u4ece B \u5230 A\u3002</li> <li>\u65e0\u73af\u6027\uff08Acyclic\uff09: \u56fe\u4e2d\u4e0d\u5b58\u5728\u4efb\u4f55\u53ef\u4ee5\u4ece\u67d0\u4e2a\u9876\u70b9\u51fa\u53d1\uff0c\u6cbf\u7740\u6709\u5411\u8fb9\u6700\u7ec8\u56de\u5230\u8be5\u9876\u70b9\u7684\u8def\u5f84\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u4f60\u65e0\u6cd5\u201c\u7ed5\u4e00\u5708\u201d\u56de\u5230\u8d77\u70b9\u3002</li> <li>\u5c42\u6b21\u7ed3\u6784\uff08Hierarchical Structure\uff09: \u7531\u4e8e\u65e0\u73af\u6027\uff0cDAG \u901a\u5e38\u8868\u73b0\u51fa\u4e00\u79cd\u5c42\u6b21\u7ed3\u6784\u3002\u5982\u679c\u5b58\u5728\u4ece\u9876\u70b9 u \u5230\u9876\u70b9 v \u7684\u8def\u5f84\uff0c\u90a3\u4e48 u \u5728\u67d0\u79cd\u610f\u4e49\u4e0a\u201c\u5148\u4e8e\u201dv\u3002\u8fd9\u4f7f\u5f97 DAG \u975e\u5e38\u9002\u5408\u8868\u793a\u4efb\u52a1\u4f9d\u8d56\u3001\u4e8b\u4ef6\u987a\u5e8f\u7b49\u3002</li> <li> <p>\u62d3\u6251\u6392\u5e8f\uff08Topological Sort\uff09: \u5bf9\u4e8e\u4efb\u4f55 DAG\uff0c\u90fd\u81f3\u5c11\u5b58\u5728\u4e00\u79cd\u62d3\u6251\u6392\u5e8f\u3002\u62d3\u6251\u6392\u5e8f\u662f\u5c06 DAG \u7684\u6240\u6709\u9876\u70b9\u7ebf\u6027\u6392\u5217\uff0c\u4f7f\u5f97\u5bf9\u4e8e\u4efb\u4f55\u6709\u5411\u8fb9 \\((u, v)\\)\uff0c\u9876\u70b9 u \u603b\u662f\u51fa\u73b0\u5728\u9876\u70b9 v \u4e4b\u524d\u3002</p> </li> <li> <p>\u6027\u8d28</p> <ol> <li> <p>\u6ca1\u6709\u56de\u8def: \u8fd9\u662f\u5176\u5b9a\u4e49\u4e2d\u6700\u6838\u5fc3\u7684\u6027\u8d28\u3002\u7531\u4e8e\u6ca1\u6709\u56de\u8def\uff0c\u4ece\u4efb\u4f55\u4e00\u4e2a\u9876\u70b9\u51fa\u53d1\uff0c\u4f60\u90fd\u65e0\u6cd5\u901a\u8fc7\u6709\u5411\u8fb9\u56de\u5230\u8be5\u9876\u70b9\u3002\u8fd9\u4f7f\u5f97 DAG \u975e\u5e38\u9002\u5408\u8868\u793a\u5177\u6709\u660e\u786e\u5f00\u59cb\u548c\u7ed3\u675f\u7684\u4efb\u52a1\u6d41\u7a0b\u3002</p> </li> <li> <p>\u62d3\u6251\u6392\u5e8f\u7684\u5b58\u5728\u6027\u4e0e\u552f\u4e00\u6027\uff08\u6216\u975e\u552f\u4e00\u6027\uff09:</p> <ul> <li>\u5b58\u5728\u6027: \u4efb\u4f55\u6709\u5411\u65e0\u73af\u56fe\u90fd\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u62d3\u6251\u6392\u5e8f\u3002\u8fd9\u662f DAG \u533a\u522b\u4e8e\u4e00\u822c\u6709\u5411\u56fe\u7684\u91cd\u8981\u6027\u8d28\u4e4b\u4e00\u3002</li> <li>\u552f\u4e00\u6027: \u62d3\u6251\u6392\u5e8f\u4e0d\u4e00\u5b9a\u662f\u552f\u4e00\u7684\u3002\u5982\u679c\u4e00\u4e2a DAG \u4e2d\u5b58\u5728\u591a\u4e2a\u4e0d\u76f8\u5173\u7684\u8def\u5f84\uff08\u5373\u5b83\u4eec\u4e4b\u95f4\u6ca1\u6709\u76f4\u63a5\u6216\u95f4\u63a5\u7684\u4f9d\u8d56\u5173\u7cfb\uff09\uff0c\u90a3\u4e48\u8fd9\u4e9b\u8def\u5f84\u4e2d\u7684\u9876\u70b9\u53ef\u4ee5\u6709\u4e0d\u540c\u7684\u76f8\u5bf9\u987a\u5e8f\uff0c\u4ece\u800c\u4ea7\u751f\u4e0d\u540c\u7684\u62d3\u6251\u6392\u5e8f\u3002\u53ea\u6709\u5f53\u56fe\u662f\u201c\u94fe\u5f0f\u201d\u7684\uff0c\u5373\u6bcf\u4e2a\u9876\u70b9\u6700\u591a\u53ea\u6709\u4e00\u4e2a\u524d\u9a71\u548c\u6700\u591a\u4e00\u4e2a\u540e\u7ee7\u65f6\uff0c\u62d3\u6251\u6392\u5e8f\u624d\u53ef\u80fd\u662f\u552f\u4e00\u7684\u3002</li> </ul> </li> <li> <p>\u8868\u793a\u504f\u5e8f\u5173\u7cfb: DAG \u53ef\u4ee5\u5f88\u597d\u5730\u8868\u793a\u504f\u5e8f\u5173\u7cfb\uff08partial order\uff09\u3002\u5982\u679c\u5b58\u5728\u4ece\u9876\u70b9 A \u5230\u9876\u70b9 B \u7684\u8def\u5f84\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u8bf4 A \u201c\u5c0f\u4e8e\u6216\u7b49\u4e8e\u201d B\uff0c\u6216\u8005 A \u201c\u5148\u4e8e\u201d B\u3002\u8fd9\u79cd\u5173\u7cfb\u662f\u975e\u5bf9\u79f0\u548c\u4f20\u9012\u7684\uff0c\u4f46\u4e0d\u662f\u5b8c\u5168\u7684\uff08\u5373\u5e76\u975e\u6240\u6709\u5143\u7d20\u4e4b\u95f4\u90fd\u6709\u53ef\u6bd4\u6027\uff09\u3002</p> </li> <li> <p>\u8def\u5f84\u7684\u6709\u9650\u6027: \u7531\u4e8e\u6ca1\u6709\u73af\uff0c\u4efb\u4f55\u4ece\u4e00\u4e2a\u9876\u70b9\u5230\u53e6\u4e00\u4e2a\u9876\u70b9\u7684\u8def\u5f84\u90fd\u662f\u6709\u9650\u957f\u7684\u3002\u8fd9\u610f\u5473\u7740\u5728 DAG \u4e2d\uff0c\u4e0d\u5b58\u5728\u65e0\u9650\u957f\u7684\u8def\u5f84\u3002</p> </li> <li> <p>\u4e0d\u5305\u542b\u5f3a\u8fde\u901a\u5206\u91cf\uff08Strongly Connected Components\uff09: \u5728\u6709\u5411\u56fe\u4e2d\uff0c\u5982\u679c\u4e24\u4e2a\u9876\u70b9 u \u548c v \u4e92\u76f8\u53ef\u8fbe\uff0c\u90a3\u4e48\u5b83\u4eec\u5c5e\u4e8e\u540c\u4e00\u4e2a\u5f3a\u8fde\u901a\u5206\u91cf\u3002\u7531\u4e8e DAG \u4e0d\u5305\u542b\u73af\uff0c\u56e0\u6b64\u4efb\u4f55\u4e00\u4e2a\u5f3a\u8fde\u901a\u5206\u91cf\u90fd\u53ea\u80fd\u5305\u542b\u4e00\u4e2a\u9876\u70b9\uff08\u5373\u9876\u70b9\u81ea\u8eab\u53ef\u8fbe\u81ea\u8eab\uff0c\u4f46\u4e0d\u80fd\u5230\u8fbe\u5176\u4ed6\u9876\u70b9\u5e76\u8fd4\u56de\uff09\u3002\u8fd9\u610f\u5473\u7740 DAG \u53ef\u4ee5\u770b\u4f5c\u662f\u8bb8\u591a\u72ec\u7acb\u7684\u9876\u70b9\u6216\u7531\u6709\u5411\u8fb9\u8fde\u63a5\u7684\u201c\u94fe\u201d\u7ec4\u6210\u3002</p> </li> <li> <p>\u6700\u77ed\u8def\u5f84\u548c\u6700\u957f\u8def\u5f84\u95ee\u9898:</p> <ul> <li>\u6700\u77ed\u8def\u5f84: \u5728\u5e26\u6743 DAG \u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff08\u4f8b\u5982\u57fa\u4e8e\u62d3\u6251\u6392\u5e8f\u7684\u52a8\u6001\u89c4\u5212\uff09\u6765\u627e\u5230\u6700\u77ed\u8def\u5f84\u3002\u8fd9\u6bd4\u4e00\u822c\u56fe\u4e2d\u9700\u8981\u4f7f\u7528 Dijkstra \u6216 Bellman-Ford \u7b97\u6cd5\u8981\u5feb\uff0c\u56e0\u4e3a\u4e0d\u9700\u8981\u5904\u7406\u8d1f\u6743\u73af\u7684\u95ee\u9898\u3002</li> <li>\u6700\u957f\u8def\u5f84: \u7c7b\u4f3c\u5730\uff0c\u5728\u5e26\u6743 DAG \u4e2d\u627e\u5230\u6700\u957f\u8def\u5f84\u4e5f\u662f\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u3002\u8fd9\u5728\u4e00\u822c\u56fe\u4e2d\u662f\u4e00\u4e2a NP-hard \u95ee\u9898\uff08\u9664\u975e\u56fe\u4e2d\u6ca1\u6709\u8d1f\u6743\u73af\uff09\u3002\u8fd9\u79cd\u6027\u8d28\u4f7f\u5f97 DAG \u5728\u9879\u76ee\u7ba1\u7406\uff08\u5173\u952e\u8def\u5f84\u6cd5\uff09\u3001\u8c03\u5ea6\u7b49\u9886\u57df\u975e\u5e38\u6709\u7528\u3002</li> </ul> </li> <li> <p>\u52a8\u6001\u89c4\u5212\u7684\u57fa\u7840: \u8bb8\u591a\u52a8\u6001\u89c4\u5212\u95ee\u9898\u90fd\u53ef\u4ee5\u88ab\u5efa\u6a21\u4e3a\u5728 DAG \u4e0a\u5bfb\u627e\u8def\u5f84\u6216\u5b50\u7ed3\u6784\u7684\u95ee\u9898\u3002\u4f8b\u5982\uff0c\u6700\u957f\u516c\u5171\u5b50\u5e8f\u5217\uff08LCS\uff09\u95ee\u9898\u5c31\u53ef\u4ee5\u8f6c\u5316\u4e3a\u5728 DAG \u4e0a\u5bfb\u627e\u6700\u957f\u8def\u5f84\u3002</p> </li> <li> <p>\u53ef\u4ee5\u88ab\u5206\u89e3\u4e3a\u6e90\u548c\u6c47:</p> <ul> <li>\u6e90\uff08Source\uff09: \u5165\u5ea6\u4e3a 0 \u7684\u9876\u70b9\uff0c\u6ca1\u6709\u6307\u5411\u5b83\u7684\u8fb9\u3002</li> <li>\u6c47\uff08Sink\uff09: \u51fa\u5ea6\u4e3a 0 \u7684\u9876\u70b9\uff0c\u6ca1\u6709\u4ece\u5b83\u53d1\u51fa\u7684\u8fb9\u3002 \u4efb\u4f55\u975e\u7a7a\u7684 DAG \u81f3\u5c11\u6709\u4e00\u4e2a\u6e90\u548c\u4e00\u4e2a\u6c47\u3002\u8fd9\u662f\u56e0\u4e3a\u5982\u679c\u4e00\u4e2a DAG \u6ca1\u6709\u6e90\uff0c\u90a3\u4e48\u6bcf\u4e2a\u9876\u70b9\u90fd\u6709\u5165\u5ea6\uff0c\u8fd9\u610f\u5473\u7740\u53ef\u4ee5\u6cbf\u7740\u5165\u5ea6\u65b9\u5411\u65e0\u9650\u56de\u6eaf\uff0c\u6700\u7ec8\u5f62\u6210\u4e00\u4e2a\u73af\uff0c\u8fd9\u4e0e DAG \u7684\u5b9a\u4e49\u77db\u76fe\u3002\u540c\u7406\uff0c\u5982\u679c\u4e00\u4e2a DAG \u6ca1\u6709\u6c47\uff0c\u4e5f\u53ef\u4ee5\u6cbf\u7740\u51fa\u5ea6\u65b9\u5411\u65e0\u9650\u524d\u8fdb\uff0c\u6700\u7ec8\u5f62\u6210\u4e00\u4e2a\u73af\u3002</li> </ul> </li> </ol> </li> </ul>"}, {"location": "campus-sources/ds-keynote/#heap", "title": "\u4ec0\u4e48\u662f\u5806\uff08heap\uff09\uff1f\u5806\u6709\u4ec0\u4e48\u6027\u8d28\uff1f\u5982\u4f55\u6784\u5efa\u5806\uff1f", "text": "<ul> <li> <p>\u5806\uff08Heap\uff09\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u6570\u636e\u7ed3\u6784\uff0c\u5b83\u901a\u5e38\u88ab\u5b9e\u73b0\u4e3a\u8fd1\u4f3c\u5b8c\u5168\u4e8c\u53c9\u6811\u3002\u5806\u7684\u4e3b\u8981\u7279\u70b9\u662f\u6ee1\u8db3\u201c\u5806\u5e8f\u6027\u201d\uff08Heap Property\uff09\u3002\u6839\u636e\u5806\u5e8f\u6027\u7684\u4e0d\u540c\uff0c\u5806\u53ef\u4ee5\u5206\u4e3a\u4e24\u79cd\uff1a</p> <ol> <li>\u6700\u5927\u5806\uff08Max Heap\uff09\uff1a\u5bf9\u4e8e\u5806\u4e2d\u7684\u4efb\u610f\u8282\u70b9 \\(P\\) \u548c\u5b83\u7684\u5b50\u8282\u70b9 \\(C\\)\uff0c\u5982\u679c \\(P\\) \u662f \\(C\\) \u7684\u7236\u8282\u70b9\uff0c\u90a3\u4e48 \\(P\\) \u7684\u503c\u5927\u4e8e\u6216\u7b49\u4e8e \\(C\\) \u7684\u503c\u3002\u8fd9\u610f\u5473\u7740\u6700\u5927\u503c\u603b\u662f\u5728\u5806\u7684\u6839\u8282\u70b9\u3002</li> <li>\u6700\u5c0f\u5806\uff08Min Heap\uff09\uff1a\u5bf9\u4e8e\u5806\u4e2d\u7684\u4efb\u610f\u8282\u70b9 \\(P\\) \u548c\u5b83\u7684\u5b50\u8282\u70b9 \\(C\\)\uff0c\u5982\u679c \\(P\\) \u662f \\(C\\) \u7684\u7236\u8282\u70b9\uff0c\u90a3\u4e48 \\(P\\) \u7684\u503c\u5c0f\u4e8e\u6216\u7b49\u4e8e \\(C\\) \u7684\u503c\u3002\u8fd9\u610f\u5473\u7740\u6700\u5c0f\u503c\u603b\u662f\u5728\u5806\u7684\u6839\u8282\u70b9\u3002</li> </ol> </li> <li> <p>\u5806\u901a\u5e38\u7528\u6570\u7ec4\u6765\u8868\u793a\uff0c\u56e0\u4e3a\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u6027\u8d28\u4f7f\u5f97\u8fd9\u79cd\u8868\u793a\u65b9\u5f0f\u975e\u5e38\u7d27\u51d1\u548c\u9ad8\u6548\u3002\u5bf9\u4e8e\u4e00\u4e2a\u4ee5\u6570\u7ec4\u5f62\u5f0f\u5b58\u50a8\u7684\u5806\uff0c\u5982\u679c\u4e00\u4e2a\u8282\u70b9\u7684\u7d22\u5f15\u662f \\(i\\)\uff1a</p> <ul> <li>\u5b83\u7684\u5de6\u5b50\u8282\u70b9\u7684\u7d22\u5f15\u662f \\(2i + 1\\)\u3002</li> <li>\u5b83\u7684\u53f3\u5b50\u8282\u70b9\u7684\u7d22\u5f15\u662f \\(2i + 2\\)\u3002</li> <li>\u5b83\u7684\u7236\u8282\u70b9\u7684\u7d22\u5f15\u662f \\(\\lfloor(i - 1) / 2\\rfloor\\)\u3002</li> </ul> </li> <li> <p>\u5806\u6709\u4ec0\u4e48\u6027\u8d28\uff1f</p> <ol> <li>\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u7ed3\u6784\uff1a\u5806\u603b\u662f\u4e00\u68f5\u5b8c\u5168\u4e8c\u53c9\u6811\u3002\u8fd9\u610f\u5473\u7740\u9664\u4e86\u6700\u5e95\u5c42\uff0c\u5176\u4ed6\u6240\u6709\u5c42\u90fd\u88ab\u5b8c\u5168\u586b\u6ee1\uff0c\u5e76\u4e14\u6700\u5e95\u5c42\u7684\u8282\u70b9\u90fd\u5c3d\u53ef\u80fd\u5730\u4ece\u5de6\u5230\u53f3\u586b\u5145\u3002\u8fd9\u4e2a\u6027\u8d28\u4f7f\u5f97\u5806\u53ef\u4ee5\u4f7f\u7528\u6570\u7ec4\u9ad8\u6548\u5730\u5b58\u50a8\uff0c\u800c\u4e0d\u9700\u8981\u4f7f\u7528\u6307\u9488\u8fde\u63a5\u8282\u70b9\uff0c\u4ece\u800c\u8282\u7701\u7a7a\u95f4\u5e76\u63d0\u9ad8\u8bbf\u95ee\u6548\u7387\u3002</li> <li>\u5806\u5e8f\u6027\uff08Heap Property\uff09\uff1a\u8fd9\u662f\u5806\u6700\u6838\u5fc3\u7684\u6027\u8d28\u3002<ul> <li>\u5728\u6700\u5927\u5806\u4e2d\uff0c\u6bcf\u4e2a\u7236\u8282\u70b9\u7684\u503c\u90fd\u5927\u4e8e\u6216\u7b49\u4e8e\u5176\u6240\u6709\u5b50\u8282\u70b9\u7684\u503c\u3002\u56e0\u6b64\uff0c\u6839\u8282\u70b9\u5305\u542b\u5806\u4e2d\u7684\u6700\u5927\u503c\u3002</li> <li>\u5728\u6700\u5c0f\u5806\u4e2d\uff0c\u6bcf\u4e2a\u7236\u8282\u70b9\u7684\u503c\u90fd\u5c0f\u4e8e\u6216\u7b49\u4e8e\u5176\u6240\u6709\u5b50\u8282\u70b9\u7684\u503c\u3002\u56e0\u6b64\uff0c\u6839\u8282\u70b9\u5305\u542b\u5806\u4e2d\u7684\u6700\u5c0f\u503c\u3002</li> <li>\u8fd9\u4e2a\u6027\u8d28\u4fdd\u8bc1\u4e86\u6211\u4eec\u53ef\u4ee5\u9ad8\u6548\u5730\u627e\u5230\u5806\u4e2d\u7684\u6700\u5927\uff08\u6216\u6700\u5c0f\uff09\u5143\u7d20\uff0c\u901a\u5e38\u662f \\(O(1)\\) \u65f6\u95f4\u590d\u6742\u5ea6\uff08\u5373\u76f4\u63a5\u8bbf\u95ee\u6839\u8282\u70b9\uff09\u3002</li> </ul> </li> </ol> </li> <li> <p>\u6784\u5efa\u5806\u7684\u4e00\u79cd\u5e38\u7528\u65b9\u6cd5\u662f\u7b5b\u9009\u6cd5\uff08Heapify\uff09\uff0c\u5b83\u901a\u8fc7\u53cd\u590d\u5e94\u7528\u201csift down\u201d\uff08\u4e0b\u6c89\uff09\u64cd\u4f5c\u6765\u5c06\u4e00\u4e2a\u65e0\u5e8f\u6570\u7ec4\u8c03\u6574\u6210\u4e00\u4e2a\u5806\u3002\u8fd9\u91cc\u7684\u201csift down\u201d\u4e5f\u88ab\u79f0\u4e3a\u201cheapify down\u201d\u6216\u201cmax/min-heapify\u201d\u3002</p> </li> <li> <p>\u5047\u8bbe\u6211\u4eec\u60f3\u6784\u5efa\u4e00\u4e2a\u6700\u5927\u5806\uff08\u5bf9\u4e8e\u6700\u5c0f\u5806\u539f\u7406\u7c7b\u4f3c\uff0c\u53ea\u662f\u6bd4\u8f83\u65b9\u5411\u76f8\u53cd\uff09\u3002<code>sift down</code> \u64cd\u4f5c\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u8282\u70b9\uff0c\u5982\u679c\u5b83\u7684\u503c\u4e0d\u6ee1\u8db3\u5806\u5e8f\u6027\uff08\u4f8b\u5982\uff0c\u5728\u6700\u5927\u5806\u4e2d\uff0c\u5b83\u6bd4\u5b83\u7684\u67d0\u4e2a\u5b50\u8282\u70b9\u5c0f\uff09\uff0c\u90a3\u4e48\u5c31\u5c06\u8fd9\u4e2a\u8282\u70b9\u7684\u503c\u4e0e\u5b83\u7684\u8f83\u5927\u5b50\u8282\u70b9\uff08\u5728\u6700\u5927\u5806\u4e2d\uff09\u8fdb\u884c\u4ea4\u6362\uff0c\u7136\u540e\u9012\u5f52\u5730\u5bf9\u88ab\u4ea4\u6362\u7684\u5b50\u8282\u70b9\u4f4d\u7f6e\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u76f4\u5230\u8fd9\u4e2a\u8282\u70b9\u7684\u503c\u6ee1\u8db3\u5806\u5e8f\u6027\uff08\u5373\u5b83\u6bd4\u6240\u6709\u5b50\u8282\u70b9\u90fd\u5927\uff09\uff0c\u6216\u8005\u5b83\u6210\u4e3a\u53f6\u5b50\u8282\u70b9\uff08\u6ca1\u6709\u5b50\u8282\u70b9\uff09\u3002</p> <ol> <li>\u9009\u62e9\u9700\u8981\u8c03\u6574\u7684\u8282\u70b9\uff1a<code>sift down</code> \u64cd\u4f5c\u901a\u5e38\u4ece\u4e00\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\u5f00\u59cb\u3002\u5728\u6784\u5efa\u6574\u4e2a\u5806\u65f6\uff0c\u6211\u4eec\u4ece\u6700\u540e\u4e00\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\u5f00\u59cb\uff0c\u7136\u540e\u5411\u524d\u4f9d\u6b21\u5904\u7406\u6240\u6709\u975e\u53f6\u5b50\u8282\u70b9\uff0c\u76f4\u5230\u6839\u8282\u70b9\u3002\u8fd9\u662f\u56e0\u4e3a\u53f6\u5b50\u8282\u70b9\u5929\u7136\u6ee1\u8db3\u5806\u5e8f\u6027\uff08\u5b83\u4eec\u6ca1\u6709\u5b50\u8282\u70b9\u53ef\u4ee5\u6bd4\u8f83\uff09\u3002</li> <li>\u6bd4\u8f83\u5e76\u4ea4\u6362\uff1a<ul> <li>\u5bf9\u4e8e\u5f53\u524d\u9700\u8981\u8c03\u6574\u7684\u8282\u70b9 \\(P\\)\uff08\u7d22\u5f15 \\(i\\)\uff09\uff0c\u627e\u5230\u5b83\u7684\u5de6\u53f3\u5b50\u8282\u70b9 \\(C_L\\)\uff08\u7d22\u5f15 \\(2i+1\\)\uff09\u548c \\(C_R\\)\uff08\u7d22\u5f15 \\(2i+2\\)\uff09\u3002</li> <li>\u5728\u6700\u5927\u5806\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u8f83 \\(P\\)\u3001\\(C_L\\)\u3001\\(C_R\\) \u4e09\u4e2a\u8282\u70b9\u7684\u503c\u3002</li> <li>\u627e\u51fa\u8fd9\u4e09\u4e2a\u8282\u70b9\u4e2d\u7684\u6700\u5927\u503c\u3002</li> <li>\u5982\u679c\u6700\u5927\u503c\u5c31\u662f \\(P\\) \u7684\u503c\uff0c\u8bf4\u660e\u5f53\u524d\u8282\u70b9 \\(P\\) \u5df2\u7ecf\u6ee1\u8db3\u5806\u5e8f\u6027\uff0c<code>sift down</code> \u8fc7\u7a0b\u7ed3\u675f\u3002</li> <li>\u5982\u679c\u6700\u5927\u503c\u662f \\(C_L\\) \u6216 \\(C_R\\) \u7684\u503c\uff08\u5047\u8bbe\u662f \\(C_{max}\\)\uff09\uff0c\u5219\u5c06 \\(P\\) \u7684\u503c\u4e0e \\(C_{max}\\) \u7684\u503c\u8fdb\u884c\u4ea4\u6362\u3002</li> </ul> </li> <li>\u9012\u5f52\u4e0b\u6c89\uff1a<ul> <li>\u5728\u4ea4\u6362\u4e4b\u540e\uff0c\\(P\\) \u7684\u539f\u59cb\u503c\u73b0\u5728\u4f4d\u4e8e \\(C_{max}\\) \u7684\u4f4d\u7f6e\u3002\u6b64\u65f6\uff0c\u9700\u8981\u68c0\u67e5 \\(C_{max}\\) \u7684\u4f4d\u7f6e\u662f\u5426\u6ee1\u8db3\u5806\u5e8f\u6027\u3002</li> <li>\u56e0\u6b64\uff0c\u4ee5 \\(C_{max}\\) \u7684\u65b0\u4f4d\u7f6e\u4f5c\u4e3a\u65b0\u7684\u5f53\u524d\u8282\u70b9\uff0c\u9012\u5f52\u5730\u91cd\u590d\u6b65\u9aa42\uff0c\u76f4\u5230\u5f53\u524d\u8282\u70b9\u7684\u503c\u4e0d\u518d\u9700\u8981\u4e0b\u6c89\uff08\u5373\u5b83\u6bd4\u5176\u6240\u6709\u5b50\u8282\u70b9\u90fd\u5927\u6216\u5b83\u662f\u4e00\u4e2a\u53f6\u5b50\u8282\u70b9\uff09\u3002</li> </ul> </li> </ol> </li> <li> <p>\u6784\u5efa\u6574\u4e2a\u5806\u7684\u8fc7\u7a0b\uff08\u4ece\u65e0\u5e8f\u6570\u7ec4\u5230\u5806\uff09\uff1a</p> <ul> <li> <p>\u8981\u5c06\u4e00\u4e2a\u4efb\u610f\u7684\u6570\u7ec4\u6784\u5efa\u6210\u4e00\u4e2a\u5806\uff0c\u6211\u4eec\u4ece\u6700\u540e\u4e00\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\u5f00\u59cb\uff0c\u9006\u5e8f\u5411\u4e0a\u5bf9\u6bcf\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\u6267\u884c <code>sift down</code> \u64cd\u4f5c\uff0c\u76f4\u5230\u6839\u8282\u70b9\u3002</p> <ul> <li>\u8d77\u59cb\u8282\u70b9\uff1a\u5728\u4e00\u4e2a\u5927\u5c0f\u4e3a \\(N\\) \u7684\u6570\u7ec4\u4e2d\uff0c\u6700\u540e\u4e00\u4e2a\u975e\u53f6\u5b50\u8282\u70b9\u7684\u7d22\u5f15\u662f \\(\\lfloor N/2 \\rfloor - 1\\)\u3002</li> <li>\u8fed\u4ee3\u8fc7\u7a0b\uff1a\u4ece\u7d22\u5f15 \\(\\lfloor N/2 \\rfloor - 1\\) \u5f00\u59cb\uff0c\u9012\u51cf\u5230\u7d22\u5f15 \\(0\\) (\u5373\u6839\u8282\u70b9)\u3002\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8282\u70b9 \\(i\\)\uff0c\u6267\u884c <code>sift down(i)</code> \u64cd\u4f5c\u3002</li> </ul> </li> <li> <p>\u5f53\u8fd9\u4e2a\u5faa\u73af\u7ed3\u675f\u65f6\uff0c\u6574\u4e2a\u6570\u7ec4\u5c31\u53d8\u6210\u4e86\u4e00\u4e2a\u6ee1\u8db3\u5806\u5e8f\u6027\u7684\u5806\u3002\u8fd9\u4e2a\u6784\u5efa\u8fc7\u7a0b\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(N)\\)\uff0c\u5c3d\u7ba1\u6bcf\u4e2a <code>sift down</code> \u64cd\u4f5c\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u53ef\u80fd\u9700\u8981 \\(O(\\log N)\\) \u7684\u65f6\u95f4\u3002\u8fd9\u662f\u56e0\u4e3a\u5927\u90e8\u5206 <code>sift down</code> \u64cd\u4f5c\u53d1\u751f\u5728\u9760\u8fd1\u53f6\u5b50\u8282\u70b9\u7684\u5c42\uff0c\u8fd9\u4e9b\u5c42\u7684\u9ad8\u5ea6\u8f83\u5c0f\uff0c\u56e0\u6b64\u603b\u7684\u590d\u6742\u5ea6\u4f1a\u4f4e\u4e8e\u7b80\u5355\u7684 \\(N \\times O(\\log N)\\)\u3002</p> </li> </ul> </li> </ul> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 29, 2025). \u300a\u6570\u636e\u7ed3\u6784\u300b\u5212\u91cd\u70b9\u7b14\u8bb0 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/ds-keynote</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{ds-keynote,\n    title={\u300a\u6570\u636e\u7ed3\u6784\u300b\u5212\u91cd\u70b9\u7b14\u8bb0},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/ds-keynote}},\n}\n</code></pre></p>"}, {"location": "campus-sources/ds-write-up/", "title": "\u300a\u6570\u636e\u7ed3\u6784\u300b\u671f\u672b\u590d\u4e60\u9898\u9898\u89e3", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 58 \u5206\u949f\u3000|\u3000\u7ea6 9979 \u5b57\u3000|\u3000\u7ea6 61 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 221 \u884c\u4ee3\u7801</p>"}, {"location": "campus-sources/ds-write-up/#_2", "title": "\u7b2c\u4e94\u7248\u7b2c\u4e00\u5957\u9898\u76ee", "text": ""}, {"location": "campus-sources/ds-write-up/#_3", "title": "\u5355\u9879\u9009\u62e9\u9898", "text": "<p>1.\u6570\u636e\u7ed3\u6784\u662f\u6307______\u3002    A. \u4e00\u79cd\u6570\u636e\u7c7b\u578b    B. \u6570\u636e\u7684\u5b58\u50a8\u7ed3\u6784    C. \u4e00\u7ec4\u6027\u8d28\u76f8\u540c\u7684\u6570\u636e\u5143\u7d20\u7684\u96c6\u5408    D. \u76f8\u4e92\u4e4b\u95f4\u5b58\u5728\u4e00\u79cd\u6216\u591a\u79cd\u7279\u5b9a\u5173\u7cfb\u7684\u6570\u636e\u5143\u7d20\u7684\u96c6\u5408  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002 \u4e09\u77ed\u4e00\u957f\u9009\u6700\u957f\u597d\u5427\u3002\u5176\u5b9e\u6570\u636e\u7ed3\u6784\u7684\u7cbe\u5999\u4e4b\u5904\u5c31\u662f\u5229\u7528\u597d\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u6765\u7ec4\u7ec7\u6570\u636e\uff0c\u4ee5\u83b7\u5f97\u66f4\u4f73\u7684\u6027\u80fd\u3002ABC\u9009\u9879\u63cf\u8ff0\u90fd\u6ca1\u6709\u6293\u4f4f\u201c\u6570\u636e\u95f4\u76f8\u4e92\u5173\u7cfb\u201d\u8fd9\u4e2a\u5173\u952e\u8bcd\u3002  <p></p> <p>2.\u4ee5\u4e0b\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a______\u3002 <pre><code>void fun(int n)\n{  int i = 1, s = 0;\n   while (i &lt;= n)\n   {  s += i + 100; i++;  }\n}\n</code></pre>    A. \\(O(n)\\)    B. \\(O(\\sqrt{n})\\)    C. \\(O(n\\log_2 n)\\)    D. \\(O(\\log_2 n)\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002  \u672c\u9898 \\(s\\) \u662f\u4e00\u4e2a\u969c\u773c\u6cd5\uff0c\u51b3\u5b9a\u5faa\u73af\u6b21\u6570\u7684\u53ea\u6709 \\(i\\) \u548c \\(n\\)\u3002\u6839\u636e\u4ee3\u7801\uff0c\\(i\\) \u4ece \\(1\\) \u5f00\u59cb\uff0c\u6bcf\u4e00\u6b21\u5faa\u73af \\(i\\) \u90fd\u589e\u52a0 \\(1\\)\uff0c\u76f4\u5230 \\(i\\) \u7684\u503c\u589e\u52a0\u5230 \\(n\\) \u4e3a\u6b62\u3002\u56e0\u6b64\u4e00\u5171\u6267\u884c\u4e86 \\(n\\) \u6b21\u5faa\u73af\uff0c\u9009A\u3002  <p></p> \u53d8\u4f53\uff1a\u5982\u679c\u628a\u5faa\u73af\u6761\u4ef6\u6539\u6210 `s &lt;= n`\uff0c\u5219\u5e94\u8be5\u9009\u54ea\u4e2a\u9009\u9879\u5462\uff1f \u70b9\u51fb\u67e5\u770b\u89e3\u7b54 <p></p>  \u8003\u8651\u5faa\u73af\u6267\u884c\u4e86 \\(x\\) \u6b21\uff0c\u5219 $$ s=\\sum_{i=1}^{x}100+i = 100x+\\dfrac{x(x-1)}{2} $$ \u4e5f\u5c31\u662f \\(s\\) \u589e\u957f\u7387\u5728 \\(x^2\\) \u91cf\u7ea7\uff0c\u7531\u4e8e\u5faa\u73af\u6761\u4ef6\u4e3a \\(s\\le n\\)\uff0c\u5c31\u53ef\u4ee5\u5f97\u51fa \\(x=O(\\sqrt n)\\)\u3002 <p></p>  \u5f53\u7136\u4e5f\u53ef\u4ee5\u5229\u7528\u4e0a\u5f0f\u628a \\(x\\) \u5173\u4e8e \\(n\\) \u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\u89e3\u51fa\u6765\u518d\u505a\u5206\u6790\uff0c\u539f\u7406\u662f\u4e00\u6837\u7684\u3002  <p></p> \u539f\u4e66\u7ed9\u7684\u7b54\u6848\u662fB\uff0c\u5176\u5b9e\u60f3\u8003\u7684\u662f\u8fd9\u4e2a\uff0c\u4f46\u662f\u51fa\u9898\u4eba\u6709\u70b9\u8349\u53f0\u73ed\u5b50\uff0c\u5f04\u5de7\u6210\u62d9\u4e86\u3002  <p></p> <p></p> <p>3.\u5728\u4e00\u4e2a\u957f\u5ea6\u4e3a\\(n\\)\u7684\u6709\u5e8f\u987a\u5e8f\u8868\u4e2d\u5220\u9664\u7b2c\u4e00\u4e2a\u5143\u7d20\u503c\u4e3a\\(x\\)\u7684\u5143\u7d20\u65f6\uff0c\u5728\u67e5\u627e\u5143\u7d20\\(x\\)\u65f6\u91c7\u7528\u4e8c\u5206\u67e5\u627e\u65b9\u6cd5\uff0c\u6b64\u65f6\u5220\u9664\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a______\u3002    A. \\(O(n)\\)    B. \\(O(n\\log_2 n)\\)    C. \\(O(n^2)\\)    D. \\(O(\\sqrt{n})\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002 \u8fd9\u91cc\u5220\u9664\u7b97\u6cd5\u5206\u4e24\u6b65\uff1a\u7b2c\u4e00\u6b65\u627e\u5230\u5f85\u5220\u9664\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\uff0c\u8fd9\u4e00\u6b65\u7531\u4e8e\u539f\u6765\u7684\u8868\u662f\u6709\u5e8f\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u4f7f\u7528\u4e8c\u5206\u6cd5\uff0c\u6bcf\u6b21\u6392\u9664\u4e00\u534a\u7684\u533a\u95f4\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(\\log_2 n)\\)\uff0c\u7b2c\u4e8c\u6b65\u662f\u628a\u8fd9\u4e2a\u5143\u7d20\u5220\u9664\uff0c\u7531\u4e8e\u91c7\u7528\u7ebf\u6027\u8868\u5b58\u50a8\u6240\u4ee5\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(n)\\)\u3002\u4e24\u6b65\u52a0\u8d77\u6765\uff0c\u7531\u4e8e\u7b2c\u4e00\u6b65\u76f8\u6bd4\u7b2c\u4e8c\u6b65\u7528\u65f6\u592a\u77ed\uff0c\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff0c\u6240\u4ee5\u603b\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(n)\\)\u3002   \u4e3a\u4ec0\u4e48\u7ebf\u6027\u8868\u968f\u673a\u5220\u9664\u5355\u4e2a\u5143\u7d20\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f O(n) ? <p></p>  \u968f\u673a\u5220\u9664\u5143\u7d20\uff0c\u5219\u4efb\u4e00\u4e0b\u6807 \\(i\\) (\u4e3a\u65b9\u4fbf\u4e66\u5199\uff0c\u4ece \\(1\\) \u5f00\u59cb)\u7684\u5143\u7d20\u88ab\u9009\u4e2d\u7684\u6982\u7387\u90fd\u662f \\(\\dfrac 1n\\)\uff0c\u5220\u9664\u64cd\u4f5c\u9700\u8981\u628a\u540e\u9762\u7684 \\((n-i)\\) \u4e2a\u5143\u7d20\u90fd\u5f80\u524d\u79fb\u52a8\u4e00\u4f4d\uff0c\u56e0\u6b64\u79fb\u52a8\u6b21\u6570\u7684\u671f\u671b\u503c\u4e3a\uff1a  $$ E=\\sum_1^{n}\\dfrac {n-i}{n}= \\dfrac{n-1}2 $$  \u662f \\(O(n)\\) \u7ea7\u522b\u7684\u64cd\u4f5c\u3002 <p></p> \u5ef6\u4f38\u8ba8\u8bba\uff1a\u94fe\u8868\u5462\uff1f\u6709\u6ca1\u6709\u5176\u4ed6\u6570\u636e\u7ed3\u6784\u80fd\u591f\u505a\u5230\u67e5\u627e-\u5220\u9664\u64cd\u4f5c\u6bd4 \\(O(n)\\) \u66f4\u5feb\uff1f <p></p> 1. \u5bf9\u94fe\u8868\u800c\u8a00\uff0c\u867d\u7136\u5220\u9664\u64cd\u4f5c\u53ef\u4ee5\u7b80\u5355\u901a\u8fc7\u6539\u53d8\u524d\u540e\u6307\u9488\u6307\u5411\u5b9e\u73b0 \\(O(1)\\) \u7684\u590d\u6742\u5ea6\uff0c\u4f46\u662f\u67e5\u627e\u5bf9\u5e94\u5143\u7d20\u5374\u9700\u8981 \\(O(n)\\) \u7684\u65f6\u95f4\u3002 <p></p> 2. \u5f53\u7136\u6709\u3002\u6bd4\u5982\u5404\u79cd\u5e73\u8861\u6811\u3002\u53c2\u8003\uff1ahttps://oi-wiki.org/ds/bst/\u672c\u8d28\u4e0a\u5e73\u8861\u6811\u5c31\u662f\u4e3a\u4e86\u51cf\u5c11\u8fd9\u4e00\u64cd\u4f5c\u7684\u590d\u6742\u5ea6\u800c\u5229\u7528\u4e86\u6811\u5f62\u7ed3\u6784\u5e76\u4e14\u5f15\u5165\u5404\u79cd\u7ed3\u6784\u8c03\u6574\u64cd\u4f5c\u6765\u9650\u5236\u6811\u7684\u6df1\u5ea6\uff0c\u4ee5\u9632\u6b62\u51fa\u73b0\u6700\u574f\u6548\u7387\u3002\u5f53\u7136\uff0c\u9664\u4e86\u6811\u5f62\u7ed3\u6784\u53ef\u4ee5\u5229\u7528\u5206\u6cbb\u4f18\u5316\uff0c\u94fe\u5f0f\u7ed3\u6784\u4e5f\u53ef\u4ee5\uff0c\u6bd4\u5982\u8df3\u8868:https://oi-wiki.org/ds/skiplist/\u3002  <p></p> <p></p> <p>4.\u82e5\u4e00\u4e2a\u6808\u91c7\u7528\u6570\u7ec4\\(s[0..n-1]\\)\u5b58\u653e\u5176\u5143\u7d20\uff0c\u521d\u59cb\u65f6\u6808\u9876\u6307\u9488\u4e3a\\(n\\)\uff0c\u5219\u4ee5\u4e0b\u5143\u7d20\\(x\\)\u8fdb\u6808\u7684\u64cd\u4f5c\u6b63\u786e\u7684\u662f______\u3002    A. \\(\\text{top}++;\\ s[\\text{top}] = x;\\)    B. \\(s[\\text{top}] = x;\\ \\text{top}++;\\)    C. \\(\\text{top}--;\\ s[\\text{top}] = x;\\)    D. \\(s[\\text{top}] = x;\\ \\text{top}--;\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002 \u5176\u5b9e\u672c\u9898\u8003\u8651\u5230ABD\u9009\u9879\u90fd\u4f1a\u9020\u6210\u6570\u7ec4\u4e0b\u6807\u8d8a\u754c\u8bbf\u95ee\u5c31\u53ef\u4ee5\u89e3\u51fa\u3002\u4f46\u8fd9\u4e2a\u9898\u672c\u610f\u662f\u8bf4\u4ece\u8fd9\u4e2a\u6570\u7ec4\u7684\u5c3e\u7aef\u5411\u524d\u88c5\u6570\u636e\uff0c\u4e5f\u80fd\u6784\u6210\u4e00\u4e2a\u6808\u3002\u8fd9\u4e48\u505a\u53ef\u4ee5\u548c\u4e00\u4e2a\u4ece\u524d\u5f80\u540e\u88c5\u6570\u636e\u7684\u6808\u7ec4\u5408\u6210\u4e00\u4e2a\u5bf9\u9876\u6808\u3002  <p></p> <p>5.\u8bbe\u73af\u5f62\u961f\u5217\u4e2d\u6570\u7ec4\u7684\u4e0b\u6807\u4e3a\\(0\\sim N-1\\)\uff0c\u5176\u961f\u5934\u3001\u961f\u5c3e\u6307\u9488\u5206\u522b\u4e3a\\(\\text{front}\\)\u548c\\(\\text{rear}\\)\uff08\\(\\text{front}\\)\u6307\u5411\u961f\u5217\u4e2d\u961f\u5934\u5143\u7d20\u7684\u524d\u4e00\u4e2a\u4f4d\u7f6e\uff0c\\(\\text{rear}\\)\u6307\u5411\u961f\u5c3e\u5143\u7d20\u7684\u4f4d\u7f6e\uff09\uff0c\u5219\u5176\u5143\u7d20\u4e2a\u6570\u4e3a______\u3002    A. \\(\\text{rear} - \\text{front}\\)    B. \\(\\text{rear} - \\text{front} - 1\\)    C. \\((\\text{rear} - \\text{front})\\%N + 1\\)    D. \\((\\text{rear} - \\text{front} + N)\\%N\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002 \u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u5faa\u73af\u961f\u5217\uff0c\u5982\u679c rear \u7684\u4e0b\u6807\u5927\u4e8e front\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u76f8\u51cf\uff0c\u4f46\u662f\u4e5f\u53ef\u80fd\u51fa\u73b0\u5c0f\u4e8e\u7684\u60c5\u51b5\uff0c\u6240\u4ee5\u9700\u8981\u52a0\u4e0a N \u6765\u4fdd\u8bc1\u7ed3\u679c\u662f\u6b63\u6570\uff0c\u7531\u4e8e\u53ef\u80fd\u5927\u4e8e N\uff0c\u6240\u4ee5\u8981\u53d6\u6a21\u3002  <p></p> <p>6.\u82e5\u7528\u4e00\u4e2a\u5927\u5c0f\u4e3a6\u7684\u6570\u7ec4\u6765\u5b9e\u73b0\u73af\u5f62\u961f\u5217\uff0c\u961f\u5934\u6307\u9488\\(\\text{front}\\)\u6307\u5411\u961f\u5217\u4e2d\u961f\u5934\u5143\u7d20\u7684\u524d\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u961f\u5c3e\u6307\u9488\\(\\text{rear}\\)\u6307\u5411\u961f\u5c3e\u5143\u7d20\u7684\u4f4d\u7f6e\u3002\u82e5\u5f53\u524d\\(\\text{rear}\\)\u548c\\(\\text{front}\\)\u7684\u503c\u5206\u522b\u4e3a0\u548c3\uff0c\u5f53\u4ece\u961f\u5217\u4e2d\u5220\u9664\u4e00\u4e2a\u5143\u7d20\uff0c\u518d\u52a0\u5165\u4e24\u4e2a\u5143\u7d20\u540e\uff0c\\(\\text{rear}\\)\u548c\\(\\text{front}\\)\u7684\u503c\u5206\u522b\u4e3a______\u3002    A. 1\u548c5    B. 2\u548c4    C. 4\u548c2    D. 5\u548c1</p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002 \u770b\u56fe\uff1a <p> </p> <p></p> <p>7.\u4e00\u68f5\u9ad8\u5ea6\u4e3a\\(h\\)\uff08\\(h\\geq1\\)\uff09\u7684\u5b8c\u5168\u4e8c\u53c9\u6811\u81f3\u5c11\u6709______\u4e2a\u7ed3\u70b9\u3002    A. \\(2^{h-1}\\)    B. \\(2^h\\)    C. \\(2^h + 1\\)    D. \\(2^{h-1} + 1\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u9996\u5148\u590d\u4e60\u5b8c\u5168\u4e8c\u53c9\u6811\u7684\u5b9a\u4e49\uff1a\u5b8c\u5168\u4e8c\u53c9\u6811\u662f\u9664\u4e86\u6700\u540e\u4e00\u5c42\u4ee5\u5916\u5176\u4ed6\u5c42\u90fd\u6ee1\u7ed3\u70b9\u7684\u4e8c\u53c9\u6811\uff0c\u4e14\u6700\u540e\u4e00\u5c42\u7684\u7ed3\u70b9\u8fde\u7eed\u96c6\u4e2d\u5728\u6700\u5de6\u8fb9\u3002\u9898\u76ee\u95ee\u81f3\u5c11\uff0c\u6240\u4ee5\u6211\u4eec\u8ba9\u6700\u540e\u4e00\u5c42\u53ea\u6709\u4e00\u4e2a\u7ed3\u70b9\uff0c\u90a3\u4e48\u603b\u7684\u7ed3\u70b9\u6570\u4e3a\uff1a  $$ N=1+\\sum_{i=0}^{h-2}2^i=2^{h-1} $$  <p></p> <p>8.\u8bbe\u4e00\u68f5\u54c8\u592b\u66fc\u6811\u4e2d\u6709999\u4e2a\u7ed3\u70b9\uff0c\u8be5\u54c8\u592b\u66fc\u6811\u7528\u4e8e\u5bf9______\u4e2a\u5b57\u7b26\u8fdb\u884c\u7f16\u7801\u3002    A. 999    B. 499    C. 500    D. 501  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u9996\u5148\uff0c\u54c8\u592b\u66fc\u6811\u53ea\u6709\u53f6\u5b50\u7ed3\u70b9\u53ef\u4ee5\u8868\u793a\u6570\u636e\u7684\u7f16\u7801\uff0c\u56e0\u6b64\u6211\u4eec\u5176\u5b9e\u5c31\u662f\u8981\u6c42\u51fa\u8fd9\u4e2a\u54c8\u592b\u66fc\u6811\u53f6\u5b50\u7ed3\u70b9\u7684\u4e2a\u6570\u3002\u56de\u5fc6\u6784\u5efa\u54c8\u592b\u66fc\u6811\u7684\u8fc7\u7a0b\uff0c\u4e00\u5f00\u59cb\u6709\u5355\u72ec\u7684\u4e00\u4e2a\u53f6\u5b50\u7ed3\u70b9\uff0c\u7136\u540e\u6bcf\u6dfb\u52a0\u4e00\u4e2a\u6570\u636e\u5c31\u65b0\u589e\u4e00\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7528\u6765\u8868\u793a\u8fd9\u4e2a\u6570\u636e\uff0c\u5e76\u65b0\u589e\u4e00\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u3002\u56e0\u6b64\u53f6\u5b50\u7ed3\u70b9\u4e2a\u6570\u59cb\u7ec8\u6bd4\u975e\u53f6\u5b50\u7ed3\u70b9\u6570\u591a 1 \u3002\u5229\u7528\u8fd9\u4e2a\u6027\u8d28\u5c31\u53ef\u7b97\u51fa\u7b54\u6848\u662f 500\u3002  <p></p> <p>9.\u4e00\u4e2a\u542b\u6709\\(n\\)\u4e2a\u9876\u70b9\u7684\u65e0\u5411\u8fde\u901a\u56fe\u91c7\u7528\u90bb\u63a5\u77e9\u9635\u5b58\u50a8\uff0c\u5219\u8be5\u77e9\u9635\u4e00\u5b9a\u662f______\u3002    A. \u5bf9\u79f0\u77e9\u9635    B. \u975e\u5bf9\u79f0\u77e9\u9635    C. \u7a00\u758f\u77e9\u9635    D. \u7a20\u5bc6\u77e9\u9635  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u5bf9\u4e8e\u7ed3\u70b9 \\(i\\) \u548c \\(j\\) \uff0c\u90bb\u63a5\u77e9\u9635\u91cc\u9762\u7684\u5143\u7d20 \\(G[i][j]\\) \u8868\u793a \\(i\\) \u5230 \\(j\\) \u7684\u8def\u5f84\u957f\u5ea6\uff0c\u540c\u7406\u5143\u7d20 \\(G[j][i]\\) \u8868\u793a \\(j\\) \u5230 \\(i\\) \u7684\u8def\u5f84\u957f\u5ea6\u3002\u7531\u4e8e\u662f\u4e00\u4e2a\u65e0\u5411\u56fe\uff0c\u6240\u4ee5\u4e24\u8005\u5e94\u8be5\u76f8\u7b49\u3002\u6240\u4ee5\u662f\u5bf9\u79f0\u77e9\u9635\u3002\u81f3\u4e8e\u7a00\u758f\u8fd8\u662f\u7a20\u5bc6\uff0c\u5c31\u53d6\u51b3\u4e8e\u56fe\u672c\u8eab\u4e86\u3002  <p></p> <p>10.\u8bbe\u65e0\u5411\u8fde\u901a\u56fe\u6709\\(n\\)\u4e2a\u9876\u70b9\u3001\\(e\\)\u6761\u8fb9\uff0c\u82e5\u6ee1\u8db3______\uff0c\u5219\u56fe\u4e2d\u4e00\u5b9a\u6709\u56de\u8def\u3002     A. \\(e\\geq n\\)     B. \\(e &lt; n-1\\)     C. \\(e = n-1\\)     D. \\(2e\\geq n\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u8003\u8651\u4e00\u5f00\u59cb\u6709 \\(n\\) \u4e2a\u72ec\u7acb\u7684\u7ed3\u70b9\uff0c\u4ece\u4efb\u610f\u4e00\u4e2a\u7ed3\u70b9\u5f00\u59cb\u52a0\u8fb9\uff0c\u6211\u4eec\u5c3d\u91cf\u4e0d\u8981\u5f62\u6210\u73af\uff0c\u90a3\u4e48\u6bcf\u4e00\u6b21\u52a0\u8fb9\u90fd\u9009\u62e9\u5ea6\u4e3a \\(0\\) \u7684\u7ed3\u70b9\uff0c\u52a0\u4e86 \\(n - 1\\) \u6b21\u8fb9\u4e4b\u540e\u6211\u4eec\u53d1\u73b0\u6ca1\u6709\u5ea6\u4e3a \\(0\\) \u7684\u7ed3\u70b9\u4e86\uff0c\u4e5f\u5c31\u662f\u5f53 \\(e = n - 1\\) \u65f6\uff0c\u8fde\u901a\u56fe\u9000\u5316\u6210\u6811\u3002\u6b64\u65f6\u4ece\u7ed3\u70b9 \\(i\\) \u5230\u7ed3\u70b9 \\(j\\) \u518d\u52a0\u4e00\u6b21\u8fb9 \\(e_n\\) \uff0c\u90a3\u4e48 \\(i\\) \u5230 \\(j\\) \u539f\u5148\u7684\u8fde\u901a\u8def\u5f84\u52a0\u4e0a\u8fd9\u4e2a\u65b0\u52a0\u5165\u7684\u8fb9\u521a\u521a\u597d\u5c31\u6784\u6210\u4e00\u4e2a\u73af\u3002  <p></p> <p>11.\u5982\u679c\u4ece\u65e0\u5411\u56fe\u7684\u4efb\u4e00\u9876\u70b9\u51fa\u53d1\u8fdb\u884c\u4e00\u6b21\u5e7f\u5ea6\u4f18\u5148\u904d\u5386\u5373\u53ef\u8bbf\u95ee\u6240\u6709\u9876\u70b9\uff0c\u5219\u8be5\u56fe\u4e00\u5b9a\u662f______\u3002     A. \u5b8c\u5168\u56fe     B. \u8fde\u901a\u56fe     C. \u6709\u56de\u8def     D. \u4e00\u68f5\u6811  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u8fde\u901a\u56fe\u662f\u6307\u56fe\u4e2d\u4efb\u610f\u4e24\u4e2a\u9876\u70b9\u4e4b\u95f4\u90fd\u5b58\u5728\u8def\u5f84\u76f8\u8fde\u7684\u65e0\u5411\u56fe\u3002\u65e2\u7136\u80fd\u591f\u88ab\u641c\u7d22\u5230\uff0c\u5c31\u610f\u5473\u7740\u80af\u5b9a\u6709\u8def\u5f84\u76f8\u8fde\u3002\u5b8c\u5168\u56fe\u3001\u6709\u56de\u8def\u548c\u6811\u7684\u5b9a\u4e49\u66f4\u4e25\u683c\u3002\u9898\u76ee\u4e2d\u6ca1\u6709\u66f4\u591a\u6761\u4ef6\u4e86\uff0c\u53ea\u80fd\u9009\u5230B\u3002  <p></p> <p>12.\u8bbe\u6709100\u4e2a\u5143\u7d20\u7684\u6709\u5e8f\u8868\uff0c\u5728\u7528\u6298\u534a\u67e5\u627e\u65f6\uff0c\u4e0d\u6210\u529f\u67e5\u627e\u65f6\u6700\u5927\u7684\u6bd4\u8f83\u6b21\u6570\u662f______\u3002     A. 25     B. 50     C. 10     D. 7  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002 \u6298\u534a\u641c\u7d22\u6bcf\u6b21\u4e22\u5f03\u4e00\u534a\u7684\u533a\u95f4\uff0c\u4e5f\u5c31\u662f\uff1a $$ 2^6=64\\le 100\\le 2^7=128 $$ \u627e 6 \u6b21\u53ef\u80fd\u627e\u4e0d\u5230\uff0c\u4f46\u662f\u627e 7 \u6b21\u4e00\u5b9a\u627e\u5f97\u5230\u3002 <p></p> \u4e5f\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3\uff1a\u6298\u534a\u67e5\u627e\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(\\log_2 n)\\) \u91cf\u7ea7\uff0c\u53ea\u6709D\u9009\u9879\u6ee1\u8db3\u8fd9\u4e2a\u6570\u91cf\u7ea7\u3002 <p></p> <p>13.\u4ece100\u4e2a\u5143\u7d20\u786e\u5b9a\u7684\u987a\u5e8f\u8868\u4e2d\u67e5\u627e\u67d0\u4e2a\u5143\u7d20\uff08\u5173\u952e\u5b57\u4e3a\u6b63\u6574\u6570\uff09\uff0c\u5982\u679c\u6700\u591a\u53ea\u8fdb\u884c5\u6b21\u5143\u7d20\u4e4b\u95f4\u7684\u6bd4\u8f83\uff0c\u5219\u91c7\u7528\u7684\u67e5\u627e\u65b9\u6cd5\u53ea\u53ef\u80fd\u662f______\u3002     A. \u6298\u534a\u67e5\u627e     B. \u987a\u5e8f\u67e5\u627e     C. \u54c8\u5e0c\u67e5\u627e     D. \u4e8c\u53c9\u6392\u5e8f\u6811\u67e5\u627e  </p>  \u7b54\u6848  <p></p> \u7b54\u6848 C\u3002  \u6839\u636e\u4e0a\u9762\u90a3\u4e2a\u9898\uff0c\\(O(\\log_2 n)\\)\u7684\u7b97\u6cd5\u7684\u6bd4\u8f83\u6b21\u6570\u4e0a\u754c\u662f7\u6b21\uff0c\u800c\u8fd9\u4e2a\u7b97\u6cd5\u6bd4 \\(O(\\log_2 n)\\) \u7684\u6bd4\u8f83\u6b21\u6570\u8fd8\u8981\u5c11\uff0c\u4e5f\u5c31\u610f\u5473\u7740\u65f6\u95f4\u590d\u6742\u5ea6\u66f4\u4f18\uff0c\u800c AD \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u90fd\u662f \\(O(\\log_2 n)\\)\uff0cB \u662f \\(O(n)\\)\uff0c\u53ea\u6709 C \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f\u5e38\u6570\u7ea7 \\(O(1)\\)\u3002  <p></p> <p>14.\u6709\u4e00\u4e2a\u542b\u6709\\(n\\)\uff08\\(n&gt;1000\\)\uff09\u4e2a\u5143\u7d20\u7684\u6570\u636e\u5e8f\u5217\uff0c\u67d0\u4eba\u91c7\u7528\u4e86\u4e00\u79cd\u6392\u5e8f\u65b9\u6cd5\u5bf9\u5176\u6309\u5173\u952e\u5b57\u9012\u589e\u6392\u5e8f\uff0c\u8be5\u6392\u5e8f\u65b9\u6cd5\u9700\u8981\u5173\u952e\u5b57\u6bd4\u8f83\uff0c\u5176\u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u597d\u7684\u60c5\u51b5\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a\\(O(1)\\)\uff0c\u8be5\u6392\u5e8f\u65b9\u6cd5\u53ef\u80fd\u662f______\u3002     A. \u5feb\u901f\u6392\u5e8f     B. \u5806\u6392\u5e8f     C. \u4e8c\u8def\u5f52\u5e76\u6392\u5e8f     D. \u57fa\u6570\u6392\u5e8f  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u672c\u9898\u5176\u5b9e\u7ed9\u4e86\u4e09\u4e2a\u9650\u5236\u6761\u4ef6\u6765\u6392\u9664\u9009\u9879\uff1a <p></p> 1. \u9700\u8981\u5173\u952e\u5b57\u6bd4\u8f83\uff1a\u6392\u9664\u57fa\u6570\u6392\u5e8f\uff0c\u8fd9\u4e2a\u4e0d\u9700\u8981\u5173\u952e\u5b57\u6bd4\u8f83\u3002 <p></p> 2. \u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u597d\u7684\u60c5\u51b5\uff1a\u6392\u9664\u5feb\u901f\u6392\u5e8f\uff0c\u56e0\u4e3a\u5b83\u7684\u6700\u574f\u65f6\u95f4\u590d\u6742\u5ea6\u662f \\(O(n^2)\\)\u3002 <p></p> 3. \u7a7a\u95f4\u590d\u6742\u5ea6 \\(O(1)\\): \u6392\u9664\u4e8c\u8def\u5f52\u5e76\u6392\u5e8f\uff0c\u56e0\u4e3a\u5b83\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\u662f \\(O(n \\log_2 n)\\)\u3002 <p></p> \u56e0\u6b64\u4f7f\u7528\u7684\u662f\u5806\u6392\u5e8f\uff0c\u5806\u6392\u5e8f\u662f\u57fa\u4e8e\u6bd4\u8f83\u7684\u539f\u5730\u7b97\u6cd5\uff0c\u4e14\u6700\u597d\u3001\u6700\u574f\u548c\u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6\u90fd\u662f\\(O(n \\log_2 n)\\)\u3002 <p></p> <p>15.\u5bf9\u4e00\u4e2a\u7ebf\u6027\u5e8f\u5217\u8fdb\u884c\u6392\u5e8f\uff0c\u8be5\u5e8f\u5217\u91c7\u7528\u5355\u94fe\u8868\u5b58\u50a8\uff0c\u6700\u597d\u91c7\u7528______\u65b9\u6cd5\u3002     A. \u76f4\u63a5\u63d2\u5165\u6392\u5e8f     B. \u5e0c\u5c14\u6392\u5e8f     C. \u5feb\u901f\u6392\u5e8f     D. \u90fd\u4e0d\u9002\u5408</p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002D\u9009\u9879\u62ff\u6765\u51d1\u6570\u7684\uff0c\u522b\u9009\u3002\u5e0c\u5c14\u6392\u5e8f\u9700\u8981\u8fdb\u884c\u6570\u636e\u5206\u7ec4\uff0c\u6d89\u53ca\u5230\u968f\u673a\u8bbf\u95ee\uff0c\u4e0d\u9002\u5408\u94fe\u8868\u7ed3\u6784\uff1b\u5feb\u6392\u9700\u8981\u8fdb\u884c\u591a\u6b21\u968f\u673a\u4ea4\u6362\uff0c\u4e5f\u4e0d\u9002\u5408\u94fe\u8868\u7ed3\u6784\u3002\u53ea\u6709\u63d2\u5165\u64cd\u4f5c\u5bf9\u5355\u94fe\u8868\u7684\u590d\u6742\u5ea6\u662f \\(O(1)\\) \u7684\u3002  <p></p>"}, {"location": "campus-sources/ds-write-up/#_4", "title": "\u95ee\u7b54\u9898", "text": "<p>1.\u5982\u679c\u5bf9\u542b\u6709 \\( n(n&gt;1) \\) \u4e2a\u5143\u7d20\u7684\u7ebf\u6027\u8868\u7684\u8fd0\u7b97\u53ea\u67094\u79cd\uff1a\u5220\u9664\u7b2c\u4e00\u4e2a\u5143\u7d20\uff1b\u5220\u9664\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff1b\u5728\u7b2c\u4e00\u4e2a\u5143\u7d20\u524d\u9762\u63d2\u5165\u65b0\u5143\u7d20\uff1b\u5728\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u540e\u9762\u63d2\u5165\u65b0\u5143\u7d20\uff0c\u5219\u6700\u597d\u91c7\u7528\u4ee5\u4e0b\u54ea\u79cd\u5b58\u50a8\u7ed3\u6784\uff0c\u5e76\u7b80\u8981\u8bf4\u660e\u7406\u7531\u3002 \uff081\uff09\u53ea\u6709\u5c3e\u7ed3\u70b9\u6307\u9488\u6ca1\u6709\u5934\u7ed3\u70b9\u6307\u9488\u7684\u5faa\u73af\u5355\u94fe\u8868\u3002 \uff082\uff09\u53ea\u6709\u5c3e\u7ed3\u70b9\u6307\u9488\u6ca1\u6709\u5934\u7ed3\u70b9\u6307\u9488\u7684\u975e\u5faa\u73af\u53cc\u94fe\u8868\u3002 \uff083\uff09\u53ea\u6709\u5934\u7ed3\u70b9\u6307\u9488\u6ca1\u6709\u5c3e\u7ed3\u70b9\u6307\u9488\u7684\u5faa\u73af\u53cc\u94fe\u8868\u3002 \uff084\uff09\u65e2\u6709\u5934\u7ed3\u70b9\u6307\u9488\u4e5f\u6709\u5c3e\u7ed3\u70b9\u6307\u9488\u7684\u5faa\u73af\u5355\u94fe\u8868\u3002  </p>  \u7b54\u6848  <p>(3)</p> <p></p> \u5176\u5b9e\u9898\u76ee\u60f3\u8ba9\u6211\u4eec\u5b9e\u73b0\u7684\u6570\u636e\u7ed3\u6784\u53eb\u505a\u53cc\u7aef\u961f\u5217\u3002\u56e0\u4e3a\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\u90fd\u96c6\u4e2d\u5728\u5934\u5c3e\uff0c\u6211\u4eec\u6765\u5206\u6790\u4e00\u4e0b\u8fd9\u56db\u4e2a\u6570\u636e\u7ed3\u6784\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff1a <p></p> (1) : \u5982\u679c\u8fd9\u4e2a\u5faa\u73af\u5355\u94fe\u8868\u53ea\u6709\u5c3e\u7ed3\u70b9\uff0c\u90a3\u4e48\u5728\u8fdb\u884c\u63d2\u5165\u548c\u5220\u9664\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u65f6\u5019\uff0c\u90fd\u8981\u53bb\u5bfb\u627e\u5c3e\u7ed3\u70b9\u7684\u524d\u9a71\u7ed3\u70b9\uff0c\u4f46\u8fd9\u53c8\u662f\u4e00\u4e2a\u5355\u94fe\u8868\uff0c\u6ca1\u6709\u524d\u5411\u4fe1\u606f\uff0c\u6240\u4ee5\u4f1a\u6d6a\u8d39\u5faa\u73af\u4e00\u6b21\u5373 \\(O(n)\\) \u7684\u65f6\u95f4\u53bb\u627e\u524d\u9a71\u3002 <p></p> (2) : \u7531\u4e8e\u8fd9\u4e2a\u975e\u5faa\u73af\u7684\u53cc\u94fe\u8868\u6ca1\u6709\u5934\u7ed3\u70b9\uff0c\u5728\u63d2\u5165\u548c\u5220\u9664\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u65f6\u5019\u90fd\u8981\u6a2a\u8de8\u6574\u4e2a\u94fe\u8868\uff0c\u4e5f\u8981\u82b1 \\(O(n)\\) \u7684\u65f6\u95f4\u3002 <p></p> (3) : \u7531\u4e8e\u8fd9\u662f\u4e00\u4e2a\u5faa\u73af\u53cc\u94fe\u8868\uff0c\u8fd9\u65f6\u5019\u76f8\u6bd4\u4e8e (1) \u548c (2) \u800c\u8a00\uff0c\u63d2\u5165\u548c\u5220\u9664\u90fd\u80fd\u591f\u5f88\u65b9\u4fbf\uff08\u4e5f\u5c31\u662f \\(O(1)\\) \u65f6\u95f4\uff09\u83b7\u53d6\u5230\u5934\u5c3e\u9644\u8fd1\u7ed3\u70b9\u7684\u5730\u5740\uff0c\u4ee5\u8fdb\u884c\u4fee\u6539\u3002 <p></p> (4) : \u95ee\u9898\u5176\u5b9e\u548c (1) \u4e00\u6837\uff0c\u5373\u4f7f\u6709\u5934\u7ed3\u70b9\u4e5f\u5f88\u96be\u53bb\u627e\u5230\u5c3e\u7ed3\u70b9\u7684\u524d\u9a71\u7ed3\u70b9\u3002 <p></p>  \u6211\u81ea\u5df1\u7528\u5e26\u5934\u5c3e\u6307\u9488\u7684\u5faa\u73af\u53cc\u94fe\u8868\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u53cc\u7aef\u961f\u5217\uff0c\u53c2\u8003\uff1ahttps://dicaeopolis.github.io/stl-wheels/#deque  <p></p> <p>2.\u5bf9\u4e8e\u4e00\u4e2a\u5e26\u6743\u8fde\u901a\u65e0\u5411\u56fe \\( G \\)\uff0c\u53ef\u4ee5\u91c7\u7528 Prim \u7b97\u6cd5\u6784\u9020\u51fa\u4ece\u67d0\u4e2a\u9876\u70b9 \\( v \\) \u51fa\u53d1\u7684\u6700\u5c0f\u751f\u6210\u6811\uff0c\u95ee\u8be5\u6700\u5c0f\u751f\u6210\u6811\u662f\u5426\u4e00\u5b9a\u5305\u542b\u4ece\u9876\u70b9 \\( v \\) \u5230\u5176\u4ed6\u6240\u6709\u9876\u70b9\u7684\u6700\u77ed\u8def\u5f84\u3002\u5982\u679c\u56de\u7b54\u662f\uff0c\u8bf7\u4e88\u4ee5\u8bc1\u660e\uff1b\u5982\u679c\u56de\u7b54\u4e0d\u662f\uff0c\u8bf7\u7ed9\u51fa\u53cd\u4f8b\u3002 </p>  \u7b54\u6848  <p></p> \u672c\u9898\u8003\u5bdf\u7684\u662f\u6700\u5c0f\uff08\u4ee3\u4ef7\uff09\u751f\u6210\u6811\u548c\u6700\u77ed\u8def\u5f84\u6811\u7684\u533a\u522b\u3002 <p></p> \u6211\u4eec\u6ce8\u610f Prim \u7b97\u6cd5\u5728\u52a0\u8fb9\u7684\u65f6\u5019\u4f18\u5148\u9009\u62e9\u957f\u5ea6\u6700\u77ed\u7684\u76f8\u90bb\u8fb9\uff0c\u4f46\u662f Dijkstra \u7b97\u6cd5\u7684\u677e\u5f1b\u64cd\u4f5c\u9009\u53d6\u7684\u662f\u5230\u6e90\u70b9\u8ddd\u79bb\u6700\u77ed\u7684\u76f8\u90bb\u8fb9\u3002\u8fd9\u5f88\u4e0d\u4e00\u6837\u3002 <p></p> \u6784\u9020\u53cd\u4f8b\u65f6\u53ef\u4ee5\u8003\u8651\u6784\u9020\u4e00\u4e2a\u6811\uff0c\u7136\u540e\u5c06\u4e00\u4e2a\u53f6\u5b50\u7ed3\u70b9\u548c\u6839\u7ed3\u70b9\u76f8\u8fde\uff0c\u8fd9\u6761\u65b0\u8fb9\u7684\u6743\u503c\u5c0f\u4e8e\u539f\u6765\u6839\u5230\u8fd9\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u8def\u5f84\u957f\u5ea6\u5373\u53ef\uff0c\u6bd4\u5982\u4e0b\u9762\u8fd9\u4e2a\u7b80\u5355\u7684\u53cd\u4f8b\uff1a <p></p> <p>3.\u6709\u4e00\u68f5\u4e8c\u53c9\u6392\u5e8f\u6811\u6309\u5148\u5e8f\u904d\u5386\u5f97\u5230\u7684\u5e8f\u5217\u4e3a \\( (12, 5, 2, 8, 6, 10, 16, 15, 18, 20) \\)\u3002\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898\uff1a \uff081\uff09\u753b\u51fa\u8be5\u4e8c\u53c9\u6392\u5e8f\u6811\u3002 \uff082\uff09\u7ed9\u51fa\u8be5\u4e8c\u53c9\u6392\u5e8f\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u5e8f\u5217\u3002 \uff083\uff09\u6c42\u5728\u7b49\u6982\u7387\u4e0b\u7684\u67e5\u627e\u6210\u529f\u548c\u4e0d\u6210\u529f\u60c5\u51b5\u4e0b\u7684\u5e73\u5747\u67e5\u627e\u957f\u5ea6\u3002  </p>  \u7b54\u6848  <p></p> \u6ce8\u610f\u5148\u5e8f\u904d\u5386\u662f ULR \u7684\u987a\u5e8f\uff0c\u6240\u4ee5\u7b2c\u4e00\u4e2a\u7ed3\u70b9\u4e00\u5b9a\u662f\u6839\u7ed3\u70b9\uff0c\u53c8\u56e0\u4e3a BST \u7684\u5de6\u5b50\u6811\u90fd\u662f\u5c0f\u4e8e\u6839\u7ed3\u70b9\uff0c\u53f3\u5b50\u6811\u5927\u4e8e\u6839\u7ed3\u70b9\uff0c\u56e0\u6b64\u627e\u5230\u7b2c\u4e00\u4e2a\u5927\u4e8e\u6839\u7ed3\u70b9\u7684\u6570\u636e\u5c31\u53ef\u4ee5\u533a\u5206\u5f00\u5de6\u53f3\u5b50\u6811\u4e86\uff0c\u5982\u56fe\uff1a <p></p> <p></p> \u5bf9\u4e8e\u67e5\u627e\u6210\u529f\u800c\u8a00\uff0c\u627e\u5230\u6bcf\u4e2a\u7ed3\u70b9\u7684\u67e5\u627e\u957f\u5ea6\u5c31\u662f\u5230\u6839\u7ed3\u70b9\u7684\u8def\u5f84\u957f\u5ea6\u52a0\u4e00\uff08\u56e0\u4e3a\u8981\u7b97\u4e0a\u6839\u7ed3\u70b9\u672c\u8eab\u7684\u67e5\u627e\uff09\uff1a  $$ L = \\dfrac{1}{10}(1+2\\times 2+3\\times 4+4\\times 3)=1.9 $$  \u5bf9\u4e8e\u67e5\u627e\u4e0d\u6210\u529f\uff0c\u8003\u8651\u4e0a\u56fe\u52a0\u4e0a\u5916\u90e8\u7ed3\u70b9\u8868\u793a\u67e5\u627e\u5931\u8d25\u8bbf\u95ee\u5230\u7684\u7ed3\u70b9\uff0c\u5982\u56fe\uff1a  <p></p> \u5219\u957f\u5ea6\u7b49\u4e8e\uff1a  $$ L = \\dfrac{1}{11}(4\\times 5+5\\times 6)=\\dfrac{30}{11} $$  <p></p>"}, {"location": "campus-sources/ds-write-up/#_5", "title": "\u7b97\u6cd5\u8bbe\u8ba1\u9898", "text": "<p>1.\uff0815\u5206\uff09\u5047\u8bbe\u4e8c\u53c9\u6811 \\( b \\) \u91c7\u7528\u4e8c\u53c9\u94fe\u5b58\u50a8\u7ed3\u6784\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u7b97\u6cd5 <code>void findparent(BTNode *b, ElemType x, BTNode *&amp;p)</code> \u6c42\u6307\u5b9a\u503c\u4e3a \\( x \\) \u7684\u7ed3\u70b9\u7684\u53cc\u4eb2\u7ed3\u70b9 \\( p \\)\u3002\u63d0\u793a\uff1a\u6839\u7ed3\u70b9\u7684\u53cc\u4eb2\u4e3a <code>NULL</code>\uff0c\u82e5\u5728\u4e8c\u53c9\u6811 \\( b \\) \u4e2d\u672a\u627e\u5230\u503c\u4e3a \\( x \\) \u7684\u7ed3\u70b9\uff0c\\( p \\) \u4e5f\u4e3a <code>NULL</code>\u3002 </p>  \u7b54\u6848  <p></p> \u601d\u8def\u662f\u4ece\u6839\u7ed3\u70b9\u5f00\u59cb\u6df1\u641c\uff0c\u5982\u679c\u5f53\u524d\u7ed3\u70b9\u7684\u5b50\u7ed3\u70b9\u503c\u4e3a x\uff0c\u90a3\u4e48\u8be5\u7ed3\u70b9\u5c31\u662f\u6240\u6c42\u7684\u7ed3\u70b9 p\u3002\u800c\u4e14\u5982\u679c\u5df2\u7ecf\u6c42\u5f97 p\uff0c\u90a3\u4e48\u5269\u4e0b\u7684\u641c\u7d22\u90fd\u53ef\u4ee5\u526a\u679d\u8df3\u8fc7\u4e86\u3002 <p></p> <pre><code>void findparent(BTNode *b, ElemType x, BTNode *&amp;p)\n{\n   if(b == NULL || b-&gt;data == x)// \u5229\u7528\u4e86\u6216\u8fd0\u7b97\u7684\u77ed\u8def\u6027\u8d28\uff0c\u53ea\u6709 b != NULL \u624d\u4f1a\u8bbf\u95ee data\uff0c\u9632\u6b62\u5bf9\u7a7a\u5730\u5740\u7684\u89e3\u5f15\u7528\u3002\n   {\n      p = NULL;\n      return ;\n   }\n   if( (b-&gt;lchild != NULL &amp;&amp; b-&gt;lchild-&gt;data == x) || (b-&gt;rchild != NULL &amp;&amp; b-&gt;rchild-&gt;data == x))\n      p = b;\n   else\n   {\n      findparent(b-&gt;lchild, x, p);\n      if(p == NULL)\n         findparent(b-&gt;rchild, x, p);\n   }\n}\n</code></pre> <p></p> <p>2.\uff0810\u5206\uff09\u5047\u8bbe\u4e00\u4e2a\u6709\u5411\u56fe \\( G \\) \u91c7\u7528\u90bb\u63a5\u8868\u5b58\u50a8\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u7b97\u6cd5\u5224\u65ad\u9876\u70b9 \\( i \\) \u548c\u9876\u70b9 \\( j \\)\uff08\\( i \\neq j \\)\uff09\u4e4b\u95f4\u662f\u5426\u76f8\u4e92\u8fde\u901a\uff0c\u5047\u8bbe\u8fd9\u4e24\u4e2a\u9876\u70b9\u5747\u5b58\u5728\u3002  </p>  \u7b54\u6848  <p></p> \u4efb\u610f\u4f7f\u7528\u4e00\u79cd\u641c\u7d22\u7b97\u6cd5\uff0c\u5982\u679c\u4ece i \u51fa\u53d1\u80fd\u591f\u641c\u7d22\u5230 j\uff0c\u5e76\u4e14\u4ece j \u51fa\u53d1\u80fd\u591f\u641c\u7d22\u5230 i\uff0c\u90a3\u4e48\u5c31\u8bf4\u660e\u4e24\u8005\u8fde\u901a\u3002\u4e3a\u65b9\u4fbf\u5b9e\u73b0\u6211\u8fd9\u91cc\u4f7f\u7528\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u3002 <p></p> <pre><code>bool vis[N];\nstd::array&lt;std::vector&lt;int&gt;, N&gt; G;\nvoid dfs(int curr, const int&amp; j, bool&amp; tag)\n{\n   if(tag) return ;\n   if(curr == j)\n   {\n      tag = true;\n      return ;\n   }\n   vis[curr] = true;\n   for(auto adj : G[curr])\n      if(!vis[adj])\n         dfs(adj, j, tag);\n}\nbool is_connected(const int&amp; i, const int&amp; j)\n{\n   std::fill(vis.begin(), vis.end(), 0);\n   bool tag_i2j = false, tag_j2i = false;\n   dfs(i, j, tag_i2j);\n   if(tag_i2j)\n   {\n      std::fill(vis.begin(), vis.end(), 0);\n      dfs(j, i, tag_j2i);\n      if(tag_j2i) return true;\n   }\n   return false;\n}\n</code></pre> <p></p> <p>3.\uff0815\u5206\uff09\u6709\u4e00\u4e2a\u542b\u6709 \\( n \\) \u4e2a\u6574\u6570\u7684\u65e0\u5e8f\u6570\u636e\u5e8f\u5217\uff0c\u6240\u6709\u7684\u6570\u636e\u5143\u7d20\u5747\u4e0d\u76f8\u540c\uff0c\u91c7\u7528\u6574\u6570\u6570\u7ec4 \\( R[0..n-1] \\) \u5b58\u50a8\uff0c\u8bf7\u5b8c\u6210\u4ee5\u4e0b\u4efb\u52a1\uff1a \uff081\uff09\u8bbe\u8ba1\u4e00\u4e2a\u5c3d\u53ef\u80fd\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u8f93\u51fa\u8be5\u5e8f\u5217\u4e2d\u7b2c \\( k \\)\uff08\\( 1 \\leq k \\leq n \\)\uff09\u5c0f\u7684\u5143\u7d20\uff0c\u7b97\u6cd5\u4e2d\u7ed9\u51fa\u9002\u5f53\u7684\u6ce8\u91ca\u4fe1\u606f\u3002\u63d0\u793a\uff1a\u5229\u7528\u5feb\u901f\u6392\u5e8f\u7684\u601d\u8def\u3002 \uff082\uff09\u5206\u6790\u4f60\u6240\u8bbe\u8ba1\u7684\u6c42\u89e3\u7b97\u6cd5\u7684\u5e73\u5747\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u7ed9\u51fa\u6c42\u89e3\u8fc7\u7a0b\u3002</p> <p>\u672c\u9898\u53ef\u4ee5\u5728\u6d1b\u8c37\u4e0a\u9762\u505a\uff1ahttps://www.luogu.com.cn/problem/P1923</p>  \u7b54\u6848  <p></p> \u6211\u4eec\u8003\u8651\u5feb\u901f\u6392\u5e8f\u91cc\u9762\u7684\u5212\u5206\u64cd\u4f5c\uff0c\u5373\uff1a\u9009\u53d6\u4e00\u4e2a\u5143\u7d20 e\uff0c\u7136\u540e\u628a\u6240\u6709\u5c0f\u4e8e\u5b83\u7684\u5143\u7d20\u653e\u5728\u5b83\u7684\u524d\u8fb9\uff0c\u5927\u4e8e\u5b83\u7684\u5143\u7d20\u653e\u5728\u5b83\u7684\u540e\u8fb9\uff0c\u8fd9\u6837\u4e00\u4e2a\u64cd\u4f5c\u3002\u90a3\u4e48\u6b64\u65f6\uff0ce \u524d\u9762\u7684\u6570\u90fd\u5c0f\u4e8e e\uff0c\u4e5f\u5c31\u662f\u8bf4\u5047\u8bbe\u73b0\u5728 e \u7684\u4e0b\u6807\u4e3a idx\uff0c\u5219 e \u5c31\u662f\u7b2c (idx + 1) \u5c0f\u7684\u6570\u3002\u5982\u679c (idx + 1) &lt; k\uff0c\u90a3\u4e48\u610f\u5473\u7740\u7b2c k \u5c0f\u7684\u6570\u5728 e \u7684\u540e\u9762\uff0c\u5982\u679c\u5927\u4e8e\u5c31\u662f\u5728\u524d\u9762\uff0c\u5982\u679c\u7b49\u4e8e\uff0c\u76f4\u63a5\u8fd4\u56de e \u7684\u503c\u5373\u53ef\u3002\u8fd9\u6837\u6bcf\u4e00\u6b21\u6211\u4eec\u90fd\u6392\u9664\u4e00\u90e8\u5206\u533a\u95f4\uff0c\u5c31\u80fd\u9012\u5f52\u6c42\u51fa e \u6765\u3002 <p></p> \u4ee3\u7801: <p></p> <pre><code>int partition(int pivot_index, int *data, int left, int right)\n{\n   int pivot = data[pivot_index], i = left, j = right;\n   while(i &lt; j)\n   {\n      while(i &lt; j &amp;&amp; data[j] &gt;= pivot) --j;\n      data[i] = data[j];\n      while(i &lt; j &amp;&amp; data[i] &lt;= pivot) ++i;\n      data[j] = data[i];\n   }\n   data[i] = pivot;\n   return i;\n}\nint kth(int *data, int left, int right, int k)\n{\n   if(left &lt; right)\n   {\n      int pivot_index = partition(left, data, left, right);\n      int n = pivot_index;\n      if(n &gt; k) return kth(data, left, pivot_index, k);\n      if(n &lt; k) return kth(data, pivot_index + 1, right, k);\n      if(n == k) return data[pivot_index];\n   }\n   return data[left];\n}\nint solve_kth(int *data, int length, int k)\n{\n   return kth(data, 0, length - 1, k - 1);\n}\n</code></pre> <p></p> \u5bf9\u4e8e\u957f\u5ea6\u4e3a m \u7684\u5e8f\u5217\uff0c\u8fdb\u884c\u4e00\u6b21\u5212\u5206\u9700\u8981\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(m)\uff0c\u540c\u65f6\u95ee\u9898\u89c4\u6a21\u53d8\u6210 m / 2\u3002  $$ \\begin{equation*}   \\begin{aligned}     T(n) &amp;= O(n) + T(n / 2) \\\\          &amp;= O(n) + O(n / 2) + T(n / 4) \\\\          &amp;= O(n) + O(n / 2) + O(n / 4) + ... \\\\          &amp;= 2*O(n)\\\\          &amp;= O(n)   \\end{aligned} \\end{equation*} $$ <p></p>"}, {"location": "campus-sources/ds-write-up/#_6", "title": "\u7b2c\u4e94\u7248\u7b2c\u4e8c\u5957\u9898\u76ee", "text": ""}, {"location": "campus-sources/ds-write-up/#_7", "title": "\u5355\u9879\u9009\u62e9\u9898", "text": "<p>1.\u4ee5\u4e0b\u6570\u636e\u7ed3\u6784\u4e2d______\u5c5e\u975e\u7ebf\u6027\u7ed3\u6784\u3002    A. \u6808    B. \u4e32    C. \u961f\u5217    D. \u5e73\u8861\u4e8c\u53c9\u6811</p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u6811\u4e0d\u662f\u7ebf\u6027\u7ed3\u6784\u3002 <p></p> <p>2.\u4ee5\u4e0b\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a______\u3002 <pre><code>void func(int n)\n{ \n    int i = 0, s = 0;\n    while (s &lt;= n)\n    { \n        i++;\n        s = s + i;\n    }\n}\n</code></pre> A. \\( O(n) \\) B. \\( O(\\sqrt{n}) \\) C. \\( O(n\\log_2 n) \\) D. \\( O(\\log_2 n) \\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u53c2\u8003\u7b2c\u4e00\u5957\u9898\u7684\u7b2c\u4e8c\u9053\u5355\u9009\u9898\u3002 <p></p> <p>3.\u5728\u4e00\u4e2a\u53cc\u94fe\u8868\u4e2d\uff0c\u5220\u9664 \\( p \\) \u6240\u6307\u7ed3\u70b9\uff08\u975e\u9996\u3001\u5c3e\u7ed3\u70b9\uff09\u7684\u64cd\u4f5c\u662f______\u3002 A.  <pre><code>p-&gt;prior-&gt;next = p-&gt;next; \np-&gt;next-&gt;prior = p-&gt;prior\n</code></pre> B. <pre><code>p-&gt;prior = p-&gt;prior-&gt;prior;\np-&gt;prior-&gt;prior = p\n</code></pre> C. <pre><code>p-&gt;next-&gt;prior = p;\np-&gt;next = p-&gt;next-&gt;next\n</code></pre> D. <pre><code>p-&gt;next = p-&gt;prior-&gt;prior;\np-&gt;prior = p-&gt;prior-&gt;prior\n</code></pre></p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u6211\u4eec\u8981\u505a\u7684\u5c31\u662f\u8ba9\u524d\u540e\u7ed3\u70b9\u201c\u7ed5\u8fc7\u201d p\uff0c\u4e5f\u5c31\u662f\u8ba9 p \u7684\u524d\u9a71\u7684\u540e\u7ee7\u8bbe\u7f6e\u6210 p \u7684\u540e\u7ee7\uff0c\u540c\u65f6 p \u7684\u540e\u7ee7\u7684\u524d\u9a71\u8bbe\u7f6e\u6210 p \u7684\u524d\u9a71\u3002\u628a\u8fd9\u4e2a\u64cd\u4f5c\u7ffb\u8bd1\u6210\u4ee3\u7801\u5c31\u5f97\u5230\u4e86 A \u9009\u9879\u3002 <p></p> <p>4.\u8bbe \\( n \\) \u4e2a\u5143\u7d20\u7684\u8fdb\u6808\u5e8f\u5217\u662f \\( 1\u30012\u30013\u3001\u2026\u3001n \\)\uff0c\u5176\u8f93\u51fa\u5e8f\u5217\u662f \\( p_1\u3001p_2\u3001\u2026\u3001p_n \\)\uff0c\u82e5 \\( p_1=3 \\)\uff0c\u5219 \\( p_2 \\) \u7684\u503c\u4e3a______\u3002 A. \u4e00\u5b9a\u662f2 B. \u4e00\u5b9a\u662f1 C. \u4e0d\u53ef\u80fd\u662f1 D. \u4ee5\u4e0a\u90fd\u4e0d\u5bf9  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002p_2 \u8981\u4e48\u662f\u63a5\u7740 p_1 \u51fa\u6808\uff0c\u6b64\u65f6\u503c\u4e3a2\uff0c\u8981\u4e48\u5c31\u662f\u63a5\u53d7\u66f4\u591a\u8fdb\u6808\u7684\u6570\uff0c\u800c\u8fdb\u6808\u5e8f\u5217\u662f\u5355\u8c03\u9012\u589e\u7684\uff0c\u600e\u4e48\u90fd\u4e0d\u53ef\u80fd\u4e0b\u964d\u5230 1 \u3002 <p></p> <p>5.\u5728\u6570\u636e\u5904\u7406\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u9700\u8981\u4fdd\u5b58\u4e00\u4e9b\u4e2d\u95f4\u6570\u636e\uff0c\u5982\u679c\u8981\u5b9e\u73b0\u5148\u4fdd\u5b58\u7684\u6570\u636e\u5148\u5904\u7406\uff0c\u5219\u5e94\u91c7\u7528______\u6765\u4fdd\u5b58\u8fd9\u4e9b\u6570\u636e\u3002 A. \u7ebf\u6027\u8868 B. \u6808 C. \u961f\u5217 D. \u5355\u94fe\u8868  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u9898\u76ee\u660e\u793a\u4e86\u5148\u8fdb\u5148\u51fa\u7684\u6570\u636e\u7ed3\u6784\uff0c\u8fd9\u5c31\u662f\u961f\u5217\u3002 <p></p> <p>6.\u4e2d\u7f00\u8868\u8fbe\u5f0f \\( a*(b+c)-d \\) \u5bf9\u5e94\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u662f______\u3002 A. \\( a\\ b\\ c\\ d\\ *\\ +\\ - \\) B. \\( a\\ b\\ c\\ +\\ *\\ d\\ - \\) C. \\( a\\ b\\ c\\ *\\ +\\ d\\ - \\) D. \\( -\\ +\\ *\\ a\\ b\\ c\\ d \\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u6211\u4eec\u628a\u7b54\u6848\u7684\u540e\u7f00\u8868\u8fbe\u5f0f\u8f6c\u6362\u6210\u4e2d\u7f00\uff0c\u6280\u5de7\u5c31\u662f\u628a\u53c2\u6570\u538b\u5165\u4e00\u4e2a\u6808\u91cc\u9762\uff0c\u7136\u540e\u8bfb\u5230\u8fd0\u7b97\u7b26\u5c31\u5f39\u51fa\u6700\u9876\u4e0a\u4e24\u4e2a\u6570\uff0c\u76f4\u5230\u5f97\u5230\u7ed3\u679c\u3002D \u9009\u9879\u4e0d\u662f\u540e\u7f00\u8868\u8fbe\u5f0f\uff0c\u4e0b\u9762\u5206\u6790 ABC: <p></p> A: a - (c * d + b) <p></p> B: (b + c) * a - d <p></p> C: b * c + a - d <p></p> <p>7.\u8bbe\u6808 \\( s \\) \u548c\u961f\u5217 \\( q \\) \u7684\u521d\u59cb\u72b6\u6001\u90fd\u4e3a\u7a7a\uff0c\u5143\u7d20 \\( a\u3001b\u3001c\u3001d\u3001e \\) \u548c \\( f \\) \u4f9d\u6b21\u901a\u8fc7\u6808 \\( s \\)\uff0c\u4e00\u4e2a\u5143\u7d20\u51fa\u6808\u540e\u5373\u8fdb\u5165\u961f\u5217 \\( q \\)\uff0c\u82e56\u4e2a\u5143\u7d20\u51fa\u961f\u7684\u5e8f\u5217\u662f \\( b\u3001d\u3001c\u3001f\u3001e\u3001a \\)\uff0c\u5219\u6808 \\( s \\) \u7684\u5bb9\u91cf\u81f3\u5c11\u80fd\u5b58______\u4e2a\u5143\u7d20\u3002 A. 2 B. 3 C. 4 D. 5  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u9996\u5148\u961f\u5217\u662f\u5148\u8fdb\u5148\u51fa\u7684\uff0c\u90a3\u4e48\u5c31\u6709\uff1a\u51fa\u6808\u5e8f\u5217=\u5165\u961f\u5e8f\u5217=\u51fa\u961f\u5e8f\u5217\u3002 <p></p> \u7136\u540e\u5982\u56fe\u6a21\u62df\u4e00\u4e0b\u6808\u7684\u8fd0\u884c\u5373\u53ef\uff1a  <p></p> <p>8.\u6267\u884c\u4ee5\u4e0b______\u64cd\u4f5c\u65f6\uff0c\u9700\u8981\u4f7f\u7528\u961f\u5217\u4f5c\u4e3a\u8f85\u52a9\u5b58\u50a8\u7a7a\u95f4\u3002 A. \u56fe\u7684\u6df1\u5ea6\u4f18\u5148\u904d\u5386 B. \u4e8c\u53c9\u6811\u7684\u5148\u5e8f\u904d\u5386 C. \u5e73\u8861\u4e8c\u53c9\u6811\u67e5\u627e D. \u56fe\u7684\u5e7f\u5ea6\u4f18\u5148\u904d\u5386  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002ABC \u90fd\u662f\u9012\u5f52\u7b97\u6cd5\uff0c\u53ea\u6709 D \u9700\u8981\u5229\u7528\u961f\u5217\u5148\u8fdb\u5148\u51fa\u7684\u7279\u70b9\u4fdd\u5b58\u5e7f\u5ea6\u4fe1\u606f\u3002 <p></p> <p>9.\u82e5\u5c06 \\( n \\) \u9636\u4e0a\u4e09\u89d2\u77e9\u9635 \\( A \\) \u6309\u5217\u4f18\u5148\u987a\u5e8f\u538b\u7f29\u5b58\u653e\u5728\u4e00\u7ef4\u6570\u7ec4 \\( B[1..n(n+1)/2] \\) \u4e2d\uff0c\\( A \\) \u4e2d\u7b2c\u4e00\u4e2a\u975e\u96f6\u5143\u7d20 \\( a_{1,1} \\) \u5b58\u4e8e \\( B \\) \u6570\u7ec4\u7684 \\( b_1 \\) \u4e2d\uff0c\u5219\u5e94\u5b58\u653e\u5230 \\( b_k \\) \u4e2d\u7684\u5143\u7d20 \\( a_{i,j} \\)\uff08\\( 1\u2264i\u2264j \\)\uff09\u7684\u4e0b\u6807 \\( i\u3001j \\) \u4e0e \\( k \\) \u7684\u5bf9\u5e94\u5173\u7cfb\u662f______\u3002 A. \\( i(i+1)/2 + j \\) B. \\( i(i\u22121)/2 + j \\) C. \\( j(j+1)/2 + i \\) D. \\( j(j\u22121)/2 + i \\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u6309\u5217\u5b58\u50a8\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e00\u5217\u90fd\u644a\u5e73\u5230\u4e00\u7ef4\u4e0a\u9762\uff0c\u662f\u5bf9\u5217\u5750\u6807\u6c42\u548c\u4e4b\u540e\u518d\u52a0\u4e0a\u884c\u5750\u6807\uff0c\u7136\u540e\u518d\u628a\u9898\u76ee\u7ed9\u7684(1,1)\u7279\u6b8a\u503c\u5e26\u8fdb\u53bb\u5c31\u5f97\u5230 D \u9009\u9879\u4e86\u3002 <p></p> <p>10.\u4e00\u68f5\u7ed3\u70b9\u4e2a\u6570\u4e3a \\( n \\)\u3001\u9ad8\u5ea6\u4e3a \\( h \\) \u7684 \\( m \\)\uff08\\( m\u22653 \\)\uff09\u6b21\u6811\u4e2d\uff0c\u5176\u603b\u5206\u652f\u6570\u662f______\u3002 A. \\( nh \\) B. \\( n+m \\) C. \\( n\u22121 \\) D. \\( h\u22121 \\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u9664\u4e86\u6839\u7ed3\u70b9\u4ee5\u5916\uff0c\u6240\u6709\u7ed3\u70b9\u90fd\u80fd\u88ab\u8bb0\u4f5c\u4e00\u4e2a\u5206\u652f\uff0c\u56e0\u6b64\u662f\u603b\u7ed3\u70b9\u6570\u51cf\u53bb 1\u3002 <p></p> <p>11.\u8bbe\u68ee\u6797 \\( F \\) \u5bf9\u5e94\u7684\u4e8c\u53c9\u6811\u4e3a \\( B \\)\uff0c\\( B \\) \u4e2d\u6709 \\( m \\) \u4e2a\u7ed3\u70b9\uff0c\u5176\u6839\u7ed3\u70b9\u7684\u53f3\u5b50\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u4e3a \\( n \\)\uff0c\u68ee\u6797 \\( F \\) \u4e2d\u7b2c\u4e00\u68f5\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u662f______\u3002 A. \\(m - n\\) B. \\(m - n - 1\\) C. \\(n + 1\\) D. \u6761\u4ef6\u4e0d\u8db3\uff0c\u65e0\u6cd5\u786e\u5b9a  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u672c\u9898\u8003\u5bdf\u5de6\u513f\u5b50\u53f3\u5144\u5f1f\u6cd5\u3002\u4e5f\u5c31\u662f\u53f3\u8fb9\u7684\u5b50\u6811\u90fd\u548c\u5b83\u7684\u7236\u6bcd\u7ed3\u70b9\u662f\u540c\u4e00\u5c42\u7ea7\u7684\u3002\u53f3\u5b50\u6811\u7684\u7ed3\u70b9\u6570\u4e3a n\uff0c\u8bf4\u660e\u9664\u4e86\u7b2c\u4e00\u68f5\u6811\u4ee5\u5916\u6240\u6709\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u4e3a n\u3002 <p></p> <p>12.\u4e00\u68f5\u4e8c\u53c9\u6811\u7684\u5148\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a ABCDEF\u3001\u4e2d\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a CBAEDF\uff0c\u5219\u540e\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a______\u3002    A. CBEFDA    B. FEDCBA    C. CBEDFA    D. \u4e0d\u786e\u5b9a  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002 <p></p> \u9996\u5148\u5148\u5e8f\u904d\u5386\u662f ULR \u7684\u987a\u5e8f\uff0c\u4e2d\u5e8f\u904d\u5386\u662f LUR \u7684\u987a\u5e8f\uff0c\u540e\u5e8f\u904d\u5386\u662f LRU \u7684\u987a\u5e8f\u3002\u4ece\u4e2d\u5e8f\u5e8f\u5217\u91cc\u9762\u627e\u5230\u5148\u5e8f\u7cfb\u5217\u7684\u7b2c\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5c31\u81ea\u7136\u5730\u5212\u5206\u5f00\u4e86\u5de6\u53f3\u5b50\u6811\uff0c\u7531\u6b64\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u8fd9\u6837\u4e00\u4e2a\u4e8c\u53c9\u6811\uff1a  <pre><code>             A\n            / \\\n           B   D\n          /   / \\\n         C   E   F\n</code></pre>  \u5f97\u5230\u540e\u5e8f\u5e8f\u5217\u4e3a\uff1aCBEFDA <p></p> <p>13.\u5728\u4e00\u4e2a\u5177\u6709 \\(n\\) \u4e2a\u9876\u70b9\u7684\u6709\u5411\u56fe\u4e2d\uff0c\u6784\u6210\u5f3a\u8fde\u901a\u56fe\u65f6\u81f3\u5c11\u6709______\u6761\u8fb9\u3002    A. \\(n\\)    B. \\(n + 1\\)    C. \\(n - 1\\)    D. \\(n / 2\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u8981\u6c42\u5f3a\u8fde\u901a\uff0c\u5219\u6bcf\u4e2a\u7ed3\u70b9\u81f3\u5c11\u8981\u6709\u4e00\u4e2a\u5165\u5ea6\u548c\u4e00\u4e2a\u51fa\u5ea6\uff0c\u8fd9\u6837\u624d\u80fd\u4fdd\u8bc1\u5176\u4ed6\u7ed3\u70b9\u80fd\u8bbf\u95ee\u5230\u5b83\uff0c\u5b83\u4e5f\u80fd\u8bbf\u95ee\u5230\u5176\u5b83\u7ed3\u70b9\u3002\u4e0d\u96be\u60f3\u5230\u628a\u8fd9 n \u4e2a\u70b9\u4e32\u6210\u4e00\u4e2a\u5faa\u73af\u5355\u94fe\u8868\uff0c\u8fd9\u6837\u6bcf\u4e00\u4e2a\u70b9\u7684\u51fa\u5ea6\u5c31\u662f\u4e0b\u4e00\u4e2a\u7ed3\u70b9\u7684\u5165\u5ea6\uff0c\u4e00\u5171 n \u6761\u8fb9\u3002\u82e5\u6bd4 n \u66f4\u5c0f\uff0c\u5fc5\u7136\u5b58\u5728\u6709\u7ed3\u70b9\u6ca1\u6709\u5165\u5ea6\u6216\u8005\u51fa\u5ea6\u3002 <p></p> <p>14.\u5bf9\u4e8e\u6709 \\(n\\) \u4e2a\u9876\u70b9\u7684\u5e26\u6743\u8fde\u901a\u56fe\uff0c\u5b83\u7684\u6700\u5c0f\u751f\u6210\u6811\u662f\u6307\u56fe\u4e2d\u4efb\u610f\u4e00\u4e2a______\u3002    A. \u7531 \\(n - 1\\) \u6761\u6743\u503c\u6700\u5c0f\u7684\u8fb9\u6784\u6210\u7684\u5b50\u56fe    B. \u7531 \\(n - 1\\) \u6761\u6743\u503c\u4e4b\u548c\u6700\u5c0f\u7684\u8fb9\u6784\u6210\u7684\u5b50\u56fe    C. \u7531 \\(n - 1\\) \u6761\u6743\u503c\u4e4b\u548c\u6700\u5c0f\u7684\u8fb9\u6784\u6210\u7684\u8fde\u901a\u5b50\u56fe    D. \u7531 \\(n\\) \u4e2a\u9876\u70b9\u6784\u6210\u7684\u6781\u5c0f\u8fde\u901a\u5b50\u56fe\uff0c\u4e14\u8fb9\u7684\u6743\u503c\u4e4b\u548c\u6700\u5c0f  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002ABC \u7684\u8bf4\u6cd5\u90fd\u6709\u4e00\u4e2a\u6f5c\u5728\u95ee\u9898\uff0c\u5373 n - 1 \u6761\u6743\u503c\u4e4b\u548c\u6700\u5c0f\u7684\u8fb9\u4e0d\u4e00\u5b9a\u80fd\u6784\u6210\u4e00\u4e2a\u8fde\u901a\u5b50\u56fe\u3002\u6700\u5c0f\u751f\u6210\u6811\u7684\u524d\u63d0\u6761\u4ef6\u5e94\u5f53\u662f\u4e00\u68f5\u6811\uff0c\u4e5f\u5c31\u662f\u8981\u8fde\u901a\u3002 <p></p> <p>15.\u5bf9\u4e8e\u6709 \\(n\\) \u4e2a\u9876\u70b9\u3001\\(e\\) \u6761\u8fb9\u7684\u6709\u5411\u56fe\uff0c\u91c7\u7528\u90bb\u63a5\u77e9\u9635\u8868\u793a\uff0c\u6c42\u5355\u6e90\u6700\u77ed\u8def\u5f84\u7684 Dijkstra \u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a______\u3002    A. \\(O(n)\\)    B. \\(O(n + e)\\)    C. \\(O(n^2)\\)    D. \\(O(ne)\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002Dijkstra \u7b97\u6cd5\u5206\u4e24\u6b65\uff0c\u5bf9\u6bcf\u4e2a\u7ed3\u70b9\u800c\u8a00\uff0c\u7b2c\u4e00\u6b65\u6c42\u53d6\u6700\u77ed\u8def\u5f84\u8fb9\uff0c\u7b2c\u4e8c\u6b65\u677e\u5f1b\uff0c\u6211\u4eec\u5206\u5f00\u6765\u770b\u3002 <p></p> \u90bb\u63a5\u77e9\u9635\u662f\u4e00\u4e2a\u5f88\u7cdf\u7cd5\u7684\u6570\u636e\u7ed3\u6784\u3002\u5728\u677e\u5f1b\u627e\u90bb\u63a5\u8fb9\u7684\u65f6\u5019\u5c31\u8981\u904d\u5386\u6240\u6709\u7ed3\u70b9\uff0c\u65f6\u95f4\u590d\u6742\u5ea6 O(n)\uff0c\u6240\u4ee5\u7b2c\u4e8c\u6b65\u65f6\u95f4\u590d\u6742\u5ea6\u5c31\u6765\u5230\u4e86 O(n^2)\u3002\u7b2c\u4e00\u6b65\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u94fe\u8868\u505a\u5230\u603b O(n^2) \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u6216\u8005\u5229\u7528\u5806\u5b9e\u73b0\u66f4\u4f18\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4f46\u90fd\u65e0\u529b\u56de\u5929\uff0c\u603b\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a O(n^2)\u3002 <p></p> <p>16.\u4e00\u68f5\u9ad8\u5ea6\u4e3a \\(h\\) \u7684\u5e73\u8861\u4e8c\u53c9\u6811\uff0c\u5176\u4e2d\u6bcf\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u5e73\u8861\u56e0\u5b50\u5747\u4e3a 0\uff0c\u5219\u8be5\u6811\u7684\u7ed3\u70b9\u4e2a\u6570\u662f______\u3002    A. \\(2^{h - 1} - 1\\)    B. \\(2^{h - 1}\\)    C. \\(2^{h - 1} + 1\\)    D. \\(2^h - 1\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u5e73\u8861\u56e0\u5b50\u662f\u5de6\u5b50\u6811\u9ad8\u5ea6\u51cf\u53bb\u53f3\u5b50\u6811\u9ad8\u5ea6\uff0c\u7531\u4e8e\u5e73\u8861\u56e0\u5b50\u662f0\uff0c\u610f\u5473\u7740\u8fd9\u662f\u4e00\u9897\u6ee1\u4e8c\u53c9\u6811\u3002\u56e0\u6b64\u7ed3\u70b9\u4e2a\u6570\uff1a  $$ N=\\sum_{i = 0}^{h - 1}2^i = 2^{h}-1 $$  <p></p> <p>17.\u5728\u5bf9\u7ebf\u6027\u8868\u8fdb\u884c\u6298\u534a\u67e5\u627e\u65f6\uff0c\u8981\u6c42\u7ebf\u6027\u8868\u5fc5\u987b______\u3002    A. \u4ee5\u987a\u5e8f\u65b9\u5f0f\u5b58\u50a8    B. \u4ee5\u94fe\u63a5\u65b9\u5f0f\u5b58\u50a8    C. \u4ee5\u987a\u5e8f\u65b9\u5f0f\u5b58\u50a8\uff0c\u4e14\u7ed3\u70b9\u6309\u5173\u952e\u5b57\u6709\u5e8f\u6392\u5e8f    D. \u4ee5\u94fe\u8868\u65b9\u5f0f\u5b58\u50a8\uff0c\u4e14\u7ed3\u70b9\u6309\u5173\u952e\u5b57\u6709\u5e8f\u6392\u5e8f  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u8981\u6298\u534a\uff0c\u5c31\u5f97\u652f\u6301\u968f\u673a\u8bbf\u95ee\u3002\u56e0\u6b64\u5fc5\u987b\u6309\u987a\u5e8f\u5b58\u50a8\uff0c\u540c\u65f6\u652f\u6301\u4e22\u5f03\u4e00\u534a\u7684\u533a\u95f4\u3002\u56e0\u6b64\u8981\u6709\u5e8f\u3002 <p></p> <p>18.\u5047\u8bbe\u6709 \\(k\\) \u4e2a\u5173\u952e\u5b57\u4e92\u4e3a\u540c\u4e49\u8bcd\uff0c\u82e5\u7528\u7ebf\u6027\u63a2\u6d4b\u6cd5\u628a\u8fd9 \\(k\\) \u4e2a\u5173\u952e\u5b57\u5b58\u5165\u54c8\u5e0c\u8868\u4e2d\uff0c\u81f3\u5c11\u8981\u8fdb\u884c______\u6b21\u63a2\u6d4b\u3002    A. \\(k - 1\\)    B. \\(k\\)    C. \\(k + 1\\)    D. \\(k(k + 1)/2\\) </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u8fd9\u4e2a\u5c31\u662f Codeforces \u91cc\u9762\u5361 std::unorded_map \u7684\u65b9\u6cd5\uff0c\u7531\u4e8e\u5b83\u4eec\u5177\u6709\u76f8\u540c\u7684\u54c8\u5e0c\uff0c\u56e0\u6b64\u90fd\u4f1a\u88c5\u8fdb\u4e00\u4e2a\u6876\u91cc\u9762\uff0c\u62c9\u94fe\u6cd5\u54c8\u5e0c\u8868\u9000\u5316\u6210\u5c3e\u63d2\u7684\u94fe\u8868\u4e86\uff0c\u6bcf\u65b0\u88c5\u4e00\u4e2a\u6570\u636e\u5c31\u5f97\u4ece\u5934\u63a2\u6d4b\u5230\u5c3e\u3002 <p></p> <p>19.\u5728\u4ee5\u4e0b\u6392\u5e8f\u7b97\u6cd5\u4e2d\uff0c\u67d0\u4e00\u8d9f\u6392\u5e8f\u7ed3\u675f\u540e\u672a\u5fc5\u80fd\u9009\u51fa\u4e00\u4e2a\u5143\u7d20\u653e\u5728\u5176\u6700\u7ec8\u4f4d\u7f6e\u4e0a\u7684\u662f______\u3002    A. \u5806\u6392\u5e8f    B. \u5192\u6ce1\u6392\u5e8f    C. \u76f4\u63a5\u63d2\u5165\u6392\u5e8f    D. \u5feb\u901f\u6392\u5e8f  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u63d2\u5165\u6392\u5e8f\u7684\u6709\u5e8f\u533a\u57df\u5e76\u4e0d\u662f\u5168\u5c40\u7684\u6709\u5e8f\u533a\u57df\uff0c\u6bd4\u5982\u67d0\u4e00\u8d9f\u9009\u51fa\u6765\u6070\u597d\u662f\u6700\u5c0f\u503c\uff0c\u5219\u6709\u5e8f\u533a\u90fd\u8981\u5f80\u540e\u632a\u4e00\u4e2a\u4f4d\u7f6e\u3002\u5806\u6392\u5e8f\u7684\u6709\u5e8f\u533a\u662f\u5168\u5c40\u7684\uff0c\u5192\u6ce1\u6392\u5e8f\u5192\u6ce1\u4e00\u8d9f\uff0c\u5192\u4e0a\u6765\u7684\u5143\u7d20\u4e5f\u4e0d\u4f1a\u53d8\u4e86\uff0c\u5feb\u6392\u9009\u53d6\u7684 pivot \u5728\u4e00\u6b21\u5212\u5206\u4e4b\u540e\u4e5f\u4e0d\u4f1a\u53d8\u3002 <p></p> <p>20.\u5728\u4ee5\u4e0b\u6392\u5e8f\u65b9\u6cd5\u4e2d\uff0c______\u4e0d\u9700\u8981\u8fdb\u884c\u5173\u952e\u5b57\u7684\u6bd4\u8f83\u3002    A. \u5feb\u901f\u6392\u5e8f    B. \u5f52\u5e76\u6392\u5e8f    C. \u57fa\u6570\u6392\u5e8f    D. \u5806\u6392\u5e8f  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aC\u3002\u57fa\u6570\u6392\u5e8f\u7684\u7279\u70b9\u5c31\u662f\u4e0d\u4f9d\u8d56\u5173\u952e\u5b57\u6bd4\u8f83\u3002\u5df2\u7ecf\u8bc1\u660e\u4f9d\u8d56\u6bd4\u8f83\u7684\u6392\u5e8f\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e0d\u53ef\u80fd\u4f18\u4e8e O(n log n)\u3002 <p></p>"}, {"location": "campus-sources/ds-write-up/#_8", "title": "\u95ee\u7b54\u9898", "text": "<p>1.\u5df2\u77e5\u4e00\u68f5\u5ea6\u4e3a \\(m\\) \u7684\u6811\u4e2d\u6709 \\(n_1\\) \u4e2a\u5ea6\u4e3a 1 \u7684\u7ed3\u70b9\u3001\\(n_2\\) \u4e2a\u5ea6\u4e3a 2 \u7684\u7ed3\u70b9\u3001\u2026\u3001\\(n_m\\) \u4e2a\u5ea6\u4e3a \\(m\\) \u7684\u7ed3\u70b9\uff0c\u95ee\u8be5\u6811\u4e2d\u6709\u591a\u5c11\u4e2a\u53f6\u5b50\u7ed3\u70b9\uff1f\uff08\u9700\u8981\u7ed9\u51fa\u63a8\u5bfc\u8fc7\u7a0b\uff09 </p>  \u7b54\u6848  <p></p>  $$ \\sum_{i = 1}^m (i - 1)n_i $$  <p></p> \u6211\u4eec\u8003\u8651\u6700\u6734\u7d20\u7684\u6784\u9020\uff1a\u6240\u6709\u7ed3\u70b9\u4ece\u6839\u7ed3\u70b9\u5f00\u59cb\u4e32\u6210\u4e00\u6761\u94fe\uff0c\u7136\u540e\u5bf9\u4e8e\u5ea6\u4e3a k \u7684\u7ed3\u70b9\uff0c\u8865\u5145 k - 1 \u4e2a\u53f6\u5b50\u7ed3\u70b9\uff0c\u5c31\u5f97\u5230\u4e86\u4e0a\u5f0f\u3002\u63a5\u4e0b\u6765\u8c03\u6574\u6811\u7684\u7ed3\u6784\uff0c\u53ef\u4ee5\u53d1\u73b0\u65e0\u8bba\u600e\u4e48\u8c03\u6574\uff0c\u53ea\u8981\u6ee1\u8db3\u9898\u76ee\u6761\u4ef6\uff0c\u90fd\u4e0d\u4f1a\u6539\u53d8\u53f6\u5b50\u7ed3\u70b9\u4e2a\u6570\u3002 <p></p> <p>2.\u8bbe\u5173\u952e\u5b57\u5e8f\u5217 \\(D = (1, 12, 5, 8, 3, 10, 7, 13, 9)\\)\uff0c\u8bd5\u5b8c\u6210\u4e0b\u5217\u5404\u9898\uff1a    \uff081\uff09\u4f9d\u6b21\u53d6 \\(D\\) \u4e2d\u7684\u5404\u5173\u952e\u5b57\uff0c\u6784\u9020\u4e00\u68f5\u4e8c\u53c9\u6392\u5e8f\u6811 \\(bt\\)\u3002    \uff082\uff09\u5982\u4f55\u4f9d\u636e\u6b64\u4e8c\u53c9\u6811 \\(bt\\) \u5f97\u5230 \\(D\\) \u7684\u4e00\u4e2a\u5173\u952e\u5b57\u9012\u589e\u5e8f\u5217\u3002    \uff083\uff09\u753b\u51fa\u5728\u4e8c\u53c9\u6811 \\(bt\\) \u4e2d\u5220\u9664 12 \u540e\u7684\u6811\u7ed3\u6784\u3002</p>  \u7b54\u6848  <p></p> <p></p>"}, {"location": "campus-sources/ds-write-up/#_9", "title": "\u7b97\u6cd5\u8bbe\u8ba1\u9898", "text": "<p>1.\u8bbe \\( A=(a_1, a_2, \\cdots, a_n) \\)\uff0c\\( B=(b_1, b_2, \\cdots, b_m) \\) \u662f\u4e24\u4e2a\u9012\u589e\u6709\u5e8f\u7684\u7ebf\u6027\u8868\uff08\u5176\u4e2d \\( n\u3001m \\) \u5747\u5927\u4e8e 1\uff09\uff0c\u4e14\u6240\u6709\u6570\u636e\u5143\u7d20\u5747\u4e0d\u76f8\u540c\u3002\u5047\u8bbe \\( A\u3001B \\) \u5747\u91c7\u7528\u5e26\u5934\u7ed3\u70b9\u7684\u5355\u94fe\u8868\u5b58\u653e\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u5c3d\u53ef\u80fd\u9ad8\u6548\u7684\u7b97\u6cd5\u5224\u65ad \\( B \\) \u662f\u5426\u4e3a \\( A \\) \u7684\u4e00\u4e2a\u8fde\u7eed\u5b50\u5e8f\u5217\uff0c\u5e76\u5206\u6790\u4f60\u8bbe\u8ba1\u7684\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002\uff0815 \u5206\uff09</p>  \u7b54\u6848  <p></p> \u601d\u8def\u5f88\u7b80\u5355\uff0c\u7531\u4e8e A\uff0cB \u90fd\u662f\u6709\u5e8f\u7684\uff0c\u56e0\u6b64\u5931\u914d\u4e00\u6b21\uff0c\u6574\u4e2a\u5339\u914d\u90fd\u4f1a\u5931\u8d25\u3002\u636e\u6b64\u53ef\u4ee5\u5199\u51fa\u4e0b\u9762\u7684\u4ee3\u7801\uff1a  <pre><code>bool match(ListNode* a, ListNode* b)\n{\n   while(a != NULL)\n   {\n      if(a-&gt;data == b-&gt;data)\n      {\n         while(b != NULL)\n         {\n            if(a == NULL || a-&gt;data != b-&gt;data)\n               return false;\n            a = a-&gt;next;\n            b = b-&gt;next;\n         }\n         return true;\n      }\n      a = a-&gt;next;\n   }\n   return false;\n}\n</code></pre> <p></p>  \u53d8\u5f0f\uff1a\u5982\u679c A \u548c B \u5e76\u4e0d\u6709\u5e8f\uff0c\u5b58\u5728\u7ebf\u6027\u65f6\u95f4\u7684\u7b97\u6cd5\u5417\uff1f  <p></p> \u5b58\u5728\u3002\u4f7f\u7528 KMP \u7b97\u6cd5\u5373\u53ef\u3002 <p></p> <p></p> <p>2.\u5047\u8bbe\u4e8c\u53c9\u6811 \\( b \\) \u91c7\u7528\u4e8c\u53c9\u94fe\u5b58\u50a8\u7ed3\u6784\u5b58\u50a8\uff0c\u8bd5\u8bbe\u8ba1\u4e00\u4e2a\u7b97\u6cd5\uff0c\u6c42\u8be5\u4e8c\u53c9\u6811\u4e2d\u4ece\u6839\u7ed3\u70b9\u51fa\u53d1\u7684\u4e00\u6761\u6700\u957f\u7684\u8def\u5f84\u957f\u5ea6\uff0c\u5e76\u8f93\u51fa\u6b64\u8def\u5f84\u4e0a\u5404\u7ed3\u70b9\u7684\u503c\u3002\uff0815 \u5206\uff09</p>  \u7b54\u6848  <p></p> \u672c\u9898\u662f\u6811\u5f62 dp \u5165\u95e8\u9898\uff0c\u540c\u65f6\u4ee3\u7801\u7a0d\u4f5c\u4fee\u6539\uff0c\u5c31\u53ef\u4ee5\u505a\u6811\u7684\u957f\u94fe\u5256\u5206\u3002  <pre><code>enum class path { left, right };\nstruct BTNode {\n   BTNode* lchild;\n   BTNode* rchild;\n   path p;\n}\n\nint dfs(BTNode* root, int depth)\n{\n   if(root == NULL) return depth;\n   int ldepth = dfs(root-&gt;lchild, depth + 1);\n   int rdepth = dfs(root-&gt;rchild, depth + 1);\n   if(ldepth &gt;= rdepth)\n   {\n      root-&gt;p = path::left;\n      return ldepth;\n   }\n   root-&gt;p = path::right;\n   return rdepth;\n}\n\nvoid output(BTNode* root)\n{\n   int dep = dfs(root, 1);\n   std::cout &lt;&lt; dep &lt;&lt; std::endl;\n   while(root != NULL)\n   {\n      std::cout &lt;&lt; root-&gt;data &lt;&lt; std::endl;\n      if(root-&gt;p == path::right)\n         root = root-&gt;rchild;\n      else\n         root = root-&gt;lchild;\n   }\n}\n</code></pre> <p></p>"}, {"location": "campus-sources/ds-write-up/#23", "title": "23\u5e74\u771f\u9898", "text": ""}, {"location": "campus-sources/ds-write-up/#_10", "title": "\u5355\u9879\u9009\u62e9\u9898", "text": "<p>1.\u8bbe\u6709\u5e8f\u8868\u4e2d\u6709 1000 \u4e2a\u5143\u7d20\uff0c\u5219\u7528\u4e8c\u5206\u67e5\u627e\u67e5\u627e\u5143\u7d20 X \u6700\u591a\u9700\u8981\u6bd4\u8f83 ____ \u6b21\u3002    A. 25    B. 10    C. 7    D. 1  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u53c2\u8003\u7b2c\u4e00\u5957\u9898\u7684\u5355\u9009\u7b2c12\u9898\u3002 <p></p> <p>2.\u8bbe\u6563\u5217\u8868\u4e2d\u6709 m \u4e2a\u5b58\u50a8\u5355\u5143\uff0c\u6563\u5217\u51fd\u6570 H(key)=key % p\uff0c\u5219 p \u6700\u597d\u9009\u62e9 ____ \u3002    A. \u5c0f\u4e8e\u7b49\u4e8e m \u7684\u6700\u5927\u5947\u6570    B. \u5c0f\u4e8e\u7b49\u4e8e m \u7684\u6700\u5927\u7d20\u6570    C. \u5c0f\u4e8e\u7b49\u4e8e m \u7684\u6700\u5927\u5076\u6570    D. \u5c0f\u4e8e\u7b49\u4e8e m \u7684\u6700\u5927\u5408\u6570  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u4e3a\u4e86\u8ba9\u6570\u636e\u51cf\u5c11\u51b2\u7a81\uff0c\u6211\u4eec\u5e94\u8be5\u5c3d\u91cf\u907f\u514d\u51fa\u73b0\u6574\u9664\u7684\u60c5\u51b5\u3002 <p></p> <p>3.\u54c8\u592b\u66fc\u6811\u6709 m \u4e2a\u53f6\u5b50\u7ed3\u70b9\uff0c\u82e5\u7528\u4e8c\u53c9\u94fe\u8868\u4f5c\u4e3a\u5b58\u50a8\u7ed3\u6784\uff0c\u5219\u8be5\u54c8\u592b\u66fc\u6811\u5171\u6709 ____ \u4e2a\u7a7a\u6307\u9488\u57df\u3002    A. 2m - 1    B. 2m    C. 2m + 1    D. 4m  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002\u9996\u5148\u6839\u7ed3\u70b9\u6709\u4e24\u4e2a\u7a7a\u6307\u9488\u57df\uff0c\u7136\u540e\u6bcf\u6b21\u5408\u5e76\u65f6\u90fd\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u6839\u7ed3\u70b9\u548c\u65b0\u7684\u53f6\u5b50\u7ed3\u70b9\uff0c\u53f6\u5b50\u7ed3\u70b9\u53c8\u6709\u4e24\u4e2a\u7a7a\u6307\u9488\u57df\uff0c\u56e0\u6b64\u662f 2m\u3002 <p></p> <p>4.\u5b57\u7b26 A\u3001B\u3001C \u4f9d\u6b21\u8fdb\u5165\u4e00\u4e2a\u6808\uff0c\u6309\u51fa\u6808\u7684\u5148\u540e\u987a\u5e8f\u7ec4\u6210\u4e0d\u540c\u7684\u5b57\u7b26\u4e32\uff0c\u81f3\u591a\u53ef\u4ee5\u7ec4\u6210 ____ \u4e2a\u4e0d\u540c\u7684\u5b57\u7b26\u4e32\u3002    A. 14    B. 5    C. 6    D. 8  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aB\u3002 <p></p> \u5b57\u7b26\u4e32\u5982\u4e0b\uff1a  <pre><code>ABC\nACB\nBAC\nBCA\nCBA\n</code></pre> <p></p> \u6216\u8005\u76f4\u63a5\u5229\u7528\u516c\u5f0f\uff1a  $$ N = \\dfrac{C^n_{2n}}{n+1} = \\dfrac{6!}{3!\\times 3!\\times 4} = 5 $$  <p></p> <p>5.\u6808\u548c\u961f\u5217\u5171\u540c\u7684\u7279\u70b9\u662f ____ \u3002    A. \u53ea\u5141\u8bb8\u5728\u7aef\u70b9\u5904\u63d2\u5165\u548c\u5220\u9664\u5143\u7d20    B. \u90fd\u662f\u5148\u8fdb\u540e\u51fa    C. \u90fd\u662f\u5148\u8fdb\u5148\u51fa    D. \u6ca1\u6709\u5171\u540c\u70b9  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u6808\u662f\u5148\u8fdb\u540e\u51fa\uff0c\u961f\u5217\u662f\u5148\u8fdb\u5148\u51fa\u3002D\u9009\u9879\u51d1\u6570\u7684\uff0c\u522b\u9009\u3002 <p></p> <p>6.\u5728\u4e8c\u53c9\u6392\u5e8f\u6811\u4e2d\u63d2\u5165\u4e00\u4e2a\u65b0\u7684\u7ed3\u70b9\u65f6\uff0c\u82e5\u6811\u4e2d\u4e0d\u5b58\u5728\u4e0e\u5f85\u63d2\u5165\u5173\u952e\u5b57\u76f8\u540c\u7684\u7ed3\u70b9\uff0c\u4e14\u65b0\u7ed3\u70b9\u7684\u5173\u952e\u5b57\u5c0f\u4e8e\u6839\u7ed3\u70b9\u7684\u5173\u952e\u5b57\uff0c\u5219\u65b0\u7ed3\u70b9\u5c06\u6210\u4e3a ____ \u3002    A. \u5de6\u5b50\u6811\u7684\u65b0\u53f6\u5b50\u7ed3\u70b9    B. \u5de6\u5b50\u6811\u7684\u5206\u652f\u7ed3\u70b9    C. \u53f3\u5b50\u6811\u7684\u65b0\u53f6\u5b50\u7ed3\u70b9    D. \u53f3\u5b50\u6811\u7684\u5206\u652f\u7ed3\u70b9  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u9996\u5148\u65b0\u7ed3\u70b9\u7684\u5173\u952e\u5b57\u66f4\u5c0f\uff0c\u56e0\u6b64\u63d2\u5728\u5de6\u5b50\u6811\u3002\u56e0\u4e3a\u4e00\u5f00\u59cb\u6ca1\u6709\u627e\u5230\uff0c\u6240\u4ee5\u662f\u8fde\u5728\u67d0\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u7a7a\u6307\u9488\u57df\u4e0a\u9762\uff0c\u5f62\u6210\u65b0\u7684\u53f6\u5b50\u7ed3\u70b9\u3002     \u5982\u679c\u4e0d\u662f BST \u800c\u662f\u4f7f\u7528\u5e73\u8861\u6811\u5462\uff1f  <p></p> \u7531\u4e8e\u6709\u65cb\u8f6c\u64cd\u4f5c\uff0c\u56e0\u6b64\u65e0\u6cd5\u4fdd\u8bc1\u63d2\u5165\u7684\u7ed3\u70b9\u6700\u540e\u4e00\u5b9a\u662f\u53f6\u5b50\u7ed3\u70b9\uff0c\u4f46\u662f\u4e00\u5b9a\u662f\u5728\u5de6\u5b50\u6811\u3002 <p></p> <p>7.\u8bbe\u6709 n \u4e2a\u5f85\u6392\u5e8f\u7684\u8bb0\u5f55\u5173\u952e\u5b57\uff0c\u5219\u5728\u5806\u6392\u5e8f\u4e2d\u9700\u8981 ____ \u4e2a\u8f85\u52a9\u8bb0\u5f55\u5355\u5143\u3002    A. 1    B. n    C. log\u2082n    D. n\u00b2  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u539f\u5730\u5efa\u5806\u3002 <p></p> <p>8.\u8bbe\u987a\u5e8f\u7ebf\u6027\u8868\u7684\u957f\u5ea6\u4e3a 30\uff0c\u5206\u6210 5 \u5757\uff0c\u6bcf\u5757 6 \u4e2a\u5143\u7d20\uff0c\u5982\u679c\u91c7\u7528\u5206\u5757\u67e5\u627e\uff0c\u5219\u5176\u5e73\u5747\u67e5\u627e\u957f\u5ea6\u4e3a ____ \u3002    A. 6    B. 11    C. 5    D. 6.5  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u9996\u5148\u786e\u5b9a\u5728\u54ea\u4e00\u4e2a\u5757\u91cc\u9762\uff0c\u7136\u540e\u786e\u5b9a\u5728\u5757\u5185\u7684\u54ea\u4e00\u4e2a\u5143\u7d20\u3002 5 / 2 + 6 / 2 = 6.5\u3002 <p></p> <p>9.\u4e0b\u5217\u5173\u4e8e\u4e8c\u53c9\u6811\u904d\u5386\u7684\u53d9\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f ____ \u3002    A. \u82e5\u4e00\u4e2a\u53f6\u5b50\u662f\u67d0\u4e8c\u53c9\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5219\u5b83\u5fc5\u662f\u8be5\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9    B. \u82e5\u4e00\u4e2a\u7ed3\u70b9\u662f\u67d0\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5219\u5b83\u5fc5\u662f\u8be5\u4e8c\u53c9\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9    C. \u82e5\u4e00\u4e2a\u7ed3\u70b9\u662f\u67d0\u4e8c\u53c9\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5219\u5b83\u5fc5\u662f\u8be5\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9    D. \u82e5\u4e00\u4e2a\u6811\u53f6\u662f\u67d0\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\uff0c\u5219\u5b83\u5fc5\u662f\u8be5\u4e8c\u53c9\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9</p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u524d\u5e8f\uff1aULR\uff0c\u4e2d\u5e8fLUR\uff0c\u540e\u5e8fLRU\uff0c\u53ef\u89c1\u524d\u5e8f\u548c\u4e2d\u5e8f\u90fd\u628a\u53f3\u5b50\u6811\u653e\u5728\u6700\u540e\u904d\u5386\u3002\u4e3a\u4e86\u8981\u8ba9\u6700\u540e\u4e00\u4e2a\u7ed3\u70b9\u4e00\u81f4\uff0c\u5fc5\u987b\u4fdd\u8bc1\u53f3\u5b50\u6811\u5b58\u5728\uff0c\u56e0\u6b64\u8fd9\u4e2a\u7ed3\u70b9\u4e00\u5b9a\u662f\u53f6\u5b50\u3002 <p></p> <p>10.\u90bb\u63a5\u591a\u91cd\u8868\u4e0e\u5341\u5b57\u94fe\u8868\u7684\u5171\u540c\u7279\u70b9\u662f ____ \u3002 A. \u90fd\u662f\u9488\u5bf9\u6709\u5411\u56fe B. \u8fb9\u7ed3\u70b9\u90fd\u9700\u8981\u4e00\u4e2a mark \u57df\u6807\u660e\u5bf9\u5e94\u7684\u8fb9\u662f\u5426\u5df2\u88ab\u8bbf\u95ee C. \u90fd\u662f\u9488\u5bf9\u65e0\u5411\u56fe D. \u6240\u6709\u7684\u8fb9\u53ea\u901a\u8fc7\u8fb9\u7ed3\u70b9\u8868\u8fbe\u4e00\u6b21  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u5341\u5b57\u94fe\u8868\u9488\u5bf9\u6709\u5411\u56fe\uff0c\u90bb\u63a5\u591a\u91cd\u8868\u9488\u5bf9\u65e0\u5411\u56fe\u3002\u5176\u4ed6\u5185\u5bb9\u53ef\u4ee5\u81ea\u884c\u590d\u4e60\u6559\u6750\u5185\u5bb9\u3002 <p></p> <p>11.\u4ee5\u4e0b\u56db\u4e2a\u9009\u9879\u4e2d\uff0c\u6709\u4e00\u9879\u4e0e\u5176\u4f59\u4e09\u9879\u4e0d\u540c\uff0c\u8fd9\u4e00\u9879\u662f ____ \u3002 A. \u4e8c\u53c9\u641c\u7d22\u6811 B. AVL \u6811 C. B+\u6811 D. B-\u6811  </p>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u6216\u8005C BST \u4e0d\u662f\u5e73\u8861\u7684\u3002\u6216\u8005\u8003\u8651\uff1aB+\u6811\u662f\u7d22\u5f15\u6570\u636e\u7ed3\u6784\uff0c\u4f46\u5176\u4ed6\u9009\u9879\u4e0d\u662f\u3002 <p></p> <ol> <li>\u6700\u5927\u5bb9\u91cf\u4e3a n \u7684\u5faa\u73af\u961f\u5217\uff0c\u961f\u6ee1\u65f6\u4ecd\u7136\u4fdd\u7559\u4e00\u4e2a\u6570\u7ec4\u5143\u7d20\u4e3a\u7a7a\u3002\u82e5 front \u6307\u5411\u961f\u5217\u7b2c\u4e00\u4e2a\u5143\u7d20\uff0crear \u6307\u5411\u961f\u5217\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u5219\u961f\u5217\u957f\u5ea6\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a ____ \u3002 A. rear-front-1 B. rear-front+1 C. (rear-front+n-1)%n D. (rear-front+n+1)%n  </li> </ol>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u8003\u8651 rear \u6307\u5411\u7684\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u800c\u4e0d\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u6240\u4ee5\u5e94\u8be5\u52a0 1. <p></p> <ol> <li>\u4ece\u4e8c\u53c9\u641c\u7d22\u6811\u4e2d\u67e5\u627e\u4e00\u4e2a\u5143\u7d20\u65f6\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u5927\u81f4\u4e3a ____ \u3002 A. O(log\u2082n) B. O(1) C. O(n\u00b2) D. O(n)  </li> </ol>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aA\u3002\u8003\u8651\u968f\u673a\u5efa\u7acb BST \u7684\u5e73\u5747\u6df1\u5ea6\u4e3a O(log\u2082n) \u5373\u53ef\u3002 <p></p> <ol> <li>\u4e8c\u53c9\u6811\u5728\u7ebf\u7d22\u5316\u4e4b\u540e\uff0c\u4ecd\u4e0d\u80fd\u6709\u6548\u6c42\u89e3\u7684\u95ee\u9898\u662f ____ \uff1f A. \u5148\u5e8f\u7ebf\u7d22\u4e8c\u53c9\u6811\u4e2d\u6c42\u5148\u5e8f\u540e\u7ee7 B. \u4e2d\u5e8f\u7ebf\u7d22\u4e8c\u53c9\u6811\u4e2d\u6c42\u4e2d\u5e8f\u540e\u7ee7 C. \u4e2d\u5e8f\u7ebf\u7d22\u4e8c\u53c9\u6811\u4e2d\u6c42\u4e2d\u5e8f\u524d\u9a71 D. \u540e\u5e8f\u7ebf\u7d22\u4e8c\u53c9\u6811\u4e2d\u6c42\u540e\u5e8f\u540e\u7ee7  </li> </ol>  \u7b54\u6848  <p></p> \u7b54\u6848\uff1aD\u3002\u5148\u5e8f\u7ebf\u7d22\u5728\u56de\u6eaf\u7684\u65f6\u5019\u81ea\u52a8\u52a0\u4e0a\u4e86\u540e\u7ee7\u7684\u7ebf\u7d22\uff0c\u4e2d\u5e8f\u6811\u5728\u56de\u6eaf\u65f6\u65e2\u6709\u524d\u9a71\u53c8\u6709\u540e\u7ee7\u7684\u7ebf\u7d22\uff0c\u53ea\u6709\u540e\u5e8f\u7ebf\u7d22\u6811\u52a0\u4e0a\u524d\u9a71\u7684\u7ebf\u7d22\u800c\u96be\u4ee5\u6c42\u5f97\u540e\u7ee7\u7684\u7ebf\u7d22\u3002 <p></p>"}, {"location": "campus-sources/ds-write-up/#_11", "title": "\u586b\u7a7a\u9898", "text": "<ol> <li>\u5c06\u4e00\u68f5\u62e5\u6709 m \u4e2a\u53f6\u5b50\u7ed3\u70b9\u548c n \u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u6811\u8f6c\u6362\u6210\u5bf9\u5e94\u7684\u4e8c\u53c9\u6811\uff0c\u5219\u5728\u6b64\u4e8c\u53c9\u6811\u4e2d\u6709 ____ \u4e2a\u7ed3\u70b9\u6709\uff08\u975e\u7a7a\u7684\uff09\u53f3\u5b69\u5b50\u3002  </li> </ol>  \u7b54\u6848    $$ m-1 $$  \u5c06\u4e00\u68f5\u6811\u8f6c\u6362\u4e3a\u4e8c\u53c9\u6811\u65f6\uff0c\u91c7\u7528\u201c\u5de6\u5b69\u5b50\u53f3\u5144\u5f1f\u201d\u89c4\u5219\u3002\u539f\u6811\u4e2d\u6bcf\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u5b50\u7ed3\u70b9\u8f6c\u6362\u4e3a\u4e8c\u53c9\u6811\u540e\uff0c\u7b2c\u4e00\u4e2a\u5b50\u7ed3\u70b9\u4f5c\u4e3a\u5de6\u5b69\u5b50\uff0c\u5176\u4f59\u5b50\u7ed3\u70b9\u4f9d\u6b21\u4f5c\u4e3a\u524d\u4e00\u4e2a\u5144\u5f1f\u7684\u53f3\u5b69\u5b50\u3002\u56e0\u6b64\uff0c\u6bcf\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u82e5\u6709 \\( k \\) \u4e2a\u5b50\u7ed3\u70b9\uff0c\u5219\u8f6c\u6362\u540e\u4f1a\u4ea7\u751f \\( k-1 \\) \u4e2a\u53f3\u5b69\u5b50\u7ed3\u70b9\u3002  \u539f\u6811\u5171\u6709 \\( m \\) \u4e2a\u53f6\u5b50\u7ed3\u70b9\u548c \\( n \\) \u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\uff0c\u603b\u8fb9\u6570\u4e3a \\( m + n - 1 \\)\u3002\u6240\u6709\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u5b50\u7ed3\u70b9\u6570\u76ee\u4e4b\u548c\u7b49\u4e8e\u603b\u8fb9\u6570\uff0c\u5373 \\( \\sum k_i = m + n - 1 \\)\u3002\u6bcf\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u8d21\u732e\u7684\u53f3\u5b69\u5b50\u6570\u76ee\u4e3a \\( k_i - 1 \\)\uff0c\u56e0\u6b64\u603b\u5171\u6709\uff1a \\[ \\sum (k_i - 1) = \\sum k_i - \\sum 1 = (m + n - 1) - n = m - 1 \\] \u4e2a\u3002  <ol> <li>\u5728\u5bf9 m \u9636 B-\u6811\u63d2\u5165\u5143\u7d20\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u5411\u4e00\u4e2a\u7ed3\u70b9\u63d2\u5165\u4e00\u4e2a\u5173\u952e\u7801\u540e\uff0c\u82e5\u8be5\u7ed3\u70b9\u7684\u5173\u952e\u7801\u4e2a\u6570\u7b49\u4e8e ____ \u65f6\uff0c\u5219\u5fc5\u987b\u628a\u5b83\u5206\u88c2\u4e3a 2 \u4e2a\u7ed3\u70b9\u3002  </li> </ol>  \u7b54\u6848    $$ m $$  \u53c2\u89c1\u6559\u67509.3.3.2\u3002  <ol> <li>\u5047\u8bbe\u5173\u952e\u5b57\u5e8f\u5217\u4e3a(K\u2081, K\u2082, \u2026, K\u2099)\uff0c\u5219\u7528\u7b5b\u9009\u6cd5\u5efa\u521d\u59cb\u5806\u5fc5\u987b\u4ece\u7b2c ____ \u4e2a\u5143\u7d20\u5f00\u59cb\u8fdb\u884c\u7b5b\u9009\u3002  </li> </ol>  \u7b54\u6848    \\[    \\lfloor \\dfrac n2 \\rfloor \\]  \u53c2\u89c1\u6559\u675010.4.2.2\u3002  <ol> <li>\u5728\u62e5\u6709 n \u4e2a\u7ed3\u70b9\u7684\u4e8c\u53c9\u6392\u5e8f\u6811\u4e2d\uff0c\u5982\u679c\u5b58\u5728\u5ea6\u4e3a 2 \u7684\u7ed3\u70b9\uff0c\u90a3\u4e48\u8fd9\u68f5\u4e8c\u53c9\u6392\u5e8f\u6811\u7684\u6700\u5927\u9ad8\u5ea6\u4e3a ____ \u3002  </li> </ol>  \u7b54\u6848    \\[    n - 1 \\]  \u8003\u8651\u9012\u589e\u5e8f\u5217 \\(1, 2, ..., n\\) \u5e76\u4ee5 \\(2\\) \u4e3a\u6839\u7ed3\u70b9\u5efa\u7acbBST\u3002  <ol> <li>\u7d22\u5f15\u5b58\u50a8\u7ed3\u6784\u662f\u7531 ____ \u548c ____ \u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u5176\u4e2d ____ \u90e8\u5206\u8981\u6c42\u6309\u5173\u952e\u5b57\u6392\u5e8f\u3002  </li> </ol>  \u7b54\u6848   \u5185\u90e8\u7ed3\u70b9\uff0c\u5916\u90e8\u7ed3\u70b9\uff0c\u5185\u90e8\u7ed3\u70b9\u3002  \u53c2\u8003\u6559\u67509.3.3\u3002  <ol> <li>\u5df2\u77e5\u4e00\u68f5\u5b8c\u5168\u4e8c\u53c9\u6811\u4e2d\u5171\u6709 768 \u4e2a\u7ed3\u70b9\uff0c\u5219\u8be5\u6811\u4e2d\u5171\u6709 ____ \u4e2a\u53f6\u5b50\u7ed3\u70b9\u3002  </li> </ol>  \u7b54\u6848    \\[    384 \\]  \u89c1\u56fe\uff1a    <ol> <li>\u5728\u53cc\u5411\u94fe\u8868\u4e2d\u6307\u5b9a\u7684\u7ed3\u70b9\u4e4b\u524d\u63d2\u5165\u4e00\u4e2a\u65b0\u7ed3\u70b9\u9700\u4fee\u6539\u7684\u6307\u9488\u6570\u662f ____ \u4e2a\u3002  </li> </ol>  \u7b54\u6848    \\[    4 \\]   <pre><code>|A|- 1 -&gt;|B|\n|A|&lt;- 2 -|B|\n</code></pre> <pre><code>|A|- 1' -&gt;|C|- 3' -&gt;|B|\n|A|&lt;- 2' -|C|&lt;- 4' -|B|\n</code></pre>  \u5982\u4e0a\uff0c\u5c06\u6307\u9488 1 \u8c03\u6574\u4e3a\u6307\u9488 1'\uff0c\u6307\u9488 2 \u8c03\u6574\u4e3a\u6307\u9488 4'\uff0c\u5e76\u52a0\u5165\u6307\u9488 3' \u548c 2'\uff0c\u5171 4 \u6b21\u8c03\u6574\u3002   <ol> <li>\u4e00\u68f5\u4e8c\u53c9\u6811\u9ad8\u5ea6\u4e3a h\uff0c\u6240\u6709\u7ed3\u70b9\u7684\u5ea6\u6216\u4e3a 0\uff0c\u6216\u4e3a 2\uff0c\u5219\u8fd9\u68f5\u4e8c\u53c9\u6811\u6700\u5c11\u6709 ____ \u4e2a\u7ed3\u70b9\u3002  </li> </ol>  \u7b54\u6848    \\[    2h - 1 \\]  \u8003\u8651\u4e00\u4e2a\u4e8c\u53c9\u6811\u6bcf\u52a0\u4e00\u4e2a\u8282\u70b9\u5c31\u9ad8\u4e00\u5c42\uff0c\u6839\u8282\u70b9\u7684\u5de6\u53f3\u7ed3\u70b9\u5206\u522b\u662f\u539f\u6765\u7684\u6839\u8282\u70b9\u548c\u65b0\u52a0\u5165\u7684\u7ed3\u70b9\uff0c\u6b64\u65f6\u4e00\u5171 \\(2h-1\\) \u4e2a\u7ed3\u70b9\u3002  <ol> <li>\u5728\u542b n \u4e2a\u9876\u70b9\u548c e \u6761\u8fb9\u7684\u65e0\u5411\u56fe\u7684\u90bb\u63a5\u77e9\u9635\u4e2d\uff0c\u96f6\u5143\u7d20\u7684\u4e2a\u6570\u4e3a ____ \u3002  </li> </ol>  \u7b54\u6848    \\[    n^2-2e \\]  \u9898\u76ee\u6ca1\u6709\u8bf4\u662f\u5e26\u6743\u7684\uff0c\u56e0\u6b64\u8ba4\u4e3a\u662f\u4e0d\u5e26\u6743\u7684\u65e0\u5411\u56fe\u3002\u6bcf\u52a0\u4e00\u6b21\u8fb9 \\(e(i,j)\\) \u90fd\u4f1a\u8bbe\u7f6e \\( G[i][j] \\) \u548c \\( G[j][i] \\) \u4e3a \\(1\\)\uff0c\u56e0\u6b64\u8981\u51cf\u53bb\\(2e\\)\u3002   <ol> <li>\u5728\u5355\u94fe\u8868\u4e0a\u96be\u4ee5\u5b9e\u73b0\u7684\u6392\u5e8f\u65b9\u6cd5\u6709 ____ \u3001 ____ \u548c ____ \u7b49\u3002  </li> </ol>  \u7b54\u6848    \u5e0c\u5c14\u6392\u5e8f\u3001\u5feb\u901f\u6392\u5e8f\u3001\u5806\u6392\u5e8f\u3002  \u5355\u94fe\u8868\u4e0a\u9762\u96be\u4ee5\u8fdb\u884c\u57fa\u4e8e\u4e0b\u6807\u7684\u968f\u673a\u8bbf\u95ee\uff0c\u4e5f\u96be\u4ee5\u8fdb\u884c\u53cd\u5411\u904d\u5386\uff0c\u56e0\u6b64\u5927\u91cf\u4f9d\u8d56\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u7684\u6392\u5e8f\u7b97\u6cd5\u90fd\u662f\u4e0d\u5229\u4e8e\u5728\u5355\u94fe\u8868\u4e0a\u9762\u5b9e\u73b0\u7684\u3002  \u5e0c\u5c14\u6392\u5e8f\u57fa\u4e8e\u76f8\u9694 \\(d\\) \u7684\u5206\u7ec4\uff0c\u6bcf\u4e00\u6b21\u5f80\u540e\u9762\u8df3\\(d\\)\u4e2a\u6570\u636e\uff0c\u6d89\u53ca\u968f\u673a\u8bbf\u95ee\u3002  \u5feb\u901f\u6392\u5e8f\u4e2d\u7684\u5212\u5206\u64cd\u4f5c\u6d89\u53ca\u53cd\u5411\u904d\u5386\u3002  \u5806\u6392\u5e8f\u7684\u8c03\u6574\u64cd\u4f5c\uff0c\u8ba1\u7b97\u7236\u8282\u70b9\u8fc7\u7a0b\u4e2d\u9700\u8981\u5bf9\u4e0b\u6807\u8fdb\u884c\u968f\u673a\u8bbf\u95ee\u3002  <ol> <li>\u4e0d\u8bba\u662f\u987a\u5e8f\u5b58\u50a8\u7ed3\u6784\u7684\u6808\u8fd8\u662f\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\u7684\u6808\uff0c\u5176\u5165\u6808\u548c\u51fa\u6808\u64cd\u4f5c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u5747\u4e3a ____ \u3002  </li> </ol>  \u7b54\u6848    \\[    O(1) \\]  \u5bf9\u4e8e\u987a\u5e8f\u6808\uff0c\u53ea\u9700\u8981\u5c06 top \u6307\u9488\u51cf\u4e00\u5373\u53ef\uff1b\u5bf9\u4e8e\u94fe\u6808\uff0c\u53ea\u9700\u8981\u5220\u9664\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u5373\u53ef\u3002   <ol> <li>\u8bbe\u67d0\u4e8c\u53c9\u6811\u7684\u524d\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a ABC\uff0c\u540e\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a BCA\uff0c\u5219\u8be5\u4e8c\u53c9\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u5e8f\u5217\u4e3a ____ \u3002  </li> </ol>  \u7b54\u6848    \\[    \\text{BAC} \\]  \u7531\u9898\u76ee\u7ed9\u5b9a\u5e8f\u5217\u5efa\u7acb\u7b26\u5408\u9898\u610f\u7684\u4e8c\u53c9\u6811\u5982\u4e0b\uff1a <pre><code>   A\n  / \\\n B   C\n</code></pre> \u56e0\u6b64\u4e2d\u5e8f\u5e8f\u5217\u4e3a BAC\u3002"}, {"location": "campus-sources/ds-write-up/#_12", "title": "\u5224\u65ad\u9898", "text": "<ol> <li>\u5728\u76f8\u540c\u7684\u89c4\u6a21 n \u4e0b\uff0c\u590d\u6742\u5ea6 O(n) \u7684\u7b97\u6cd5\u5728\u65f6\u95f4\u4e0a\u603b\u662f\u4f18\u4e8e\u590d\u6742\u5ea6 O(2\u207f) \u7684\u7b97\u6cd5\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u4e0d\u4ec5\u53d7\u5230\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u5f71\u54cd\uff0c\u8fd8\u53d7\u5230\u5e38\u6570\u7684\u5f71\u54cd\uff0c\u8003\u8651\u7b97\u6cd5 A \u5bf9\u4e8e\u89c4\u6a21 \\(n\\) \u7684\u95ee\u9898\u9700\u8981\u6267\u884c \\(200 n\\) \u6b21\u64cd\u4f5c\u800c\u7b97\u6cd5 B \u5bf9\u4e8e\u540c\u6837\u89c4\u6a21\u7684\u95ee\u9898\u9700\u8981\u6267\u884c \\(2^n\\) \u6b21\u64cd\u4f5c\uff0c\u5219\u5f53 \\(n &lt; 12\\) \u65f6\u53cd\u800c\u7b97\u6cd5 B \u7684\u8fd0\u884c\u65f6\u95f4\u66f4\u77ed\u3002   <ol> <li>\u6d88\u9664\u9012\u5f52\u4e0d\u4e00\u5b9a\u9700\u8981\u4f7f\u7528\u6808\u3002</li> </ol>  \u7b54\u6848  \u5bf9\u3002  \u6d88\u9664\u5c3e\u9012\u5f52\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u5faa\u73af\u3002   <ol> <li>\u82e5\u4e00\u68f5\u4e8c\u53c9\u6811\u7684\u4efb\u610f\u7ed3\u70b9\u7684\u5de6\u5b50\u6811\u548c\u53f3\u5b50\u6811\u90fd\u662f\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u5219\u8fd9\u68f5\u4e8c\u53c9\u6811\u5fc5\u662f\u4e8c\u53c9\u641c\u7d22\u6811\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u8fd8\u9700\u5b9a\u4e49\u7edf\u4e00\u7684\u504f\u5e8f\u5173\u7cfb\u3002\u6bd4\u5982\u4ea4\u6362\u6839\u8282\u70b9\u7684\u5de6\u53f3\u5b50\u6811\u3002   <ol> <li>\u5faa\u73af\u961f\u5217\u5c31\u662f\u7528\u5faa\u73af\u94fe\u8868\u8868\u793a\u7684\u961f\u5217\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u5faa\u73af\u961f\u5217\u4e5f\u53ef\u4ee5\u4f7f\u7528\u6570\u7ec4\u5b9e\u73b0\u3002   <ol> <li>\u5728\u591a\u5173\u952e\u5b57\u6392\u5e8f\u4e2d\uff0c\u4ece\u7b2c\u4e8c\u4f4e\u4f4d\u5173\u952e\u5b57\u5f00\u59cb\uff0c\u6240\u91c7\u7528\u7684\u5355\u8d9f\u6392\u5e8f\u7b97\u6cd5\u5fc5\u987b\u662f\u7a33\u5b9a\u7684\u6392\u5e8f\u7b97\u6cd5\u3002  </li> </ol>  \u7b54\u6848  \u5bf9\u3002  \u7a33\u5b9a\u6392\u5e8f\u7684\u5b9a\u4e49\u5c31\u662f\u5177\u6709\u76f8\u540c\u5173\u952e\u5b57\u7684\u6570\u636e\u7684\u76f8\u5bf9\u6b21\u5e8f\u4e0d\u53d8\u3002   <ol> <li>\u54c8\u592b\u66fc\u7f16\u7801\u4e00\u5b9a\u662f\u524d\u7f00\u7f16\u7801\uff1b\u4e00\u5957\u524d\u7f00\u7f16\u7801\uff0c\u6309\u7167\u8d8a\u957f\u7684\u7f16\u7801\u5206\u914d\u7ed9\u8d8a\u4f4e\u9891\u7387\u5b57\u7b26\u7684\u539f\u5219\u8fdb\u884c\u5206\u914d\uff0c\u5c31\u4e00\u5b9a\u662f\u54c8\u592b\u66fc\u7f16\u7801\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u7f16\u7801\u957f\u5ea6\u4e0d\u4e00\u5b9a\u6ee1\u8db3\u5e26\u6743\u8def\u5f84\u6700\u77ed\u8fd9\u4e2a\u6761\u4ef6\uff0c\u5bfc\u81f4\u6784\u9020\u51fa\u6765\u7684\u7f16\u7801\u4e0d\u662f\u54c8\u592b\u66fc\u7f16\u7801\u3002   <ol> <li>\u4ece\u8fde\u901a\u65e0\u5411\u56fe\u7684\u540c\u4e00\u4e2a\u9876\u70b9\u51fa\u53d1\uff0cBFS \u751f\u6210\u6811\u7684\u9ad8\u5ea6\u4e0d\u4f1a\u5927\u4e8e DFS \u751f\u6210\u6811\u7684\u9ad8\u5ea6\u3002  </li> </ol>  \u7b54\u6848  \u5bf9\u3002  \u8003\u8651\u6839\u8282\u70b9\u5230 BFS \u751f\u6210\u6811\u6700\u6df1\u7684\u4e00\u4e2a\u8282\u70b9\u7684\u8def\u5f84\uff0c\u5219\u5728 DFS \u8fc7\u7a0b\u4e2d\uff0c\u8be5\u8282\u70b9\u5fc5\u7136\u662f\u4f18\u5148\u8bbf\u95ee\u7684\uff0c\u56e0\u6b64 DFS \u751f\u6210\u6811\u9ad8\u5ea6\u5fc5\u7136\u5927\u4e8e\u7b49\u4e8e BFS \u751f\u6210\u6811\u9ad8\u5ea6\u3002  <ol> <li>\u5229\u7528\u7b5b\u9009\u6cd5\u5bf9 n \u4e2a\u5173\u952e\u5b57\u8fdb\u884c\u5efa\u5806\u64cd\u4f5c\uff0c\u7b97\u6cd5\u590d\u6742\u5ea6\u4e3a O(n)\u3002  </li> </ol>  \u7b54\u6848  \u5bf9\u3002  \u53c2\u8003\uff1ahttps://oi-wiki.org/ds/binary-heap/#%E6%96%B9%E6%B3%95%E4%BA%8C%E4%BD%BF%E7%94%A8%E5%90%91%E4%B8%8B%E8%B0%83%E6%95%B4  <ol> <li>\u81f3\u5c11\u6709\u4e00\u4e2a\u9876\u70b9\u7684\u5ea6\u4e3a 1 \u7684\u65e0\u5411\u8fde\u901a\u56fe\u4e0d\u53ef\u80fd\u5305\u542b\u56de\u8def\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002 <pre><code>  A\n  |\n  B\n / \\\nC---D\n</code></pre>  \u5982\u56fe\u6240\u793a\u3002   <ol> <li>\u4e00\u4e2a\u65e0\u5411\u56fe\u7684\u8fde\u901a\u5206\u91cf\u662f\u5176\u6781\u5927\u7684\u8fde\u901a\u5b50\u56fe\u3002  </li> </ol>  \u7b54\u6848  \u5bf9\u3002 \u9996\u5148\u8fde\u901a\u5206\u91cf\u662f\u8fde\u901a\u7684\uff0c\u5176\u6b21\u8fde\u901a\u5206\u91cf\u7684\u7ed3\u70b9\u4e00\u5b9a\u5305\u542b\u5728\u56fe\u7684\u6240\u6709\u7ed3\u70b9\u91cc\u9762\uff0c\u6240\u4ee5\u662f\u8fde\u901a\u5b50\u56fe\u3002\u6700\u540e\u7531\u4e8e\u4e0d\u80fd\u518d\u5f80\u8fde\u901a\u5206\u91cf\u91cc\u9762\u518d\u6dfb\u52a0\u8fb9\uff0c\u56e0\u6b64\u662f\u6781\u5927\u7684\u8fde\u901a\u5b50\u56fe\u3002    <ol> <li>\u6392\u5e8f\u6240\u9700\u8981\u7684\u6240\u6709\u64cd\u4f5c\u90fd\u5728\u5916\u5b58\u4e2d\u5b8c\u6210\uff0c\u5219\u79f0\u4e4b\u4e3a\u5916\u6392\u5e8f\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u6559\u675011\u7ae0\u5bfc\u8bfb\u3002   <ol> <li>\u5728\u5bf9\u534a\u67e5\u627e\u7684\u4e8c\u53c9\u5224\u5b9a\u6811\u4e2d\uff0c\u5916\u90e8\u7ed3\u70b9\u53ea\u53ef\u80fd\u51fa\u73b0\u5728\u6700\u4e0b\u7684\u4e24\u5c42\u7ed3\u70b9\u4e2d\u3002  </li> </ol>  \u7b54\u6848  \u5bf9\u3002 <ol> <li>\u5b58\u5728\u4e00\u68f5\u603b\u5171\u6709 2016 \u4e2a\u7ed3\u70b9\u7684\u4e8c\u53c9\u6811\uff0c\u5176\u4e2d\u6709\u4e14\u4ec5\u6709 16 \u4e2a\u7ed3\u70b9\u53ea\u6709\u4e00\u4e2a\u5b69\u5b50\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002  \u8003\u8651\u8ba1\u7b97\u8fd9\u4e2a\u4e8c\u53c9\u6811\u7684\u603b\u7ed3\u70b9\u6570\uff1a\u603b\u7ed3\u70b9\u6570 = \u5ea6\u4e3a2\u7684\u8282\u70b9\u6570 * 2 + \u5ea6\u4e3a 1 \u7684\u8282\u70b9\u6570 + 1\uff08\u6839\u8282\u70b9\uff09\uff0c\u53ef\u89c1\u662f\u4e00\u4e2a\u5947\u6570\u3002\u56e0\u6b64\u4e0d\u80fd\u6784\u9020\u3002  <ol> <li>Floyd \u7b97\u6cd5\u6c42\u4e24\u4e2a\u9876\u70b9\u7684\u6700\u77ed\u8def\u5f84\u65f6\uff0cpath_{k-1} \u4e00\u5b9a\u662f path_k \u7684\u5b50\u96c6\u3002  </li> </ol>  \u7b54\u6848  \u9519\u3002 \u6559\u67508.5.3\u3002\u7ecf\u8fc7\u7ed3\u70b9 k-1 \u7684\u6700\u77ed\u8def\u957f\u5ea6\u53ef\u80fd\u88ab\u5f15\u5165\u7ed3\u70b9 k \u66f4\u65b0\u3002  <ol> <li>\u4e0d\u80fd\u5411\u9759\u6001\u67e5\u627e\u8868\u4e2d\u63d2\u5165\u65b0\u7684\u5143\u7d20\u3002</li> </ol>  \u7b54\u6848  \u5bf9\u3002 \u6559\u67509.1\u3002"}, {"location": "campus-sources/ds-write-up/#_13", "title": "\u7efc\u5408\u9898", "text": "<ol> <li>\u8bbe\u6709\u5982\u4e0b\u65e0\u5411\u56fe G\uff0c\u7ed9\u51fa\u8be5\u56fe\u7684\u6700\u5c0f\u751f\u6210\u6811\u4e0a\u8fb9\u7684\u96c6\u5408\u5e76\u8ba1\u7b97\u6700\u5c0f\u751f\u6210\u6811\u5404\u8fb9\u4e0a\u7684\u6743\u503c\u4e4b\u548c\u3002\uff088 \u5206\uff09</li> </ol>  \u7b54\u6848  <ol> <li>\u8bbe\u6709\u5982\u4e0b\u56fe\u6240\u793a\u7684 AOE \u7f51\uff08\u5176\u4e2d vi\uff08i=1\uff0c2\uff0c\u2026\uff0c6\uff09\u8868\u793a\u4e8b\u4ef6\uff0c\u8fb9\u4e0a\u8868\u793a\u6d3b\u52a8\u7684\u5929\u6570\uff09\u3002\uff085 \u5206\uff09</li> </ol> <p>\uff081\uff09\u627e\u51fa\u6240\u6709\u7684\u5173\u952e\u8def\u5f84\u3002</p> <p>\uff082\uff09v3 \u4e8b\u4ef6\u7684\u6700\u65e9\u5f00\u59cb\u65f6\u95f4\u662f\u591a\u5c11\u3002</p>  \u7b54\u6848  <p></p> <p></p> <ol> <li>\u8bd5\u5217\u51fa\u5982\u4e0b\u56fe\u4e2d\u5168\u90e8\u53ef\u80fd\u7684\u62d3\u6251\u6392\u5e8f\u5e8f\u5217\u3002\uff088\u5206\uff09</li> </ol>  \u7b54\u6848  <p></p> <p></p> <ol> <li>\u5df2\u77e5\u67d0\u6709\u5411\u56fe\u67095\u4e2a\u9876\u70b9\uff0c\u5404\u9876\u70b9\u7684\u5ea6\u4e4b\u548c\u4e3a14\u3002\u4e14\u6ee1\u8db3\u5982\u4e0b\u6761\u4ef6\uff1a (1)\u4ece\u9876\u70b9v0\u51fa\u53d1\u7684\u6df1\u5ea6\u4f18\u5148\u904d\u5386\u6b21\u5e8f\u4e0e\u5e7f\u5ea6\u4f18\u5148\u904d\u5386\u6b21\u5e8f\u76f8\u540c\u4e14\u552f\u4e00\uff0c\u662fv0,v3,v1,v4,v2\u3002 (2)\u5b58\u5728\u5165\u5ea6\u4e3a0\u7684\u9876\u70b9\uff0c\u4e5f\u5b58\u5728\u51fa\u5ea6\u4e3a0\u7684\u9876\u70b9\u3002 (3)\u56fe\u4e2d\u6709\u4e14\u4ec5\u6709\u4e00\u6761\u56de\u8def\uff0c\u5176\u8def\u5f84\u957f\u5ea6\u5927\u4e8e2\u3002 \u8bf7\u753b\u51fa\u8be5\u56fe\u5e76\u753b\u51fa\u8be5\u56fe\u7684\u90bb\u63a5\u8868\u3002\uff085\u5206\uff09  </li> </ol>  \u7b54\u6848  <p></p> <p></p>"}, {"location": "campus-sources/ds-write-up/#_14", "title": "\u7b97\u6cd5\u8bbe\u8ba1\u9898", "text": "<ol> <li>\u7ed9\u5b9a\u4e00\u68f5\u4e8c\u53c9\u6811\uff0c\u5224\u65ad\u8be5\u4e8c\u53c9\u6811\u5728\u7ed3\u6784\u4e0a\u662f\u5426\u5c5e\u4e8e\u5de6\u53f3\u5bf9\u79f0\u7684\u7ed3\u6784\u3002\u8981\u6c42\u7528\u9012\u5f52\u51fd\u6570\u5b9e\u73b0\uff0c\u4e14\u6709\u6700\u4f4e\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002  </li> </ol>  \u7b54\u6848   \u5bf9\u79f0\u7684\u610f\u601d\u5c31\u662f\uff0c\u5de6\u534a\u8fb9\u7684\u7ed3\u70b9\u8f74\u5bf9\u79f0\u8fc7\u6765\u5c31\u53d8\u6210\u4e86\u53f3\u534a\u8fb9\u3002\u4e5f\u5c31\u662f\u5916\u4fa7\u4e92\u76f8\u76f8\u7b49\uff0c\u5185\u4fa7\u4e5f\u4e92\u76f8\u76f8\u7b49\u3002  \u9898\u76ee\u6ca1\u6709\u7ed9\u51fa\u7ed3\u70b9\u7684\u6570\u636e\uff0c\u56e0\u6b64\u4ee3\u7801\u5b9e\u73b0\u53ea\u5224\u5b9a\u6811\u7684\u7ed3\u6784\u662f\u5426\u5bf9\u79f0\u3002  <pre><code>bool compare(BTNode* left, BTNode* right)\n{\n   if( (!left) ^ (!right)) return false;\n   if( !(left || right) ) return true;\n   return compare(left-&gt;lchild, right-&gt;rchild) &amp;&amp; compare(left-&gt;rchild, right-&gt;lchild);\n}\n\nbool is_symmetric(BTNode* root)\n{\n   return compare(root-&gt;lchild, root-&gt;rchild);\n}\n</code></pre> <ol> <li>\u7ed9\u5b9a\u4e00\u4e2a\u6b63\u6574\u6570\u6570\u7ec4 A\uff0c\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20 A[i]\u8868\u660e\u4ece\u5f53\u524d\u4f4d\u7f6e\u53ef\u4ee5\u5411\u53f3\u8de8\u8d8a\u7684\u8ddd\u79bb\uff08\u5373\u53ef\u4ee5\u5230\u8fbe\u4e0b\u6807 i+A[i]\uff09\u3002\u518d\u7ed9\u5b9a\u4e00\u4e2a\u6761\u4ef6\uff0c\u4e00\u4e2a\u4eba\u4ece\u5143\u7d20 A[i]\u53ef\u4ee5\u4e00\u6b65\u56de\u5230\u4efb\u610f\u7684 Aj\u3002\u5047\u5b9a\u4e00\u4e2a\u4eba\u4ece\u4e0b\u6807 0 \u51fa\u53d1\uff0c\u8bf7\u8bbe\u8ba1\u4e00\u4e2a\u7b97\u6cd5\u6c42\u51fa\u8be5\u4eba\u8d70\u51fa\u6570\u7ec4\u8303\u56f4.\uff08\u5230\u8fbe\u6570\u7ec4\u6700\u5927\u4e0b\u6807\u7684\u53f3\u8fb9\uff09\u6240\u9700\u8981\u7684\u6700\u5c0f\u6b65\u6570\uff0c\u5e76\u8f93\u51fa\u6bcf\u4e00\u6b65\u6240\u5728\u7684\u4e0b\u6807\u3002\u4f8b\u5982\uff1a</li> </ol> <p>\u8f93\u5165\uff1aA = [2,5,1,1,1,1]</p> <p>\u8f93\u51fa\uff1a3\uff0c0-&gt;2-&gt;1-&gt;6</p> <p>\u89e3\u91ca\uff1a\u6700\u5c11\u8981\u8d70 3 \u6b65\uff0c\u5c31\u53ef\u4ee5\u8df3\u79bb\u6570\u7ec4\u8303\u56f4\u3002\u4f9d\u6b21\u5230\u8fbe\u7684\u987a\u5e8f\u4e3a 0-&gt;2-&gt;1-&gt;6\uff0c6 \u5df2\u7ecf\u8131\u79bb\u4e86\u6700\u5927\u4e0b\u6807 5\u3002</p> <p>\u8981\u6c42\uff1a\u7528\u975e\u9012\u5f52\u65b9\u5f0f\u5b9e\u73b0\u7b97\u6cd5\uff0c\u4e14\u6709\u6700\u5c0f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002</p>  \u7b54\u6848  <p></p>  \u5047\u8bbe\u6570\u7ec4\u957f\u4e3a n\uff0c\u6211\u4eec\u628a\u95ee\u9898\u62bd\u8c61\u6210\u56fe\u4e2d\u7684\u6700\u77ed\u8def\u95ee\u9898\uff1a\u5bf9\u4f4d\u7f6e \\(i\\)\uff0c\u62bd\u8c61\u6210\u7ed3\u70b9 \\(i\\)\uff0c\u5219\u5b83\u53ef\u4ee5\u8bbf\u95ee\u7684\u7ed3\u70b9\u6709\uff1a\u7ed3\u70b9 \\(0\\) \u5230 \\(i-1\\)\uff0c\u4ee5\u53ca\u7ed3\u70b9 \\(i+A[i]\\)\u3002\u7531\u4e8e\u53ef\u80fd\u51fa\u73b0 \\( i+A[i] &gt; n\\)\uff0c\u6211\u4eec\u5b9a\u4e49\u7ed3\u70b9 \\(n\\) \u4e3a\u6c47\u70b9\uff0c\u4e5f\u5c31\u662f\u8df3\u51fa\u6570\u7ec4\u7684\u72b6\u6001\u3002\u7136\u540e\u8dd1\u4e00\u904d\u4ece\u7ed3\u70b9 \\(0\\) \u5230\u7ed3\u70b9 \\(n\\) \u7684 BFS \u5373\u53ef\u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u95ee\u9898\u4e0d\u5fc5\u771f\u7684\u5efa\u56fe\uff0c\u53ea\u9700\u8981 BFS \u904d\u5386\u7684\u65f6\u5019\u9009\u62e9\u5408\u9002\u7684\u7ed3\u70b9\u5373\u53ef\u3002\u540c\u65f6\u53e6\u5916\u5f00\u4e00\u4e2a fa \u6570\u7ec4\u8bb0\u5f55\u8def\u5f84\u8f6c\u79fb\u6765\u6e90\uff0c\u4ece\u6c47\u70b9\u5f80\u524d\u56de\u6eaf\u5230 BFS \u751f\u6210\u6811\u7684\u6839\u8282\u70b9\uff0c\u518d\u628a\u8fd9\u4e2a\u987a\u5e8f\u5012\u5e8f\u8f93\u51fa\u5373\u53ef\u83b7\u5f97\u8def\u5f84\u3002  <pre><code>int A[N], fa[N], vis[N], path[N];\nvoid bfs(int n)\n{\n   std::queue&lt;int&gt; q;\n   std::fill(vis, vis + N, 0);\n   q.push(0);\n   while(!q.empty())\n   {\n      int curr = q.front();\n      if(vis[curr]) continue;\n      vis[curr] = 1;\n      q.pop();\n      if(curr + A[curr] &gt; n)\n      {\n         fa[n] = curr;\n         break;\n      }\n      else\n      {\n         q.push(curr + A[curr]);\n         fa[curr + A[curr]] = curr;\n      }\n      for(int i = 0; i &lt; curr; ++i)\n         if(!vis[i])\n         {\n            q.push(i);\n            fa[i] = curr;\n         }\n   }\n}\n\nvoid solve(int n)\n{\n   bfs(n);\n   int cnt = 0, inx = n;\n   while(fa[idx])\n   {\n      path[cnt++] = idx;\n      idx = fa[idx];\n   }\n   std::cout &lt;&lt; cnt &lt;&lt; '\\n';\n   for(int i = cnt - 1; i &gt;= 0; --i)\n      std::cout &lt;&lt; path[i] &lt;&lt; ' ';\n}\n</code></pre> <p></p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Aug. 3, 2025). \u300a\u6570\u636e\u7ed3\u6784\u300b\u671f\u672b\u590d\u4e60\u9898\u9898\u89e3 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/ds-write-up</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{ds-write-up,\n    title={\u300a\u6570\u636e\u7ed3\u6784\u300b\u671f\u672b\u590d\u4e60\u9898\u9898\u89e3},\n    author={Yan Li},\n    year={2025},\n    month={Aug},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/ds-write-up}},\n}\n</code></pre></p>"}, {"location": "campus-sources/textbook/", "title": "\u672c\u79d1\u6559\u79d1\u4e66\u7535\u5b50\u8d44\u6e90", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 2 \u5206\u949f\u3000|\u3000\u7ea6 452 \u5b57\u3000|\u3000\u6ca1\u6709\u4ee3\u7801\uff0c\u8bf7\u653e\u5fc3\u98df\u7528</p> <p>\u672c\u6587\u4e3b\u8981\u7ed9\u51fa\u7b14\u8005\u672c\u79d1\u9636\u6bb5\u4f7f\u7528\u7684 pdf \u7535\u5b50\u7248\u6559\u6750\uff0c\u6309\u8bfe\u7a0b\u7ed9\u51fa\u3002</p> <p>\u90e8\u5206\u4e66\u76ee\u7531\u4e8e\u662f\u626b\u63cf\u7684 pdf \u6587\u6863\uff0c\u5c3a\u5bf8\u8f83\u5927\uff0c\u56e0\u6b64\u91c7\u7528\u4e86\u5206\u5377\u538b\u7f29\uff0c\u8bf7\u52a1\u5fc5\u5c06\u6bcf\u4e00\u4efd\u6587\u4ef6\u90fd\u4e0b\u8f7d\u4e0b\u6765\u3002\u5f53\u7136\uff0c\u4f60\u4e5f\u53ef\u4ee5\u9009\u62e9\u76f4\u63a5 clone \u8fd9\u4e2a Github \u4ed3\u5e93\u3002</p> <p>\uff08\u6b63\u5728\u65bd\u5de5\u4e2d\uff09</p>"}, {"location": "campus-sources/textbook/#_2", "title": "\u5927\u5b66\u7269\u7406\uff08\u5927\u7269\uff09", "text": "<p>\u5927\u5b66\u7269\u7406\u4e0b Note: \u8fd9\u672c\u4e66\u6392\u7248\u548c\u7eb8\u8d28\u5370\u5237\u7248\u4e0d\u540c\uff0c\u4f46\u662f\u5185\u5bb9\u662f\u4e00\u81f4\u7684\u3002</p>"}, {"location": "campus-sources/textbook/#_3", "title": "\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1\uff08\u6982\u7edf\uff09", "text": "<p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_00</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_01</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_02</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_03</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_04</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_05</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_06</p> <p>\u6982\u7387\u8bba\u4e0e\u6570\u7406\u7edf\u8ba1_07</p>"}, {"location": "campus-sources/textbook/#_4", "title": "\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\uff08\u8ba1\u7ec4\uff09", "text": "<p>\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406_00</p> <p>\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406_01</p> <p>\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406_02</p>"}, {"location": "campus-sources/textbook/#_5", "title": "\u79bb\u6563\u6570\u5b66\uff08\u79bb\u6563\uff09", "text": "<p>\u79bb\u6563\u6570\u5b66_00</p> <p>\u79bb\u6563\u6570\u5b66_01</p> <p>\u79bb\u6563\u6570\u5b66_02</p> <p>\u79bb\u6563\u6570\u5b66_03</p> <p>\ud83d\udcdd \u5982\u679c\u60a8\u9700\u8981\u5f15\u7528\u672c\u6587</p> <p>Yan Li. (Sep. 9, 2025). \u672c\u79d1\u6559\u79d1\u4e66\u7535\u5b50\u8d44\u6e90 [Blog post]. Retrieved from https://dicaeopolis.github.io/campus-sources/textbook</p> <p>\u5728 BibTeX \u683c\u5f0f\u4e2d\uff1a <pre><code>@online{textbook,\n    title={\u672c\u79d1\u6559\u79d1\u4e66\u7535\u5b50\u8d44\u6e90},\n    author={Yan Li},\n    year={2025},\n    month={Sep},\n    url={\\url{https://dicaeopolis.github.io/campus-sources/textbook}},\n}\n</code></pre></p>"}, {"location": "misc/", "title": "\u5173\u4e8e\u672c\u7c7b\u522b", "text": "<p>\u65e0\u3002</p>"}, {"location": "misc/test/", "title": "\u529f\u80fd\u6d4b\u8bd5\u9875\u9762", "text": "<p>\ud83d\udcd6 \u9605\u8bfb\u4fe1\u606f</p> <p>\u9605\u8bfb\u65f6\u95f4\u7ea6 1 \u5206\u949f\u3000|\u3000\u7ea6 13 \u5b57\u3000|\u3000\u7ea6 1 \u4e2a\u516c\u5f0f\u3000|\u3000\u7ea6 7 \u884c\u4ee3\u7801</p> <p>\u4ee3\u7801\u5757\uff1a</p> <pre><code>auto index = static_cast&lt;int&gt;(std::distance(vec.begin(), std::lower_bound(vec.begin(), vec.end(), val));\n</code></pre> <p>\u516c\u5f0f\uff1a</p> \\[ \\lim_{n\\rightarrow \\infty}\\sum^n_{i = 1}\\dfrac{1}{i^2} = \\dfrac{\\pi^2}{6} \\] <p>mermaid \u6846\u56fe\uff1a</p> <pre><code>graph TD;\n    A[\u5b89\u88c5 Mermaid \u63d2\u4ef6] --&gt; B{\u662f\u5426\u6e32\u67d3\u6b63\u786e};\n    B -- Yes --&gt; C[\u597d\u8036];\n    B -- No --&gt; D[\u574f\uff01];\n    C --&gt; E[\u884c\u5427];\n    D --&gt; E;</code></pre>"}]}