import re
import os
import json
from functools import lru_cache
from datetime import datetime

# --- è°ƒè¯•å¼€å…³ ---
# è¿™ä¸ªå…¨å±€å˜é‡ç¡®ä¿æˆ‘ä»¬åªæ‰“å°ä¸€æ¬¡æ‰€æœ‰å¯ç”¨çš„é”®ï¼Œé¿å…åˆ·å±
_TIMESTAMP_KEYS_PRINTED = False

# --- é…ç½® (ä¿æŒä¸å˜) ---
EXCLUDE_PATTERNS = [re.compile(r'^index\.md$'), re.compile(r'^about/'), re.compile(r'^trip/index\.md$'), re.compile(r'^relax/index\.md$'), re.compile(r'^blog/indexblog\.md$'), re.compile(r'^blog/posts\.md$'), re.compile(r'^develop/index\.md$'), re.compile(r'waline\.md$'), re.compile(r'link\.md$'), re.compile(r'404\.md$')]
CHINESE_CHARS_PATTERN = re.compile(r'[\u4e00-\u9fff\u3400-\u4dbf]')
CODE_BLOCK_PATTERN = re.compile(r'```.*?```', re.DOTALL)
EXCLUDE_TYPES = frozenset({'landing', 'special', 'widget'})

# --- æ ¸å¿ƒå‡½æ•° (åªå¢åŠ è°ƒè¯•) ---
@lru_cache(maxsize=256)
def extract_non_code_content(content_hash, markdown):
    return CODE_BLOCK_PATTERN.sub('', markdown)

def count_code_lines(markdown):
    code_blocks = CODE_BLOCK_PATTERN.findall(markdown)
    total_code_lines = 0
    for block in code_blocks:
        lines = block.split('\n')
        code_lines = [line for line in lines if not line.strip().startswith('```') and line.strip()]
        total_code_lines += len(code_lines)
    return total_code_lines

def calculate_reading_stats(markdown):
    content_hash = hash(markdown)
    non_code_content = extract_non_code_content(content_hash, markdown)
    chinese_chars = len(CHINESE_CHARS_PATTERN.findall(non_code_content))
    code_lines = count_code_lines(markdown)
    reading_time = max(1, round(chinese_chars / 200))
    return reading_time, chinese_chars, code_lines

# ###############################################################
# #               â†“ â†“ â†“ å”¯ä¸€ä¿®æ”¹çš„å‡½æ•°åœ¨è¿™é‡Œ â†“ â†“ â†“                 #
# ###############################################################

@lru_cache(maxsize=1)
def load_timestamps(docs_dir):
    """ã€è°ƒè¯•ç‰ˆæœ¬ã€‘åŠ è½½å¹¶ç¼“å­˜å”¯ä¸€çš„ timestamps.json æ–‡ä»¶"""
    timestamps_path = os.path.join(docs_dir, 'timestamps.json')
    if not os.path.exists(timestamps_path):
        print(f"--- [DEBUG] --- [!] load_timestamps: File NOT FOUND at '{timestamps_path}'")
        return None
    try:
        with open(timestamps_path, 'r', encoding='utf-8') as f:
            # print(f"--- [DEBUG] --- [+] load_timestamps: File found and loaded from '{timestamps_path}'")
            return json.load(f)
    except Exception as e:
        print(f"--- [DEBUG] --- [!] load_timestamps: EXCEPTION while reading file: {e}")
        return None

def get_git_revision_date(page, config):
    """ã€è°ƒè¯•ç‰ˆæœ¬ã€‘ä»å”¯ä¸€çš„ docs/timestamps.json ä¸­è·å–æ—¶é—´"""
    global _TIMESTAMP_KEYS_PRINTED
    from datetime import datetime

    print("\n--- [DEBUG] Entering get_git_revision_date ---")
    
    # 1. æ‰“å°æˆ‘ä»¬ç”¨æ¥æŸ¥æ‰¾çš„ KEY æ˜¯ä»€ä¹ˆ
    relative_path_key = page.file.src_path.replace(os.path.sep, '/')
    print(f"[*] Page being processed: '{page.title}' (from file: {page.file.src_path})")
    print(f"[*] Generated lookup KEY: '{relative_path_key}'")

    # 2. åŠ è½½æ•°æ®
    docs_dir = config['docs_dir']
    timestamps = load_timestamps(docs_dir)
    
    if timestamps is None:
        print("[!] FAILURE: timestamps.json could not be loaded or was not found. Aborting lookup.")
        print("--- [DEBUG] Exiting ---\n")
        return None

    # 3. æ‰“å° JSON æ–‡ä»¶ä¸­æ‰€æœ‰å¯ç”¨çš„ KEY (åªæ‰“å°ä¸€æ¬¡)
    if not _TIMESTAMP_KEYS_PRINTED:
        print("[*] All available KEYS in timestamps.json (first 20 shown):")
        # åªæ˜¾ç¤ºå‰20ä¸ªï¼Œé¿å…åˆ·å±
        print(sorted(list(timestamps.keys()))[:20])
        print(f"    ... (total {len(timestamps.keys())} keys)")
        _TIMESTAMP_KEYS_PRINTED = True

    # 4. è¿›è¡ŒæŸ¥æ‰¾å¹¶æŠ¥å‘Šç»“æœ
    if relative_path_key in timestamps:
        timestamp_value = timestamps[relative_path_key]
        print(f"[+] SUCCESS: Key '{relative_path_key}' found!")
        print("--- [DEBUG] Exiting ---\n")
        return datetime.fromtimestamp(timestamp_value)
    else:
        print(f"[!] FAILURE: Key '{relative_path_key}' was NOT FOUND in the available keys.")
        print("--- [DEBUG] Exiting ---\n")
        return None
        
# ###############################################################
# #               â†‘ â†‘ â†‘ å”¯ä¸€çš„ä¿®æ”¹åˆ°æ­¤ä¸ºæ­¢ â†‘ â†‘ â†‘                     #
# ###############################################################


def get_file_modification_time(page, config):
    last_modified = get_git_revision_date(page, config)
    if not last_modified:
        file_path = page.file.abs_src_path
        if os.path.exists(file_path):
            mtime = os.path.getmtime(file_path)
            last_modified = datetime.fromtimestamp(mtime)
    if not last_modified:
        last_modified = datetime.now()
    return last_modified, bool(last_modified)

def generate_citation(page, config):
    title = page.meta.get('title', page.title)
    author = 'Yan Li'
    mod_time, state = get_file_modification_time(page, config)
    year = mod_time.year
    month_en = mod_time.strftime('%b')
    day = mod_time.day
    date_display = f"{month_en}. {day}, {year}"
    site_url = 'https://dicaeopolis.github.io/'.rstrip('/')
    page_url = page.url.rstrip('/')
    full_url = f"{site_url}/{page_url}"
    page_id = page_url.split('/')[-1] or 'index'
    citation = f"""
!!! info "ğŸ“ å¦‚æœæ‚¨éœ€è¦å¼•ç”¨æœ¬æ–‡"
    {author}. ({date_display}). {title} [Blog post]. Retrieved from {full_url}

    åœ¨ BibTeX æ ¼å¼ä¸­ï¼š
    ```text
    @online{{{page_id},
        title={{{title}}},
        author={{{author}}},
        year={{{year}}},
        month={{{month_en}}},
        url={{\\url{{{full_url}}}}},
    }}
    ```
"""
    return citation

def on_page_markdown(markdown, **kwargs):
    page = kwargs['page']
    config = kwargs['config']
    if page.meta.get('hide_reading_time', False): return markdown
    src_path = page.file.src_path
    for pattern in EXCLUDE_PATTERNS:
        if pattern.match(src_path): return markdown
    page_type = page.meta.get('type', '')
    if page_type in EXCLUDE_TYPES: return markdown
    if len(markdown) < 300: return markdown
    reading_time, chinese_chars, code_lines = calculate_reading_stats(markdown)
    creation_statement = page.meta.get('statement', '')
    no_info = page.meta.get('noinfo', '')
    reading_info = f"""!!! info "ğŸ“– é˜…è¯»ä¿¡æ¯"
    é˜…è¯»æ—¶é—´çº¦ **{reading_time}** åˆ†é’Ÿã€€|ã€€çº¦ **{chinese_chars}** å­—"""
    if chinese_chars > 10000: reading_info += f"""ã€€âš ï¸ ä¸‡å­—é•¿æ–‡ï¼Œè¯·æ…¢æ…¢é˜…è¯»"""
    if code_lines > 0: reading_info += f"""ã€€|ã€€çº¦ **{code_lines}** è¡Œä»£ç 

"""
    else: reading_info += f"""ã€€|ã€€æ²¡æœ‰ä»£ç ï¼Œè¯·æ”¾å¿ƒé£Ÿç”¨

"""
    if creation_statement: reading_info += f"    åˆ›ä½œå£°æ˜ï¼š{creation_statement}\n\n"
    if no_info: reading_info = ""
    pattern = r'(^# .*\n)'
    if re.search(pattern, markdown, flags=re.MULTILINE): markdown = re.sub(pattern, r'\1' + reading_info, markdown, count=1, flags=re.MULTILINE)
    else: markdown = reading_info + markdown
    if chinese_chars < 50: return markdown
    if not page.meta.get('hide_citation', False): markdown += generate_citation(page, config)
    return markdown